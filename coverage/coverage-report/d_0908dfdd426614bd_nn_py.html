<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>Coverage for fluid\contrib\layers\nn.py: 10%</title>
    <link rel="icon" sizes="32x32" href="favicon_32.png">
    <link rel="stylesheet" href="style.css" type="text/css">
    <script type="text/javascript" src="coverage_html.js" defer></script>
</head>
<body class="pyfile">
<header>
    <div class="content">
        <h1>
            <span class="text">Coverage for </span><b>fluid\contrib\layers\nn.py</b>:
            <span class="pc_cov">10%</span>
        </h1>
        <aside id="help_panel_wrapper">
            <input id="help_panel_state" type="checkbox">
            <label for="help_panel_state">
                <img id="keyboard_icon" src="keybd_closed.png" alt="Show/hide keyboard shortcuts" />
            </label>
            <div id="help_panel">
                <p class="legend">Shortcuts on this page</p>
                <div class="keyhelp">
                    <p>
                        <kbd>r</kbd>
                        <kbd>m</kbd>
                        <kbd>x</kbd>
                        <kbd>p</kbd>
                        &nbsp; toggle line displays
                    </p>
                    <p>
                        <kbd>j</kbd>
                        <kbd>k</kbd>
                        &nbsp; next/prev highlighted chunk
                    </p>
                    <p>
                        <kbd>0</kbd> &nbsp; (zero) top of page
                    </p>
                    <p>
                        <kbd>1</kbd> &nbsp; (one) first highlighted chunk
                    </p>
                    <p>
                        <kbd>[</kbd>
                        <kbd>]</kbd>
                        &nbsp; prev/next file
                    </p>
                    <p>
                        <kbd>u</kbd> &nbsp; up to the index
                    </p>
                    <p>
                        <kbd>?</kbd> &nbsp; show/hide this help
                    </p>
                </div>
            </div>
        </aside>
        <h2>
            <span class="text">353 statements &nbsp;</span>
            <button type="button" class="run button_toggle_run" value="run" data-shortcut="r" title="Toggle lines run">42<span class="text"> run</span></button>
            <button type="button" class="mis show_mis button_toggle_mis" value="mis" data-shortcut="m" title="Toggle lines missing">311<span class="text"> missing</span></button>
            <button type="button" class="exc show_exc button_toggle_exc" value="exc" data-shortcut="x" title="Toggle lines excluded">1<span class="text"> excluded</span></button>
            <button type="button" class="par run show_par button_toggle_par" value="par" data-shortcut="p" title="Toggle lines partially run">0<span class="text"> partial</span></button>
        </h2>
        <p class="text">
            <a id="prevFileLink" class="nav" href="d_0908dfdd426614bd_metric_op_py.html">&#xab; prev</a> &nbsp; &nbsp;
            <a id="indexLink" class="nav" href="index.html">&Hat; index</a> &nbsp; &nbsp;
            <a id="nextFileLink" class="nav" href="d_0908dfdd426614bd_rnn_impl_py.html">&#xbb; next</a>
            &nbsp; &nbsp; &nbsp;
            <a class="nav" href="https://coverage.readthedocs.io/en/7.2.4">coverage.py v7.2.4</a>,
            created at 2023-05-05 05:16 -0500
        </p>
        <aside class="hidden">
            <button type="button" class="button_next_chunk" data-shortcut="j"/>
            <button type="button" class="button_prev_chunk" data-shortcut="k"/>
            <button type="button" class="button_top_of_page" data-shortcut="0"/>
            <button type="button" class="button_first_chunk" data-shortcut="1"/>
            <button type="button" class="button_prev_file" data-shortcut="["/>
            <button type="button" class="button_next_file" data-shortcut="]"/>
            <button type="button" class="button_to_index" data-shortcut="u"/>
            <button type="button" class="button_show_hide_help" data-shortcut="?"/>
        </aside>
    </div>
</header>
<main id="source">
    <p class="pln"><span class="n"><a id="t1" href="#t1">1</a></span><span class="t"><span class="com"># Copyright (c) 2022 PaddlePaddle Authors. All Rights Reserved.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2" href="#t2">2</a></span><span class="t"><span class="com">#</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3" href="#t3">3</a></span><span class="t"><span class="com"># Licensed under the Apache License, Version 2.0 (the "License");</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4" href="#t4">4</a></span><span class="t"><span class="com"># you may not use this file except in compliance with the License.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5" href="#t5">5</a></span><span class="t"><span class="com"># You may obtain a copy of the License at</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6" href="#t6">6</a></span><span class="t"><span class="com">#</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7" href="#t7">7</a></span><span class="t"><span class="com">#     http://www.apache.org/licenses/LICENSE-2.0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8" href="#t8">8</a></span><span class="t"><span class="com">#</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9" href="#t9">9</a></span><span class="t"><span class="com"># Unless required by applicable law or agreed to in writing, software</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10" href="#t10">10</a></span><span class="t"><span class="com"># distributed under the License is distributed on an "AS IS" BASIS,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11" href="#t11">11</a></span><span class="t"><span class="com"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12" href="#t12">12</a></span><span class="t"><span class="com"># See the License for the specific language governing permissions and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13" href="#t13">13</a></span><span class="t"><span class="com"># limitations under the License.</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14" href="#t14">14</a></span><span class="t"><span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15" href="#t15">15</a></span><span class="t"><span class="str">Contrib layers just related to the neural network.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16" href="#t16">16</a></span><span class="t"><span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t17" href="#t17">17</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t18" href="#t18">18</a></span><span class="t"><span class="key">from</span> <span class="nam">__future__</span> <span class="key">import</span> <span class="nam">print_function</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t19" href="#t19">19</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t20" href="#t20">20</a></span><span class="t"><span class="key">import</span> <span class="nam">os</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t21" href="#t21">21</a></span><span class="t"><span class="key">import</span> <span class="nam">six</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t22" href="#t22">22</a></span><span class="t"><span class="key">import</span> <span class="nam">warnings</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t23" href="#t23">23</a></span><span class="t"><span class="key">import</span> <span class="nam">inspect</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t24" href="#t24">24</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t25" href="#t25">25</a></span><span class="t"><span class="key">import</span> <span class="nam">numpy</span> <span class="key">as</span> <span class="nam">np</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t26" href="#t26">26</a></span><span class="t"><span class="key">import</span> <span class="nam">paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t27" href="#t27">27</a></span><span class="t"><span class="key">from</span> <span class="nam">paddle</span><span class="op">.</span><span class="nam">fluid</span><span class="op">.</span><span class="nam">layer_helper</span> <span class="key">import</span> <span class="nam">LayerHelper</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t28" href="#t28">28</a></span><span class="t"><span class="key">from</span> <span class="nam">paddle</span><span class="op">.</span><span class="nam">fluid</span><span class="op">.</span><span class="nam">layers</span> <span class="key">import</span> <span class="nam">utils</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t29" href="#t29">29</a></span><span class="t"><span class="key">from</span> <span class="op">...</span> <span class="key">import</span> <span class="nam">unique_name</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t30" href="#t30">30</a></span><span class="t"><span class="key">from</span> <span class="nam">paddle</span><span class="op">.</span><span class="nam">fluid</span><span class="op">.</span><span class="nam">initializer</span> <span class="key">import</span> <span class="nam">Normal</span><span class="op">,</span> <span class="nam">Constant</span><span class="op">,</span> <span class="nam">NumpyArrayInitializer</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t31" href="#t31">31</a></span><span class="t"><span class="key">from</span> <span class="nam">paddle</span><span class="op">.</span><span class="nam">fluid</span><span class="op">.</span><span class="nam">data_feeder</span> <span class="key">import</span> <span class="nam">check_variable_and_dtype</span><span class="op">,</span> <span class="nam">check_type</span><span class="op">,</span> <span class="nam">check_dtype</span><span class="op">,</span> <span class="nam">convert_dtype</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t32" href="#t32">32</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t33" href="#t33">33</a></span><span class="t"><span class="key">from</span> <span class="nam">paddle</span><span class="op">.</span><span class="nam">fluid</span> <span class="key">import</span> <span class="nam">core</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t34" href="#t34">34</a></span><span class="t"><span class="key">from</span> <span class="nam">paddle</span><span class="op">.</span><span class="nam">fluid</span><span class="op">.</span><span class="nam">param_attr</span> <span class="key">import</span> <span class="nam">ParamAttr</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t35" href="#t35">35</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t36" href="#t36">36</a></span><span class="t"><span class="key">from</span> <span class="nam">paddle</span><span class="op">.</span><span class="nam">fluid</span><span class="op">.</span><span class="nam">framework</span> <span class="key">import</span> <span class="nam">Variable</span><span class="op">,</span> <span class="nam">convert_np_dtype_to_dtype_</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t37" href="#t37">37</a></span><span class="t"><span class="key">from</span> <span class="nam">paddle</span><span class="op">.</span><span class="nam">fluid</span><span class="op">.</span><span class="nam">layers</span> <span class="key">import</span> <span class="nam">slice</span><span class="op">,</span> <span class="nam">reshape</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t38" href="#t38">38</a></span><span class="t"><span class="key">import</span> <span class="nam">warnings</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t39" href="#t39">39</a></span><span class="t"><span class="key">from</span> <span class="nam">paddle</span> <span class="key">import</span> <span class="nam">_C_ops</span><span class="op">,</span> <span class="nam">_legacy_C_ops</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t40" href="#t40">40</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t41" href="#t41">41</a></span><span class="t"><span class="nam">__all__</span> <span class="op">=</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t42" href="#t42">42</a></span><span class="t">    <span class="str">'fused_elemwise_activation'</span><span class="op">,</span> <span class="str">'sequence_topk_avg_pooling'</span><span class="op">,</span> <span class="str">'var_conv_2d'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t43" href="#t43">43</a></span><span class="t">    <span class="str">'match_matrix_tensor'</span><span class="op">,</span> <span class="str">'tree_conv'</span><span class="op">,</span> <span class="str">'fused_embedding_seq_pool'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t44" href="#t44">44</a></span><span class="t">    <span class="str">'multiclass_nms2'</span><span class="op">,</span> <span class="str">'search_pyramid_hash'</span><span class="op">,</span> <span class="str">'shuffle_batch'</span><span class="op">,</span> <span class="str">'partial_concat'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t45" href="#t45">45</a></span><span class="t">    <span class="str">'sparse_embedding'</span><span class="op">,</span> <span class="str">'partial_sum'</span><span class="op">,</span> <span class="str">'tdm_child'</span><span class="op">,</span> <span class="str">'rank_attention'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t46" href="#t46">46</a></span><span class="t">    <span class="str">'tdm_sampler'</span><span class="op">,</span> <span class="str">'batch_fc'</span><span class="op">,</span> <span class="str">'_pull_box_extended_sparse'</span><span class="op">,</span> <span class="str">'bilateral_slice'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t47" href="#t47">47</a></span><span class="t">    <span class="str">'correlation'</span><span class="op">,</span> <span class="str">'fused_bn_add_act'</span><span class="op">,</span> <span class="str">'fused_seqpool_cvm'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t48" href="#t48">48</a></span><span class="t"><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t49" href="#t49">49</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t50" href="#t50">50</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t51" href="#t51">51</a></span><span class="t"><span class="key">def</span> <span class="nam">fused_elemwise_activation</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t52" href="#t52">52</a></span><span class="t">                              <span class="nam">y</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t53" href="#t53">53</a></span><span class="t">                              <span class="nam">functor_list</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t54" href="#t54">54</a></span><span class="t">                              <span class="nam">axis</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t55" href="#t55">55</a></span><span class="t">                              <span class="nam">scale</span><span class="op">=</span><span class="num">0.0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t56" href="#t56">56</a></span><span class="t">                              <span class="nam">save_intermediate_out</span><span class="op">=</span><span class="key">True</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t57" href="#t57">57</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t58" href="#t58">58</a></span><span class="t"><span class="str">    **Fused elementwise_add/mul and activation layers**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t59" href="#t59">59</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t60" href="#t60">60</a></span><span class="t"><span class="str">    This function computes an elementwise_add/mul cooperated with an activation.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t61" href="#t61">61</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t62" href="#t62">62</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t63" href="#t63">63</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t64" href="#t64">64</a></span><span class="t"><span class="str">        out = Unary(Binary(x, y))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t65" href="#t65">65</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t66" href="#t66">66</a></span><span class="t"><span class="str">    or</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t67" href="#t67">67</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t68" href="#t68">68</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t69" href="#t69">69</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t70" href="#t70">70</a></span><span class="t"><span class="str">        out = Binary(x, Unary(y))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t71" href="#t71">71</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t72" href="#t72">72</a></span><span class="t"><span class="str">    Unary operators can be: `scale`, `relu`, `tanh`. Binary operators can be:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t73" href="#t73">73</a></span><span class="t"><span class="str">    `elementwise_add`, `elementwise_mul`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t74" href="#t74">74</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t75" href="#t75">75</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t76" href="#t76">76</a></span><span class="t"><span class="str">        x (Variable): left operation of the binary operator.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t77" href="#t77">77</a></span><span class="t"><span class="str">        y (Variable): right operator of the binary operator.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t78" href="#t78">78</a></span><span class="t"><span class="str">        functor_list (list of str): types of operator which will be executed</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t79" href="#t79">79</a></span><span class="t"><span class="str">            by this layer. For example, ['elementwise_add', 'relu']</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t80" href="#t80">80</a></span><span class="t"><span class="str">            (out = elementwise_add(x, relu(y))),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t81" href="#t81">81</a></span><span class="t"><span class="str">            or ['relu', 'elemmentwise_add'] (out = relu(elementwise_add(x, y))).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t82" href="#t82">82</a></span><span class="t"><span class="str">        axis (int32, default -1): axis of elementwise op.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t83" href="#t83">83</a></span><span class="t"><span class="str">        scale (float32, default 0): parameter of scale op.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t84" href="#t84">84</a></span><span class="t"><span class="str">        save_intermediate_out (bool, default True): whether to save the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t85" href="#t85">85</a></span><span class="t"><span class="str">            intermediate result, Unary(y) or Binary(x, y).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t86" href="#t86">86</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t87" href="#t87">87</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t88" href="#t88">88</a></span><span class="t"><span class="str">        Variable: The computation result.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t89" href="#t89">89</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t90" href="#t90">90</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">functor_list</span><span class="op">,</span> <span class="nam">str</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t91" href="#t91">91</a></span><span class="t">        <span class="nam">functor_list</span> <span class="op">=</span> <span class="nam">functor_list</span><span class="op">.</span><span class="nam">split</span><span class="op">(</span><span class="str">','</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t92" href="#t92">92</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t93" href="#t93">93</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">functor_list</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span> <span class="key">or</span> <span class="nam">len</span><span class="op">(</span><span class="nam">functor_list</span><span class="op">)</span> <span class="op">!=</span> <span class="num">2</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t94" href="#t94">94</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t95" href="#t95">95</a></span><span class="t">            <span class="str">'functor_list should be a list of str, and the length should be 2.'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t96" href="#t96">96</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t97" href="#t97">97</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'fused_elemwise_activation'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t98" href="#t98">98</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t99" href="#t99">99</a></span><span class="t">    <span class="nam">intermediate_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t100" href="#t100">100</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">'fused_elemwise_activation'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t101" href="#t101">101</a></span><span class="t">                     <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t102" href="#t102">102</a></span><span class="t">                         <span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t103" href="#t103">103</a></span><span class="t">                         <span class="str">'Y'</span><span class="op">:</span> <span class="nam">y</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t104" href="#t104">104</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t105" href="#t105">105</a></span><span class="t">                     <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t106" href="#t106">106</a></span><span class="t">                         <span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t107" href="#t107">107</a></span><span class="t">                         <span class="str">'IntermediateOut'</span><span class="op">:</span> <span class="nam">intermediate_out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t108" href="#t108">108</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t109" href="#t109">109</a></span><span class="t">                     <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t110" href="#t110">110</a></span><span class="t">                         <span class="str">'axis'</span><span class="op">:</span> <span class="nam">axis</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t111" href="#t111">111</a></span><span class="t">                         <span class="str">'scale'</span><span class="op">:</span> <span class="nam">scale</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t112" href="#t112">112</a></span><span class="t">                         <span class="str">'save_intermediate_out'</span><span class="op">:</span> <span class="nam">save_intermediate_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t113" href="#t113">113</a></span><span class="t">                         <span class="str">'functor_list'</span><span class="op">:</span> <span class="nam">functor_list</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t114" href="#t114">114</a></span><span class="t">                     <span class="op">}</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t115" href="#t115">115</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t116" href="#t116">116</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t117" href="#t117">117</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t118" href="#t118">118</a></span><span class="t"><span class="key">def</span> <span class="nam">var_conv_2d</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t119" href="#t119">119</a></span><span class="t">                <span class="nam">row</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t120" href="#t120">120</a></span><span class="t">                <span class="nam">col</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t121" href="#t121">121</a></span><span class="t">                <span class="nam">input_channel</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t122" href="#t122">122</a></span><span class="t">                <span class="nam">output_channel</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t123" href="#t123">123</a></span><span class="t">                <span class="nam">filter_size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t124" href="#t124">124</a></span><span class="t">                <span class="nam">stride</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t125" href="#t125">125</a></span><span class="t">                <span class="nam">param_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t126" href="#t126">126</a></span><span class="t">                <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t127" href="#t127">127</a></span><span class="t">                <span class="nam">dtype</span><span class="op">=</span><span class="str">'float32'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t128" href="#t128">128</a></span><span class="t">                <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t129" href="#t129">129</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t130" href="#t130">130</a></span><span class="t"><span class="str">    The var_conv_2d layer calculates the output base on the :attr:`input` with variable length,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t131" href="#t131">131</a></span><span class="t"><span class="str">    row, col, input channel, filter size and strides. Both :attr:`input`, :attr:`row`,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t132" href="#t132">132</a></span><span class="t"><span class="str">    and :attr:`col` are 1-level LodTensor. The convolution operation is same as conv2d layer with</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t133" href="#t133">133</a></span><span class="t"><span class="str">    padding. Besides, input.dims[1] should be 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t134" href="#t134">134</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t135" href="#t135">135</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t136" href="#t136">136</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t137" href="#t137">137</a></span><span class="t"><span class="str">            If input_channel is 2 and given row lodTensor and col lodTensor as follows:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t138" href="#t138">138</a></span><span class="t"><span class="str">                row.lod = [[5, 4]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t139" href="#t139">139</a></span><span class="t"><span class="str">                col.lod = [[6, 7]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t140" href="#t140">140</a></span><span class="t"><span class="str">            input is a lodTensor:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t141" href="#t141">141</a></span><span class="t"><span class="str">                input.lod = [[60, 56]]  # where 60 = input_channel * 5 * 6</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t142" href="#t142">142</a></span><span class="t"><span class="str">                input.dims = [116, 1]   # where 116 = 60 + 56</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t143" href="#t143">143</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t144" href="#t144">144</a></span><span class="t"><span class="str">            If set output_channel is 3, filter_size is [3, 3], stride is [1, 1]:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t145" href="#t145">145</a></span><span class="t"><span class="str">                # where 90 = output_channel * [(5-1)/stride + 1] * [(6-1)/stride + 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t146" href="#t146">146</a></span><span class="t"><span class="str">                output.lod = [[90, 84]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t147" href="#t147">147</a></span><span class="t"><span class="str">                output.dims = [174, 1]  # where 174 = 90 + 84</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t148" href="#t148">148</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t149" href="#t149">149</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t150" href="#t150">150</a></span><span class="t"><span class="str">        input (Variable): The input should be 1-level LodTensor with dims[1] equals 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t151" href="#t151">151</a></span><span class="t"><span class="str">        row (Variable): The row should be 1-level LodTensor to provide height information.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t152" href="#t152">152</a></span><span class="t"><span class="str">        col (Variable): The col should be 1-level LodTensor to provide width information.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t153" href="#t153">153</a></span><span class="t"><span class="str">        input_channel (int): The number of input channel.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t154" href="#t154">154</a></span><span class="t"><span class="str">        output_channel (int): The number of output channel.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t155" href="#t155">155</a></span><span class="t"><span class="str">        filter_size (int|tuple|None): The filter size. If filter_size is a tuple,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t156" href="#t156">156</a></span><span class="t"><span class="str">            it must contain two integers, (filter_size_H, filter_size_W).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t157" href="#t157">157</a></span><span class="t"><span class="str">            Otherwise, the filter will be a square.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t158" href="#t158">158</a></span><span class="t"><span class="str">        stride (int|tuple): The stride size. If stride is a tuple, it must</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t159" href="#t159">159</a></span><span class="t"><span class="str">            contain two integers, (stride_H, stride_W). Otherwise, the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t160" href="#t160">160</a></span><span class="t"><span class="str">            stride_H = stride_W = stride. Default: stride = 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t161" href="#t161">161</a></span><span class="t"><span class="str">        param_attr (ParamAttr|None): The parameter attribute for learnable parameters/weights</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t162" href="#t162">162</a></span><span class="t"><span class="str">            of var_conv2d. If it is set to None or one attribute of ParamAttr, var_conv2d</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t163" href="#t163">163</a></span><span class="t"><span class="str">            will create ParamAttr as param_attr. If the Initializer of the param_attr</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t164" href="#t164">164</a></span><span class="t"><span class="str">            is not set, the parameter is initialized with :math:`Normal(0.0, std)`,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t165" href="#t165">165</a></span><span class="t"><span class="str">            and the :math:`std` is :math:`(\\frac{2.0 }{filter\_elem\_num})^{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t166" href="#t166">166</a></span><span class="t"><span class="str">  0.5}`. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t167" href="#t167">167</a></span><span class="t"><span class="str">        act (str): Activation type, if it is set to None, activation is not appended.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t168" href="#t168">168</a></span><span class="t"><span class="str">            Default: None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t169" href="#t169">169</a></span><span class="t"><span class="str">        dtype ('float32'): The data type of parameter and output.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t170" href="#t170">170</a></span><span class="t"><span class="str">        name (str|None): A name for this layer(optional). If set None, the layer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t171" href="#t171">171</a></span><span class="t"><span class="str">            will be named automatically. Default: None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t172" href="#t172">172</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t173" href="#t173">173</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t174" href="#t174">174</a></span><span class="t"><span class="str">        Variable: Output variable with LoD specified by this layer.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t175" href="#t175">175</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t176" href="#t176">176</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t177" href="#t177">177</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t178" href="#t178">178</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t179" href="#t179">179</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t180" href="#t180">180</a></span><span class="t"><span class="str">            from paddle.fluid import layers</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t181" href="#t181">181</a></span><span class="t"><span class="str">            from paddle.fluid import contrib</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t182" href="#t182">182</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t183" href="#t183">183</a></span><span class="t"><span class="str">            x_lod_tensor = layers.data(name='x', shape=[1], lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t184" href="#t184">184</a></span><span class="t"><span class="str">            row_lod_tensor = layers.data(name='row', shape=[6], lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t185" href="#t185">185</a></span><span class="t"><span class="str">            col_lod_tensor = layers.data(name='col', shape=[6], lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t186" href="#t186">186</a></span><span class="t"><span class="str">            out = contrib.var_conv_2d(input=x_lod_tensor,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t187" href="#t187">187</a></span><span class="t"><span class="str">                                     row=row_lod_tensor,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t188" href="#t188">188</a></span><span class="t"><span class="str">                                     col=col_lod_tensor,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t189" href="#t189">189</a></span><span class="t"><span class="str">                                     input_channel=3,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t190" href="#t190">190</a></span><span class="t"><span class="str">                                     output_channel=5,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t191" href="#t191">191</a></span><span class="t"><span class="str">                                     filter_size=[3, 3],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t192" href="#t192">192</a></span><span class="t"><span class="str">                                     stride=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t193" href="#t193">193</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t194" href="#t194">194</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'var_conv_2d'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t195" href="#t195">195</a></span><span class="t">    <span class="nam">x_shape</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t196" href="#t196">196</a></span><span class="t">    <span class="key">assert</span> <span class="nam">len</span><span class="op">(</span><span class="nam">x_shape</span><span class="op">)</span> <span class="op">==</span> <span class="num">2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t197" href="#t197">197</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t198" href="#t198">198</a></span><span class="t">    <span class="nam">filter_size</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">filter_size</span><span class="op">,</span> <span class="num">2</span><span class="op">,</span> <span class="str">'filter_size'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t199" href="#t199">199</a></span><span class="t">    <span class="nam">stride</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">stride</span><span class="op">,</span> <span class="num">2</span><span class="op">,</span> <span class="str">'stride'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t200" href="#t200">200</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t201" href="#t201">201</a></span><span class="t">    <span class="nam">filter_shape</span> <span class="op">=</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t202" href="#t202">202</a></span><span class="t">        <span class="nam">int</span><span class="op">(</span><span class="nam">output_channel</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t203" href="#t203">203</a></span><span class="t">        <span class="nam">int</span><span class="op">(</span><span class="nam">input_channel</span><span class="op">)</span> <span class="op">*</span> <span class="nam">filter_size</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">*</span> <span class="nam">filter_size</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t204" href="#t204">204</a></span><span class="t">    <span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t205" href="#t205">205</a></span><span class="t">    <span class="nam">filter_param</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t206" href="#t206">206</a></span><span class="t">        <span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">param_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t207" href="#t207">207</a></span><span class="t">        <span class="nam">shape</span><span class="op">=</span><span class="nam">filter_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t208" href="#t208">208</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t209" href="#t209">209</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t210" href="#t210">210</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t211" href="#t211">211</a></span><span class="t">    <span class="nam">conv_res</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t212" href="#t212">212</a></span><span class="t">    <span class="nam">tmp_res</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t213" href="#t213">213</a></span><span class="t">                                                        <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t214" href="#t214">214</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t215" href="#t215">215</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">'var_conv_2d'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t216" href="#t216">216</a></span><span class="t">                     <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t217" href="#t217">217</a></span><span class="t">                         <span class="str">'X'</span><span class="op">:</span> <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t218" href="#t218">218</a></span><span class="t">                         <span class="str">'ROW'</span><span class="op">:</span> <span class="nam">row</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t219" href="#t219">219</a></span><span class="t">                         <span class="str">'COLUMN'</span><span class="op">:</span> <span class="nam">col</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t220" href="#t220">220</a></span><span class="t">                         <span class="str">'W'</span><span class="op">:</span> <span class="nam">filter_param</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t221" href="#t221">221</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t222" href="#t222">222</a></span><span class="t">                     <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t223" href="#t223">223</a></span><span class="t">                         <span class="str">"Out"</span><span class="op">:</span> <span class="nam">conv_res</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t224" href="#t224">224</a></span><span class="t">                         <span class="str">"Col"</span><span class="op">:</span> <span class="nam">tmp_res</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t225" href="#t225">225</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t226" href="#t226">226</a></span><span class="t">                     <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t227" href="#t227">227</a></span><span class="t">                         <span class="str">'InputChannel'</span><span class="op">:</span> <span class="nam">input_channel</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t228" href="#t228">228</a></span><span class="t">                         <span class="str">'OutputChannel'</span><span class="op">:</span> <span class="nam">output_channel</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t229" href="#t229">229</a></span><span class="t">                         <span class="str">'StrideH'</span><span class="op">:</span> <span class="nam">stride</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t230" href="#t230">230</a></span><span class="t">                         <span class="str">'StrideW'</span><span class="op">:</span> <span class="nam">stride</span><span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t231" href="#t231">231</a></span><span class="t">                         <span class="str">'KernelH'</span><span class="op">:</span> <span class="nam">filter_size</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t232" href="#t232">232</a></span><span class="t">                         <span class="str">'KernelW'</span><span class="op">:</span> <span class="nam">filter_size</span><span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t233" href="#t233">233</a></span><span class="t">                     <span class="op">}</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t234" href="#t234">234</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t235" href="#t235">235</a></span><span class="t">    <span class="key">return</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_activation</span><span class="op">(</span><span class="nam">conv_res</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t236" href="#t236">236</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t237" href="#t237">237</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t238" href="#t238">238</a></span><span class="t"><span class="key">def</span> <span class="nam">match_matrix_tensor</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t239" href="#t239">239</a></span><span class="t">                        <span class="nam">y</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t240" href="#t240">240</a></span><span class="t">                        <span class="nam">channel_num</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t241" href="#t241">241</a></span><span class="t">                        <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t242" href="#t242">242</a></span><span class="t">                        <span class="nam">param_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t243" href="#t243">243</a></span><span class="t">                        <span class="nam">dtype</span><span class="op">=</span><span class="str">'float32'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t244" href="#t244">244</a></span><span class="t">                        <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t245" href="#t245">245</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t246" href="#t246">246</a></span><span class="t"><span class="str">    Calculate the semantic matching matrix of two word sequences with variable length.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t247" href="#t247">247</a></span><span class="t"><span class="str">    Given a query A of length `n` and a title B of length `m`, the input shape are respectively</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t248" href="#t248">248</a></span><span class="t"><span class="str">    [n, h] and [m, h], which h is hidden_size. If :attr:`channel_num` is set to 3,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t249" href="#t249">249</a></span><span class="t"><span class="str">    it will generate a learnable parameter matrix W with shape [h, 3, h].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t250" href="#t250">250</a></span><span class="t"><span class="str">    Then the semantic matching matrix of query A and title B is calculated by</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t251" href="#t251">251</a></span><span class="t"><span class="str">    A * W * B.T = [n, h]*[h, 3, h]*[h, m] = [n, 3, m]. The learnable parameter matrix `W`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t252" href="#t252">252</a></span><span class="t"><span class="str">    is equivalent to a fully connected layer in the calculation process. If :attr:`act` is provided,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t253" href="#t253">253</a></span><span class="t"><span class="str">    the corresponding activation function will be applied to output matrix.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t254" href="#t254">254</a></span><span class="t"><span class="str">    The :attr:`x` and :attr:`y` should be LodTensor and only one level LoD is supported.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t255" href="#t255">255</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t256" href="#t256">256</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t257" href="#t257">257</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t258" href="#t258">258</a></span><span class="t"><span class="str">            Given a 1-level LoDTensor x:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t259" href="#t259">259</a></span><span class="t"><span class="str">                x.lod =  [</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t260" href="#t260">260</a></span><span class="t"><span class="str">                    [2,                     3,                               ]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t261" href="#t261">261</a></span><span class="t"><span class="str">                x.data = [[0.3, 0.1], [0.2, 0.3], [</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t262" href="#t262">262</a></span><span class="t"><span class="str">                    0.5, 0.6], [0.7, 0.1], [0.3, 0.4]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t263" href="#t263">263</a></span><span class="t"><span class="str">                x.dims = [5, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t264" href="#t264">264</a></span><span class="t"><span class="str">            y is a Tensor:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t265" href="#t265">265</a></span><span class="t"><span class="str">                y.lod =  [[3,                                 1,       ]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t266" href="#t266">266</a></span><span class="t"><span class="str">                y.data = [[0.1, 0.2], [0.3, 0.7], [0.9, 0.2], [0.4, 0.1]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t267" href="#t267">267</a></span><span class="t"><span class="str">                y.dims = [4, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t268" href="#t268">268</a></span><span class="t"><span class="str">            set channel_num 2, then we get a 1-level LoDTensor:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t269" href="#t269">269</a></span><span class="t"><span class="str">                # where 12 = channel_num * x.lod[0][0] * y.lod[0][0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t270" href="#t270">270</a></span><span class="t"><span class="str">                out.lod =  [[12, 6]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t271" href="#t271">271</a></span><span class="t"><span class="str">                out.dims = [18, 1]     # where 18 = 12 + 6</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t272" href="#t272">272</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t273" href="#t273">273</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t274" href="#t274">274</a></span><span class="t"><span class="str">        x (Variable): Input variable x which should be 1-level LodTensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t275" href="#t275">275</a></span><span class="t"><span class="str">        y (Variable): Input variable y which should be 1-level LodTensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t276" href="#t276">276</a></span><span class="t"><span class="str">        channel_num (int): The channel number of learnable parameter W.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t277" href="#t277">277</a></span><span class="t"><span class="str">        act (str, default None): Activation to be applied to the output of this layer.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t278" href="#t278">278</a></span><span class="t"><span class="str">        param_attr (ParamAttr|list of ParamAttr, default None): The parameter attribute for learnable</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t279" href="#t279">279</a></span><span class="t"><span class="str">            parameters/weights of this layer.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t280" href="#t280">280</a></span><span class="t"><span class="str">        dtype ('float32'): The data type of w data.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t281" href="#t281">281</a></span><span class="t"><span class="str">        name (str|None): A name for this layer(optional). If set None, the layer will be named automatically. Default: None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t282" href="#t282">282</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t283" href="#t283">283</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t284" href="#t284">284</a></span><span class="t"><span class="str">        Variable: output with LoD specified by this layer.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t285" href="#t285">285</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t286" href="#t286">286</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t287" href="#t287">287</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t288" href="#t288">288</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t289" href="#t289">289</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t290" href="#t290">290</a></span><span class="t"><span class="str">            from paddle.fluid import layers</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t291" href="#t291">291</a></span><span class="t"><span class="str">            from paddle.fluid import contrib</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t292" href="#t292">292</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t293" href="#t293">293</a></span><span class="t"><span class="str">            x_lod_tensor = layers.data(name='x', shape=[10], lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t294" href="#t294">294</a></span><span class="t"><span class="str">            y_lod_tensor = layers.data(name='y', shape=[10], lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t295" href="#t295">295</a></span><span class="t"><span class="str">            out, out_tmp = contrib.match_matrix_tensor(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t296" href="#t296">296</a></span><span class="t"><span class="str">                x=x_lod_tensor, y=y_lod_tensor, channel_num=3)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t297" href="#t297">297</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t298" href="#t298">298</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'match_matrix_tensor'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t299" href="#t299">299</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t300" href="#t300">300</a></span><span class="t">    <span class="nam">x_shape</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t301" href="#t301">301</a></span><span class="t">    <span class="nam">y_shape</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="nam">y</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t302" href="#t302">302</a></span><span class="t">    <span class="key">assert</span> <span class="nam">len</span><span class="op">(</span><span class="nam">x_shape</span><span class="op">)</span> <span class="op">==</span> <span class="num">2</span> <span class="key">and</span> <span class="nam">len</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t303" href="#t303">303</a></span><span class="t">        <span class="nam">y_shape</span><span class="op">)</span> <span class="op">==</span> <span class="num">2</span> <span class="key">and</span> <span class="nam">x_shape</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span> <span class="op">==</span> <span class="nam">y_shape</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t304" href="#t304">304</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t305" href="#t305">305</a></span><span class="t">    <span class="nam">weight_shape</span> <span class="op">=</span> <span class="op">[</span><span class="nam">x_shape</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span><span class="op">,</span> <span class="nam">channel_num</span><span class="op">,</span> <span class="nam">y_shape</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t306" href="#t306">306</a></span><span class="t">    <span class="nam">w</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span><span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">param_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t307" href="#t307">307</a></span><span class="t">                                <span class="nam">shape</span><span class="op">=</span><span class="nam">weight_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t308" href="#t308">308</a></span><span class="t">                                <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t309" href="#t309">309</a></span><span class="t">                                <span class="nam">is_bias</span><span class="op">=</span><span class="key">False</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t310" href="#t310">310</a></span><span class="t">    <span class="nam">mm_res</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t311" href="#t311">311</a></span><span class="t">    <span class="nam">tmp_res</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t312" href="#t312">312</a></span><span class="t">                                                        <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t313" href="#t313">313</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">'match_matrix_tensor'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t314" href="#t314">314</a></span><span class="t">                     <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t315" href="#t315">315</a></span><span class="t">                         <span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t316" href="#t316">316</a></span><span class="t">                         <span class="str">'Y'</span><span class="op">:</span> <span class="nam">y</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t317" href="#t317">317</a></span><span class="t">                         <span class="str">'W'</span><span class="op">:</span> <span class="nam">w</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t318" href="#t318">318</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t319" href="#t319">319</a></span><span class="t">                     <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t320" href="#t320">320</a></span><span class="t">                         <span class="str">"Out"</span><span class="op">:</span> <span class="nam">mm_res</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t321" href="#t321">321</a></span><span class="t">                         <span class="str">"Tmp"</span><span class="op">:</span> <span class="nam">tmp_res</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t322" href="#t322">322</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t323" href="#t323">323</a></span><span class="t">                     <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'dim_t'</span><span class="op">:</span> <span class="nam">channel_num</span><span class="op">}</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t324" href="#t324">324</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t325" href="#t325">325</a></span><span class="t">    <span class="key">return</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_activation</span><span class="op">(</span><span class="nam">mm_res</span><span class="op">)</span><span class="op">,</span> <span class="nam">tmp_res</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t326" href="#t326">326</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t327" href="#t327">327</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t328" href="#t328">328</a></span><span class="t"><span class="key">def</span> <span class="nam">sequence_topk_avg_pooling</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">row</span><span class="op">,</span> <span class="nam">col</span><span class="op">,</span> <span class="nam">topks</span><span class="op">,</span> <span class="nam">channel_num</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t329" href="#t329">329</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t330" href="#t330">330</a></span><span class="t"><span class="str">    The :attr:`topks` is a list with incremental values in this function. For each topk,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t331" href="#t331">331</a></span><span class="t"><span class="str">    it will average the topk features as an output feature for each channel of every</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t332" href="#t332">332</a></span><span class="t"><span class="str">    input sequence. Both :attr:`row` and :attr:`col` are LodTensor, which provide height</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t333" href="#t333">333</a></span><span class="t"><span class="str">    and width information for :attr:`input` tensor. If feature size of input sequence is less</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t334" href="#t334">334</a></span><span class="t"><span class="str">    than topk, it will padding 0 at the back.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t335" href="#t335">335</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t336" href="#t336">336</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t337" href="#t337">337</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t338" href="#t338">338</a></span><span class="t"><span class="str">            If channel_num is 2 and given row LoDTensor and col LoDTensor as follows:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t339" href="#t339">339</a></span><span class="t"><span class="str">                row.lod = [[5, 4]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t340" href="#t340">340</a></span><span class="t"><span class="str">                col.lod = [[6, 7]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t341" href="#t341">341</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t342" href="#t342">342</a></span><span class="t"><span class="str">            input is a LoDTensor with input.lod[0][i] = channel_num * row.lod[0][i] * col.lod[0][i]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t343" href="#t343">343</a></span><span class="t"><span class="str">                input.lod = [[60, 56]]  # where 60 = channel_num * 5 * 6</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t344" href="#t344">344</a></span><span class="t"><span class="str">                input.dims = [116, 1]   # where 116 = 60 + 56</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t345" href="#t345">345</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t346" href="#t346">346</a></span><span class="t"><span class="str">            If topks is [1, 3, 5], then we get a 1-level LoDTensor:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t347" href="#t347">347</a></span><span class="t"><span class="str">                out.lod =  [[5, 4]]     # share Lod info with row LodTensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t348" href="#t348">348</a></span><span class="t"><span class="str">                out.dims = [9, 6]       # where 6 = len(topks) * channel_num</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t349" href="#t349">349</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t350" href="#t350">350</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t351" href="#t351">351</a></span><span class="t"><span class="str">        input (Variable): The input should be 2D LodTensor with dims[1] equals 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t352" href="#t352">352</a></span><span class="t"><span class="str">        row (Variable): The row should be 1-level LodTensor to provide the height information</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t353" href="#t353">353</a></span><span class="t"><span class="str">                        of the input tensor data.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t354" href="#t354">354</a></span><span class="t"><span class="str">        col (Variable): The col should be 1-level LodTensor to provide the width information</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t355" href="#t355">355</a></span><span class="t"><span class="str">                        of the input tensor data.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t356" href="#t356">356</a></span><span class="t"><span class="str">        topks (list): A list of incremental value to average the topk feature.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t357" href="#t357">357</a></span><span class="t"><span class="str">        channel_num (int): The number of input channel.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t358" href="#t358">358</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t359" href="#t359">359</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t360" href="#t360">360</a></span><span class="t"><span class="str">        Variable: output LodTensor specified by this layer.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t361" href="#t361">361</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t362" href="#t362">362</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t363" href="#t363">363</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t364" href="#t364">364</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t365" href="#t365">365</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t366" href="#t366">366</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t367" href="#t367">367</a></span><span class="t"><span class="str">            from paddle.fluid import layers</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t368" href="#t368">368</a></span><span class="t"><span class="str">            from paddle.fluid import contrib</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t369" href="#t369">369</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t370" href="#t370">370</a></span><span class="t"><span class="str">            x_lod_tensor = layers.data(name='x', shape=[1], lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t371" href="#t371">371</a></span><span class="t"><span class="str">            row_lod_tensor = layers.data(name='row', shape=[6], lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t372" href="#t372">372</a></span><span class="t"><span class="str">            col_lod_tensor = layers.data(name='col', shape=[6], lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t373" href="#t373">373</a></span><span class="t"><span class="str">            out = contrib.sequence_topk_avg_pooling(input=x_lod_tensor,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t374" href="#t374">374</a></span><span class="t"><span class="str">                                                   row=row_lod_tensor,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t375" href="#t375">375</a></span><span class="t"><span class="str">                                                   col=col_lod_tensor,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t376" href="#t376">376</a></span><span class="t"><span class="str">                                                   topks=[1, 3, 5],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t377" href="#t377">377</a></span><span class="t"><span class="str">                                                   channel_num=5)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t378" href="#t378">378</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t379" href="#t379">379</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'sequence_topk_avg_pooling'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t380" href="#t380">380</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t381" href="#t381">381</a></span><span class="t">    <span class="nam">pos</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t382" href="#t382">382</a></span><span class="t">                                                    <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t383" href="#t383">383</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">'sequence_topk_avg_pooling'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t384" href="#t384">384</a></span><span class="t">                     <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t385" href="#t385">385</a></span><span class="t">                         <span class="str">'X'</span><span class="op">:</span> <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t386" href="#t386">386</a></span><span class="t">                         <span class="str">'ROW'</span><span class="op">:</span> <span class="nam">row</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t387" href="#t387">387</a></span><span class="t">                         <span class="str">'COLUMN'</span><span class="op">:</span> <span class="nam">col</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t388" href="#t388">388</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t389" href="#t389">389</a></span><span class="t">                     <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t390" href="#t390">390</a></span><span class="t">                         <span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t391" href="#t391">391</a></span><span class="t">                         <span class="str">'pos'</span><span class="op">:</span> <span class="nam">pos</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t392" href="#t392">392</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t393" href="#t393">393</a></span><span class="t">                     <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t394" href="#t394">394</a></span><span class="t">                         <span class="str">'topks'</span><span class="op">:</span> <span class="nam">topks</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t395" href="#t395">395</a></span><span class="t">                         <span class="str">'channel_num'</span><span class="op">:</span> <span class="nam">channel_num</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t396" href="#t396">396</a></span><span class="t">                     <span class="op">}</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t397" href="#t397">397</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t398" href="#t398">398</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t399" href="#t399">399</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t400" href="#t400">400</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t401" href="#t401">401</a></span><span class="t"><span class="key">def</span> <span class="nam">tree_conv</span><span class="op">(</span><span class="nam">nodes_vector</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t402" href="#t402">402</a></span><span class="t">              <span class="nam">edge_set</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t403" href="#t403">403</a></span><span class="t">              <span class="nam">output_size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t404" href="#t404">404</a></span><span class="t">              <span class="nam">num_filters</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t405" href="#t405">405</a></span><span class="t">              <span class="nam">max_depth</span><span class="op">=</span><span class="num">2</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t406" href="#t406">406</a></span><span class="t">              <span class="nam">act</span><span class="op">=</span><span class="str">'tanh'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t407" href="#t407">407</a></span><span class="t">              <span class="nam">param_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t408" href="#t408">408</a></span><span class="t">              <span class="nam">bias_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t409" href="#t409">409</a></span><span class="t">              <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t410" href="#t410">410</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t411" href="#t411">411</a></span><span class="t"><span class="str">    ${comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t412" href="#t412">412</a></span><span class="t"><span class="str">Args : nodes_vector(${nodes_vector_type}) : $ { nodes_vector_comment }</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t413" href="#t413">413</a></span><span class="t"><span class="str">edge_set(${edge_set_type}) : $ { edge_set_comment }</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t414" href="#t414">414</a></span><span class="t"><span class="str">        output_size(int): output feature width</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t415" href="#t415">415</a></span><span class="t"><span class="str">        num_filters(int): number of filters, Default 1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t416" href="#t416">416</a></span><span class="t"><span class="str">        max_depth(int): max depth of filters, Default 2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t417" href="#t417">417</a></span><span class="t"><span class="str">        act(str): activation function, Default tanh</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t418" href="#t418">418</a></span><span class="t"><span class="str">        param_attr(ParamAttr): the parameter attribute for the filters, Default None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t419" href="#t419">419</a></span><span class="t"><span class="str">        bias_attr(ParamAttr): the parameter attribute for the bias of this layer, Default None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t420" href="#t420">420</a></span><span class="t"><span class="str">        name(str): a name of this layer(optional). If set None, the layer will be named automatically, Default None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t421" href="#t421">421</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t422" href="#t422">422</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t423" href="#t423">423</a></span><span class="t"><span class="str">        out(${out_type}): ${</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t424" href="#t424">424</a></span><span class="t"><span class="str">          out_comment</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t425" href="#t425">425</a></span><span class="t"><span class="str">        }</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t426" href="#t426">426</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t427" href="#t427">427</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t428" href="#t428">428</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t429" href="#t429">429</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t430" href="#t430">430</a></span><span class="t"><span class="str">          import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t431" href="#t431">431</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t432" href="#t432">432</a></span><span class="t"><span class="str">          # 10 for max_node_size of dataset, 5 for vector width</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t433" href="#t433">433</a></span><span class="t"><span class="str">          nodes_vector = fluid.layers.data(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t434" href="#t434">434</a></span><span class="t"><span class="str">              name='vectors', shape=[10, 5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t435" href="#t435">435</a></span><span class="t"><span class="str">          # 10 for max_node_size of dataset, 2 for every edge has two nodes</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t436" href="#t436">436</a></span><span class="t"><span class="str">          # edges must be directional</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t437" href="#t437">437</a></span><span class="t"><span class="str">          edge_set = fluid.layers.data(name='edge_set', shape=[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t438" href="#t438">438</a></span><span class="t"><span class="str">                                       10, 2], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t439" href="#t439">439</a></span><span class="t"><span class="str">          # the shape of output will be [10, 6, 1],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t440" href="#t440">440</a></span><span class="t"><span class="str">          # 10 for max_node_size of dataset, 6 for output size, 1 for 1 filter</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t441" href="#t441">441</a></span><span class="t"><span class="str">          out_vector = fluid.layers.tree_conv(nodes_vector, edge_set, 6, 1, 2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t442" href="#t442">442</a></span><span class="t"><span class="str">#After reshape, output tensor could be nodes_vector for next tree convolution</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t443" href="#t443">443</a></span><span class="t"><span class="str">          out_vector = fluid.layers.reshape(out_vector, shape=[-1, 10, 6])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t444" href="#t444">444</a></span><span class="t"><span class="str">          out_vector_2 = fluid.layers.tree_conv(out_vector, edge_set, 3, 4, 2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t445" href="#t445">445</a></span><span class="t"><span class="str">#also output tensor could be pooling(the pooling in paper called global pooling)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t446" href="#t446">446</a></span><span class="t"><span class="str">          pooled = fluid.layers.reduce_max(out_vector, dim=2) # global pooling</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t447" href="#t447">447</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t448" href="#t448">448</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">nodes_vector</span><span class="op">,</span> <span class="str">'nodes_vector'</span><span class="op">,</span> <span class="op">(</span><span class="nam">Variable</span><span class="op">)</span><span class="op">,</span> <span class="str">'tree_conv'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t449" href="#t449">449</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">edge_set</span><span class="op">,</span> <span class="str">'edge_set'</span><span class="op">,</span> <span class="op">(</span><span class="nam">Variable</span><span class="op">)</span><span class="op">,</span> <span class="str">'tree_conv'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t450" href="#t450">450</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t451" href="#t451">451</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"tree_conv"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t452" href="#t452">452</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="str">'nodes_vector'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t453" href="#t453">453</a></span><span class="t">    <span class="nam">feature_size</span> <span class="op">=</span> <span class="nam">nodes_vector</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">2</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t454" href="#t454">454</a></span><span class="t">    <span class="nam">W_shape</span> <span class="op">=</span> <span class="op">[</span><span class="nam">feature_size</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="nam">output_size</span><span class="op">,</span> <span class="nam">num_filters</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t455" href="#t455">455</a></span><span class="t">    <span class="nam">W</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span><span class="nam">attr</span><span class="op">=</span><span class="nam">param_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t456" href="#t456">456</a></span><span class="t">                                <span class="nam">shape</span><span class="op">=</span><span class="nam">W_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t457" href="#t457">457</a></span><span class="t">                                <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t458" href="#t458">458</a></span><span class="t">                                <span class="nam">is_bias</span><span class="op">=</span><span class="key">False</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t459" href="#t459">459</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t460" href="#t460">460</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">'tree_conv'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t461" href="#t461">461</a></span><span class="t">                     <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t462" href="#t462">462</a></span><span class="t">                         <span class="str">'NodesVector'</span><span class="op">:</span> <span class="nam">nodes_vector</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t463" href="#t463">463</a></span><span class="t">                         <span class="str">'EdgeSet'</span><span class="op">:</span> <span class="nam">edge_set</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t464" href="#t464">464</a></span><span class="t">                         <span class="str">'Filter'</span><span class="op">:</span> <span class="nam">W</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t465" href="#t465">465</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t466" href="#t466">466</a></span><span class="t">                     <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t467" href="#t467">467</a></span><span class="t">                         <span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t468" href="#t468">468</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t469" href="#t469">469</a></span><span class="t">                     <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'max_depth'</span><span class="op">:</span> <span class="nam">max_depth</span><span class="op">}</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t470" href="#t470">470</a></span><span class="t">    <span class="key">if</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">bias_attr</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t471" href="#t471">471</a></span><span class="t">        <span class="nam">pre_activation</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_bias_op</span><span class="op">(</span><span class="nam">out</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t472" href="#t472">472</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t473" href="#t473">473</a></span><span class="t">        <span class="nam">pre_activation</span> <span class="op">=</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t474" href="#t474">474</a></span><span class="t">    <span class="key">return</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_activation</span><span class="op">(</span><span class="nam">pre_activation</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t475" href="#t475">475</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t476" href="#t476">476</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t477" href="#t477">477</a></span><span class="t"><span class="key">def</span> <span class="nam">fused_embedding_seq_pool</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t478" href="#t478">478</a></span><span class="t">                             <span class="nam">size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t479" href="#t479">479</a></span><span class="t">                             <span class="nam">is_sparse</span><span class="op">=</span><span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t480" href="#t480">480</a></span><span class="t">                             <span class="nam">padding_idx</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t481" href="#t481">481</a></span><span class="t">                             <span class="nam">combiner</span><span class="op">=</span><span class="str">'sum'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t482" href="#t482">482</a></span><span class="t">                             <span class="nam">param_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t483" href="#t483">483</a></span><span class="t">                             <span class="nam">dtype</span><span class="op">=</span><span class="str">'float32'</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t484" href="#t484">484</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t485" href="#t485">485</a></span><span class="t"><span class="str">    **Embedding Sequence pool**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t486" href="#t486">486</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t487" href="#t487">487</a></span><span class="t"><span class="str">    This layer is the fusion of lookup table and sequence_pool.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t488" href="#t488">488</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t489" href="#t489">489</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t490" href="#t490">490</a></span><span class="t"><span class="str">        input (Variable): Input is a Tensor&lt;int64> Variable, which contains the IDs' information.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t491" href="#t491">491</a></span><span class="t"><span class="str">            The value of the input IDs should satisfy :math:`0&lt;= id &lt; size[0]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t492" href="#t492">492</a></span><span class="t"><span class="str">        size (tuple|list): The shape of the lookup_table parameter. It should</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t493" href="#t493">493</a></span><span class="t"><span class="str">            have two elements which indicate the size of the dictionary of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t494" href="#t494">494</a></span><span class="t"><span class="str">            embedding and the size of each embedding vector respectively.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t495" href="#t495">495</a></span><span class="t"><span class="str">        is_sparse (bool): The flag indicating whether to use sparse update.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t496" href="#t496">496</a></span><span class="t"><span class="str">            Default: False.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t497" href="#t497">497</a></span><span class="t"><span class="str">        padding_idx (int|long|None): It will output all-zero padding data whenever</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t498" href="#t498">498</a></span><span class="t"><span class="str">            lookup encounters :math:`padding\_idx` in Ids. If set :attr:`None`, it makes</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t499" href="#t499">499</a></span><span class="t"><span class="str">            no effect to output. If :math:`padding\_idx &lt; 0`, the :math:`padding\_idx`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t500" href="#t500">500</a></span><span class="t"><span class="str">            will automatically be converted to :math:`size[0] + padding\_idx` to use.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t501" href="#t501">501</a></span><span class="t"><span class="str">            Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t502" href="#t502">502</a></span><span class="t"><span class="str">        combiner (str): The pooling type of sequence_pool, and only support `sum`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t503" href="#t503">503</a></span><span class="t"><span class="str">            Default: sum.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t504" href="#t504">504</a></span><span class="t"><span class="str">        param_attr (ParamAttr): Parameters for this layer.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t505" href="#t505">505</a></span><span class="t"><span class="str">        dtype (np.dtype|core.VarDesc.VarType|str): The dtype refers to the data type of output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t506" href="#t506">506</a></span><span class="t"><span class="str">            tensor. It can be float32, float_16, int etc.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t507" href="#t507">507</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t508" href="#t508">508</a></span><span class="t"><span class="str">        The sequence pooling variable which is a Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t509" href="#t509">509</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t510" href="#t510">510</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t511" href="#t511">511</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t512" href="#t512">512</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t513" href="#t513">513</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t514" href="#t514">514</a></span><span class="t"><span class="str">            dict_size = 20</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t515" href="#t515">515</a></span><span class="t"><span class="str">            data_t = fluid.layers.data(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t516" href="#t516">516</a></span><span class="t"><span class="str">                name='word', shape=[1], dtype='int64', lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t517" href="#t517">517</a></span><span class="t"><span class="str">            padding_idx = np.random.randint(1, 10)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t518" href="#t518">518</a></span><span class="t"><span class="str">            out = fluid.contrib.fused_embedding_seq_pool(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t519" href="#t519">519</a></span><span class="t"><span class="str">                input=data_t,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t520" href="#t520">520</a></span><span class="t"><span class="str">                size=[dict_size, 32],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t521" href="#t521">521</a></span><span class="t"><span class="str">                param_attr='w',</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t522" href="#t522">522</a></span><span class="t"><span class="str">                padding_idx=padding_idx,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t523" href="#t523">523</a></span><span class="t"><span class="str">                is_sparse=False)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t524" href="#t524">524</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t525" href="#t525">525</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'fused_embedding_seq_pool'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t526" href="#t526">526</a></span><span class="t">    <span class="nam">w</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span><span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">param_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t527" href="#t527">527</a></span><span class="t">                                <span class="nam">shape</span><span class="op">=</span><span class="nam">size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t528" href="#t528">528</a></span><span class="t">                                <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t529" href="#t529">529</a></span><span class="t">                                <span class="nam">is_bias</span><span class="op">=</span><span class="key">False</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t530" href="#t530">530</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t531" href="#t531">531</a></span><span class="t">    <span class="nam">padding_idx</span> <span class="op">=</span> <span class="op">-</span><span class="num">1</span> <span class="key">if</span> <span class="nam">padding_idx</span> <span class="key">is</span> <span class="key">None</span> <span class="key">else</span> <span class="nam">padding_idx</span> <span class="key">if</span> <span class="nam">padding_idx</span> <span class="op">>=</span> <span class="num">0</span> <span class="key">else</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t532" href="#t532">532</a></span><span class="t">        <span class="nam">size</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">+</span> <span class="nam">padding_idx</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t533" href="#t533">533</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">'fused_embedding_seq_pool'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t534" href="#t534">534</a></span><span class="t">                     <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t535" href="#t535">535</a></span><span class="t">                         <span class="str">'Ids'</span><span class="op">:</span> <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t536" href="#t536">536</a></span><span class="t">                         <span class="str">'W'</span><span class="op">:</span> <span class="nam">w</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t537" href="#t537">537</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t538" href="#t538">538</a></span><span class="t">                     <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t539" href="#t539">539</a></span><span class="t">                     <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t540" href="#t540">540</a></span><span class="t">                         <span class="str">'is_sparse'</span><span class="op">:</span> <span class="nam">is_sparse</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t541" href="#t541">541</a></span><span class="t">                         <span class="str">'combiner'</span><span class="op">:</span> <span class="nam">combiner</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t542" href="#t542">542</a></span><span class="t">                         <span class="str">'padding_idx'</span><span class="op">:</span> <span class="nam">padding_idx</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t543" href="#t543">543</a></span><span class="t">                     <span class="op">}</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t544" href="#t544">544</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t545" href="#t545">545</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t546" href="#t546">546</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t547" href="#t547">547</a></span><span class="t"><span class="key">def</span> <span class="nam">fused_seqpool_cvm</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t548" href="#t548">548</a></span><span class="t">                      <span class="nam">pool_type</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t549" href="#t549">549</a></span><span class="t">                      <span class="nam">cvm</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t550" href="#t550">550</a></span><span class="t">                      <span class="nam">pad_value</span><span class="op">=</span><span class="num">0.0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t551" href="#t551">551</a></span><span class="t">                      <span class="nam">use_cvm</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t552" href="#t552">552</a></span><span class="t">                      <span class="nam">cvm_offset</span><span class="op">=</span><span class="num">2</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t553" href="#t553">553</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t554" href="#t554">554</a></span><span class="t"><span class="str">    :api_attr: Static Graph</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t555" href="#t555">555</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t556" href="#t556">556</a></span><span class="t"><span class="str">    This OP is the fusion of sequence_pool and continuous_value_model op.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t557" href="#t557">557</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t558" href="#t558">558</a></span><span class="t"><span class="str">    **Note:** The Op only receives List of LoDTensor as input, only support SUM pooling now.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t559" href="#t559">559</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t560" href="#t560">560</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t561" href="#t561">561</a></span><span class="t"><span class="str">        input(Variable|list of Variable): Input is List of LoDTensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t562" href="#t562">562</a></span><span class="t"><span class="str">        pool_type(str): pooling type, only support SUM pooling now.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t563" href="#t563">563</a></span><span class="t"><span class="str">        cvm(Variable): cvm Variable.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t564" href="#t564">564</a></span><span class="t"><span class="str">        pad_value(float, optional): padding value of sequence pool. Default: 0.0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t565" href="#t565">565</a></span><span class="t"><span class="str">        use_cvm(bool, optional): use cvm or not. Default: True.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t566" href="#t566">566</a></span><span class="t"><span class="str">        cvm_offset(int, optional): cvm offset. Default: 2, which means cvm contains show, click.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t567" href="#t567">567</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t568" href="#t568">568</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t569" href="#t569">569</a></span><span class="t"><span class="str">        Variable|list of Variable: The tensor variable storing sequence pool and cvm</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t570" href="#t570">570</a></span><span class="t"><span class="str">        of input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t571" href="#t571">571</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t572" href="#t572">572</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t573" href="#t573">573</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t574" href="#t574">574</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t575" href="#t575">575</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t576" href="#t576">576</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t577" href="#t577">577</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t578" href="#t578">578</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t579" href="#t579">579</a></span><span class="t"><span class="str">            data = paddle.static.data(name='x', shape=[-1, 1], dtype='int64', lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t580" href="#t580">580</a></span><span class="t"><span class="str">            data2 = paddle.static.data(name='y', shape=[-1, 1], dtype='int64', lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t581" href="#t581">581</a></span><span class="t"><span class="str">            inputs = [data, data2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t582" href="#t582">582</a></span><span class="t"><span class="str">            embs = fluid.layers.nn._pull_box_sparse(input=inputs, size=11, is_distributed=True, is_sparse=True)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t583" href="#t583">583</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t584" href="#t584">584</a></span><span class="t"><span class="str">            label = paddle.static.data(name="label", shape=[-1, 1], dtype="int64", lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t585" href="#t585">585</a></span><span class="t"><span class="str">            ones = fluid.layers.fill_constant_batch_size_like(input=label, shape=[-1, 1], dtype="int64", value=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t586" href="#t586">586</a></span><span class="t"><span class="str">            show_clk = paddle.cast(paddle.concat([ones, label], axis=1), dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t587" href="#t587">587</a></span><span class="t"><span class="str">            show_clk.stop_gradient = True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t588" href="#t588">588</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t589" href="#t589">589</a></span><span class="t"><span class="str">            cvms = fluid.contrib.layers.fused_seqpool_cvm(embs, 'sum', show_clk)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t590" href="#t590">590</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t591" href="#t591">591</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t592" href="#t592">592</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t593" href="#t593">593</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'fused_seqpool_cvm'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t594" href="#t594">594</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t595" href="#t595">595</a></span><span class="t">    <span class="key">if</span> <span class="nam">pool_type</span><span class="op">.</span><span class="nam">upper</span><span class="op">(</span><span class="op">)</span> <span class="op">!=</span> <span class="str">'SUM'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t596" href="#t596">596</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t597" href="#t597">597</a></span><span class="t">            <span class="str">"fused_seqpool_cvm only support SUM pooling now, and your type is: "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t598" href="#t598">598</a></span><span class="t">            <span class="op">+</span> <span class="nam">pool_type</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t599" href="#t599">599</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t600" href="#t600">600</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="nam">list</span><span class="op">,</span> <span class="str">'fused_seqpool_cvm'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t601" href="#t601">601</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t602" href="#t602">602</a></span><span class="t">        <span class="key">for</span> <span class="nam">_input</span> <span class="key">in</span> <span class="nam">input</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t603" href="#t603">603</a></span><span class="t">            <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">_input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t604" href="#t604">604</a></span><span class="t">                                     <span class="str">'fused_seqpool_cvm'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t605" href="#t605">605</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t606" href="#t606">606</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t607" href="#t607">607</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">multiple_input</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t608" href="#t608">608</a></span><span class="t">    <span class="nam">outs</span> <span class="op">=</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t609" href="#t609">609</a></span><span class="t">        <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t610" href="#t610">610</a></span><span class="t">        <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">len</span><span class="op">(</span><span class="nam">inputs</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t611" href="#t611">611</a></span><span class="t">    <span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t612" href="#t612">612</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t613" href="#t613">613</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">"fused_seqpool_cvm"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t614" href="#t614">614</a></span><span class="t">                     <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t615" href="#t615">615</a></span><span class="t">                         <span class="str">"X"</span><span class="op">:</span> <span class="nam">inputs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t616" href="#t616">616</a></span><span class="t">                         <span class="str">"CVM"</span><span class="op">:</span> <span class="nam">cvm</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t617" href="#t617">617</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t618" href="#t618">618</a></span><span class="t">                     <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">outs</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t619" href="#t619">619</a></span><span class="t">                     <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t620" href="#t620">620</a></span><span class="t">                         <span class="str">"pooltype"</span><span class="op">:</span> <span class="nam">pool_type</span><span class="op">.</span><span class="nam">upper</span><span class="op">(</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t621" href="#t621">621</a></span><span class="t">                         <span class="str">"pad_value"</span><span class="op">:</span> <span class="nam">pad_value</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t622" href="#t622">622</a></span><span class="t">                         <span class="str">"use_cvm"</span><span class="op">:</span> <span class="nam">use_cvm</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t623" href="#t623">623</a></span><span class="t">                         <span class="str">"cvm_offset"</span><span class="op">:</span> <span class="nam">cvm_offset</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t624" href="#t624">624</a></span><span class="t">                     <span class="op">}</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t625" href="#t625">625</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t626" href="#t626">626</a></span><span class="t">    <span class="key">return</span> <span class="nam">outs</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t627" href="#t627">627</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t628" href="#t628">628</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t629" href="#t629">629</a></span><span class="t"><span class="key">def</span> <span class="nam">multiclass_nms2</span><span class="op">(</span><span class="nam">bboxes</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t630" href="#t630">630</a></span><span class="t">                    <span class="nam">scores</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t631" href="#t631">631</a></span><span class="t">                    <span class="nam">score_threshold</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t632" href="#t632">632</a></span><span class="t">                    <span class="nam">nms_top_k</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t633" href="#t633">633</a></span><span class="t">                    <span class="nam">keep_top_k</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t634" href="#t634">634</a></span><span class="t">                    <span class="nam">nms_threshold</span><span class="op">=</span><span class="num">0.3</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t635" href="#t635">635</a></span><span class="t">                    <span class="nam">normalized</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t636" href="#t636">636</a></span><span class="t">                    <span class="nam">nms_eta</span><span class="op">=</span><span class="num">1.</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t637" href="#t637">637</a></span><span class="t">                    <span class="nam">background_label</span><span class="op">=</span><span class="num">0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t638" href="#t638">638</a></span><span class="t">                    <span class="nam">return_index</span><span class="op">=</span><span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t639" href="#t639">639</a></span><span class="t">                    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t640" href="#t640">640</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t641" href="#t641">641</a></span><span class="t"><span class="str">    **Multiclass NMS2**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t642" href="#t642">642</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t643" href="#t643">643</a></span><span class="t"><span class="str">    This operator is to do multi-class non maximum suppression (NMS) on</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t644" href="#t644">644</a></span><span class="t"><span class="str">    boxes and scores.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t645" href="#t645">645</a></span><span class="t"><span class="str">    In the NMS step, this operator greedily selects a subset of detection bounding</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t646" href="#t646">646</a></span><span class="t"><span class="str">    boxes that have high scores larger than score_threshold, if providing this</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t647" href="#t647">647</a></span><span class="t"><span class="str">    threshold, then selects the largest nms_top_k confidences scores if nms_top_k</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t648" href="#t648">648</a></span><span class="t"><span class="str">    is larger than -1. Then this operator pruns away boxes that have high IOU</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t649" href="#t649">649</a></span><span class="t"><span class="str">    (intersection over union) overlap with already selected boxes by adaptive</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t650" href="#t650">650</a></span><span class="t"><span class="str">    threshold NMS based on parameters of nms_threshold and nms_eta.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t651" href="#t651">651</a></span><span class="t"><span class="str">    Aftern NMS step, at most keep_top_k number of total bboxes are to be kept</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t652" href="#t652">652</a></span><span class="t"><span class="str">    per image if keep_top_k is larger than -1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t653" href="#t653">653</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t654" href="#t654">654</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t655" href="#t655">655</a></span><span class="t"><span class="str">        bboxes (Variable): Two types of bboxes are supported:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t656" href="#t656">656</a></span><span class="t"><span class="str">                           1. (Tensor) A 3-D Tensor with shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t657" href="#t657">657</a></span><span class="t"><span class="str">                           [N, M, 4 or 8 16 24 32] represents the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t658" href="#t658">658</a></span><span class="t"><span class="str">                           predicted locations of M bounding bboxes,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t659" href="#t659">659</a></span><span class="t"><span class="str">                           N is the batch size. Each bounding box has four</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t660" href="#t660">660</a></span><span class="t"><span class="str">                           coordinate values and the layout is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t661" href="#t661">661</a></span><span class="t"><span class="str">                           [xmin, ymin, xmax, ymax], when box size equals to 4.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t662" href="#t662">662</a></span><span class="t"><span class="str">                           2. (LoDTensor) A 3-D Tensor with shape [M, C, 4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t663" href="#t663">663</a></span><span class="t"><span class="str">                           M is the number of bounding boxes, C is the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t664" href="#t664">664</a></span><span class="t"><span class="str">                           class number</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t665" href="#t665">665</a></span><span class="t"><span class="str">        scores (Variable): Two types of scores are supported:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t666" href="#t666">666</a></span><span class="t"><span class="str">                           1. (Tensor) A 3-D Tensor with shape [N, C, M]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t667" href="#t667">667</a></span><span class="t"><span class="str">                           represents the predicted confidence predictions.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t668" href="#t668">668</a></span><span class="t"><span class="str">                           N is the batch size, C is the class number, M is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t669" href="#t669">669</a></span><span class="t"><span class="str">                           number of bounding boxes. For each category there</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t670" href="#t670">670</a></span><span class="t"><span class="str">                           are total M scores which corresponding M bounding</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t671" href="#t671">671</a></span><span class="t"><span class="str">                           boxes. Please note, M is equal to the 2nd dimension</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t672" href="#t672">672</a></span><span class="t"><span class="str">                           of BBoxes.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t673" href="#t673">673</a></span><span class="t"><span class="str">                           2. (LoDTensor) A 2-D LoDTensor with shape [M, C].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t674" href="#t674">674</a></span><span class="t"><span class="str">                           M is the number of bbox, C is the class number.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t675" href="#t675">675</a></span><span class="t"><span class="str">                           In this case, input BBoxes should be the second</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t676" href="#t676">676</a></span><span class="t"><span class="str">                           case with shape [M, C, 4].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t677" href="#t677">677</a></span><span class="t"><span class="str">        background_label (int): The index of background label, the background</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t678" href="#t678">678</a></span><span class="t"><span class="str">                                label will be ignored. If set to -1, then all</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t679" href="#t679">679</a></span><span class="t"><span class="str">                                categories will be considered. Default: 0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t680" href="#t680">680</a></span><span class="t"><span class="str">        score_threshold (float): Threshold to filter out bounding boxes with</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t681" href="#t681">681</a></span><span class="t"><span class="str">                                 low confidence score. If not provided,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t682" href="#t682">682</a></span><span class="t"><span class="str">                                 consider all boxes.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t683" href="#t683">683</a></span><span class="t"><span class="str">        nms_top_k (int): Maximum number of detections to be kept according to</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t684" href="#t684">684</a></span><span class="t"><span class="str">                         the confidences after the filtering detections based</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t685" href="#t685">685</a></span><span class="t"><span class="str">                         on score_threshold.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t686" href="#t686">686</a></span><span class="t"><span class="str">        nms_threshold (float): The threshold to be used in NMS. Default: 0.3</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t687" href="#t687">687</a></span><span class="t"><span class="str">        nms_eta (float): The threshold to be used in NMS. Default: 1.0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t688" href="#t688">688</a></span><span class="t"><span class="str">        keep_top_k (int): Number of total bboxes to be kept per image after NMS</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t689" href="#t689">689</a></span><span class="t"><span class="str">                          step. -1 means keeping all bboxes after NMS step.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t690" href="#t690">690</a></span><span class="t"><span class="str">        normalized (bool): Whether detections are normalized. Default: True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t691" href="#t691">691</a></span><span class="t"><span class="str">        return_index(bool): Whether return selected index. Default: False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t692" href="#t692">692</a></span><span class="t"><span class="str">        name(str): Name of the multiclass nms op. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t693" href="#t693">693</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t694" href="#t694">694</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t695" href="#t695">695</a></span><span class="t"><span class="str">        A tuple with two Variables: (Out, Index) if return_index is True,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t696" href="#t696">696</a></span><span class="t"><span class="str">        otherwise, a tuple with one Variable(Out) is returned.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t697" href="#t697">697</a></span><span class="t"><span class="str">        Out: A 2-D LoDTensor with shape [No, 6] represents the detections.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t698" href="#t698">698</a></span><span class="t"><span class="str">        Each row has 6 values: [label, confidence, xmin, ymin, xmax, ymax]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t699" href="#t699">699</a></span><span class="t"><span class="str">        or A 2-D LoDTensor with shape [No, 10] represents the detections.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t700" href="#t700">700</a></span><span class="t"><span class="str">        Each row has 10 values: [label, confidence, x1, y1, x2, y2, x3, y3,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t701" href="#t701">701</a></span><span class="t"><span class="str">        x4, y4]. No is the total number of detections.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t702" href="#t702">702</a></span><span class="t"><span class="str">        If all images have not detected results, all elements in LoD will be</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t703" href="#t703">703</a></span><span class="t"><span class="str">        0, and output tensor is empty (None).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t704" href="#t704">704</a></span><span class="t"><span class="str">        Index: Only return when return_index is True. A 2-D LoDTensor with</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t705" href="#t705">705</a></span><span class="t"><span class="str">        shape [No, 1] represents the selected index which type is Integer.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t706" href="#t706">706</a></span><span class="t"><span class="str">        The index is the absolute value cross batches. No is the same number</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t707" href="#t707">707</a></span><span class="t"><span class="str">        as Out. If the index is used to gather other attribute such as age,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t708" href="#t708">708</a></span><span class="t"><span class="str">        one needs to reshape the input(N, M, 1) to (N * M, 1) as first, where</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t709" href="#t709">709</a></span><span class="t"><span class="str">        N is the batch size and M is the number of boxes.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t710" href="#t710">710</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t711" href="#t711">711</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t712" href="#t712">712</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t713" href="#t713">713</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t714" href="#t714">714</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t715" href="#t715">715</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t716" href="#t716">716</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t717" href="#t717">717</a></span><span class="t"><span class="str">            boxes = fluid.layers.data(name='bboxes', shape=[81, 4],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t718" href="#t718">718</a></span><span class="t"><span class="str">                                      dtype='float32', lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t719" href="#t719">719</a></span><span class="t"><span class="str">            scores = fluid.layers.data(name='scores', shape=[81],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t720" href="#t720">720</a></span><span class="t"><span class="str">                                      dtype='float32', lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t721" href="#t721">721</a></span><span class="t"><span class="str">            out, index = fluid.layers.multiclass_nms2(bboxes=boxes,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t722" href="#t722">722</a></span><span class="t"><span class="str">                                              scores=scores,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t723" href="#t723">723</a></span><span class="t"><span class="str">                                              background_label=0,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t724" href="#t724">724</a></span><span class="t"><span class="str">                                              score_threshold=0.5,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t725" href="#t725">725</a></span><span class="t"><span class="str">                                              nms_top_k=400,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t726" href="#t726">726</a></span><span class="t"><span class="str">                                              nms_threshold=0.3,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t727" href="#t727">727</a></span><span class="t"><span class="str">                                              keep_top_k=200,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t728" href="#t728">728</a></span><span class="t"><span class="str">                                              normalized=False,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t729" href="#t729">729</a></span><span class="t"><span class="str">                                              return_index=True)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t730" href="#t730">730</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t731" href="#t731">731</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'multiclass_nms2'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t732" href="#t732">732</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t733" href="#t733">733</a></span><span class="t">    <span class="nam">output</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">bboxes</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t734" href="#t734">734</a></span><span class="t">    <span class="nam">index</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="str">'int'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t735" href="#t735">735</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">"multiclass_nms2"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t736" href="#t736">736</a></span><span class="t">                     <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t737" href="#t737">737</a></span><span class="t">                         <span class="str">'BBoxes'</span><span class="op">:</span> <span class="nam">bboxes</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t738" href="#t738">738</a></span><span class="t">                         <span class="str">'Scores'</span><span class="op">:</span> <span class="nam">scores</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t739" href="#t739">739</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t740" href="#t740">740</a></span><span class="t">                     <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t741" href="#t741">741</a></span><span class="t">                         <span class="str">'background_label'</span><span class="op">:</span> <span class="nam">background_label</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t742" href="#t742">742</a></span><span class="t">                         <span class="str">'score_threshold'</span><span class="op">:</span> <span class="nam">score_threshold</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t743" href="#t743">743</a></span><span class="t">                         <span class="str">'nms_top_k'</span><span class="op">:</span> <span class="nam">nms_top_k</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t744" href="#t744">744</a></span><span class="t">                         <span class="str">'nms_threshold'</span><span class="op">:</span> <span class="nam">nms_threshold</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t745" href="#t745">745</a></span><span class="t">                         <span class="str">'keep_top_k'</span><span class="op">:</span> <span class="nam">keep_top_k</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t746" href="#t746">746</a></span><span class="t">                         <span class="str">'nms_eta'</span><span class="op">:</span> <span class="nam">nms_eta</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t747" href="#t747">747</a></span><span class="t">                         <span class="str">'normalized'</span><span class="op">:</span> <span class="nam">normalized</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t748" href="#t748">748</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t749" href="#t749">749</a></span><span class="t">                     <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t750" href="#t750">750</a></span><span class="t">                         <span class="str">'Out'</span><span class="op">:</span> <span class="nam">output</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t751" href="#t751">751</a></span><span class="t">                         <span class="str">'Index'</span><span class="op">:</span> <span class="nam">index</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t752" href="#t752">752</a></span><span class="t">                     <span class="op">}</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t753" href="#t753">753</a></span><span class="t">    <span class="nam">output</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t754" href="#t754">754</a></span><span class="t">    <span class="nam">index</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t755" href="#t755">755</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t756" href="#t756">756</a></span><span class="t">    <span class="key">if</span> <span class="nam">return_index</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t757" href="#t757">757</a></span><span class="t">        <span class="key">return</span> <span class="nam">output</span><span class="op">,</span> <span class="nam">index</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t758" href="#t758">758</a></span><span class="t">    <span class="key">return</span> <span class="nam">output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t759" href="#t759">759</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t760" href="#t760">760</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t761" href="#t761">761</a></span><span class="t"><span class="key">def</span> <span class="nam">search_pyramid_hash</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t762" href="#t762">762</a></span><span class="t">                        <span class="nam">num_emb</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t763" href="#t763">763</a></span><span class="t">                        <span class="nam">space_len</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t764" href="#t764">764</a></span><span class="t">                        <span class="nam">pyramid_layer</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t765" href="#t765">765</a></span><span class="t">                        <span class="nam">rand_len</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t766" href="#t766">766</a></span><span class="t">                        <span class="nam">drop_out_percent</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t767" href="#t767">767</a></span><span class="t">                        <span class="nam">is_training</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t768" href="#t768">768</a></span><span class="t">                        <span class="nam">use_filter</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t769" href="#t769">769</a></span><span class="t">                        <span class="nam">white_list_len</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t770" href="#t770">770</a></span><span class="t">                        <span class="nam">black_list_len</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t771" href="#t771">771</a></span><span class="t">                        <span class="nam">seed</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t772" href="#t772">772</a></span><span class="t">                        <span class="nam">lr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t773" href="#t773">773</a></span><span class="t">                        <span class="nam">param_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t774" href="#t774">774</a></span><span class="t">                        <span class="nam">param_attr_wl</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t775" href="#t775">775</a></span><span class="t">                        <span class="nam">param_attr_bl</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t776" href="#t776">776</a></span><span class="t">                        <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t777" href="#t777">777</a></span><span class="t">                        <span class="nam">distribute_update_vars</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t778" href="#t778">778</a></span><span class="t">                        <span class="nam">dtype</span><span class="op">=</span><span class="str">'float32'</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t779" href="#t779">779</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t780" href="#t780">780</a></span><span class="t"><span class="str">    **Pyramid hash embedding**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t781" href="#t781">781</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t782" href="#t782">782</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t783" href="#t783">783</a></span><span class="t"><span class="str">        input (Variable): LoDTensor&lt;int32> Variable contained the IDs' information.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t784" href="#t784">784</a></span><span class="t"><span class="str">        num_emb (int): The embedding size of output.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t785" href="#t785">785</a></span><span class="t"><span class="str">        space_len (int): The length of pyramid hash embedding space.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t786" href="#t786">786</a></span><span class="t"><span class="str">        pyramid_layer (int): The number of pyramid layers. It should be greater than 2.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t787" href="#t787">787</a></span><span class="t"><span class="str">        rand_len (int): The minimum length of pyramid hash cell.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t788" href="#t788">788</a></span><span class="t"><span class="str">        drop_out_percent (float): The probability of dropping out the input token randomly.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t789" href="#t789">789</a></span><span class="t"><span class="str">            It should satisfy: [0., 1.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t790" href="#t790">790</a></span><span class="t"><span class="str">        is_training (bool): Whether in training or testing phrase.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t791" href="#t791">791</a></span><span class="t"><span class="str">        use_filter(bool): If set True, the white filter and black filter should be given by</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t792" href="#t792">792</a></span><span class="t"><span class="str">            :attr:`param_attr_wl` and :attr:`param_attr_bl` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t793" href="#t793">793</a></span><span class="t"><span class="str">        white_list_len(int): If set :math:`white_list_len>0` , white filter with shape [white_list_len, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t794" href="#t794">794</a></span><span class="t"><span class="str">            should be provided by param_attr_wl.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t795" href="#t795">795</a></span><span class="t"><span class="str">        black_list_len(int): If set :math:`black_list_len>0` , black filter with shape [black_list_len, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t796" href="#t796">796</a></span><span class="t"><span class="str">            should be provided by param_attr_bl.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t797" href="#t797">797</a></span><span class="t"><span class="str">        seed(int): The number of random seed.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t798" href="#t798">798</a></span><span class="t"><span class="str">        lr(float): The learning rate of weight created by :attr:`param_attr` with shape [space_len+rand_len, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t799" href="#t799">799</a></span><span class="t"><span class="str">            in this layer.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t800" href="#t800">800</a></span><span class="t"><span class="str">        param_attr(ParamAttr): To specify the weight parameter property. Default: None, which means the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t801" href="#t801">801</a></span><span class="t"><span class="str">            default weight parameter property is used. See usage for details in :ref:`api_fluid_ParamAttr` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t802" href="#t802">802</a></span><span class="t"><span class="str">        param_attr_wl(ParamAttr): Specified parameters of white filter.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t803" href="#t803">803</a></span><span class="t"><span class="str">        param_attr_bl(ParamAttr): Specified parameters of black filter.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t804" href="#t804">804</a></span><span class="t"><span class="str">        distribute_update_vars(list[ParamAttr.name]): Decided which params should be updated in distribute training.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t805" href="#t805">805</a></span><span class="t"><span class="str">            Used in Distribute Transpiler to create a trainer/server program.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t806" href="#t806">806</a></span><span class="t"><span class="str">        name(str, optional): The default value is None.  Normally there is no need for user to set this property.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t807" href="#t807">807</a></span><span class="t"><span class="str">            For more information, please refer to :ref:`api_guide_Name` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t808" href="#t808">808</a></span><span class="t"><span class="str">        dtype(str): The data type of output variable, float32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t809" href="#t809">809</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t810" href="#t810">810</a></span><span class="t"><span class="str">        Variable: LoDTensor of pyramid hash embedding.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t811" href="#t811">811</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t812" href="#t812">812</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'search_pyramid_hash'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t813" href="#t813">813</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t814" href="#t814">814</a></span><span class="t">    <span class="nam">w_shape</span> <span class="op">=</span> <span class="op">[</span><span class="nam">space_len</span> <span class="op">+</span> <span class="nam">rand_len</span><span class="op">,</span> <span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t815" href="#t815">815</a></span><span class="t">    <span class="nam">w</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span><span class="nam">attr</span><span class="op">=</span><span class="nam">param_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t816" href="#t816">816</a></span><span class="t">                                <span class="nam">shape</span><span class="op">=</span><span class="nam">w_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t817" href="#t817">817</a></span><span class="t">                                <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t818" href="#t818">818</a></span><span class="t">                                <span class="nam">is_bias</span><span class="op">=</span><span class="key">False</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t819" href="#t819">819</a></span><span class="t">    <span class="nam">w</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t820" href="#t820">820</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t821" href="#t821">821</a></span><span class="t">    <span class="nam">input_vars</span> <span class="op">=</span> <span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">input</span><span class="op">,</span> <span class="str">'W'</span><span class="op">:</span> <span class="nam">w</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t822" href="#t822">822</a></span><span class="t">    <span class="key">if</span> <span class="nam">white_list_len</span> <span class="op">></span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t823" href="#t823">823</a></span><span class="t">        <span class="nam">wl_shape</span> <span class="op">=</span> <span class="op">[</span><span class="nam">white_list_len</span><span class="op">,</span> <span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t824" href="#t824">824</a></span><span class="t">        <span class="nam">white_list</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span><span class="nam">attr</span><span class="op">=</span><span class="nam">param_attr_wl</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t825" href="#t825">825</a></span><span class="t">                                             <span class="nam">shape</span><span class="op">=</span><span class="nam">wl_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t826" href="#t826">826</a></span><span class="t">                                             <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t827" href="#t827">827</a></span><span class="t">                                             <span class="nam">is_bias</span><span class="op">=</span><span class="key">False</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t828" href="#t828">828</a></span><span class="t">        <span class="nam">white_list</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t829" href="#t829">829</a></span><span class="t">        <span class="nam">input_vars</span><span class="op">[</span><span class="str">'WhiteList'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">white_list</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t830" href="#t830">830</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t831" href="#t831">831</a></span><span class="t">    <span class="key">if</span> <span class="nam">black_list_len</span> <span class="op">>=</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t832" href="#t832">832</a></span><span class="t">        <span class="nam">bl_shape</span> <span class="op">=</span> <span class="op">[</span><span class="nam">black_list_len</span><span class="op">,</span> <span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t833" href="#t833">833</a></span><span class="t">        <span class="nam">black_list</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span><span class="nam">attr</span><span class="op">=</span><span class="nam">param_attr_bl</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t834" href="#t834">834</a></span><span class="t">                                             <span class="nam">shape</span><span class="op">=</span><span class="nam">bl_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t835" href="#t835">835</a></span><span class="t">                                             <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t836" href="#t836">836</a></span><span class="t">                                             <span class="nam">is_bias</span><span class="op">=</span><span class="key">False</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t837" href="#t837">837</a></span><span class="t">        <span class="nam">black_list</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t838" href="#t838">838</a></span><span class="t">        <span class="nam">input_vars</span><span class="op">[</span><span class="str">'BlackList'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">black_list</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t839" href="#t839">839</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t840" href="#t840">840</a></span><span class="t">    <span class="nam">distribute_update_vars_str</span> <span class="op">=</span> <span class="str">""</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t841" href="#t841">841</a></span><span class="t">    <span class="key">if</span> <span class="nam">distribute_update_vars</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t842" href="#t842">842</a></span><span class="t">        <span class="key">assert</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">distribute_update_vars</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t843" href="#t843">843</a></span><span class="t">        <span class="nam">special_name_list</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t844" href="#t844">844</a></span><span class="t">        <span class="key">if</span> <span class="nam">param_attr</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t845" href="#t845">845</a></span><span class="t">            <span class="nam">special_name_list</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">param_attr</span><span class="op">.</span><span class="nam">name</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t846" href="#t846">846</a></span><span class="t">        <span class="key">if</span> <span class="nam">param_attr_wl</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t847" href="#t847">847</a></span><span class="t">            <span class="nam">special_name_list</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">param_attr_wl</span><span class="op">.</span><span class="nam">name</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t848" href="#t848">848</a></span><span class="t">        <span class="key">if</span> <span class="nam">param_attr_bl</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t849" href="#t849">849</a></span><span class="t">            <span class="nam">special_name_list</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">param_attr_bl</span><span class="op">.</span><span class="nam">name</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t850" href="#t850">850</a></span><span class="t">        <span class="key">for</span> <span class="nam">param</span> <span class="key">in</span> <span class="nam">distribute_update_vars</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t851" href="#t851">851</a></span><span class="t">            <span class="key">if</span> <span class="nam">param</span> <span class="key">not</span> <span class="key">in</span> <span class="nam">special_name_list</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t852" href="#t852">852</a></span><span class="t">                <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t853" href="#t853">853</a></span><span class="t">                    <span class="str">"Pyramid Hash layer didn't have parameter {}"</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">param</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t854" href="#t854">854</a></span><span class="t">        <span class="nam">distribute_update_vars_str</span> <span class="op">=</span> <span class="str">","</span><span class="op">.</span><span class="nam">join</span><span class="op">(</span><span class="nam">distribute_update_vars</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t855" href="#t855">855</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t856" href="#t856">856</a></span><span class="t">    <span class="nam">res</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t857" href="#t857">857</a></span><span class="t">    <span class="nam">drop_pos</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t858" href="#t858">858</a></span><span class="t">    <span class="nam">x_temp_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t859" href="#t859">859</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">'pyramid_hash'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t860" href="#t860">860</a></span><span class="t">                     <span class="nam">inputs</span><span class="op">=</span><span class="nam">input_vars</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t861" href="#t861">861</a></span><span class="t">                     <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t862" href="#t862">862</a></span><span class="t">                         <span class="str">"Out"</span><span class="op">:</span> <span class="nam">res</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t863" href="#t863">863</a></span><span class="t">                         <span class="str">"X_Temp_Out"</span><span class="op">:</span> <span class="nam">x_temp_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t864" href="#t864">864</a></span><span class="t">                         <span class="str">'DropPos'</span><span class="op">:</span> <span class="nam">drop_pos</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t865" href="#t865">865</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t866" href="#t866">866</a></span><span class="t">                     <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t867" href="#t867">867</a></span><span class="t">                         <span class="str">'num_emb'</span><span class="op">:</span> <span class="nam">num_emb</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t868" href="#t868">868</a></span><span class="t">                         <span class="str">'space_len'</span><span class="op">:</span> <span class="nam">space_len</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t869" href="#t869">869</a></span><span class="t">                         <span class="str">'pyramid_layer'</span><span class="op">:</span> <span class="nam">pyramid_layer</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t870" href="#t870">870</a></span><span class="t">                         <span class="str">'rand_len'</span><span class="op">:</span> <span class="nam">rand_len</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t871" href="#t871">871</a></span><span class="t">                         <span class="str">'drop_out_percent'</span><span class="op">:</span> <span class="nam">drop_out_percent</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t872" href="#t872">872</a></span><span class="t">                         <span class="str">'is_training'</span><span class="op">:</span> <span class="nam">is_training</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t873" href="#t873">873</a></span><span class="t">                         <span class="str">'use_filter'</span><span class="op">:</span> <span class="nam">use_filter</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t874" href="#t874">874</a></span><span class="t">                         <span class="str">'white_list_len'</span><span class="op">:</span> <span class="nam">white_list_len</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t875" href="#t875">875</a></span><span class="t">                         <span class="str">'black_list_len'</span><span class="op">:</span> <span class="nam">black_list_len</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t876" href="#t876">876</a></span><span class="t">                         <span class="str">'seed'</span><span class="op">:</span> <span class="nam">seed</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t877" href="#t877">877</a></span><span class="t">                         <span class="str">'lr'</span><span class="op">:</span> <span class="nam">lr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t878" href="#t878">878</a></span><span class="t">                         <span class="str">'distribute_update_vars'</span><span class="op">:</span> <span class="nam">distribute_update_vars_str</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t879" href="#t879">879</a></span><span class="t">                     <span class="op">}</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t880" href="#t880">880</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t881" href="#t881">881</a></span><span class="t">    <span class="key">return</span> <span class="nam">res</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t882" href="#t882">882</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t883" href="#t883">883</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t884" href="#t884">884</a></span><span class="t"><span class="key">def</span> <span class="nam">shuffle_batch</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">seed</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t885" href="#t885">885</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t886" href="#t886">886</a></span><span class="t"><span class="str">    This layer shuffle input tensor :attr:`x` . Normally, :attr:`x` is 2-D LoDTensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t887" href="#t887">887</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t888" href="#t888">888</a></span><span class="t"><span class="str">    :attr:`x` is a LoDTensor to be shuffled with shape :math:`[N_1, N_2, ..., N_k, D]` . Note that the last dim of input will not be shuffled.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t889" href="#t889">889</a></span><span class="t"><span class="str">    :math:`N_1 * N_2 * ... * N_k` numbers of elements with length :math:`D` will be shuffled randomly.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t890" href="#t890">890</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t891" href="#t891">891</a></span><span class="t"><span class="str">    For Example:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t892" href="#t892">892</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t893" href="#t893">893</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t894" href="#t894">894</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t895" href="#t895">895</a></span><span class="t"><span class="str">      Input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t896" href="#t896">896</a></span><span class="t"><span class="str">        x.data = [[1, 2], [3, 4], [5, 6], [7, 8]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t897" href="#t897">897</a></span><span class="t"><span class="str">        x.dims = [4, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t898" href="#t898">898</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t899" href="#t899">899</a></span><span class="t"><span class="str">      Attrs:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t900" href="#t900">900</a></span><span class="t"><span class="str">        seed = 2019</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t901" href="#t901">901</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t902" href="#t902">902</a></span><span class="t"><span class="str">      Output:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t903" href="#t903">903</a></span><span class="t"><span class="str">        Out.data =[[7, 8], [1, 2], [3, 4], [5, 6]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t904" href="#t904">904</a></span><span class="t"><span class="str">        Out.dims = [4, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t905" href="#t905">905</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t906" href="#t906">906</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t907" href="#t907">907</a></span><span class="t"><span class="str">        x (Variable): The input variable. The input variable is a N-D LoDTensor with type int, float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t908" href="#t908">908</a></span><span class="t"><span class="str">        seed (None|int|Variable): The start up seed. If set, seed will be set as the start up seed of shuffle engine.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t909" href="#t909">909</a></span><span class="t"><span class="str">                If not set(Default), start up seed of shuffle engine will be generated randomly.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t910" href="#t910">910</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t911" href="#t911">911</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t912" href="#t912">912</a></span><span class="t"><span class="str">        Variables: The shuffled LoDTensor with the same shape and lod as input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t913" href="#t913">913</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t914" href="#t914">914</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t915" href="#t915">915</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t916" href="#t916">916</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t917" href="#t917">917</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t918" href="#t918">918</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t919" href="#t919">919</a></span><span class="t"><span class="str">            x = fluid.layers.data(name="x", shape=[-1, 4])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t920" href="#t920">920</a></span><span class="t"><span class="str">            out = fluid.contrib.layers.shuffle_batch(x)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t921" href="#t921">921</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t922" href="#t922">922</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'shuffle_batch'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t923" href="#t923">923</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t924" href="#t924">924</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t925" href="#t925">925</a></span><span class="t">    <span class="nam">shuffle_idx</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">np</span><span class="op">.</span><span class="nam">int64</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t926" href="#t926">926</a></span><span class="t">    <span class="key">if</span> <span class="nam">seed</span> <span class="key">is</span> <span class="key">None</span> <span class="key">and</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">main_program</span><span class="op">.</span><span class="nam">random_seed</span> <span class="op">!=</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t927" href="#t927">927</a></span><span class="t">        <span class="nam">seed</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">main_program</span><span class="op">.</span><span class="nam">random_seed</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t928" href="#t928">928</a></span><span class="t">    <span class="key">if</span> <span class="nam">seed</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t929" href="#t929">929</a></span><span class="t">        <span class="nam">seed</span> <span class="op">=</span> <span class="nam">np</span><span class="op">.</span><span class="nam">random</span><span class="op">.</span><span class="nam">randint</span><span class="op">(</span><span class="op">-</span><span class="num">65536</span><span class="op">,</span> <span class="num">65535</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t930" href="#t930">930</a></span><span class="t">    <span class="nam">op_attrs</span> <span class="op">=</span> <span class="op">{</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t931" href="#t931">931</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">seed</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t932" href="#t932">932</a></span><span class="t">        <span class="nam">op_attrs</span><span class="op">[</span><span class="str">"startup_seed"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">seed</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t933" href="#t933">933</a></span><span class="t">        <span class="nam">seed</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t934" href="#t934">934</a></span><span class="t">            <span class="nam">name</span><span class="op">=</span><span class="nam">unique_name</span><span class="op">.</span><span class="nam">generate</span><span class="op">(</span><span class="str">"shuffle_batch_seed"</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t935" href="#t935">935</a></span><span class="t">            <span class="nam">dtype</span><span class="op">=</span><span class="str">"int64"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t936" href="#t936">936</a></span><span class="t">            <span class="nam">persistable</span><span class="op">=</span><span class="key">False</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t937" href="#t937">937</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">'shuffle_batch'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t938" href="#t938">938</a></span><span class="t">                     <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t939" href="#t939">939</a></span><span class="t">                         <span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t940" href="#t940">940</a></span><span class="t">                         <span class="str">'Seed'</span><span class="op">:</span> <span class="nam">seed</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t941" href="#t941">941</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t942" href="#t942">942</a></span><span class="t">                     <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t943" href="#t943">943</a></span><span class="t">                         <span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t944" href="#t944">944</a></span><span class="t">                         <span class="str">'ShuffleIdx'</span><span class="op">:</span> <span class="nam">shuffle_idx</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t945" href="#t945">945</a></span><span class="t">                         <span class="str">'SeedOut'</span><span class="op">:</span> <span class="nam">seed</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t946" href="#t946">946</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t947" href="#t947">947</a></span><span class="t">                     <span class="nam">attrs</span><span class="op">=</span><span class="nam">op_attrs</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t948" href="#t948">948</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t949" href="#t949">949</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t950" href="#t950">950</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t951" href="#t951">951</a></span><span class="t"><span class="key">def</span> <span class="nam">partial_concat</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">start_index</span><span class="op">=</span><span class="num">0</span><span class="op">,</span> <span class="nam">length</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t952" href="#t952">952</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t953" href="#t953">953</a></span><span class="t"><span class="str">    **Partial Concat**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t954" href="#t954">954</a></span><span class="t"><span class="str">    This OP concatenates the inputs according to the start index and length. This</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t955" href="#t955">955</a></span><span class="t"><span class="str">    OP exists in contrib, which means that it is not shown to the public.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t956" href="#t956">956</a></span><span class="t"><span class="str">    Only 2-D Tensor or LodTensor input is supported. Slice and concat can only be</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t957" href="#t957">957</a></span><span class="t"><span class="str">    performed along the second dimension.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t958" href="#t958">958</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t959" href="#t959">959</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t960" href="#t960">960</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t961" href="#t961">961</a></span><span class="t"><span class="str">        Given:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t962" href="#t962">962</a></span><span class="t"><span class="str">            x = [[0, 1, 2],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t963" href="#t963">963</a></span><span class="t"><span class="str">                 [3, 4, 5]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t964" href="#t964">964</a></span><span class="t"><span class="str">            y = [[6, 7 ,8],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t965" href="#t965">965</a></span><span class="t"><span class="str">                 [9, 10, 11]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t966" href="#t966">966</a></span><span class="t"><span class="str">            output = partial_concat([x, y], start_index=0, length=2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t967" href="#t967">967</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t968" href="#t968">968</a></span><span class="t"><span class="str">          we get:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t969" href="#t969">969</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t970" href="#t970">970</a></span><span class="t"><span class="str">            output = [[0, 1, 6, 7],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t971" href="#t971">971</a></span><span class="t"><span class="str">                      [3, 4, 9, 10]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t972" href="#t972">972</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t973" href="#t973">973</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t974" href="#t974">974</a></span><span class="t"><span class="str">        input(list): List of input Tensors with data type float32, float64, int32,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t975" href="#t975">975</a></span><span class="t"><span class="str">            int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t976" href="#t976">976</a></span><span class="t"><span class="str">        start_index(int32): The start index of each instance for partial concatenation.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t977" href="#t977">977</a></span><span class="t"><span class="str">            Default is 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t978" href="#t978">978</a></span><span class="t"><span class="str">        length(int32): The length of each instance for partial concatenation. Default is -1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t979" href="#t979">979</a></span><span class="t"><span class="str">            Negative values for all elements after start_index.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t980" href="#t980">980</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t981" href="#t981">981</a></span><span class="t"><span class="str">        Variable: A Tensor with the same data type as input's.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t982" href="#t982">982</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t983" href="#t983">983</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t984" href="#t984">984</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t985" href="#t985">985</a></span><span class="t"><span class="str">            x = fluid.data(name="x", shape=[None,3], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t986" href="#t986">986</a></span><span class="t"><span class="str">            y = fluid.data(name="y", shape=[None,3], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t987" href="#t987">987</a></span><span class="t"><span class="str">            concat = fluid.contrib.layers.partial_concat(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t988" href="#t988">988</a></span><span class="t"><span class="str">                [x, y], start_index=0, length=2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t989" href="#t989">989</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t990" href="#t990">990</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t991" href="#t991">991</a></span><span class="t">        <span class="nam">warnings</span><span class="op">.</span><span class="nam">warn</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t992" href="#t992">992</a></span><span class="t">            <span class="str">"The type of input in partial_concat should be list, but received %s."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t993" href="#t993">993</a></span><span class="t">            <span class="op">%</span> <span class="op">(</span><span class="nam">type</span><span class="op">(</span><span class="nam">input</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t994" href="#t994">994</a></span><span class="t">        <span class="nam">input</span> <span class="op">=</span> <span class="op">[</span><span class="nam">input</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t995" href="#t995">995</a></span><span class="t">    <span class="key">for</span> <span class="nam">id</span><span class="op">,</span> <span class="nam">x</span> <span class="key">in</span> <span class="nam">enumerate</span><span class="op">(</span><span class="nam">input</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t996" href="#t996">996</a></span><span class="t">        <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t997" href="#t997">997</a></span><span class="t">            <span class="nam">x</span><span class="op">,</span> <span class="str">'input['</span> <span class="op">+</span> <span class="nam">str</span><span class="op">(</span><span class="nam">id</span><span class="op">)</span> <span class="op">+</span> <span class="str">']'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t998" href="#t998">998</a></span><span class="t">            <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t999" href="#t999">999</a></span><span class="t">            <span class="str">'partial_concat'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1000" href="#t1000">1000</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">start_index</span><span class="op">,</span> <span class="str">'start_index'</span><span class="op">,</span> <span class="op">(</span><span class="nam">int</span><span class="op">)</span><span class="op">,</span> <span class="str">'partial_concat'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1001" href="#t1001">1001</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">length</span><span class="op">,</span> <span class="str">'length'</span><span class="op">,</span> <span class="op">(</span><span class="nam">int</span><span class="op">)</span><span class="op">,</span> <span class="str">'partial_concat'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1002" href="#t1002">1002</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1003" href="#t1003">1003</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'start_index'</span><span class="op">:</span> <span class="nam">start_index</span><span class="op">,</span> <span class="str">'length'</span><span class="op">:</span> <span class="nam">length</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1004" href="#t1004">1004</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'partial_concat'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1005" href="#t1005">1005</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1006" href="#t1006">1006</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">'partial_concat'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1007" href="#t1007">1007</a></span><span class="t">                     <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1008" href="#t1008">1008</a></span><span class="t">                     <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="op">[</span><span class="nam">out</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1009" href="#t1009">1009</a></span><span class="t">                     <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1010" href="#t1010">1010</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1011" href="#t1011">1011</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1012" href="#t1012">1012</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1013" href="#t1013">1013</a></span><span class="t"><span class="key">def</span> <span class="nam">partial_sum</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">start_index</span><span class="op">=</span><span class="num">0</span><span class="op">,</span> <span class="nam">length</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1014" href="#t1014">1014</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1015" href="#t1015">1015</a></span><span class="t"><span class="str">    **PartialSum**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1016" href="#t1016">1016</a></span><span class="t"><span class="str">    This Op can sum the vars by specifying the initial position(start_index) and length(length).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1017" href="#t1017">1017</a></span><span class="t"><span class="str">    This Op exists in contrib, which means that it is not shown to the public.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1018" href="#t1018">1018</a></span><span class="t"><span class="str">    Only 2-D Tensor or LodTensor input is supported. Slice and concat can only be</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1019" href="#t1019">1019</a></span><span class="t"><span class="str">    performed along the second dimension.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1020" href="#t1020">1020</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1021" href="#t1021">1021</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1022" href="#t1022">1022</a></span><span class="t"><span class="str">        Given:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1023" href="#t1023">1023</a></span><span class="t"><span class="str">            x = [[0, 1, 2],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1024" href="#t1024">1024</a></span><span class="t"><span class="str">                 [3, 4, 5]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1025" href="#t1025">1025</a></span><span class="t"><span class="str">            y = [[6, 7 ,8],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1026" href="#t1026">1026</a></span><span class="t"><span class="str">                 [9, 10, 11]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1027" href="#t1027">1027</a></span><span class="t"><span class="str">            output = partial_sum([x, y], start_index=0, length=2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1028" href="#t1028">1028</a></span><span class="t"><span class="str">          we get:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1029" href="#t1029">1029</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1030" href="#t1030">1030</a></span><span class="t"><span class="str">            output = [[6, 8],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1031" href="#t1031">1031</a></span><span class="t"><span class="str">                      [12, 14]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1032" href="#t1032">1032</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1033" href="#t1033">1033</a></span><span class="t"><span class="str">        input(list): List of input Tensors with data type float32, float64, int32,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1034" href="#t1034">1034</a></span><span class="t"><span class="str">            int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1035" href="#t1035">1035</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1036" href="#t1036">1036</a></span><span class="t"><span class="str">        Variable: A Tensor with the same data type as input's.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1037" href="#t1037">1037</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1038" href="#t1038">1038</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1039" href="#t1039">1039</a></span><span class="t"><span class="str">        import paddle.fluid.layers as layers</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1040" href="#t1040">1040</a></span><span class="t"><span class="str">        import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1041" href="#t1041">1041</a></span><span class="t"><span class="str">        import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1042" href="#t1042">1042</a></span><span class="t"><span class="str">        x = fluid.data(name="x", shape=[None, 3], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1043" href="#t1043">1043</a></span><span class="t"><span class="str">        y = fluid.data(name="y", shape=[None, 3], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1044" href="#t1044">1044</a></span><span class="t"><span class="str">        sum = layers.partial_sum([x,y], start_index=0, length=2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1045" href="#t1045">1045</a></span><span class="t"><span class="str">        place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1046" href="#t1046">1046</a></span><span class="t"><span class="str">        exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1047" href="#t1047">1047</a></span><span class="t"><span class="str">        xx = np.array([1,2,3,4,5,6]).reshape((2,3)).astype("float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1048" href="#t1048">1048</a></span><span class="t"><span class="str">        yy = np.array([6,5,4,4,5,6]).reshape((2,3)).astype("float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1049" href="#t1049">1049</a></span><span class="t"><span class="str">        out = exe.run(feed={"x":xx, "y":yy}, fetch_list=[sum])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1050" href="#t1050">1050</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1051" href="#t1051">1051</a></span><span class="t">    <span class="key">for</span> <span class="nam">id</span><span class="op">,</span> <span class="nam">x</span> <span class="key">in</span> <span class="nam">enumerate</span><span class="op">(</span><span class="nam">input</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1052" href="#t1052">1052</a></span><span class="t">        <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'input['</span> <span class="op">+</span> <span class="nam">str</span><span class="op">(</span><span class="nam">id</span><span class="op">)</span> <span class="op">+</span> <span class="str">']'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1053" href="#t1053">1053</a></span><span class="t">                                 <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1054" href="#t1054">1054</a></span><span class="t">                                 <span class="str">'partial_sum'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1055" href="#t1055">1055</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1056" href="#t1056">1056</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1057" href="#t1057">1057</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1058" href="#t1058">1058</a></span><span class="t">    <span class="nam">attrs</span><span class="op">[</span><span class="str">'start_index'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">start_index</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1059" href="#t1059">1059</a></span><span class="t">    <span class="nam">attrs</span><span class="op">[</span><span class="str">'length'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">length</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1060" href="#t1060">1060</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'partial_sum'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1061" href="#t1061">1061</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1062" href="#t1062">1062</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">'partial_sum'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1063" href="#t1063">1063</a></span><span class="t">                     <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1064" href="#t1064">1064</a></span><span class="t">                     <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="op">[</span><span class="nam">out</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1065" href="#t1065">1065</a></span><span class="t">                     <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1066" href="#t1066">1066</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1067" href="#t1067">1067</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1068" href="#t1068">1068</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1069" href="#t1069">1069</a></span><span class="t"><span class="key">def</span> <span class="nam">sparse_embedding</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1070" href="#t1070">1070</a></span><span class="t">                     <span class="nam">size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1071" href="#t1071">1071</a></span><span class="t">                     <span class="nam">padding_idx</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1072" href="#t1072">1072</a></span><span class="t">                     <span class="nam">is_test</span><span class="op">=</span><span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1073" href="#t1073">1073</a></span><span class="t">                     <span class="nam">entry</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1074" href="#t1074">1074</a></span><span class="t">                     <span class="nam">table_class</span><span class="op">=</span><span class="str">"MemorySparseTable"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1075" href="#t1075">1075</a></span><span class="t">                     <span class="nam">param_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1076" href="#t1076">1076</a></span><span class="t">                     <span class="nam">dtype</span><span class="op">=</span><span class="str">'float32'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1077" href="#t1077">1077</a></span><span class="t">                     <span class="nam">slot</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1078" href="#t1078">1078</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1079" href="#t1079">1079</a></span><span class="t"><span class="str">    :api_attr: Static Graph</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1080" href="#t1080">1080</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1081" href="#t1081">1081</a></span><span class="t"><span class="str">    The OP is used as the operator of the Embedding Lookup layer in the large-scale </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1082" href="#t1082">1082</a></span><span class="t"><span class="str">    sparse training of the parameter server mode, instead of using the paddle.nn.functional.embedding.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1083" href="#t1083">1083</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1084" href="#t1084">1084</a></span><span class="t"><span class="str">    The operator is used to lookup embeddings vector of ids provided by :attr:`input` . </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1085" href="#t1085">1085</a></span><span class="t"><span class="str">    It automatically constructs a 2D embedding matrix based on the input :attr:`size` </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1086" href="#t1086">1086</a></span><span class="t"><span class="str">    (vocab_size, emb_size) and :attr:`dtype` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1087" href="#t1087">1087</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1088" href="#t1088">1088</a></span><span class="t"><span class="str">    The shape of output Tensor is generated by appending an emb_size dimension to the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1089" href="#t1089">1089</a></span><span class="t"><span class="str">    last dimension of the input Tensor shape.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1090" href="#t1090">1090</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1091" href="#t1091">1091</a></span><span class="t"><span class="str">    **Note:** The id in :attr:`input` must satisfy :math:`0 =&lt; id &lt; size[0]` , otherwise </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1092" href="#t1092">1092</a></span><span class="t"><span class="str">    the program will throw an exception and exit.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1093" href="#t1093">1093</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1094" href="#t1094">1094</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1095" href="#t1095">1095</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1096" href="#t1096">1096</a></span><span class="t"><span class="str">        Case 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1097" href="#t1097">1097</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1098" href="#t1098">1098</a></span><span class="t"><span class="str">        input is a Tensor. padding_idx = -1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1099" href="#t1099">1099</a></span><span class="t"><span class="str">            input.data = [[1, 3], [2, 4], [4, 127]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1100" href="#t1100">1100</a></span><span class="t"><span class="str">            input.shape = [3, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1101" href="#t1101">1101</a></span><span class="t"><span class="str">        Given size = [128, 16]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1102" href="#t1102">1102</a></span><span class="t"><span class="str">        output is a Tensor:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1103" href="#t1103">1103</a></span><span class="t"><span class="str">            out.shape = [3, 2, 16]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1104" href="#t1104">1104</a></span><span class="t"><span class="str">            out.data = [[[0.129435295, 0.244512452, ..., 0.436322452],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1105" href="#t1105">1105</a></span><span class="t"><span class="str">                        [0.345421456, 0.524563927, ..., 0.144534654]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1106" href="#t1106">1106</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1107" href="#t1107">1107</a></span><span class="t"><span class="str">                        [[0.345249859, 0.124939536, ..., 0.194353745],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1108" href="#t1108">1108</a></span><span class="t"><span class="str">                        [0.945345345, 0.435394634, ..., 0.435345365]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1109" href="#t1109">1109</a></span><span class="t"><span class="str">                        </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1110" href="#t1110">1110</a></span><span class="t"><span class="str">                        [[0.945345345, 0.435394634, ..., 0.435345365],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1111" href="#t1111">1111</a></span><span class="t"><span class="str">                        [0.0,         0.0,         ..., 0.0        ]]]  # padding data</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1112" href="#t1112">1112</a></span><span class="t"><span class="str">        The input padding_idx is less than 0, it is automatically converted to padding_idx = -1 + 128 = 127</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1113" href="#t1113">1113</a></span><span class="t"><span class="str">        It will pad all-zero data when ids is 127.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1114" href="#t1114">1114</a></span><span class="t"><span class="str">        </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1115" href="#t1115">1115</a></span><span class="t"><span class="str">        Case 2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1116" href="#t1116">1116</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1117" href="#t1117">1117</a></span><span class="t"><span class="str">        input is a LoDTensor with 1-level LoD. padding_idx = 0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1118" href="#t1118">1118</a></span><span class="t"><span class="str">            input.lod = [[2, 3]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1119" href="#t1119">1119</a></span><span class="t"><span class="str">            input.data = [[1], [3], [2], [4], [0]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1120" href="#t1120">1120</a></span><span class="t"><span class="str">            input.shape = [5, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1121" href="#t1121">1121</a></span><span class="t"><span class="str">        Given size = [128, 16]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1122" href="#t1122">1122</a></span><span class="t"><span class="str">        output is a LoDTensor:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1123" href="#t1123">1123</a></span><span class="t"><span class="str">            out.lod = [[2, 3]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1124" href="#t1124">1124</a></span><span class="t"><span class="str">            out.shape = [5, 1, 16]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1125" href="#t1125">1125</a></span><span class="t"><span class="str">            out.data = [[[0.129435295, 0.244512452, ..., 0.436322452]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1126" href="#t1126">1126</a></span><span class="t"><span class="str">                        [[0.345421456, 0.524563927, ..., 0.144534654]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1127" href="#t1127">1127</a></span><span class="t"><span class="str">                        [[0.345249859, 0.124939536, ..., 0.194353745]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1128" href="#t1128">1128</a></span><span class="t"><span class="str">                        [[0.945345345, 0.435394634, ..., 0.435345365]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1129" href="#t1129">1129</a></span><span class="t"><span class="str">                        [[0.0,         0.0,         ..., 0.0        ]]]  # padding data</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1130" href="#t1130">1130</a></span><span class="t"><span class="str">        It will pad all-zero data when ids is 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1131" href="#t1131">1131</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1132" href="#t1132">1132</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1133" href="#t1133">1133</a></span><span class="t"><span class="str">        input(Variable): A Tensor or LoDTensor with type int64, which contains the id </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1134" href="#t1134">1134</a></span><span class="t"><span class="str">            information. The value of the input id should satisfy :math:`0&lt;= id &lt; size[0]` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1135" href="#t1135">1135</a></span><span class="t"><span class="str">        size(tuple|list): The shape of lookup table parameter (vocab_size, emb_size). It </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1136" href="#t1136">1136</a></span><span class="t"><span class="str">            should have two elements which indicates the size of the dictionary of embeddings </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1137" href="#t1137">1137</a></span><span class="t"><span class="str">            and the size of each embedding vector respectively. The initial parameter size </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1138" href="#t1138">1138</a></span><span class="t"><span class="str">            is 0 in the large-scale sparse scenario, which will gradually expand with the </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1139" href="#t1139">1139</a></span><span class="t"><span class="str">            training. So if vocab_size is temporarily useless, its value can be any integer.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1140" href="#t1140">1140</a></span><span class="t"><span class="str">            The emb_size is the dimensional configuration of the word embedding weight parameter.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1141" href="#t1141">1141</a></span><span class="t"><span class="str">        padding_idx(int|long|None, optional): padding_idx needs to be in the interval [-vocab_size, vocab_size). </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1142" href="#t1142">1142</a></span><span class="t"><span class="str">            If :math:`padding\_idx &lt; 0`, the :math:`padding\_idx` will automatically be converted</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1143" href="#t1143">1143</a></span><span class="t"><span class="str">            to :math:`vocab\_size + padding\_idx` . It will output all-zero padding data whenever </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1144" href="#t1144">1144</a></span><span class="t"><span class="str">            lookup encounters :math:`padding\_idx` in id. And the padding data will not be updated </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1145" href="#t1145">1145</a></span><span class="t"><span class="str">            while training. If set None, it makes no efe mfect to output. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1146" href="#t1146">1146</a></span><span class="t"><span class="str">        is_test(bool, optional): Training or prediction mode. In prediction mode (is_test=False), </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1147" href="#t1147">1147</a></span><span class="t"><span class="str">            the output is not initialized and created, and it is filled with 0 and returned. Default: False.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1148" href="#t1148">1148</a></span><span class="t"><span class="str">        entry(str, optional): Entry config with parameter server whose value is ProbabilityEntry, </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1149" href="#t1149">1149</a></span><span class="t"><span class="str">            CountFilterEntry or None. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1150" href="#t1150">1150</a></span><span class="t"><span class="str">        table_class(str, optional): The type of the sparse table. The value can be CommonSparseTable </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1151" href="#t1151">1151</a></span><span class="t"><span class="str">            or SSDSparseTable. The default is CommonSparseTable.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1152" href="#t1152">1152</a></span><span class="t"><span class="str">        param_attr(ParamAttr, optional): To specify the weight parameter property. Default: None, which means the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1153" href="#t1153">1153</a></span><span class="t"><span class="str">            default weight parameter property is used. In addition, user-defined or pre-trained word </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1154" href="#t1154">1154</a></span><span class="t"><span class="str">            vectors can be loaded with the :attr:`param_attr` parameter. The local word vector needs </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1155" href="#t1155">1155</a></span><span class="t"><span class="str">            to be transformed into numpy format, and the shape of local word vector should be consistent </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1156" href="#t1156">1156</a></span><span class="t"><span class="str">            with :attr:`size` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1157" href="#t1157">1157</a></span><span class="t"><span class="str">        dtype(str): It refers to the data type of output Tensor. It must be float32 or </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1158" href="#t1158">1158</a></span><span class="t"><span class="str">            float64. Default: float32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1159" href="#t1159">1159</a></span><span class="t"><span class="str">            </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1160" href="#t1160">1160</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1161" href="#t1161">1161</a></span><span class="t"><span class="str">        Variable: Embedding Tensor or LoDTensor mapped by input. The data type is the same as :attr:`dtype` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1162" href="#t1162">1162</a></span><span class="t"><span class="str">    </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1163" href="#t1163">1163</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1164" href="#t1164">1164</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1165" href="#t1165">1165</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1166" href="#t1166">1166</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1167" href="#t1167">1167</a></span><span class="t"><span class="str">            </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1168" href="#t1168">1168</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1169" href="#t1169">1169</a></span><span class="t"><span class="str">            sparse_feature_dim = 1024</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1170" href="#t1170">1170</a></span><span class="t"><span class="str">            embedding_size = 64</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1171" href="#t1171">1171</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1172" href="#t1172">1172</a></span><span class="t"><span class="str">            # Only when the feature appear more than 10 times or more will be participated in the training.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1173" href="#t1173">1173</a></span><span class="t"><span class="str">            entry = paddle.distributed.CountFilterEntry(10)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1174" href="#t1174">1174</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1175" href="#t1175">1175</a></span><span class="t"><span class="str">            input = paddle.static.data(name='ins', shape=[1], dtype='int64')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1176" href="#t1176">1176</a></span><span class="t"><span class="str">        </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1177" href="#t1177">1177</a></span><span class="t"><span class="str">            emb = paddle.static.nn.sparse_embedding(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1178" href="#t1178">1178</a></span><span class="t"><span class="str">                input=input,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1179" href="#t1179">1179</a></span><span class="t"><span class="str">                size=[sparse_feature_dim, embedding_size],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1180" href="#t1180">1180</a></span><span class="t"><span class="str">                is_test=False,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1181" href="#t1181">1181</a></span><span class="t"><span class="str">                entry=entry,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1182" href="#t1182">1182</a></span><span class="t"><span class="str">                param_attr=paddle.ParamAttr(name="SparseFeatFactors",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1183" href="#t1183">1183</a></span><span class="t"><span class="str">                initializer=paddle.nn.initializer.Uniform()))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1184" href="#t1184">1184</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1185" href="#t1185">1185</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1186" href="#t1186">1186</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1187" href="#t1187">1187</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'sparse_embedding'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1188" href="#t1188">1188</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1189" href="#t1189">1189</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'int64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1190" href="#t1190">1190</a></span><span class="t">                             <span class="str">'fluid.contrib.layers.sparse_embedding'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1191" href="#t1191">1191</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1192" href="#t1192">1192</a></span><span class="t">    <span class="nam">check_dtype</span><span class="op">(</span><span class="nam">dtype</span><span class="op">,</span> <span class="str">'dtype'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1193" href="#t1193">1193</a></span><span class="t">                <span class="str">'paddle.static.nn.sparse_embedding'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1194" href="#t1194">1194</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1195" href="#t1195">1195</a></span><span class="t">    <span class="nam">w</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span><span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">param_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1196" href="#t1196">1196</a></span><span class="t">                                <span class="nam">shape</span><span class="op">=</span><span class="nam">size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1197" href="#t1197">1197</a></span><span class="t">                                <span class="nam">type</span><span class="op">=</span><span class="nam">core</span><span class="op">.</span><span class="nam">VarDesc</span><span class="op">.</span><span class="nam">VarType</span><span class="op">.</span><span class="nam">SELECTED_ROWS</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1198" href="#t1198">1198</a></span><span class="t">                                <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1199" href="#t1199">1199</a></span><span class="t">                                <span class="nam">is_bias</span><span class="op">=</span><span class="key">False</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1200" href="#t1200">1200</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1201" href="#t1201">1201</a></span><span class="t">    <span class="nam">tmp</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1202" href="#t1202">1202</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1203" href="#t1203">1203</a></span><span class="t">    <span class="nam">padding_idx</span> <span class="op">=</span> <span class="op">-</span><span class="num">1</span> <span class="key">if</span> <span class="nam">padding_idx</span> <span class="key">is</span> <span class="key">None</span> <span class="key">else</span> <span class="nam">padding_idx</span> <span class="key">if</span> <span class="nam">padding_idx</span> <span class="op">>=</span> <span class="num">0</span> <span class="key">else</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1204" href="#t1204">1204</a></span><span class="t">        <span class="nam">size</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">+</span> <span class="nam">padding_idx</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1205" href="#t1205">1205</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1206" href="#t1206">1206</a></span><span class="t">    <span class="key">if</span> <span class="nam">table_class</span> <span class="key">not</span> <span class="key">in</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1207" href="#t1207">1207</a></span><span class="t">            <span class="str">"CommonSparseTable"</span><span class="op">,</span> <span class="str">"SSDSparseTable"</span><span class="op">,</span> <span class="str">"MemorySparseTable"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1208" href="#t1208">1208</a></span><span class="t">    <span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1209" href="#t1209">1209</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1210" href="#t1210">1210</a></span><span class="t">            <span class="str">"table_class must be in [CommonSparseTable, SSDSparseTable, MemorySparseTable]"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1211" href="#t1211">1211</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1212" href="#t1212">1212</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1213" href="#t1213">1213</a></span><span class="t">    <span class="nam">entry_str</span> <span class="op">=</span> <span class="str">"none"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1214" href="#t1214">1214</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1215" href="#t1215">1215</a></span><span class="t">    <span class="key">if</span> <span class="nam">entry</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1216" href="#t1216">1216</a></span><span class="t">        <span class="key">if</span> <span class="nam">entry</span><span class="op">.</span><span class="nam">__class__</span><span class="op">.</span><span class="nam">__name__</span> <span class="key">not</span> <span class="key">in</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1217" href="#t1217">1217</a></span><span class="t">                <span class="str">"ProbabilityEntry"</span><span class="op">,</span> <span class="str">"CountFilterEntry"</span><span class="op">,</span> <span class="str">"ShowClickEntry"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1218" href="#t1218">1218</a></span><span class="t">        <span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1219" href="#t1219">1219</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1220" href="#t1220">1220</a></span><span class="t">                <span class="str">"entry must be instance in [paddle.distributed.ProbabilityEntry, paddle.distributed.CountFilterEntry, paddle.distributed.ShowClickEntry]"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1221" href="#t1221">1221</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1222" href="#t1222">1222</a></span><span class="t">        <span class="nam">entry_str</span> <span class="op">=</span> <span class="nam">entry</span><span class="op">.</span><span class="nam">_to_attr</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1223" href="#t1223">1223</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1224" href="#t1224">1224</a></span><span class="t">    <span class="key">if</span> <span class="nam">slot</span> <span class="op">==</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1225" href="#t1225">1225</a></span><span class="t">        <span class="nam">slot</span> <span class="op">=</span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1226" href="#t1226">1226</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1227" href="#t1227">1227</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">'lookup_table'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1228" href="#t1228">1228</a></span><span class="t">                     <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1229" href="#t1229">1229</a></span><span class="t">                         <span class="str">'Ids'</span><span class="op">:</span> <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1230" href="#t1230">1230</a></span><span class="t">                         <span class="str">'W'</span><span class="op">:</span> <span class="nam">w</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1231" href="#t1231">1231</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1232" href="#t1232">1232</a></span><span class="t">                     <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">tmp</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1233" href="#t1233">1233</a></span><span class="t">                     <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1234" href="#t1234">1234</a></span><span class="t">                         <span class="str">'padding_idx'</span><span class="op">:</span> <span class="nam">padding_idx</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1235" href="#t1235">1235</a></span><span class="t">                         <span class="str">'is_sparse'</span><span class="op">:</span> <span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1236" href="#t1236">1236</a></span><span class="t">                         <span class="str">'is_distributed'</span><span class="op">:</span> <span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1237" href="#t1237">1237</a></span><span class="t">                         <span class="str">'remote_prefetch'</span><span class="op">:</span> <span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1238" href="#t1238">1238</a></span><span class="t">                         <span class="str">'is_test'</span><span class="op">:</span> <span class="nam">is_test</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1239" href="#t1239">1239</a></span><span class="t">                         <span class="str">'entry'</span><span class="op">:</span> <span class="nam">entry_str</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1240" href="#t1240">1240</a></span><span class="t">                         <span class="str">'table_class'</span><span class="op">:</span> <span class="nam">table_class</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1241" href="#t1241">1241</a></span><span class="t">                         <span class="str">'slot'</span><span class="op">:</span> <span class="nam">slot</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1242" href="#t1242">1242</a></span><span class="t">                     <span class="op">}</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1243" href="#t1243">1243</a></span><span class="t">    <span class="key">return</span> <span class="nam">tmp</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1244" href="#t1244">1244</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1245" href="#t1245">1245</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1246" href="#t1246">1246</a></span><span class="t"><span class="key">def</span> <span class="nam">tdm_child</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">node_nums</span><span class="op">,</span> <span class="nam">child_nums</span><span class="op">,</span> <span class="nam">param_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="str">'int32'</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1247" href="#t1247">1247</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1248" href="#t1248">1248</a></span><span class="t"><span class="str">    **Tdm Child**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1249" href="#t1249">1249</a></span><span class="t"><span class="str">     According to the input node_id on the given tree, return the corresponding child node_id and </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1250" href="#t1250">1250</a></span><span class="t"><span class="str">      whether child is a leaf node by leaf_mask value.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1251" href="#t1251">1251</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1252" href="#t1252">1252</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1253" href="#t1253">1253</a></span><span class="t"><span class="str">        Given:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1254" href="#t1254">1254</a></span><span class="t"><span class="str">            tree[[0], [1, 2], [3, 4], [5, 6]] # A binary tree with seven nodes</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1255" href="#t1255">1255</a></span><span class="t"><span class="str">            x = [[2], [3]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1256" href="#t1256">1256</a></span><span class="t"><span class="str">            node_nums = 7</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1257" href="#t1257">1257</a></span><span class="t"><span class="str">            child_nums = 2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1258" href="#t1258">1258</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1259" href="#t1259">1259</a></span><span class="t"><span class="str">          we get:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1260" href="#t1260">1260</a></span><span class="t"><span class="str">            child = [[5, 6],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1261" href="#t1261">1261</a></span><span class="t"><span class="str">                     [0, 0]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1262" href="#t1262">1262</a></span><span class="t"><span class="str">            leaf_mask = [[1, 1],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1263" href="#t1263">1263</a></span><span class="t"><span class="str">                         [0, 0]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1264" href="#t1264">1264</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1265" href="#t1265">1265</a></span><span class="t"><span class="str">        x(Variable): Variable contained the node_id information, dtype support int32/int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1266" href="#t1266">1266</a></span><span class="t"><span class="str">        node_nums(int): Number of total nodes.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1267" href="#t1267">1267</a></span><span class="t"><span class="str">        child_nums(int): Maximum number of child nodes per node.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1268" href="#t1268">1268</a></span><span class="t"><span class="str">        param_attr(ParamAttr): To specify the tdm-tree-info parameter property. Default: None, which means the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1269" href="#t1269">1269</a></span><span class="t"><span class="str">            default weight parameter property is used. See usage for details in: ref: `api_fluid_ParamAttr`, should</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1270" href="#t1270">1270</a></span><span class="t"><span class="str">            has shape(node_nums, 3 + child_nums), dtype support int32/int64. </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1271" href="#t1271">1271</a></span><span class="t"><span class="str">            The dimension[1] of tdm-tree-info contains the following: </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1272" href="#t1272">1272</a></span><span class="t"><span class="str">            1. Item_id(int, shape(1)), if node is a leaf node, give its item_id corresponding to node_id, else give 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1273" href="#t1273">1273</a></span><span class="t"><span class="str">            2. Layer_id(int, shape(1)), indicates which layer the node is on.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1274" href="#t1274">1274</a></span><span class="t"><span class="str">            3. Parent_id(int, shape(1)), node's parent node.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1275" href="#t1275">1275</a></span><span class="t"><span class="str">            4. Child_id(int, shape(child_nums)), all child node's node_id of this node should be given. </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1276" href="#t1276">1276</a></span><span class="t"><span class="str">            If the number of child nodes is insufficient, padding 0 until child nums equal to child_nums</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1277" href="#t1277">1277</a></span><span class="t"><span class="str">        dtype(str): The data type of output child and leaf_mask, support int32/int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1278" href="#t1278">1278</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1279" href="#t1279">1279</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1280" href="#t1280">1280</a></span><span class="t"><span class="str">        tuple: A tuple including input node's child(Variable) and leaf_mask(Variable). </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1281" href="#t1281">1281</a></span><span class="t"><span class="str">            If child is a leaf node, leaf_mask equal ot 1, otherwise equal to 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1282" href="#t1282">1282</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1283" href="#t1283">1283</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1284" href="#t1284">1284</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1285" href="#t1285">1285</a></span><span class="t"><span class="str">        import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1286" href="#t1286">1286</a></span><span class="t"><span class="str">        import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1287" href="#t1287">1287</a></span><span class="t"><span class="str">        x = fluid.data(name="x", shape=[None, 1], dtype="int32", lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1288" href="#t1288">1288</a></span><span class="t"><span class="str">        tree_info = [[0,0,0,1,2],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1289" href="#t1289">1289</a></span><span class="t"><span class="str">                     [0,1,0,3,4],[0,1,0,5,6],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1290" href="#t1290">1290</a></span><span class="t"><span class="str">                     [0,2,1,0,0],[1,2,1,0,0],[2,2,2,0,0],[3,2,2,0,0]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1291" href="#t1291">1291</a></span><span class="t"><span class="str">        tree_info_np = np.array(tree_info)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1292" href="#t1292">1292</a></span><span class="t"><span class="str">        tree_info_np = np.reshape(tree_info_np, (7,5))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1293" href="#t1293">1293</a></span><span class="t"><span class="str">        node_nums = 7</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1294" href="#t1294">1294</a></span><span class="t"><span class="str">        child_nums = 2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1295" href="#t1295">1295</a></span><span class="t"><span class="str">        child, leaf_mask  = fluid.contrib.layers.tdm_child(x, node_nums, child_nums,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1296" href="#t1296">1296</a></span><span class="t"><span class="str">                                param_attr=fluid.ParamAttr(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1297" href="#t1297">1297</a></span><span class="t"><span class="str">                                    initializer=fluid.initializer.NumpyArrayInitializer(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1298" href="#t1298">1298</a></span><span class="t"><span class="str">                                                                            tree_info_np)))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1299" href="#t1299">1299</a></span><span class="t"><span class="str">        place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1300" href="#t1300">1300</a></span><span class="t"><span class="str">        exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1301" href="#t1301">1301</a></span><span class="t"><span class="str">        exe.run(fluid.default_startup_program())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1302" href="#t1302">1302</a></span><span class="t"><span class="str">        xx = np.array([[2],[3]]).reshape((2,1)).astype("int32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1303" href="#t1303">1303</a></span><span class="t"><span class="str">        child_res, leaf_mask_res = exe.run(feed={"x":xx}, fetch_list=[child, leaf_mask])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1304" href="#t1304">1304</a></span><span class="t"><span class="str">     """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1305" href="#t1305">1305</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"tdm_child"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1306" href="#t1306">1306</a></span><span class="t">    <span class="nam">check_dtype</span><span class="op">(</span><span class="nam">dtype</span><span class="op">,</span> <span class="str">'dtype'</span><span class="op">,</span> <span class="op">[</span><span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1307" href="#t1307">1307</a></span><span class="t">                <span class="str">'fluid.contrib.layers.tdm_child'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1308" href="#t1308">1308</a></span><span class="t">    <span class="nam">c_dtype</span> <span class="op">=</span> <span class="nam">convert_np_dtype_to_dtype_</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1309" href="#t1309">1309</a></span><span class="t">    <span class="nam">tree_info</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span><span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">param_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1310" href="#t1310">1310</a></span><span class="t">                                        <span class="nam">shape</span><span class="op">=</span><span class="op">[</span><span class="nam">node_nums</span><span class="op">,</span> <span class="num">3</span> <span class="op">+</span> <span class="nam">child_nums</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1311" href="#t1311">1311</a></span><span class="t">                                        <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1312" href="#t1312">1312</a></span><span class="t">                                        <span class="nam">default_initializer</span><span class="op">=</span><span class="nam">Constant</span><span class="op">(</span><span class="num">0</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1313" href="#t1313">1313</a></span><span class="t">    <span class="nam">tree_info</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1314" href="#t1314">1314</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1315" href="#t1315">1315</a></span><span class="t">    <span class="nam">child</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1316" href="#t1316">1316</a></span><span class="t">    <span class="nam">leaf_mask</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1317" href="#t1317">1317</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1318" href="#t1318">1318</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">'tdm_child'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1319" href="#t1319">1319</a></span><span class="t">                     <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1320" href="#t1320">1320</a></span><span class="t">                         <span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1321" href="#t1321">1321</a></span><span class="t">                         <span class="str">'TreeInfo'</span><span class="op">:</span> <span class="nam">tree_info</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1322" href="#t1322">1322</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1323" href="#t1323">1323</a></span><span class="t">                     <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1324" href="#t1324">1324</a></span><span class="t">                         <span class="str">'Child'</span><span class="op">:</span> <span class="nam">child</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1325" href="#t1325">1325</a></span><span class="t">                         <span class="str">'LeafMask'</span><span class="op">:</span> <span class="nam">leaf_mask</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1326" href="#t1326">1326</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1327" href="#t1327">1327</a></span><span class="t">                     <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1328" href="#t1328">1328</a></span><span class="t">                         <span class="str">'child_nums'</span><span class="op">:</span> <span class="nam">child_nums</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1329" href="#t1329">1329</a></span><span class="t">                         <span class="str">'dtype'</span><span class="op">:</span> <span class="nam">c_dtype</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1330" href="#t1330">1330</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1331" href="#t1331">1331</a></span><span class="t">                     <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1332" href="#t1332">1332</a></span><span class="t">    <span class="key">return</span> <span class="op">(</span><span class="nam">child</span><span class="op">,</span> <span class="nam">leaf_mask</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1333" href="#t1333">1333</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1334" href="#t1334">1334</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1335" href="#t1335">1335</a></span><span class="t"><span class="key">def</span> <span class="nam">tdm_sampler</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1336" href="#t1336">1336</a></span><span class="t">                <span class="nam">neg_samples_num_list</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1337" href="#t1337">1337</a></span><span class="t">                <span class="nam">layer_node_num_list</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1338" href="#t1338">1338</a></span><span class="t">                <span class="nam">leaf_node_num</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1339" href="#t1339">1339</a></span><span class="t">                <span class="nam">tree_travel_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1340" href="#t1340">1340</a></span><span class="t">                <span class="nam">tree_layer_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1341" href="#t1341">1341</a></span><span class="t">                <span class="nam">output_positive</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1342" href="#t1342">1342</a></span><span class="t">                <span class="nam">output_list</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1343" href="#t1343">1343</a></span><span class="t">                <span class="nam">seed</span><span class="op">=</span><span class="num">0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1344" href="#t1344">1344</a></span><span class="t">                <span class="nam">tree_dtype</span><span class="op">=</span><span class="str">'int32'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1345" href="#t1345">1345</a></span><span class="t">                <span class="nam">dtype</span><span class="op">=</span><span class="str">'int32'</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1346" href="#t1346">1346</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1347" href="#t1347">1347</a></span><span class="t"><span class="str">    **Tdm Sampler**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1348" href="#t1348">1348</a></span><span class="t"><span class="str">    According to the input positive samples at leaf node(x), do negative sampling layer by layer on the given tree.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1349" href="#t1349">1349</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1350" href="#t1350">1350</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1351" href="#t1351">1351</a></span><span class="t"><span class="str">        Given:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1352" href="#t1352">1352</a></span><span class="t"><span class="str">            tree[[0], [1, 2], [3, 4], [5, 6]] # A binary tree with seven nodes</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1353" href="#t1353">1353</a></span><span class="t"><span class="str">            travel_list = [[1, 3], [1, 4], [2, 5], [2, 6]] # leaf node's travel path (exclude root node)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1354" href="#t1354">1354</a></span><span class="t"><span class="str">            layer_list = [[1, 2], [3, 4, 5, 6]] # two layer (exclude root node)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1355" href="#t1355">1355</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1356" href="#t1356">1356</a></span><span class="t"><span class="str">            x = [[0], [1], [2], [3]] # Corresponding to leaf node [[3], [4], [5], [6]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1357" href="#t1357">1357</a></span><span class="t"><span class="str">            neg_samples_num_list = [0, 0] # negative sample nums = 0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1358" href="#t1358">1358</a></span><span class="t"><span class="str">            layer_node_num_list = [2, 4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1359" href="#t1359">1359</a></span><span class="t"><span class="str">            leaf_node_num = 4</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1360" href="#t1360">1360</a></span><span class="t"><span class="str">            output_list = False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1361" href="#t1361">1361</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1362" href="#t1362">1362</a></span><span class="t"><span class="str">          we get:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1363" href="#t1363">1363</a></span><span class="t"><span class="str">            out = [[1, 3], [1, 4], [2, 5], [2, 6]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1364" href="#t1364">1364</a></span><span class="t"><span class="str">            labels = [[1, 1], [1, 1], [1, 1], [1, 1]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1365" href="#t1365">1365</a></span><span class="t"><span class="str">            mask = [[1, 1], [1, 1], [1, 1], [1, 1]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1366" href="#t1366">1366</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1367" href="#t1367">1367</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1368" href="#t1368">1368</a></span><span class="t"><span class="str">        x (Variable): Variable contained the item_id(corresponding to leaf node) information, dtype support int32/int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1369" href="#t1369">1369</a></span><span class="t"><span class="str">        neg_samples_num_list (list(int)): Number of negative samples per layer.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1370" href="#t1370">1370</a></span><span class="t"><span class="str">        layer_node_num_list (list(int)): Number of nodes per layer, must has same shape with neg_samples_num_list.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1371" href="#t1371">1371</a></span><span class="t"><span class="str">        leaf_node_num (int): Number of leaf nodes.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1372" href="#t1372">1372</a></span><span class="t"><span class="str">        tree_travel_attr (ParamAttr): To specify the tdm-travel parameter property. Default: None, which means the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1373" href="#t1373">1373</a></span><span class="t"><span class="str">            default weight parameter property is used. See usage for details in :ref:`api_fluid_ParamAttr`, should </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1374" href="#t1374">1374</a></span><span class="t"><span class="str">            has shape (leaf_node_num, len(layer_node_num_list)), dtype support int32/int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1375" href="#t1375">1375</a></span><span class="t"><span class="str">        tree_layer_attr (ParamAttr): To specify the tdm-layer parameter property. Default: None, which means the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1376" href="#t1376">1376</a></span><span class="t"><span class="str">            default weight parameter property is used. See usage for details in :ref:`api_fluid_ParamAttr`, should </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1377" href="#t1377">1377</a></span><span class="t"><span class="str">            has shape (node_num, 1), dtype support int32/int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1378" href="#t1378">1378</a></span><span class="t"><span class="str">        output_positive (bool): Whether to output positive samples (includ label and mask )at the same time.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1379" href="#t1379">1379</a></span><span class="t"><span class="str">        output_list (bool): Whether to divide the output into layers and organize it into list format.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1380" href="#t1380">1380</a></span><span class="t"><span class="str">        seed (int): The number of random seed.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1381" href="#t1381">1381</a></span><span class="t"><span class="str">        tree_dtype(np.dtype|core.VarDesc.VarType|str): The dtype of tdm-travel and tdm-layer, support int32/int64</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1382" href="#t1382">1382</a></span><span class="t"><span class="str">        dtype(np.dtype|core.VarDesc.VarType|str): The dtype of output(sampling results, labels and masks) </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1383" href="#t1383">1383</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1384" href="#t1384">1384</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1385" href="#t1385">1385</a></span><span class="t"><span class="str">        tuple: A tuple including sampling results, corresponding labels and masks. if output_positive = True, sampling</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1386" href="#t1386">1386</a></span><span class="t"><span class="str">            result  will include both positive and negative samples. If sampling reseult is a positive sample, the label is 1, </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1387" href="#t1387">1387</a></span><span class="t"><span class="str">            and if it is a negative sample, it is 0. If the tree is unbalanced, in order to ensure the consistency of the </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1388" href="#t1388">1388</a></span><span class="t"><span class="str">            sampling result shape, the padding sample's mask = 0, the real sample's mask value = 1. </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1389" href="#t1389">1389</a></span><span class="t"><span class="str">            If output_list = True, the result will organize into list format specified by layer information.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1390" href="#t1390">1390</a></span><span class="t"><span class="str">            Output variable have same type with tdm-travel and tdm-layer parameter(tree_dtype).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1391" href="#t1391">1391</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1392" href="#t1392">1392</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1393" href="#t1393">1393</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1394" href="#t1394">1394</a></span><span class="t"><span class="str">        import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1395" href="#t1395">1395</a></span><span class="t"><span class="str">        import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1396" href="#t1396">1396</a></span><span class="t"><span class="str">        x = fluid.data(name="x", shape=[None, 1], dtype="int32", lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1397" href="#t1397">1397</a></span><span class="t"><span class="str">        travel_list = [[1, 3], [1, 4], [2, 5], [2, 6]] # leaf node's travel path, shape(leaf_node_num, layer_num)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1398" href="#t1398">1398</a></span><span class="t"><span class="str">        layer_list_flat = [[1], [2], [3], [4], [5], [6]] # shape(node_nums, 1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1399" href="#t1399">1399</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1400" href="#t1400">1400</a></span><span class="t"><span class="str">        neg_samples_num_list = [0, 0] # negative sample nums = 0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1401" href="#t1401">1401</a></span><span class="t"><span class="str">        layer_node_num_list = [2, 4] #two layer (exclude root node)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1402" href="#t1402">1402</a></span><span class="t"><span class="str">        leaf_node_num = 4</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1403" href="#t1403">1403</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1404" href="#t1404">1404</a></span><span class="t"><span class="str">        travel_array = np.array(travel_list)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1405" href="#t1405">1405</a></span><span class="t"><span class="str">        layer_array = np.array(layer_list_flat)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1406" href="#t1406">1406</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1407" href="#t1407">1407</a></span><span class="t"><span class="str">        sample, label, mask = fluid.contrib.layers.tdm_sampler(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1408" href="#t1408">1408</a></span><span class="t"><span class="str">            x,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1409" href="#t1409">1409</a></span><span class="t"><span class="str">            neg_samples_num_list,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1410" href="#t1410">1410</a></span><span class="t"><span class="str">            layer_node_num_list,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1411" href="#t1411">1411</a></span><span class="t"><span class="str">            leaf_node_num,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1412" href="#t1412">1412</a></span><span class="t"><span class="str">            tree_travel_attr=fluid.ParamAttr(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1413" href="#t1413">1413</a></span><span class="t"><span class="str">                initializer=fluid.initializer.NumpyArrayInitializer(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1414" href="#t1414">1414</a></span><span class="t"><span class="str">                    travel_array)),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1415" href="#t1415">1415</a></span><span class="t"><span class="str">            tree_layer_attr=fluid.ParamAttr(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1416" href="#t1416">1416</a></span><span class="t"><span class="str">                initializer=fluid.initializer.NumpyArrayInitializer(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1417" href="#t1417">1417</a></span><span class="t"><span class="str">                    layer_array)),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1418" href="#t1418">1418</a></span><span class="t"><span class="str">            output_positive=True,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1419" href="#t1419">1419</a></span><span class="t"><span class="str">            output_list=True,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1420" href="#t1420">1420</a></span><span class="t"><span class="str">            seed=0,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1421" href="#t1421">1421</a></span><span class="t"><span class="str">            tree_dtype='int32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1422" href="#t1422">1422</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1423" href="#t1423">1423</a></span><span class="t"><span class="str">        place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1424" href="#t1424">1424</a></span><span class="t"><span class="str">        exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1425" href="#t1425">1425</a></span><span class="t"><span class="str">        exe.run(fluid.default_startup_program())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1426" href="#t1426">1426</a></span><span class="t"><span class="str">        xx = np.array([[0],[1]]).reshape((2,1)).astype("int32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1427" href="#t1427">1427</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1428" href="#t1428">1428</a></span><span class="t"><span class="str">        exe.run(feed={"x":xx})</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1429" href="#t1429">1429</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1430" href="#t1430">1430</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1431" href="#t1431">1431</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"tdm_sampler"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1432" href="#t1432">1432</a></span><span class="t">    <span class="nam">check_dtype</span><span class="op">(</span><span class="nam">tree_dtype</span><span class="op">,</span> <span class="str">'tree_dtype'</span><span class="op">,</span> <span class="op">[</span><span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1433" href="#t1433">1433</a></span><span class="t">                <span class="str">'fluid.contrib.layers.tdm_sampler'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1434" href="#t1434">1434</a></span><span class="t">    <span class="nam">check_dtype</span><span class="op">(</span><span class="nam">dtype</span><span class="op">,</span> <span class="str">'dtype'</span><span class="op">,</span> <span class="op">[</span><span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1435" href="#t1435">1435</a></span><span class="t">                <span class="str">'fluid.contrib.layers.tdm_sampler'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1436" href="#t1436">1436</a></span><span class="t">    <span class="nam">c_dtype</span> <span class="op">=</span> <span class="nam">convert_np_dtype_to_dtype_</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1437" href="#t1437">1437</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1438" href="#t1438">1438</a></span><span class="t">    <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">neg_samples_num_list</span><span class="op">)</span> <span class="op">!=</span> <span class="nam">len</span><span class="op">(</span><span class="nam">layer_node_num_list</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1439" href="#t1439">1439</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1440" href="#t1440">1440</a></span><span class="t">            <span class="str">"The shape of negative samples list must match the shape of layers. "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1441" href="#t1441">1441</a></span><span class="t">            <span class="str">"But received len of neg_samples_num_list: {},"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1442" href="#t1442">1442</a></span><span class="t">            <span class="str">"and len of layer_node_num_list: {}, please check your input."</span><span class="op">.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1443" href="#t1443">1443</a></span><span class="t">            <span class="nam">format</span><span class="op">(</span><span class="nam">len</span><span class="op">(</span><span class="nam">neg_samples_num_list</span><span class="op">)</span><span class="op">,</span> <span class="nam">len</span><span class="op">(</span><span class="nam">layer_node_num_list</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1444" href="#t1444">1444</a></span><span class="t">    <span class="key">assert</span> <span class="nam">leaf_node_num</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">,</span> <span class="str">"leaf_node_num should not be None here."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1445" href="#t1445">1445</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1446" href="#t1446">1446</a></span><span class="t">    <span class="nam">layer_nums</span> <span class="op">=</span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1447" href="#t1447">1447</a></span><span class="t">    <span class="nam">node_nums</span> <span class="op">=</span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1448" href="#t1448">1448</a></span><span class="t">    <span class="nam">tree_layer_offset_lod</span> <span class="op">=</span> <span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1449" href="#t1449">1449</a></span><span class="t">    <span class="key">for</span> <span class="nam">layer_idx</span><span class="op">,</span> <span class="nam">layer_node_num</span> <span class="key">in</span> <span class="nam">enumerate</span><span class="op">(</span><span class="nam">layer_node_num_list</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1450" href="#t1450">1450</a></span><span class="t">        <span class="nam">layer_nums</span> <span class="op">+=</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1451" href="#t1451">1451</a></span><span class="t">        <span class="nam">node_nums</span> <span class="op">+=</span> <span class="nam">layer_node_num</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1452" href="#t1452">1452</a></span><span class="t">        <span class="nam">tree_layer_offset_lod</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">node_nums</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1453" href="#t1453">1453</a></span><span class="t">        <span class="key">if</span> <span class="nam">neg_samples_num_list</span><span class="op">[</span><span class="nam">layer_idx</span><span class="op">]</span> <span class="op">>=</span> <span class="nam">layer_node_num_list</span><span class="op">[</span><span class="nam">layer_idx</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1454" href="#t1454">1454</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1455" href="#t1455">1455</a></span><span class="t">                <span class="str">"The number of negative samples must be less than the number of nodes "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1456" href="#t1456">1456</a></span><span class="t">                <span class="str">"in the layer {}, But received negative nums {}, and num of node at layer {} "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1457" href="#t1457">1457</a></span><span class="t">                <span class="str">"is {}, please check your input."</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1458" href="#t1458">1458</a></span><span class="t">                    <span class="nam">layer_idx</span><span class="op">,</span> <span class="nam">neg_samples_num_list</span><span class="op">[</span><span class="nam">layer_idx</span><span class="op">]</span><span class="op">,</span> <span class="nam">layer_idx</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1459" href="#t1459">1459</a></span><span class="t">                    <span class="nam">layer_node_num_list</span><span class="op">[</span><span class="nam">layer_idx</span><span class="op">]</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1460" href="#t1460">1460</a></span><span class="t">    <span class="key">assert</span> <span class="nam">leaf_node_num</span> <span class="op">&lt;</span> <span class="nam">node_nums</span><span class="op">,</span> <span class="str">"leaf_node_num must be less than total node nums."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1461" href="#t1461">1461</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1462" href="#t1462">1462</a></span><span class="t">    <span class="nam">travel_shape</span> <span class="op">=</span> <span class="op">[</span><span class="nam">leaf_node_num</span><span class="op">,</span> <span class="nam">layer_nums</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1463" href="#t1463">1463</a></span><span class="t">    <span class="nam">travel</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span><span class="nam">attr</span><span class="op">=</span><span class="nam">tree_travel_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1464" href="#t1464">1464</a></span><span class="t">                                     <span class="nam">shape</span><span class="op">=</span><span class="nam">travel_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1465" href="#t1465">1465</a></span><span class="t">                                     <span class="nam">dtype</span><span class="op">=</span><span class="nam">tree_dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1466" href="#t1466">1466</a></span><span class="t">                                     <span class="nam">default_initializer</span><span class="op">=</span><span class="nam">Constant</span><span class="op">(</span><span class="num">0</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1467" href="#t1467">1467</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1468" href="#t1468">1468</a></span><span class="t">    <span class="nam">layer_shape</span> <span class="op">=</span> <span class="op">[</span><span class="nam">node_nums</span><span class="op">,</span> <span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1469" href="#t1469">1469</a></span><span class="t">    <span class="nam">layer</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span><span class="nam">attr</span><span class="op">=</span><span class="nam">tree_layer_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1470" href="#t1470">1470</a></span><span class="t">                                    <span class="nam">shape</span><span class="op">=</span><span class="nam">layer_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1471" href="#t1471">1471</a></span><span class="t">                                    <span class="nam">dtype</span><span class="op">=</span><span class="nam">tree_dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1472" href="#t1472">1472</a></span><span class="t">                                    <span class="nam">default_initializer</span><span class="op">=</span><span class="nam">Constant</span><span class="op">(</span><span class="num">0</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1473" href="#t1473">1473</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1474" href="#t1474">1474</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1475" href="#t1475">1475</a></span><span class="t">    <span class="nam">out</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1476" href="#t1476">1476</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1477" href="#t1477">1477</a></span><span class="t">    <span class="nam">labels</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1478" href="#t1478">1478</a></span><span class="t">    <span class="nam">labels</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1479" href="#t1479">1479</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1480" href="#t1480">1480</a></span><span class="t">    <span class="nam">mask</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1481" href="#t1481">1481</a></span><span class="t">    <span class="nam">mask</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1482" href="#t1482">1482</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1483" href="#t1483">1483</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">'tdm_sampler'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1484" href="#t1484">1484</a></span><span class="t">                     <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1485" href="#t1485">1485</a></span><span class="t">                         <span class="str">"X"</span><span class="op">:</span> <span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1486" href="#t1486">1486</a></span><span class="t">                         <span class="str">"Travel"</span><span class="op">:</span> <span class="nam">travel</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1487" href="#t1487">1487</a></span><span class="t">                         <span class="str">"Layer"</span><span class="op">:</span> <span class="nam">layer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1488" href="#t1488">1488</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1489" href="#t1489">1489</a></span><span class="t">                     <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1490" href="#t1490">1490</a></span><span class="t">                         <span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1491" href="#t1491">1491</a></span><span class="t">                         <span class="str">'Labels'</span><span class="op">:</span> <span class="nam">labels</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1492" href="#t1492">1492</a></span><span class="t">                         <span class="str">'Mask'</span><span class="op">:</span> <span class="nam">mask</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1493" href="#t1493">1493</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1494" href="#t1494">1494</a></span><span class="t">                     <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1495" href="#t1495">1495</a></span><span class="t">                         <span class="str">'neg_samples_num_list'</span><span class="op">:</span> <span class="nam">neg_samples_num_list</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1496" href="#t1496">1496</a></span><span class="t">                         <span class="str">'output_positive'</span><span class="op">:</span> <span class="nam">output_positive</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1497" href="#t1497">1497</a></span><span class="t">                         <span class="str">'layer_offset_lod'</span><span class="op">:</span> <span class="nam">tree_layer_offset_lod</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1498" href="#t1498">1498</a></span><span class="t">                         <span class="str">'seed'</span><span class="op">:</span> <span class="nam">seed</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1499" href="#t1499">1499</a></span><span class="t">                         <span class="str">'dtype'</span><span class="op">:</span> <span class="nam">c_dtype</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1500" href="#t1500">1500</a></span><span class="t">                     <span class="op">}</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1501" href="#t1501">1501</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1502" href="#t1502">1502</a></span><span class="t">    <span class="key">if</span> <span class="nam">output_list</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1503" href="#t1503">1503</a></span><span class="t">        <span class="nam">output_list</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1504" href="#t1504">1504</a></span><span class="t">        <span class="nam">labels_list</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1505" href="#t1505">1505</a></span><span class="t">        <span class="nam">mask_list</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1506" href="#t1506">1506</a></span><span class="t">        <span class="nam">start_offset</span> <span class="op">=</span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1507" href="#t1507">1507</a></span><span class="t">        <span class="nam">positive_flag</span> <span class="op">=</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1508" href="#t1508">1508</a></span><span class="t">        <span class="key">if</span> <span class="key">not</span> <span class="nam">output_positive</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1509" href="#t1509">1509</a></span><span class="t">            <span class="nam">positive_flag</span> <span class="op">=</span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1510" href="#t1510">1510</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1511" href="#t1511">1511</a></span><span class="t">        <span class="key">for</span> <span class="nam">layer_sample_num</span> <span class="key">in</span> <span class="nam">neg_samples_num_list</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1512" href="#t1512">1512</a></span><span class="t">            <span class="nam">end_offset</span> <span class="op">=</span> <span class="nam">start_offset</span> <span class="op">+</span> <span class="xx">\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1513" href="#t1513">1513</a></span><span class="t">                <span class="nam">layer_sample_num</span> <span class="op">+</span> <span class="nam">positive_flag</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1514" href="#t1514">1514</a></span><span class="t">            <span class="nam">layer_samples</span> <span class="op">=</span> <span class="nam">slice</span><span class="op">(</span><span class="nam">out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1515" href="#t1515">1515</a></span><span class="t">                                  <span class="nam">axes</span><span class="op">=</span><span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1516" href="#t1516">1516</a></span><span class="t">                                  <span class="nam">starts</span><span class="op">=</span><span class="op">[</span><span class="nam">start_offset</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1517" href="#t1517">1517</a></span><span class="t">                                  <span class="nam">ends</span><span class="op">=</span><span class="op">[</span><span class="nam">end_offset</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1518" href="#t1518">1518</a></span><span class="t">            <span class="nam">layer_labels</span> <span class="op">=</span> <span class="nam">slice</span><span class="op">(</span><span class="nam">labels</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1519" href="#t1519">1519</a></span><span class="t">                                 <span class="nam">axes</span><span class="op">=</span><span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1520" href="#t1520">1520</a></span><span class="t">                                 <span class="nam">starts</span><span class="op">=</span><span class="op">[</span><span class="nam">start_offset</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1521" href="#t1521">1521</a></span><span class="t">                                 <span class="nam">ends</span><span class="op">=</span><span class="op">[</span><span class="nam">end_offset</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1522" href="#t1522">1522</a></span><span class="t">            <span class="nam">layer_mask</span> <span class="op">=</span> <span class="nam">slice</span><span class="op">(</span><span class="nam">mask</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1523" href="#t1523">1523</a></span><span class="t">                               <span class="nam">axes</span><span class="op">=</span><span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1524" href="#t1524">1524</a></span><span class="t">                               <span class="nam">starts</span><span class="op">=</span><span class="op">[</span><span class="nam">start_offset</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1525" href="#t1525">1525</a></span><span class="t">                               <span class="nam">ends</span><span class="op">=</span><span class="op">[</span><span class="nam">end_offset</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1526" href="#t1526">1526</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1527" href="#t1527">1527</a></span><span class="t">            <span class="nam">layer_samples</span> <span class="op">=</span> <span class="nam">reshape</span><span class="op">(</span><span class="nam">layer_samples</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1528" href="#t1528">1528</a></span><span class="t">                                    <span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="nam">layer_sample_num</span> <span class="op">+</span> <span class="nam">positive_flag</span><span class="op">,</span> <span class="num">1</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1529" href="#t1529">1529</a></span><span class="t">            <span class="nam">layer_samples</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1530" href="#t1530">1530</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1531" href="#t1531">1531</a></span><span class="t">            <span class="nam">layer_labels</span> <span class="op">=</span> <span class="nam">reshape</span><span class="op">(</span><span class="nam">layer_labels</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1532" href="#t1532">1532</a></span><span class="t">                                   <span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="nam">layer_sample_num</span> <span class="op">+</span> <span class="nam">positive_flag</span><span class="op">,</span> <span class="num">1</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1533" href="#t1533">1533</a></span><span class="t">            <span class="nam">layer_labels</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1534" href="#t1534">1534</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1535" href="#t1535">1535</a></span><span class="t">            <span class="nam">layer_mask</span> <span class="op">=</span> <span class="nam">reshape</span><span class="op">(</span><span class="nam">layer_mask</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1536" href="#t1536">1536</a></span><span class="t">                                 <span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="nam">layer_sample_num</span> <span class="op">+</span> <span class="nam">positive_flag</span><span class="op">,</span> <span class="num">1</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1537" href="#t1537">1537</a></span><span class="t">            <span class="nam">layer_mask</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1538" href="#t1538">1538</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1539" href="#t1539">1539</a></span><span class="t">            <span class="nam">output_list</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">layer_samples</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1540" href="#t1540">1540</a></span><span class="t">            <span class="nam">labels_list</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">layer_labels</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1541" href="#t1541">1541</a></span><span class="t">            <span class="nam">mask_list</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">layer_mask</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1542" href="#t1542">1542</a></span><span class="t">            <span class="nam">start_offset</span> <span class="op">=</span> <span class="nam">end_offset</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1543" href="#t1543">1543</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1544" href="#t1544">1544</a></span><span class="t">        <span class="nam">out</span> <span class="op">=</span> <span class="nam">output_list</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1545" href="#t1545">1545</a></span><span class="t">        <span class="nam">labels</span> <span class="op">=</span> <span class="nam">labels_list</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1546" href="#t1546">1546</a></span><span class="t">        <span class="nam">mask</span> <span class="op">=</span> <span class="nam">mask_list</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1547" href="#t1547">1547</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1548" href="#t1548">1548</a></span><span class="t">    <span class="key">return</span> <span class="op">(</span><span class="nam">out</span><span class="op">,</span> <span class="nam">labels</span><span class="op">,</span> <span class="nam">mask</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1549" href="#t1549">1549</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1550" href="#t1550">1550</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1551" href="#t1551">1551</a></span><span class="t"><span class="key">def</span> <span class="nam">rank_attention</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1552" href="#t1552">1552</a></span><span class="t">                   <span class="nam">rank_offset</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1553" href="#t1553">1553</a></span><span class="t">                   <span class="nam">rank_param_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1554" href="#t1554">1554</a></span><span class="t">                   <span class="nam">rank_param_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1555" href="#t1555">1555</a></span><span class="t">                   <span class="nam">max_rank</span><span class="op">=</span><span class="num">3</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1556" href="#t1556">1556</a></span><span class="t">                   <span class="nam">max_size</span><span class="op">=</span><span class="num">0</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1557" href="#t1557">1557</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1558" href="#t1558">1558</a></span><span class="t"><span class="str">    **Rank Attention layer**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1559" href="#t1559">1559</a></span><span class="t"><span class="str">    This Op can calculate rank attention between input and rank_param, and </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1560" href="#t1560">1560</a></span><span class="t"><span class="str">    rank_param gives the organization of data. Notice: It currently supports</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1561" href="#t1561">1561</a></span><span class="t"><span class="str">    GPU device.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1562" href="#t1562">1562</a></span><span class="t"><span class="str">    This Op exists in contrib, which means that it is not shown to the public.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1563" href="#t1563">1563</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1564" href="#t1564">1564</a></span><span class="t"><span class="str">        input: Tensor with data type float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1565" href="#t1565">1565</a></span><span class="t"><span class="str">        rank_offset: Tensor with data type int32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1566" href="#t1566">1566</a></span><span class="t"><span class="str">        rank_para_shape: The shape of rank_param.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1567" href="#t1567">1567</a></span><span class="t"><span class="str">        rank_param_attr: Attribute initializer of rank_param.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1568" href="#t1568">1568</a></span><span class="t"><span class="str">        max_rank: The max rank of input's ranks.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1569" href="#t1569">1569</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1570" href="#t1570">1570</a></span><span class="t"><span class="str">        Variable: A Tensor with the same data type as input's.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1571" href="#t1571">1571</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1572" href="#t1572">1572</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1573" href="#t1573">1573</a></span><span class="t"><span class="str">           import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1574" href="#t1574">1574</a></span><span class="t"><span class="str">           import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1575" href="#t1575">1575</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1576" href="#t1576">1576</a></span><span class="t"><span class="str">           input = fluid.data(name="input", shape=[None, 2], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1577" href="#t1577">1577</a></span><span class="t"><span class="str">           rank_offset = fluid.data(name="rank_offset", shape=[None, 7], dtype="int32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1578" href="#t1578">1578</a></span><span class="t"><span class="str">           out = fluid.contrib.layers.rank_attention(input=input,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1579" href="#t1579">1579</a></span><span class="t"><span class="str">                                                     rank_offset=rank_offset,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1580" href="#t1580">1580</a></span><span class="t"><span class="str">                                                     rank_param_shape=[18,3],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1581" href="#t1581">1581</a></span><span class="t"><span class="str">                                                     rank_param_attr=</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1582" href="#t1582">1582</a></span><span class="t"><span class="str">                                                       fluid.ParamAttr(learning_rate=1.0,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1583" href="#t1583">1583</a></span><span class="t"><span class="str">                                                                     name="ubm_rank_param.w_0",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1584" href="#t1584">1584</a></span><span class="t"><span class="str">                                                                     initializer=</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1585" href="#t1585">1585</a></span><span class="t"><span class="str">                                                                     fluid.initializer.Xavier(uniform=False)),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1586" href="#t1586">1586</a></span><span class="t"><span class="str">                                                      max_rank=3,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1587" href="#t1587">1587</a></span><span class="t"><span class="str">                                                      max_size=0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1588" href="#t1588">1588</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1589" href="#t1589">1589</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'rank_attention'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1590" href="#t1590">1590</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="nam">input_param_name</span><span class="op">=</span><span class="str">'input'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1591" href="#t1591">1591</a></span><span class="t">    <span class="nam">input_shape</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1592" href="#t1592">1592</a></span><span class="t">    <span class="key">assert</span> <span class="nam">input_shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span> <span class="op">*</span> <span class="nam">max_rank</span> <span class="op">*</span> <span class="nam">max_rank</span> <span class="op">==</span> <span class="nam">rank_param_shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1593" href="#t1593">1593</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1594" href="#t1594">1594</a></span><span class="t">    <span class="nam">rank_param</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span><span class="nam">attr</span><span class="op">=</span><span class="nam">rank_param_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1595" href="#t1595">1595</a></span><span class="t">                                         <span class="nam">shape</span><span class="op">=</span><span class="nam">rank_param_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1596" href="#t1596">1596</a></span><span class="t">                                         <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1597" href="#t1597">1597</a></span><span class="t">    <span class="nam">rank_param</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1598" href="#t1598">1598</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1599" href="#t1599">1599</a></span><span class="t">    <span class="nam">output</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1600" href="#t1600">1600</a></span><span class="t">    <span class="nam">input_help</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1601" href="#t1601">1601</a></span><span class="t">                                                           <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1602" href="#t1602">1602</a></span><span class="t">    <span class="nam">ins_rank</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1603" href="#t1603">1603</a></span><span class="t">                                                         <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1604" href="#t1604">1604</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1605" href="#t1605">1605</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">"rank_attention"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1606" href="#t1606">1606</a></span><span class="t">                     <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1607" href="#t1607">1607</a></span><span class="t">                         <span class="str">"X"</span><span class="op">:</span> <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1608" href="#t1608">1608</a></span><span class="t">                         <span class="str">"RankOffset"</span><span class="op">:</span> <span class="nam">rank_offset</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1609" href="#t1609">1609</a></span><span class="t">                         <span class="str">"RankParam"</span><span class="op">:</span> <span class="nam">rank_param</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1610" href="#t1610">1610</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1611" href="#t1611">1611</a></span><span class="t">                     <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1612" href="#t1612">1612</a></span><span class="t">                         <span class="str">"Out"</span><span class="op">:</span> <span class="nam">output</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1613" href="#t1613">1613</a></span><span class="t">                         <span class="str">"InputHelp"</span><span class="op">:</span> <span class="nam">input_help</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1614" href="#t1614">1614</a></span><span class="t">                         <span class="str">"InsRank"</span><span class="op">:</span> <span class="nam">ins_rank</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1615" href="#t1615">1615</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1616" href="#t1616">1616</a></span><span class="t">                     <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1617" href="#t1617">1617</a></span><span class="t">                         <span class="str">"MaxRank"</span><span class="op">:</span> <span class="nam">max_rank</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1618" href="#t1618">1618</a></span><span class="t">                         <span class="str">"MaxSize"</span><span class="op">:</span> <span class="nam">max_size</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1619" href="#t1619">1619</a></span><span class="t">                     <span class="op">}</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1620" href="#t1620">1620</a></span><span class="t">    <span class="key">return</span> <span class="nam">output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1621" href="#t1621">1621</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1622" href="#t1622">1622</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1623" href="#t1623">1623</a></span><span class="t"><span class="key">def</span> <span class="nam">batch_fc</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">param_size</span><span class="op">,</span> <span class="nam">param_attr</span><span class="op">,</span> <span class="nam">bias_size</span><span class="op">,</span> <span class="nam">bias_attr</span><span class="op">,</span> <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1624" href="#t1624">1624</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1625" href="#t1625">1625</a></span><span class="t"><span class="str">    **Batch FC layer**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1626" href="#t1626">1626</a></span><span class="t"><span class="str">    This Op can calculate BatchFC. This is similar to matmul op, </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1627" href="#t1627">1627</a></span><span class="t"><span class="str">    except that the bias and relu activation layers are added. </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1628" href="#t1628">1628</a></span><span class="t"><span class="str">    Notice: It currently supports GPU device.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1629" href="#t1629">1629</a></span><span class="t"><span class="str">    This Op exists in contrib, which means that it is not shown to the public.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1630" href="#t1630">1630</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1631" href="#t1631">1631</a></span><span class="t"><span class="str">        input: Tensor with data type float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1632" href="#t1632">1632</a></span><span class="t"><span class="str">        param_size: The size of w.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1633" href="#t1633">1633</a></span><span class="t"><span class="str">        param_attr: Attribute initializer of w.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1634" href="#t1634">1634</a></span><span class="t"><span class="str">        bias_size: The size of bias.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1635" href="#t1635">1635</a></span><span class="t"><span class="str">        bias_attr: Attribute initializer of bias.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1636" href="#t1636">1636</a></span><span class="t"><span class="str">        act: Activation to be applied to the output of this layer.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1637" href="#t1637">1637</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1638" href="#t1638">1638</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1639" href="#t1639">1639</a></span><span class="t"><span class="str">        Variable: A Tensor with the same data type as input's.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1640" href="#t1640">1640</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1641" href="#t1641">1641</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1642" href="#t1642">1642</a></span><span class="t"><span class="str">           import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1643" href="#t1643">1643</a></span><span class="t"><span class="str">           </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1644" href="#t1644">1644</a></span><span class="t"><span class="str">           input = fluid.data(name="input", shape=[16, 2, 3], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1645" href="#t1645">1645</a></span><span class="t"><span class="str">           out = fluid.contrib.layers.batch_fc(input=input,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1646" href="#t1646">1646</a></span><span class="t"><span class="str">                                               param_size=[16, 3, 10],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1647" href="#t1647">1647</a></span><span class="t"><span class="str">                                               param_attr=</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1648" href="#t1648">1648</a></span><span class="t"><span class="str">                                                 fluid.ParamAttr(learning_rate=1.0,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1649" href="#t1649">1649</a></span><span class="t"><span class="str">                                                               name="w_0",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1650" href="#t1650">1650</a></span><span class="t"><span class="str">                                                               initializer=</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1651" href="#t1651">1651</a></span><span class="t"><span class="str">                                                               fluid.initializer.Xavier(uniform=False)),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1652" href="#t1652">1652</a></span><span class="t"><span class="str">                                               bias_size=[16, 10],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1653" href="#t1653">1653</a></span><span class="t"><span class="str">                                               bias_attr=</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1654" href="#t1654">1654</a></span><span class="t"><span class="str">                                                 fluid.ParamAttr(learning_rate=1.0,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1655" href="#t1655">1655</a></span><span class="t"><span class="str">                                                               name="b_0",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1656" href="#t1656">1656</a></span><span class="t"><span class="str">                                                               initializer=</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1657" href="#t1657">1657</a></span><span class="t"><span class="str">                                                               fluid.initializer.Xavier(uniform=False)),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1658" href="#t1658">1658</a></span><span class="t"><span class="str">                                                   act="relu")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1659" href="#t1659">1659</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1660" href="#t1660">1660</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1661" href="#t1661">1661</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"batch_fc"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1662" href="#t1662">1662</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">(</span><span class="nam">Variable</span><span class="op">)</span><span class="op">,</span> <span class="str">'batch_fc'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1663" href="#t1663">1663</a></span><span class="t">    <span class="nam">input_shape</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1664" href="#t1664">1664</a></span><span class="t">    <span class="key">assert</span> <span class="nam">input_shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">==</span> <span class="nam">param_size</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1665" href="#t1665">1665</a></span><span class="t">    <span class="key">assert</span> <span class="nam">input_shape</span><span class="op">[</span><span class="num">2</span><span class="op">]</span> <span class="op">==</span> <span class="nam">param_size</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1666" href="#t1666">1666</a></span><span class="t">    <span class="key">assert</span> <span class="nam">param_size</span><span class="op">[</span><span class="num">2</span><span class="op">]</span> <span class="op">==</span> <span class="nam">bias_size</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1667" href="#t1667">1667</a></span><span class="t">    <span class="key">assert</span> <span class="nam">input_shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">==</span> <span class="nam">bias_size</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1668" href="#t1668">1668</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1669" href="#t1669">1669</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1670" href="#t1670">1670</a></span><span class="t">    <span class="nam">check_dtype</span><span class="op">(</span><span class="nam">dtype</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'batch_fc'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1671" href="#t1671">1671</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1672" href="#t1672">1672</a></span><span class="t">    <span class="nam">w</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span><span class="nam">attr</span><span class="op">=</span><span class="nam">param_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1673" href="#t1673">1673</a></span><span class="t">                                <span class="nam">shape</span><span class="op">=</span><span class="nam">param_size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1674" href="#t1674">1674</a></span><span class="t">                                <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1675" href="#t1675">1675</a></span><span class="t">                                <span class="nam">is_bias</span><span class="op">=</span><span class="key">False</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1676" href="#t1676">1676</a></span><span class="t">    <span class="nam">b</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span><span class="nam">attr</span><span class="op">=</span><span class="nam">bias_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1677" href="#t1677">1677</a></span><span class="t">                                <span class="nam">shape</span><span class="op">=</span><span class="nam">bias_size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1678" href="#t1678">1678</a></span><span class="t">                                <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1679" href="#t1679">1679</a></span><span class="t">                                <span class="nam">is_bias</span><span class="op">=</span><span class="key">False</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1680" href="#t1680">1680</a></span><span class="t">    <span class="nam">pre_act</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1681" href="#t1681">1681</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">"batch_fc"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1682" href="#t1682">1682</a></span><span class="t">                     <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1683" href="#t1683">1683</a></span><span class="t">                         <span class="str">"Input"</span><span class="op">:</span> <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1684" href="#t1684">1684</a></span><span class="t">                         <span class="str">"W"</span><span class="op">:</span> <span class="nam">w</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1685" href="#t1685">1685</a></span><span class="t">                         <span class="str">"Bias"</span><span class="op">:</span> <span class="nam">b</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1686" href="#t1686">1686</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1687" href="#t1687">1687</a></span><span class="t">                     <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">pre_act</span><span class="op">}</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1688" href="#t1688">1688</a></span><span class="t">    <span class="key">return</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_activation</span><span class="op">(</span><span class="nam">pre_act</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1689" href="#t1689">1689</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1690" href="#t1690">1690</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1691" href="#t1691">1691</a></span><span class="t"><span class="key">def</span> <span class="nam">_pull_box_extended_sparse</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">size</span><span class="op">,</span> <span class="nam">extend_size</span><span class="op">=</span><span class="num">64</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="str">'float32'</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1692" href="#t1692">1692</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1693" href="#t1693">1693</a></span><span class="t"><span class="str">    **Pull Box Extended Sparse Layer**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1694" href="#t1694">1694</a></span><span class="t"><span class="str">    This layer is used to lookup embeddings of IDs, provided by :attr:`input`, in</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1695" href="#t1695">1695</a></span><span class="t"><span class="str">    BoxPS lookup table. The result of this lookup is the embedding of each ID in the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1696" href="#t1696">1696</a></span><span class="t"><span class="str">    :attr:`input`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1697" href="#t1697">1697</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1698" href="#t1698">1698</a></span><span class="t"><span class="str">        input(Variable|list of Variable): Input is a Tensor&lt;int64> Variable, which</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1699" href="#t1699">1699</a></span><span class="t"><span class="str">            contains the IDs information.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1700" href="#t1700">1700</a></span><span class="t"><span class="str">        size(int): The embedding size parameter, which indicates the size of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1701" href="#t1701">1701</a></span><span class="t"><span class="str">            each embedding vector respectively.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1702" href="#t1702">1702</a></span><span class="t"><span class="str">        extend_size(int): The embedding size parameter in extended dim, </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1703" href="#t1703">1703</a></span><span class="t"><span class="str">            which indicates the size of each embedding vector respectively.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1704" href="#t1704">1704</a></span><span class="t"><span class="str">        dtype(str): The dtype refers to the data type of output tensor. Only supports</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1705" href="#t1705">1705</a></span><span class="t"><span class="str">      float32 now.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1706" href="#t1706">1706</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1707" href="#t1707">1707</a></span><span class="t"><span class="str">        Variable|list of Variable: The tensor variable storing the embeddings of the \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1708" href="#t1708">1708</a></span><span class="t"><span class="str">                  supplied inputs.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1709" href="#t1709">1709</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1710" href="#t1710">1710</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1711" href="#t1711">1711</a></span><span class="t"><span class="str">          import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1712" href="#t1712">1712</a></span><span class="t"><span class="str">          data = fluid.layers.data(name='sequence', shape=[1], dtype='int64', lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1713" href="#t1713">1713</a></span><span class="t"><span class="str">          emb, emb_ex = fluid.contrib.layers._pull_box_extended_sparse(input=data, size=8, extend_size=128)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1714" href="#t1714">1714</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1715" href="#t1715">1715</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'pull_box_extended_sparse'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1716" href="#t1716">1716</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1717" href="#t1717">1717</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">multiple_input</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1718" href="#t1718">1718</a></span><span class="t">    <span class="nam">outs</span> <span class="op">=</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1719" href="#t1719">1719</a></span><span class="t">        <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1720" href="#t1720">1720</a></span><span class="t">        <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">len</span><span class="op">(</span><span class="nam">inputs</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1721" href="#t1721">1721</a></span><span class="t">    <span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1722" href="#t1722">1722</a></span><span class="t">    <span class="nam">outs_extend</span> <span class="op">=</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1723" href="#t1723">1723</a></span><span class="t">        <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1724" href="#t1724">1724</a></span><span class="t">        <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">len</span><span class="op">(</span><span class="nam">inputs</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1725" href="#t1725">1725</a></span><span class="t">    <span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1726" href="#t1726">1726</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">'pull_box_extended_sparse'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1727" href="#t1727">1727</a></span><span class="t">                     <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Ids'</span><span class="op">:</span> <span class="nam">inputs</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1728" href="#t1728">1728</a></span><span class="t">                     <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1729" href="#t1729">1729</a></span><span class="t">                         <span class="str">'Out'</span><span class="op">:</span> <span class="nam">outs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1730" href="#t1730">1730</a></span><span class="t">                         <span class="str">'OutExtend'</span><span class="op">:</span> <span class="nam">outs_extend</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1731" href="#t1731">1731</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1732" href="#t1732">1732</a></span><span class="t">                     <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1733" href="#t1733">1733</a></span><span class="t">                         <span class="str">'emb_size'</span><span class="op">:</span> <span class="nam">size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1734" href="#t1734">1734</a></span><span class="t">                         <span class="str">'emb_extended_size'</span><span class="op">:</span> <span class="nam">extend_size</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1735" href="#t1735">1735</a></span><span class="t">                     <span class="op">}</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1736" href="#t1736">1736</a></span><span class="t">    <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">outs</span><span class="op">)</span> <span class="op">==</span> <span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1737" href="#t1737">1737</a></span><span class="t">        <span class="key">return</span> <span class="nam">outs</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span> <span class="nam">outs_extend</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1738" href="#t1738">1738</a></span><span class="t">    <span class="key">return</span> <span class="nam">outs</span><span class="op">,</span> <span class="nam">outs_extend</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1739" href="#t1739">1739</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1740" href="#t1740">1740</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1741" href="#t1741">1741</a></span><span class="t"><span class="key">def</span> <span class="nam">bilateral_slice</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">guide</span><span class="op">,</span> <span class="nam">grid</span><span class="op">,</span> <span class="nam">has_offset</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1742" href="#t1742">1742</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1743" href="#t1743">1743</a></span><span class="t"><span class="str">    :alias_main: paddle.nn.functional.bilateral_slice</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1744" href="#t1744">1744</a></span><span class="t"><span class="str">        :alias: paddle.nn.functional.bilateral_slice,paddle.nn.functional.vision.bilateral_slice</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1745" href="#t1745">1745</a></span><span class="t"><span class="str">        :old_api: paddle.fluid.layers.bilateral_slice</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1746" href="#t1746">1746</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1747" href="#t1747">1747</a></span><span class="t"><span class="str">    This operation implements bilateral slicing on the input according to the guide map.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1748" href="#t1748">1748</a></span><span class="t"><span class="str">    For more information of bilateral slicing, please refer to Deep Bilateral Learning for Real-Time Image Enhancement &lt;https://groups.csail.mit.edu/graphics/hdrnet/data/hdrnet.pdf>_</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1749" href="#t1749">1749</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1750" href="#t1750">1750</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1751" href="#t1751">1751</a></span><span class="t"><span class="str">        x(Variable): The input tensor, which is a 4-D tensor with shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1752" href="#t1752">1752</a></span><span class="t"><span class="str">                     [N, C, H, W], N is the batch size, C is the channel</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1753" href="#t1753">1753</a></span><span class="t"><span class="str">                     number, H and W is the feature height and width.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1754" href="#t1754">1754</a></span><span class="t"><span class="str">                     The data type is float32 and float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1755" href="#t1755">1755</a></span><span class="t"><span class="str">        guide(Variable): Input grid tensor of shape [N, H, W]. The</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1756" href="#t1756">1756</a></span><span class="t"><span class="str">                        data type is float32 and float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1757" href="#t1757">1757</a></span><span class="t"><span class="str">        grid(Variable): Input grid tensor of shape [N, C, D, H, W]. The</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1758" href="#t1758">1758</a></span><span class="t"><span class="str">                        data type is float32 and float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1759" href="#t1759">1759</a></span><span class="t"><span class="str">        has_offset(bool): Whether to slice with affine offset.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1760" href="#t1760">1760</a></span><span class="t"><span class="str">        name(str, optional): For detailed information, please refer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1761" href="#t1761">1761</a></span><span class="t"><span class="str">                             to :ref:`api_guide_Name`. Usually name is no need to set and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1762" href="#t1762">1762</a></span><span class="t"><span class="str">                             None by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1763" href="#t1763">1763</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1764" href="#t1764">1764</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1765" href="#t1765">1765</a></span><span class="t"><span class="str">        Variable: Output of shape [N, C, H, W]. The data type is same as input tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1766" href="#t1766">1766</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1767" href="#t1767">1767</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1768" href="#t1768">1768</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1769" href="#t1769">1769</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1770" href="#t1770">1770</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1771" href="#t1771">1771</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1772" href="#t1772">1772</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1773" href="#t1773">1773</a></span><span class="t"><span class="str">            x = fluid.data(name='x', shape=[None, 3, 101, 60], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1774" href="#t1774">1774</a></span><span class="t"><span class="str">            guide = fluid.data(name='guide', shape=[None, 101, 60], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1775" href="#t1775">1775</a></span><span class="t"><span class="str">            grid = fluid.data(name='grid', shape=[None, 12, 8, 10, 6], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1776" href="#t1776">1776</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1777" href="#t1777">1777</a></span><span class="t"><span class="str">            # without offset</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1778" href="#t1778">1778</a></span><span class="t"><span class="str">            output = fluid.contrib.bilateral_slice(x, guide, grid, has_offset=False)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1779" href="#t1779">1779</a></span><span class="t"><span class="str">            </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1780" href="#t1780">1780</a></span><span class="t"><span class="str">            # has offset</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1781" href="#t1781">1781</a></span><span class="t"><span class="str">            output = fluid.contrib.bilateral_slice(x, guide, grid, has_offset=True)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1782" href="#t1782">1782</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1783" href="#t1783">1783</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1784" href="#t1784">1784</a></span><span class="t">    <span class="key">if</span> <span class="nam">paddle</span><span class="op">.</span><span class="nam">fluid</span><span class="op">.</span><span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1785" href="#t1785">1785</a></span><span class="t">        <span class="nam">attrs</span> <span class="op">=</span> <span class="op">(</span><span class="str">'has_offset'</span><span class="op">,</span> <span class="nam">has_offset</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1786" href="#t1786">1786</a></span><span class="t">        <span class="key">return</span> <span class="nam">getattr</span><span class="op">(</span><span class="nam">_legacy_C_ops</span><span class="op">,</span> <span class="str">"bilateral_slice"</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">grid</span><span class="op">,</span> <span class="nam">guide</span><span class="op">,</span> <span class="op">*</span><span class="nam">attrs</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1787" href="#t1787">1787</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1788" href="#t1788">1788</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'bilateral_slice'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1789" href="#t1789">1789</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">guide</span><span class="op">,</span> <span class="str">'guide'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1790" href="#t1790">1790</a></span><span class="t">                             <span class="str">'bilateral_slice'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1791" href="#t1791">1791</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">grid</span><span class="op">,</span> <span class="str">'grid'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1792" href="#t1792">1792</a></span><span class="t">                             <span class="str">'bilateral_slice'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1793" href="#t1793">1793</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"bilateral_slice"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1794" href="#t1794">1794</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1795" href="#t1795">1795</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">,</span> <span class="str">'Guide'</span><span class="op">:</span> <span class="nam">guide</span><span class="op">,</span> <span class="str">'Grid'</span><span class="op">:</span> <span class="nam">grid</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1796" href="#t1796">1796</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">'bilateral_slice'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1797" href="#t1797">1797</a></span><span class="t">                     <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1798" href="#t1798">1798</a></span><span class="t">                     <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'has_offset'</span><span class="op">:</span> <span class="nam">has_offset</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1799" href="#t1799">1799</a></span><span class="t">                     <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1800" href="#t1800">1800</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1801" href="#t1801">1801</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1802" href="#t1802">1802</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1803" href="#t1803">1803</a></span><span class="t"><span class="key">def</span> <span class="nam">correlation</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1804" href="#t1804">1804</a></span><span class="t">                <span class="nam">y</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1805" href="#t1805">1805</a></span><span class="t">                <span class="nam">pad_size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1806" href="#t1806">1806</a></span><span class="t">                <span class="nam">kernel_size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1807" href="#t1807">1807</a></span><span class="t">                <span class="nam">max_displacement</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1808" href="#t1808">1808</a></span><span class="t">                <span class="nam">stride1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1809" href="#t1809">1809</a></span><span class="t">                <span class="nam">stride2</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1810" href="#t1810">1810</a></span><span class="t">                <span class="nam">corr_type_multiply</span><span class="op">=</span><span class="num">1</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1811" href="#t1811">1811</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1812" href="#t1812">1812</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1813" href="#t1813">1813</a></span><span class="t"><span class="str">    This operation compute correlation of two tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1814" href="#t1814">1814</a></span><span class="t"><span class="str">    For more information of correlation, please refer to PWC-Net: </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1815" href="#t1815">1815</a></span><span class="t"><span class="str">    CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1816" href="#t1816">1816</a></span><span class="t"><span class="str">    &lt;https://arxiv.org/pdf/1709.02371.pdf>_</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1817" href="#t1817">1817</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1818" href="#t1818">1818</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1819" href="#t1819">1819</a></span><span class="t"><span class="str">        x(Tensor): The input x is 4-D Tensor with shape [N, C, H, W]. The data type is float32 and float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1820" href="#t1820">1820</a></span><span class="t"><span class="str">        y(Tensor): The input y is 4-D Tensor with shape [N, C, H, W]. The data type is float32 and float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1821" href="#t1821">1821</a></span><span class="t"><span class="str">        pad_size(int): Pad size. The data type is int.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1822" href="#t1822">1822</a></span><span class="t"><span class="str">        max_displacement(int): Max displacement. The data type is int.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1823" href="#t1823">1823</a></span><span class="t"><span class="str">        stride1(int): stride size of x. The data type is int.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1824" href="#t1824">1824</a></span><span class="t"><span class="str">        stride2(int): stride size of y. The data type is int.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1825" href="#t1825">1825</a></span><span class="t"><span class="str">        corr_type_multiply(int, optional): The type of multiply. The data type is int. Default: 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1826" href="#t1826">1826</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1827" href="#t1827">1827</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1828" href="#t1828">1828</a></span><span class="t"><span class="str">        Tensor: The data type is same as input tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1829" href="#t1829">1829</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1830" href="#t1830">1830</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1831" href="#t1831">1831</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1832" href="#t1832">1832</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1833" href="#t1833">1833</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1834" href="#t1834">1834</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1835" href="#t1835">1835</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1836" href="#t1836">1836</a></span><span class="t"><span class="str">            x1 = fluid.layers.data(name='x1',</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1837" href="#t1837">1837</a></span><span class="t"><span class="str">                               shape=x_shape,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1838" href="#t1838">1838</a></span><span class="t"><span class="str">                               dtype=x_type,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1839" href="#t1839">1839</a></span><span class="t"><span class="str">                               append_batch_size=False)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1840" href="#t1840">1840</a></span><span class="t"><span class="str">            x2 = fluid.layers.data(name='x2',</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1841" href="#t1841">1841</a></span><span class="t"><span class="str">                                shape=x_shape,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1842" href="#t1842">1842</a></span><span class="t"><span class="str">                                dtype=x_type,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1843" href="#t1843">1843</a></span><span class="t"><span class="str">                                append_batch_size=False)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1844" href="#t1844">1844</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1845" href="#t1845">1845</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1846" href="#t1846">1846</a></span><span class="t"><span class="str">            out = fluid.contrib.correlation(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1847" href="#t1847">1847</a></span><span class="t"><span class="str">                            x1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1848" href="#t1848">1848</a></span><span class="t"><span class="str">                            x2,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1849" href="#t1849">1849</a></span><span class="t"><span class="str">                            pad_size=4,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1850" href="#t1850">1850</a></span><span class="t"><span class="str">                            kernel_size=1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1851" href="#t1851">1851</a></span><span class="t"><span class="str">                            max_displacement=4,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1852" href="#t1852">1852</a></span><span class="t"><span class="str">                            stride1=1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1853" href="#t1853">1853</a></span><span class="t"><span class="str">                            stride2=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1854" href="#t1854">1854</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1855" href="#t1855">1855</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1856" href="#t1856">1856</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1857" href="#t1857">1857</a></span><span class="t">    <span class="key">if</span> <span class="nam">paddle</span><span class="op">.</span><span class="nam">fluid</span><span class="op">.</span><span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1858" href="#t1858">1858</a></span><span class="t">        <span class="nam">attrs</span> <span class="op">=</span> <span class="op">(</span><span class="str">"pad_size"</span><span class="op">,</span> <span class="nam">pad_size</span><span class="op">,</span> <span class="str">"kernel_size"</span><span class="op">,</span> <span class="nam">kernel_size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1859" href="#t1859">1859</a></span><span class="t">                 <span class="str">"max_displacement"</span><span class="op">,</span> <span class="nam">max_displacement</span><span class="op">,</span> <span class="str">"stride1"</span><span class="op">,</span> <span class="nam">stride1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1860" href="#t1860">1860</a></span><span class="t">                 <span class="str">"stride2"</span><span class="op">,</span> <span class="nam">stride2</span><span class="op">,</span> <span class="str">"corr_type_multiply"</span><span class="op">,</span> <span class="nam">corr_type_multiply</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1861" href="#t1861">1861</a></span><span class="t">        <span class="nam">output</span> <span class="op">=</span> <span class="nam">getattr</span><span class="op">(</span><span class="nam">_legacy_C_ops</span><span class="op">,</span> <span class="str">"correlation"</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="op">*</span><span class="nam">attrs</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1862" href="#t1862">1862</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1863" href="#t1863">1863</a></span><span class="t">        <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"correlation"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1864" href="#t1864">1864</a></span><span class="t">        <span class="nam">output</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1865" href="#t1865">1865</a></span><span class="t">        <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">"correlation"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1866" href="#t1866">1866</a></span><span class="t">                         <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1867" href="#t1867">1867</a></span><span class="t">                             <span class="str">"Input1"</span><span class="op">:</span> <span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1868" href="#t1868">1868</a></span><span class="t">                             <span class="str">"Input2"</span><span class="op">:</span> <span class="nam">y</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1869" href="#t1869">1869</a></span><span class="t">                         <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1870" href="#t1870">1870</a></span><span class="t">                         <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1871" href="#t1871">1871</a></span><span class="t">                             <span class="str">"pad_size"</span><span class="op">:</span> <span class="nam">pad_size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1872" href="#t1872">1872</a></span><span class="t">                             <span class="str">"kernel_size"</span><span class="op">:</span> <span class="nam">kernel_size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1873" href="#t1873">1873</a></span><span class="t">                             <span class="str">"max_displacement"</span><span class="op">:</span> <span class="nam">max_displacement</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1874" href="#t1874">1874</a></span><span class="t">                             <span class="str">"stride1"</span><span class="op">:</span> <span class="nam">stride1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1875" href="#t1875">1875</a></span><span class="t">                             <span class="str">"stride2"</span><span class="op">:</span> <span class="nam">stride2</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1876" href="#t1876">1876</a></span><span class="t">                             <span class="str">"corr_type_multiply"</span><span class="op">:</span> <span class="nam">corr_type_multiply</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1877" href="#t1877">1877</a></span><span class="t">                         <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1878" href="#t1878">1878</a></span><span class="t">                         <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Output"</span><span class="op">:</span> <span class="nam">output</span><span class="op">}</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1879" href="#t1879">1879</a></span><span class="t">    <span class="key">return</span> <span class="nam">output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1880" href="#t1880">1880</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1881" href="#t1881">1881</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1882" href="#t1882">1882</a></span><span class="t"><span class="key">def</span> <span class="nam">fused_bn_add_act</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1883" href="#t1883">1883</a></span><span class="t">                     <span class="nam">y</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1884" href="#t1884">1884</a></span><span class="t">                     <span class="nam">momentum</span><span class="op">=</span><span class="num">0.9</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1885" href="#t1885">1885</a></span><span class="t">                     <span class="nam">epsilon</span><span class="op">=</span><span class="num">1e-05</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1886" href="#t1886">1886</a></span><span class="t">                     <span class="nam">param_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1887" href="#t1887">1887</a></span><span class="t">                     <span class="nam">bias_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1888" href="#t1888">1888</a></span><span class="t">                     <span class="nam">moving_mean_name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1889" href="#t1889">1889</a></span><span class="t">                     <span class="nam">moving_variance_name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1890" href="#t1890">1890</a></span><span class="t">                     <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1891" href="#t1891">1891</a></span><span class="t">                     <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1892" href="#t1892">1892</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1893" href="#t1893">1893</a></span><span class="t"><span class="str">    This Op performs batch norm on input x, and adds the result to input y. Then</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1894" href="#t1894">1894</a></span><span class="t"><span class="str">    it performs activation on the sum. The data format of inputs must be NHWC</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1895" href="#t1895">1895</a></span><span class="t"><span class="str">    `[batch, in_height, in_width, in_channels]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1896" href="#t1896">1896</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1897" href="#t1897">1897</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1898" href="#t1898">1898</a></span><span class="t"><span class="str">        x(Tensor): The rank of input tensor can be 2, 3, 4, 5. The data type</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1899" href="#t1899">1899</a></span><span class="t"><span class="str">            is float16.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1900" href="#t1900">1900</a></span><span class="t"><span class="str">        y(Tensor): The rank of input tensor can be 2, 3, 4, 5. The data type</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1901" href="#t1901">1901</a></span><span class="t"><span class="str">            is float16.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1902" href="#t1902">1902</a></span><span class="t"><span class="str">        momentum(float|Tensor, optional): The value used for the moving_mean and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1903" href="#t1903">1903</a></span><span class="t"><span class="str">            moving_var computation. This should be a float number or a tensor with</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1904" href="#t1904">1904</a></span><span class="t"><span class="str">            shape [1] and data type as float32. The updated formula is:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1905" href="#t1905">1905</a></span><span class="t"><span class="str">            :math:`moving\_mean = moving\_mean * momentum + new\_mean * (1. - momentum)`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1906" href="#t1906">1906</a></span><span class="t"><span class="str">            :math:`moving\_var = moving\_var * momentum + new\_var * (1. - momentum)`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1907" href="#t1907">1907</a></span><span class="t"><span class="str">            Default is 0.9.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1908" href="#t1908">1908</a></span><span class="t"><span class="str">        epsilon(float, optional): A value added to the denominator for</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1909" href="#t1909">1909</a></span><span class="t"><span class="str">            numerical stability. Default is 1e-5.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1910" href="#t1910">1910</a></span><span class="t"><span class="str">        param_attr(ParamAttr, optional): The parameter attribute for Parameter `scale`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1911" href="#t1911">1911</a></span><span class="t"><span class="str">            of batch_norm. If it is set to None or one attribute of ParamAttr, batch_norm</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1912" href="#t1912">1912</a></span><span class="t"><span class="str">                will create ParamAttr as param_attr, the name of scale can be set in ParamAttr.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1913" href="#t1913">1913</a></span><span class="t"><span class="str">                If the Initializer of the param_attr is not set, the parameter is initialized</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1914" href="#t1914">1914</a></span><span class="t"><span class="str">                with Xavier. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1915" href="#t1915">1915</a></span><span class="t"><span class="str">        bias_attr(ParamAttr, optional): The parameter attribute for the bias of batch_norm.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1916" href="#t1916">1916</a></span><span class="t"><span class="str">            If it is set to None or one attribute of ParamAttr, batch_norm</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1917" href="#t1917">1917</a></span><span class="t"><span class="str">                will create ParamAttr as bias_attr, the name of bias can be set in ParamAttr.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1918" href="#t1918">1918</a></span><span class="t"><span class="str">                If the Initializer of the bias_attr is not set, the bias is initialized zero.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1919" href="#t1919">1919</a></span><span class="t"><span class="str">                Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1920" href="#t1920">1920</a></span><span class="t"><span class="str">        moving_mean_name(str, optional): The name of moving_mean which store the global Mean. If it</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1921" href="#t1921">1921</a></span><span class="t"><span class="str">            is set to None, batch_norm will save global mean with a random name, otherwise, batch_norm</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1922" href="#t1922">1922</a></span><span class="t"><span class="str">            will save global mean with the string.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1923" href="#t1923">1923</a></span><span class="t"><span class="str">        moving_variance_name(str, optional): The name of the moving_variance which store the global Variance.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1924" href="#t1924">1924</a></span><span class="t"><span class="str">            If it is set to None, batch_norm will save global variance with a random name, otherwise, batch_norm</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1925" href="#t1925">1925</a></span><span class="t"><span class="str">            will save global variance with the string.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1926" href="#t1926">1926</a></span><span class="t"><span class="str">        act(string, optional): Activation type, linear|relu|prelu|...</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1927" href="#t1927">1927</a></span><span class="t"><span class="str">        name(str, optional): For detailed information, please refer to :ref:`api_guide_Name`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1928" href="#t1928">1928</a></span><span class="t"><span class="str">            Usually name is no need to set and None by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1929" href="#t1929">1929</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1930" href="#t1930">1930</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1931" href="#t1931">1931</a></span><span class="t"><span class="str">            .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1932" href="#t1932">1932</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1933" href="#t1933">1933</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1934" href="#t1934">1934</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1935" href="#t1935">1935</a></span><span class="t"><span class="str">            def build_program(main_program, startup_program):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1936" href="#t1936">1936</a></span><span class="t"><span class="str">                with fluid.program_guard(main_program, startup_program):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1937" href="#t1937">1937</a></span><span class="t"><span class="str">                    x = fluid.layers.data(name='x', shape=[1, 28, 28], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1938" href="#t1938">1938</a></span><span class="t"><span class="str">                    y = fluid.layers.data(name="y", shape=[1], dtype='int64')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1939" href="#t1939">1939</a></span><span class="t"><span class="str">                    conv1_1 = fluid.layers.conv2d(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1940" href="#t1940">1940</a></span><span class="t"><span class="str">                        input=x,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1941" href="#t1941">1941</a></span><span class="t"><span class="str">                        filter_size=3,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1942" href="#t1942">1942</a></span><span class="t"><span class="str">                        num_filters=32,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1943" href="#t1943">1943</a></span><span class="t"><span class="str">                        stride=1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1944" href="#t1944">1944</a></span><span class="t"><span class="str">                        padding=1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1945" href="#t1945">1945</a></span><span class="t"><span class="str">                        act=None,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1946" href="#t1946">1946</a></span><span class="t"><span class="str">                        bias_attr=False,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1947" href="#t1947">1947</a></span><span class="t"><span class="str">                        data_format='NHWC')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1948" href="#t1948">1948</a></span><span class="t"><span class="str">                    conv1_2 = fluid.layers.conv2d(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1949" href="#t1949">1949</a></span><span class="t"><span class="str">                        input=x,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1950" href="#t1950">1950</a></span><span class="t"><span class="str">                        filter_size=3,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1951" href="#t1951">1951</a></span><span class="t"><span class="str">                        num_filters=32,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1952" href="#t1952">1952</a></span><span class="t"><span class="str">                        stride=1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1953" href="#t1953">1953</a></span><span class="t"><span class="str">                        padding=1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1954" href="#t1954">1954</a></span><span class="t"><span class="str">                        act=None,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1955" href="#t1955">1955</a></span><span class="t"><span class="str">                        bias_attr=False,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1956" href="#t1956">1956</a></span><span class="t"><span class="str">                        data_format='NHWC')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1957" href="#t1957">1957</a></span><span class="t"><span class="str">                    bn = fluid.layers.batch_norm(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1958" href="#t1958">1958</a></span><span class="t"><span class="str">                        input=conv1_1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1959" href="#t1959">1959</a></span><span class="t"><span class="str">                        act=None,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1960" href="#t1960">1960</a></span><span class="t"><span class="str">                        data_layout='NHWC')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1961" href="#t1961">1961</a></span><span class="t"><span class="str">                    fused_bn_add_act = fluid.contrib.layers.fused_bn_add_act(conv1_2, bn)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1962" href="#t1962">1962</a></span><span class="t"><span class="str">                    prediction = fluid.layers.fc(input=fused_bn_add_act, size=10, act='softmax')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1963" href="#t1963">1963</a></span><span class="t"><span class="str">                    loss = fluid.layers.cross_entropy(input=prediction, label=y)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1964" href="#t1964">1964</a></span><span class="t"><span class="str">                    loss = fluid.layers.mean(loss)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1965" href="#t1965">1965</a></span><span class="t"><span class="str">                    sgd = fluid.optimizer.SGD(learning_rate=0.001)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1966" href="#t1966">1966</a></span><span class="t"><span class="str">                    sgd = fluid.contrib.mixed_precision.decorate(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1967" href="#t1967">1967</a></span><span class="t"><span class="str">                        sgd, use_dynamic_loss_scaling=True, init_loss_scaling=128.0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1968" href="#t1968">1968</a></span><span class="t"><span class="str">                    sgd.minimize(loss)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1969" href="#t1969">1969</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1970" href="#t1970">1970</a></span><span class="t"><span class="str">                return x, y, loss</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1971" href="#t1971">1971</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1972" href="#t1972">1972</a></span><span class="t"><span class="str">            iters = 5</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1973" href="#t1973">1973</a></span><span class="t"><span class="str">            batch_size = 16</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1974" href="#t1974">1974</a></span><span class="t"><span class="str">            support_gpu = fluid.is_compiled_with_cuda()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1975" href="#t1975">1975</a></span><span class="t"><span class="str">            if support_gpu:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1976" href="#t1976">1976</a></span><span class="t"><span class="str">                main_program = fluid.Program()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1977" href="#t1977">1977</a></span><span class="t"><span class="str">                startup_program = fluid.Program()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1978" href="#t1978">1978</a></span><span class="t"><span class="str">                place = fluid.CUDAPlace(0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1979" href="#t1979">1979</a></span><span class="t"><span class="str">                x, y, loss = build_program(main_program, startup_program)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1980" href="#t1980">1980</a></span><span class="t"><span class="str">  </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1981" href="#t1981">1981</a></span><span class="t"><span class="str">                feeder = fluid.DataFeeder(feed_list=[x, y], place=place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1982" href="#t1982">1982</a></span><span class="t"><span class="str">                train_reader = paddle.batch(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1983" href="#t1983">1983</a></span><span class="t"><span class="str">                    paddle.dataset.mnist.train(), batch_size=batch_size)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1984" href="#t1984">1984</a></span><span class="t"><span class="str">                exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1985" href="#t1985">1985</a></span><span class="t"><span class="str">                scope = fluid.Scope()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1986" href="#t1986">1986</a></span><span class="t"><span class="str">                with fluid.scope_guard(scope):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1987" href="#t1987">1987</a></span><span class="t"><span class="str">                    exe.run(startup_program)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1988" href="#t1988">1988</a></span><span class="t"><span class="str">                    for _ in range(iters):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1989" href="#t1989">1989</a></span><span class="t"><span class="str">                        data = next(train_reader())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1990" href="#t1990">1990</a></span><span class="t"><span class="str">                        loss_v = exe.run(main_program, feed=feeder.feed(data), fetch_list=[loss])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1991" href="#t1991">1991</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1992" href="#t1992">1992</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'fused_bn_add_act'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1993" href="#t1993">1993</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1994" href="#t1994">1994</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1995" href="#t1995">1995</a></span><span class="t">                             <span class="str">'fused_bn_add_act'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1996" href="#t1996">1996</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">y</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1997" href="#t1997">1997</a></span><span class="t">                             <span class="str">'fused_bn_add_act'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1998" href="#t1998">1998</a></span><span class="t">    <span class="nam">bn_param_dtype</span> <span class="op">=</span> <span class="nam">core</span><span class="op">.</span><span class="nam">VarDesc</span><span class="op">.</span><span class="nam">VarType</span><span class="op">.</span><span class="nam">FP32</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1999" href="#t1999">1999</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2000" href="#t2000">2000</a></span><span class="t">    <span class="nam">x_shape</span> <span class="op">=</span> <span class="nam">x</span><span class="op">.</span><span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2001" href="#t2001">2001</a></span><span class="t">    <span class="nam">channel_num</span> <span class="op">=</span> <span class="nam">x_shape</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2002" href="#t2002">2002</a></span><span class="t">    <span class="nam">param_shape</span> <span class="op">=</span> <span class="op">[</span><span class="nam">channel_num</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2003" href="#t2003">2003</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2004" href="#t2004">2004</a></span><span class="t">    <span class="com"># create parameter</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2005" href="#t2005">2005</a></span><span class="t">    <span class="nam">scale</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span><span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">param_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2006" href="#t2006">2006</a></span><span class="t">                                    <span class="nam">shape</span><span class="op">=</span><span class="nam">param_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2007" href="#t2007">2007</a></span><span class="t">                                    <span class="nam">dtype</span><span class="op">=</span><span class="nam">bn_param_dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2008" href="#t2008">2008</a></span><span class="t">                                    <span class="nam">default_initializer</span><span class="op">=</span><span class="nam">Constant</span><span class="op">(</span><span class="num">1.0</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2009" href="#t2009">2009</a></span><span class="t">    <span class="nam">bias</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span><span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">bias_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2010" href="#t2010">2010</a></span><span class="t">                                   <span class="nam">shape</span><span class="op">=</span><span class="nam">param_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2011" href="#t2011">2011</a></span><span class="t">                                   <span class="nam">dtype</span><span class="op">=</span><span class="nam">bn_param_dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2012" href="#t2012">2012</a></span><span class="t">                                   <span class="nam">is_bias</span><span class="op">=</span><span class="key">True</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2013" href="#t2013">2013</a></span><span class="t">    <span class="nam">mean</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span><span class="nam">attr</span><span class="op">=</span><span class="nam">ParamAttr</span><span class="op">(</span><span class="nam">name</span><span class="op">=</span><span class="nam">moving_mean_name</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2014" href="#t2014">2014</a></span><span class="t">                                                  <span class="nam">initializer</span><span class="op">=</span><span class="nam">Constant</span><span class="op">(</span><span class="num">0.0</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2015" href="#t2015">2015</a></span><span class="t">                                                  <span class="nam">trainable</span><span class="op">=</span><span class="key">False</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2016" href="#t2016">2016</a></span><span class="t">                                   <span class="nam">shape</span><span class="op">=</span><span class="nam">param_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2017" href="#t2017">2017</a></span><span class="t">                                   <span class="nam">dtype</span><span class="op">=</span><span class="nam">bn_param_dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2018" href="#t2018">2018</a></span><span class="t">    <span class="nam">mean</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2019" href="#t2019">2019</a></span><span class="t">    <span class="nam">variance</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span><span class="nam">attr</span><span class="op">=</span><span class="nam">ParamAttr</span><span class="op">(</span><span class="nam">name</span><span class="op">=</span><span class="nam">moving_variance_name</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2020" href="#t2020">2020</a></span><span class="t">                                                      <span class="nam">initializer</span><span class="op">=</span><span class="nam">Constant</span><span class="op">(</span><span class="num">1.0</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2021" href="#t2021">2021</a></span><span class="t">                                                      <span class="nam">trainable</span><span class="op">=</span><span class="key">False</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2022" href="#t2022">2022</a></span><span class="t">                                       <span class="nam">shape</span><span class="op">=</span><span class="nam">param_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2023" href="#t2023">2023</a></span><span class="t">                                       <span class="nam">dtype</span><span class="op">=</span><span class="nam">bn_param_dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2024" href="#t2024">2024</a></span><span class="t">    <span class="nam">variance</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2025" href="#t2025">2025</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2026" href="#t2026">2026</a></span><span class="t">    <span class="com"># create output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2027" href="#t2027">2027</a></span><span class="t">    <span class="com"># mean and mean_out share the same memory</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2028" href="#t2028">2028</a></span><span class="t">    <span class="nam">mean_out</span> <span class="op">=</span> <span class="nam">mean</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2029" href="#t2029">2029</a></span><span class="t">    <span class="com"># variance and variance out share the same memory</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2030" href="#t2030">2030</a></span><span class="t">    <span class="nam">variance_out</span> <span class="op">=</span> <span class="nam">variance</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2031" href="#t2031">2031</a></span><span class="t">    <span class="nam">saved_mean</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">bn_param_dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2032" href="#t2032">2032</a></span><span class="t">                                                           <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2033" href="#t2033">2033</a></span><span class="t">    <span class="nam">saved_variance</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2034" href="#t2034">2034</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">bn_param_dtype</span><span class="op">,</span> <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2035" href="#t2035">2035</a></span><span class="t">    <span class="nam">reserve_space</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2036" href="#t2036">2036</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">core</span><span class="op">.</span><span class="nam">VarDesc</span><span class="op">.</span><span class="nam">VarType</span><span class="op">.</span><span class="nam">FP16</span><span class="op">,</span> <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2037" href="#t2037">2037</a></span><span class="t">    <span class="nam">batch_norm_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2038" href="#t2038">2038</a></span><span class="t">        <span class="nam">core</span><span class="op">.</span><span class="nam">VarDesc</span><span class="op">.</span><span class="nam">VarType</span><span class="op">.</span><span class="nam">FP16</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2039" href="#t2039">2039</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2040" href="#t2040">2040</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2041" href="#t2041">2041</a></span><span class="t">        <span class="str">"X"</span><span class="op">:</span> <span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2042" href="#t2042">2042</a></span><span class="t">        <span class="str">"Z"</span><span class="op">:</span> <span class="nam">y</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2043" href="#t2043">2043</a></span><span class="t">        <span class="str">"Scale"</span><span class="op">:</span> <span class="nam">scale</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2044" href="#t2044">2044</a></span><span class="t">        <span class="str">"Bias"</span><span class="op">:</span> <span class="nam">bias</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2045" href="#t2045">2045</a></span><span class="t">    <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2046" href="#t2046">2046</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="str">"epsilon"</span><span class="op">:</span> <span class="nam">epsilon</span><span class="op">,</span> <span class="str">'momentum'</span><span class="op">:</span> <span class="nam">momentum</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2047" href="#t2047">2047</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2048" href="#t2048">2048</a></span><span class="t">    <span class="nam">outputs</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2049" href="#t2049">2049</a></span><span class="t">        <span class="str">"Y"</span><span class="op">:</span> <span class="nam">batch_norm_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2050" href="#t2050">2050</a></span><span class="t">        <span class="str">"MeanOut"</span><span class="op">:</span> <span class="nam">mean_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2051" href="#t2051">2051</a></span><span class="t">        <span class="str">"VarianceOut"</span><span class="op">:</span> <span class="nam">variance_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2052" href="#t2052">2052</a></span><span class="t">        <span class="str">"SavedMean"</span><span class="op">:</span> <span class="nam">saved_mean</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2053" href="#t2053">2053</a></span><span class="t">        <span class="str">"SavedVariance"</span><span class="op">:</span> <span class="nam">saved_variance</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2054" href="#t2054">2054</a></span><span class="t">        <span class="str">"ReserveSpace"</span><span class="op">:</span> <span class="nam">reserve_space</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2055" href="#t2055">2055</a></span><span class="t">    <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2056" href="#t2056">2056</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2057" href="#t2057">2057</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">"fused_bn_add_activation"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2058" href="#t2058">2058</a></span><span class="t">                     <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2059" href="#t2059">2059</a></span><span class="t">                     <span class="nam">outputs</span><span class="op">=</span><span class="nam">outputs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2060" href="#t2060">2060</a></span><span class="t">                     <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2061" href="#t2061">2061</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2062" href="#t2062">2062</a></span><span class="t">    <span class="key">return</span> <span class="nam">batch_norm_out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2063" href="#t2063">2063</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2064" href="#t2064">2064</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t2065" href="#t2065">2065</a></span><span class="t"><span class="key">def</span> <span class="nam">pow2_decay_with_linear_warmup</span><span class="op">(</span><span class="nam">warmup_steps</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2066" href="#t2066">2066</a></span><span class="t">                                  <span class="nam">total_steps</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2067" href="#t2067">2067</a></span><span class="t">                                  <span class="nam">base_lr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2068" href="#t2068">2068</a></span><span class="t">                                  <span class="nam">end_lr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2069" href="#t2069">2069</a></span><span class="t">                                  <span class="nam">dtype</span><span class="op">=</span><span class="str">'float32'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2070" href="#t2070">2070</a></span><span class="t">                                  <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2071" href="#t2071">2071</a></span><span class="t">    <span class="key">if</span> <span class="nam">paddle</span><span class="op">.</span><span class="nam">fluid</span><span class="op">.</span><span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="exc show_exc"><span class="n"><a id="t2072" href="#t2072">2072</a></span><span class="t">        <span class="key">raise</span> <span class="nam">NotImplementedError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2073" href="#t2073">2073</a></span><span class="t">            <span class="str">"pow2_decay_with_linear_warmup does not support dygraph mode yet."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2074" href="#t2074">2074</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2075" href="#t2075">2075</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"pow2_decay_with_linear_warmup"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2076" href="#t2076">2076</a></span><span class="t">    <span class="nam">lr</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_global_variable</span><span class="op">(</span><span class="nam">persistable</span><span class="op">=</span><span class="key">True</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">shape</span><span class="op">=</span><span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2077" href="#t2077">2077</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">set_variable_initializer</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2078" href="#t2078">2078</a></span><span class="t">        <span class="nam">lr</span><span class="op">,</span> <span class="nam">Constant</span><span class="op">(</span><span class="nam">value</span><span class="op">=</span><span class="nam">float</span><span class="op">(</span><span class="nam">base_lr</span><span class="op">)</span> <span class="op">/</span> <span class="nam">warmup_steps</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2079" href="#t2079">2079</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2080" href="#t2080">2080</a></span><span class="t">    <span class="nam">step</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_global_variable</span><span class="op">(</span><span class="nam">persistable</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2081" href="#t2081">2081</a></span><span class="t">                                         <span class="nam">dtype</span><span class="op">=</span><span class="str">'int64'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2082" href="#t2082">2082</a></span><span class="t">                                         <span class="nam">shape</span><span class="op">=</span><span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2083" href="#t2083">2083</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">set_variable_initializer</span><span class="op">(</span><span class="nam">step</span><span class="op">,</span> <span class="nam">Constant</span><span class="op">(</span><span class="nam">value</span><span class="op">=</span><span class="num">0</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2084" href="#t2084">2084</a></span><span class="t">    <span class="key">assert</span> <span class="nam">warmup_steps</span> <span class="op">&lt;=</span> <span class="nam">total_steps</span><span class="op">,</span> <span class="str">"warmup_steps cannot be larger than total_steps"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2085" href="#t2085">2085</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2086" href="#t2086">2086</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">"pow2_decay_with_linear_warmup"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2087" href="#t2087">2087</a></span><span class="t">                     <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2088" href="#t2088">2088</a></span><span class="t">                         <span class="str">"LearningRate"</span><span class="op">:</span> <span class="nam">lr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2089" href="#t2089">2089</a></span><span class="t">                         <span class="str">"Step"</span><span class="op">:</span> <span class="nam">step</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2090" href="#t2090">2090</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2091" href="#t2091">2091</a></span><span class="t">                     <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2092" href="#t2092">2092</a></span><span class="t">                         <span class="str">"LearningRateOut"</span><span class="op">:</span> <span class="nam">lr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2093" href="#t2093">2093</a></span><span class="t">                         <span class="str">"StepOut"</span><span class="op">:</span> <span class="nam">step</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2094" href="#t2094">2094</a></span><span class="t">                     <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2095" href="#t2095">2095</a></span><span class="t">                     <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2096" href="#t2096">2096</a></span><span class="t">                         <span class="str">"warmup_steps"</span><span class="op">:</span> <span class="nam">warmup_steps</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2097" href="#t2097">2097</a></span><span class="t">                         <span class="str">"total_steps"</span><span class="op">:</span> <span class="nam">total_steps</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2098" href="#t2098">2098</a></span><span class="t">                         <span class="str">"base_lr"</span><span class="op">:</span> <span class="nam">base_lr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2099" href="#t2099">2099</a></span><span class="t">                         <span class="str">"end_lr"</span><span class="op">:</span> <span class="nam">end_lr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2100" href="#t2100">2100</a></span><span class="t">                     <span class="op">}</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2101" href="#t2101">2101</a></span><span class="t">    <span class="key">return</span> <span class="nam">lr</span>&nbsp;</span><span class="r"></span></p>
</main>
<footer>
    <div class="content">
        <p>
            <a id="prevFileLink" class="nav" href="d_0908dfdd426614bd_metric_op_py.html">&#xab; prev</a> &nbsp; &nbsp;
            <a id="indexLink" class="nav" href="index.html">&Hat; index</a> &nbsp; &nbsp;
            <a id="nextFileLink" class="nav" href="d_0908dfdd426614bd_rnn_impl_py.html">&#xbb; next</a>
            &nbsp; &nbsp; &nbsp;
            <a class="nav" href="https://coverage.readthedocs.io/en/7.2.4">coverage.py v7.2.4</a>,
            created at 2023-05-05 05:16 -0500
        </p>
    </div>
</footer>
</body>
</html>
