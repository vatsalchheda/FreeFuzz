<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>Coverage for fluid\layers\nn.py: 17%</title>
    <link rel="icon" sizes="32x32" href="favicon_32.png">
    <link rel="stylesheet" href="style.css" type="text/css">
    <script type="text/javascript" src="coverage_html.js" defer></script>
</head>
<body class="pyfile">
<header>
    <div class="content">
        <h1>
            <span class="text">Coverage for </span><b>fluid\layers\nn.py</b>:
            <span class="pc_cov">17%</span>
        </h1>
        <aside id="help_panel_wrapper">
            <input id="help_panel_state" type="checkbox">
            <label for="help_panel_state">
                <img id="keyboard_icon" src="keybd_closed.png" alt="Show/hide keyboard shortcuts" />
            </label>
            <div id="help_panel">
                <p class="legend">Shortcuts on this page</p>
                <div class="keyhelp">
                    <p>
                        <kbd>r</kbd>
                        <kbd>m</kbd>
                        <kbd>x</kbd>
                        <kbd>p</kbd>
                        &nbsp; toggle line displays
                    </p>
                    <p>
                        <kbd>j</kbd>
                        <kbd>k</kbd>
                        &nbsp; next/prev highlighted chunk
                    </p>
                    <p>
                        <kbd>0</kbd> &nbsp; (zero) top of page
                    </p>
                    <p>
                        <kbd>1</kbd> &nbsp; (one) first highlighted chunk
                    </p>
                    <p>
                        <kbd>[</kbd>
                        <kbd>]</kbd>
                        &nbsp; prev/next file
                    </p>
                    <p>
                        <kbd>u</kbd> &nbsp; up to the index
                    </p>
                    <p>
                        <kbd>?</kbd> &nbsp; show/hide this help
                    </p>
                </div>
            </div>
        </aside>
        <h2>
            <span class="text">2971 statements &nbsp;</span>
            <button type="button" class="run button_toggle_run" value="run" data-shortcut="r" title="Toggle lines run">599<span class="text"> run</span></button>
            <button type="button" class="mis show_mis button_toggle_mis" value="mis" data-shortcut="m" title="Toggle lines missing">2372<span class="text"> missing</span></button>
            <button type="button" class="exc show_exc button_toggle_exc" value="exc" data-shortcut="x" title="Toggle lines excluded">0<span class="text"> excluded</span></button>
            <button type="button" class="par run show_par button_toggle_par" value="par" data-shortcut="p" title="Toggle lines partially run">83<span class="text"> partial</span></button>
        </h2>
        <p class="text">
            <a id="prevFileLink" class="nav" href="d_a9a759b3e33e713a_metric_op_py.html">&#xab; prev</a> &nbsp; &nbsp;
            <a id="indexLink" class="nav" href="index.html">&Hat; index</a> &nbsp; &nbsp;
            <a id="nextFileLink" class="nav" href="d_a9a759b3e33e713a_ops_py.html">&#xbb; next</a>
            &nbsp; &nbsp; &nbsp;
            <a class="nav" href="https://coverage.readthedocs.io/en/7.2.4">coverage.py v7.2.4</a>,
            created at 2023-05-05 14:52 -0500
        </p>
        <aside class="hidden">
            <button type="button" class="button_next_chunk" data-shortcut="j"/>
            <button type="button" class="button_prev_chunk" data-shortcut="k"/>
            <button type="button" class="button_top_of_page" data-shortcut="0"/>
            <button type="button" class="button_first_chunk" data-shortcut="1"/>
            <button type="button" class="button_prev_file" data-shortcut="["/>
            <button type="button" class="button_next_file" data-shortcut="]"/>
            <button type="button" class="button_to_index" data-shortcut="u"/>
            <button type="button" class="button_show_hide_help" data-shortcut="?"/>
        </aside>
    </div>
</header>
<main id="source">
    <p class="pln"><span class="n"><a id="t1" href="#t1">1</a></span><span class="t"><span class="com"># Copyright (c) 2018 PaddlePaddle Authors. All Rights Reserved.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2" href="#t2">2</a></span><span class="t"><span class="com">#</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3" href="#t3">3</a></span><span class="t"><span class="com"># Licensed under the Apache License, Version 2.0 (the "License");</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4" href="#t4">4</a></span><span class="t"><span class="com"># you may not use this file except in compliance with the License.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5" href="#t5">5</a></span><span class="t"><span class="com"># You may obtain a copy of the License at</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6" href="#t6">6</a></span><span class="t"><span class="com">#</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7" href="#t7">7</a></span><span class="t"><span class="com">#     http://www.apache.org/licenses/LICENSE-2.0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8" href="#t8">8</a></span><span class="t"><span class="com">#</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9" href="#t9">9</a></span><span class="t"><span class="com"># Unless required by applicable law or agreed to in writing, software</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10" href="#t10">10</a></span><span class="t"><span class="com"># distributed under the License is distributed on an "AS IS" BASIS,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11" href="#t11">11</a></span><span class="t"><span class="com"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12" href="#t12">12</a></span><span class="t"><span class="com"># See the License for the specific language governing permissions and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13" href="#t13">13</a></span><span class="t"><span class="com"># limitations under the License.</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14" href="#t14">14</a></span><span class="t"><span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15" href="#t15">15</a></span><span class="t"><span class="str">All layers just related to the neural network.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16" href="#t16">16</a></span><span class="t"><span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t17" href="#t17">17</a></span><span class="t"><span class="key">from</span> <span class="nam">__future__</span> <span class="key">import</span> <span class="nam">print_function</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t18" href="#t18">18</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t19" href="#t19">19</a></span><span class="t"><span class="key">import</span> <span class="nam">os</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t20" href="#t20">20</a></span><span class="t"><span class="key">import</span> <span class="nam">inspect</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t21" href="#t21">21</a></span><span class="t"><span class="key">import</span> <span class="nam">warnings</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t22" href="#t22">22</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t23" href="#t23">23</a></span><span class="t"><span class="key">import</span> <span class="nam">numpy</span> <span class="key">as</span> <span class="nam">np</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t24" href="#t24">24</a></span><span class="t"><span class="key">import</span> <span class="nam">six</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t25" href="#t25">25</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t26" href="#t26">26</a></span><span class="t"><span class="key">import</span> <span class="nam">paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t27" href="#t27">27</a></span><span class="t"><span class="key">from</span> <span class="op">.</span><span class="op">.</span><span class="nam">layer_helper</span> <span class="key">import</span> <span class="nam">LayerHelper</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t28" href="#t28">28</a></span><span class="t"><span class="key">from</span> <span class="nam">paddle</span><span class="op">.</span><span class="nam">fluid</span><span class="op">.</span><span class="nam">framework</span> <span class="key">import</span> <span class="nam">_in_legacy_dygraph</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t29" href="#t29">29</a></span><span class="t"><span class="key">from</span> <span class="op">.</span><span class="op">.</span><span class="nam">initializer</span> <span class="key">import</span> <span class="nam">Normal</span><span class="op">,</span> <span class="nam">Constant</span><span class="op">,</span> <span class="nam">NumpyArrayInitializer</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t30" href="#t30">30</a></span><span class="t"><span class="key">from</span> <span class="op">.</span><span class="op">.</span><span class="nam">framework</span> <span class="key">import</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t31" href="#t31">31</a></span><span class="t">    <span class="nam">Variable</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t32" href="#t32">32</a></span><span class="t">    <span class="nam">OpProtoHolder</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t33" href="#t33">33</a></span><span class="t">    <span class="nam">_non_static_mode</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t34" href="#t34">34</a></span><span class="t">    <span class="nam">dygraph_only</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t35" href="#t35">35</a></span><span class="t">    <span class="nam">_dygraph_tracer</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t36" href="#t36">36</a></span><span class="t">    <span class="nam">default_main_program</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t37" href="#t37">37</a></span><span class="t">    <span class="nam">_varbase_creator</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t38" href="#t38">38</a></span><span class="t">    <span class="nam">static_only</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t39" href="#t39">39</a></span><span class="t">    <span class="nam">_global_flags</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t40" href="#t40">40</a></span><span class="t">    <span class="nam">_in_legacy_dygraph</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t41" href="#t41">41</a></span><span class="t">    <span class="nam">in_dygraph_mode</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t42" href="#t42">42</a></span><span class="t"><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t43" href="#t43">43</a></span><span class="t"><span class="key">from</span> <span class="op">.</span><span class="op">.</span><span class="nam">framework</span> <span class="key">import</span> <span class="nam">_current_expected_place</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t44" href="#t44">44</a></span><span class="t"><span class="key">from</span> <span class="op">.</span><span class="op">.</span> <span class="key">import</span> <span class="nam">dygraph_utils</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t45" href="#t45">45</a></span><span class="t"><span class="key">from</span> <span class="op">.</span><span class="op">.</span><span class="nam">param_attr</span> <span class="key">import</span> <span class="nam">ParamAttr</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t46" href="#t46">46</a></span><span class="t"><span class="key">from</span> <span class="op">.</span><span class="nam">layer_function_generator</span> <span class="key">import</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t47" href="#t47">47</a></span><span class="t">    <span class="nam">autodoc</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t48" href="#t48">48</a></span><span class="t">    <span class="nam">templatedoc</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t49" href="#t49">49</a></span><span class="t">    <span class="nam">_generate_doc_string_</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t50" href="#t50">50</a></span><span class="t"><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t51" href="#t51">51</a></span><span class="t"><span class="key">from</span> <span class="op">.</span><span class="nam">tensor</span> <span class="key">import</span> <span class="nam">concat</span><span class="op">,</span> <span class="nam">assign</span><span class="op">,</span> <span class="nam">fill_constant</span><span class="op">,</span> <span class="nam">zeros</span><span class="op">,</span> <span class="nam">tensor_array_to_tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t52" href="#t52">52</a></span><span class="t"><span class="key">from</span> <span class="op">.</span> <span class="key">import</span> <span class="nam">utils</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t53" href="#t53">53</a></span><span class="t"><span class="key">from</span> <span class="op">.</span><span class="op">.</span> <span class="key">import</span> <span class="nam">unique_name</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t54" href="#t54">54</a></span><span class="t"><span class="key">from</span> <span class="nam">functools</span> <span class="key">import</span> <span class="nam">reduce</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t55" href="#t55">55</a></span><span class="t"><span class="key">from</span> <span class="op">.</span><span class="op">.</span> <span class="key">import</span> <span class="nam">core</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t56" href="#t56">56</a></span><span class="t"><span class="key">from</span> <span class="op">...</span><span class="nam">utils</span> <span class="key">import</span> <span class="nam">deprecated</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t57" href="#t57">57</a></span><span class="t"><span class="key">from</span> <span class="op">.</span><span class="op">.</span><span class="nam">data_feeder</span> <span class="key">import</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t58" href="#t58">58</a></span><span class="t">    <span class="nam">convert_dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t59" href="#t59">59</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t60" href="#t60">60</a></span><span class="t">    <span class="nam">check_type</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t61" href="#t61">61</a></span><span class="t">    <span class="nam">check_dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t62" href="#t62">62</a></span><span class="t"><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t63" href="#t63">63</a></span><span class="t"><span class="key">import</span> <span class="nam">paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t64" href="#t64">64</a></span><span class="t"><span class="key">from</span> <span class="nam">paddle</span><span class="op">.</span><span class="nam">utils</span> <span class="key">import</span> <span class="nam">deprecated</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t65" href="#t65">65</a></span><span class="t"><span class="key">from</span> <span class="nam">paddle</span> <span class="key">import</span> <span class="nam">_C_ops</span><span class="op">,</span> <span class="nam">_legacy_C_ops</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t66" href="#t66">66</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t67" href="#t67">67</a></span><span class="t"><span class="nam">__all__</span> <span class="op">=</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t68" href="#t68">68</a></span><span class="t">    <span class="str">'fc'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t69" href="#t69">69</a></span><span class="t">    <span class="str">'embedding'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t70" href="#t70">70</a></span><span class="t">    <span class="str">'linear_chain_crf'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t71" href="#t71">71</a></span><span class="t">    <span class="str">'crf_decoding'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t72" href="#t72">72</a></span><span class="t">    <span class="str">'cos_sim'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t73" href="#t73">73</a></span><span class="t">    <span class="str">'chunk_eval'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t74" href="#t74">74</a></span><span class="t">    <span class="str">'conv2d'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t75" href="#t75">75</a></span><span class="t">    <span class="str">'conv3d'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t76" href="#t76">76</a></span><span class="t">    <span class="str">'softmax'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t77" href="#t77">77</a></span><span class="t">    <span class="str">'pool2d'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t78" href="#t78">78</a></span><span class="t">    <span class="str">'pool3d'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t79" href="#t79">79</a></span><span class="t">    <span class="str">'adaptive_pool2d'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t80" href="#t80">80</a></span><span class="t">    <span class="str">'adaptive_pool3d'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t81" href="#t81">81</a></span><span class="t">    <span class="str">'batch_norm'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t82" href="#t82">82</a></span><span class="t">    <span class="str">'inplace_abn'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t83" href="#t83">83</a></span><span class="t">    <span class="str">'instance_norm'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t84" href="#t84">84</a></span><span class="t">    <span class="str">'data_norm'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t85" href="#t85">85</a></span><span class="t">    <span class="str">'conv2d_transpose'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t86" href="#t86">86</a></span><span class="t">    <span class="str">'conv3d_transpose'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t87" href="#t87">87</a></span><span class="t">    <span class="str">'reduce_sum'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t88" href="#t88">88</a></span><span class="t">    <span class="str">'reduce_mean'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t89" href="#t89">89</a></span><span class="t">    <span class="str">'reduce_max'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t90" href="#t90">90</a></span><span class="t">    <span class="str">'reduce_min'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t91" href="#t91">91</a></span><span class="t">    <span class="str">'reduce_prod'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t92" href="#t92">92</a></span><span class="t">    <span class="str">'reduce_all'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t93" href="#t93">93</a></span><span class="t">    <span class="str">'reduce_any'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t94" href="#t94">94</a></span><span class="t">    <span class="str">'dropout'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t95" href="#t95">95</a></span><span class="t">    <span class="str">'split'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t96" href="#t96">96</a></span><span class="t">    <span class="str">'ctc_greedy_decoder'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t97" href="#t97">97</a></span><span class="t">    <span class="str">'l2_normalize'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t98" href="#t98">98</a></span><span class="t">    <span class="str">'matmul'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t99" href="#t99">99</a></span><span class="t">    <span class="str">'topk'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t100" href="#t100">100</a></span><span class="t">    <span class="str">'transpose'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t101" href="#t101">101</a></span><span class="t">    <span class="str">'im2sequence'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t102" href="#t102">102</a></span><span class="t">    <span class="str">'row_conv'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t103" href="#t103">103</a></span><span class="t">    <span class="str">'multiplex'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t104" href="#t104">104</a></span><span class="t">    <span class="str">'layer_norm'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t105" href="#t105">105</a></span><span class="t">    <span class="str">'group_norm'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t106" href="#t106">106</a></span><span class="t">    <span class="str">'spectral_norm'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t107" href="#t107">107</a></span><span class="t">    <span class="str">'smooth_l1'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t108" href="#t108">108</a></span><span class="t">    <span class="str">'one_hot'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t109" href="#t109">109</a></span><span class="t">    <span class="str">'autoincreased_step_counter'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t110" href="#t110">110</a></span><span class="t">    <span class="str">'reshape'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t111" href="#t111">111</a></span><span class="t">    <span class="str">'squeeze'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t112" href="#t112">112</a></span><span class="t">    <span class="str">'unsqueeze'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t113" href="#t113">113</a></span><span class="t">    <span class="str">'lod_reset'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t114" href="#t114">114</a></span><span class="t">    <span class="str">'lod_append'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t115" href="#t115">115</a></span><span class="t">    <span class="str">'lrn'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t116" href="#t116">116</a></span><span class="t">    <span class="str">'pad'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t117" href="#t117">117</a></span><span class="t">    <span class="str">'pad_constant_like'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t118" href="#t118">118</a></span><span class="t">    <span class="str">'label_smooth'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t119" href="#t119">119</a></span><span class="t">    <span class="str">'roi_pool'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t120" href="#t120">120</a></span><span class="t">    <span class="str">'roi_align'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t121" href="#t121">121</a></span><span class="t">    <span class="str">'dice_loss'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t122" href="#t122">122</a></span><span class="t">    <span class="str">'image_resize'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t123" href="#t123">123</a></span><span class="t">    <span class="str">'image_resize_short'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t124" href="#t124">124</a></span><span class="t">    <span class="str">'resize_linear'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t125" href="#t125">125</a></span><span class="t">    <span class="str">'resize_bilinear'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t126" href="#t126">126</a></span><span class="t">    <span class="str">'resize_trilinear'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t127" href="#t127">127</a></span><span class="t">    <span class="str">'resize_nearest'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t128" href="#t128">128</a></span><span class="t">    <span class="str">'gather'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t129" href="#t129">129</a></span><span class="t">    <span class="str">'gather_nd'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t130" href="#t130">130</a></span><span class="t">    <span class="str">'scatter'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t131" href="#t131">131</a></span><span class="t">    <span class="str">'scatter_nd_add'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t132" href="#t132">132</a></span><span class="t">    <span class="str">'scatter_nd'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t133" href="#t133">133</a></span><span class="t">    <span class="str">'random_crop'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t134" href="#t134">134</a></span><span class="t">    <span class="str">'mean_iou'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t135" href="#t135">135</a></span><span class="t">    <span class="str">'relu'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t136" href="#t136">136</a></span><span class="t">    <span class="str">'selu'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t137" href="#t137">137</a></span><span class="t">    <span class="str">'log'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t138" href="#t138">138</a></span><span class="t">    <span class="str">'crop'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t139" href="#t139">139</a></span><span class="t">    <span class="str">'crop_tensor'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t140" href="#t140">140</a></span><span class="t">    <span class="str">'elu'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t141" href="#t141">141</a></span><span class="t">    <span class="str">'relu6'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t142" href="#t142">142</a></span><span class="t">    <span class="str">'pow'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t143" href="#t143">143</a></span><span class="t">    <span class="str">'stanh'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t144" href="#t144">144</a></span><span class="t">    <span class="str">'hard_sigmoid'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t145" href="#t145">145</a></span><span class="t">    <span class="str">'swish'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t146" href="#t146">146</a></span><span class="t">    <span class="str">'prelu'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t147" href="#t147">147</a></span><span class="t">    <span class="str">'brelu'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t148" href="#t148">148</a></span><span class="t">    <span class="str">'leaky_relu'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t149" href="#t149">149</a></span><span class="t">    <span class="str">'soft_relu'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t150" href="#t150">150</a></span><span class="t">    <span class="str">'flatten'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t151" href="#t151">151</a></span><span class="t">    <span class="str">'stack'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t152" href="#t152">152</a></span><span class="t">    <span class="str">'pad2d'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t153" href="#t153">153</a></span><span class="t">    <span class="str">'unstack'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t154" href="#t154">154</a></span><span class="t">    <span class="str">'unique'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t155" href="#t155">155</a></span><span class="t">    <span class="str">'unique_with_counts'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t156" href="#t156">156</a></span><span class="t">    <span class="str">'expand'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t157" href="#t157">157</a></span><span class="t">    <span class="str">'expand_as'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t158" href="#t158">158</a></span><span class="t">    <span class="str">'scale'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t159" href="#t159">159</a></span><span class="t">    <span class="str">'elementwise_add'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t160" href="#t160">160</a></span><span class="t">    <span class="str">'elementwise_div'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t161" href="#t161">161</a></span><span class="t">    <span class="str">'elementwise_sub'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t162" href="#t162">162</a></span><span class="t">    <span class="str">'elementwise_mul'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t163" href="#t163">163</a></span><span class="t">    <span class="str">'elementwise_max'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t164" href="#t164">164</a></span><span class="t">    <span class="str">'elementwise_min'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t165" href="#t165">165</a></span><span class="t">    <span class="str">'elementwise_pow'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t166" href="#t166">166</a></span><span class="t">    <span class="str">'elementwise_mod'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t167" href="#t167">167</a></span><span class="t">    <span class="str">'elementwise_floordiv'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t168" href="#t168">168</a></span><span class="t">    <span class="str">'uniform_random_batch_size_like'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t169" href="#t169">169</a></span><span class="t">    <span class="str">'gaussian_random'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t170" href="#t170">170</a></span><span class="t">    <span class="str">'sampling_id'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t171" href="#t171">171</a></span><span class="t">    <span class="str">'gaussian_random_batch_size_like'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t172" href="#t172">172</a></span><span class="t">    <span class="str">'sum'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t173" href="#t173">173</a></span><span class="t">    <span class="str">'slice'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t174" href="#t174">174</a></span><span class="t">    <span class="str">'strided_slice'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t175" href="#t175">175</a></span><span class="t">    <span class="str">'shape'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t176" href="#t176">176</a></span><span class="t">    <span class="str">'rank'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t177" href="#t177">177</a></span><span class="t">    <span class="str">'size'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t178" href="#t178">178</a></span><span class="t">    <span class="str">'logical_and'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t179" href="#t179">179</a></span><span class="t">    <span class="str">'logical_or'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t180" href="#t180">180</a></span><span class="t">    <span class="str">'logical_xor'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t181" href="#t181">181</a></span><span class="t">    <span class="str">'logical_not'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t182" href="#t182">182</a></span><span class="t">    <span class="str">'clip'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t183" href="#t183">183</a></span><span class="t">    <span class="str">'clip_by_norm'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t184" href="#t184">184</a></span><span class="t">    <span class="str">'mean'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t185" href="#t185">185</a></span><span class="t">    <span class="str">'mul'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t186" href="#t186">186</a></span><span class="t">    <span class="str">'maxout'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t187" href="#t187">187</a></span><span class="t">    <span class="str">'space_to_depth'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t188" href="#t188">188</a></span><span class="t">    <span class="str">'affine_grid'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t189" href="#t189">189</a></span><span class="t">    <span class="str">'affine_channel'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t190" href="#t190">190</a></span><span class="t">    <span class="str">'similarity_focus'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t191" href="#t191">191</a></span><span class="t">    <span class="str">'hash'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t192" href="#t192">192</a></span><span class="t">    <span class="str">'grid_sampler'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t193" href="#t193">193</a></span><span class="t">    <span class="str">'log_loss'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t194" href="#t194">194</a></span><span class="t">    <span class="str">'add_position_encoding'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t195" href="#t195">195</a></span><span class="t">    <span class="str">'bilinear_tensor_product'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t196" href="#t196">196</a></span><span class="t">    <span class="str">'merge_selected_rows'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t197" href="#t197">197</a></span><span class="t">    <span class="str">'get_tensor_from_selected_rows'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t198" href="#t198">198</a></span><span class="t">    <span class="str">'shuffle_channel'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t199" href="#t199">199</a></span><span class="t">    <span class="str">'temporal_shift'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t200" href="#t200">200</a></span><span class="t">    <span class="str">'py_func'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t201" href="#t201">201</a></span><span class="t">    <span class="str">'psroi_pool'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t202" href="#t202">202</a></span><span class="t">    <span class="str">'prroi_pool'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t203" href="#t203">203</a></span><span class="t">    <span class="str">'pixel_shuffle'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t204" href="#t204">204</a></span><span class="t">    <span class="str">'fsp_matrix'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t205" href="#t205">205</a></span><span class="t">    <span class="str">'continuous_value_model'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t206" href="#t206">206</a></span><span class="t">    <span class="str">'where'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t207" href="#t207">207</a></span><span class="t">    <span class="str">'sign'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t208" href="#t208">208</a></span><span class="t">    <span class="str">'deformable_conv'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t209" href="#t209">209</a></span><span class="t">    <span class="str">'unfold'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t210" href="#t210">210</a></span><span class="t">    <span class="str">'deformable_roi_pooling'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t211" href="#t211">211</a></span><span class="t">    <span class="str">'filter_by_instag'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t212" href="#t212">212</a></span><span class="t">    <span class="str">'shard_index'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t213" href="#t213">213</a></span><span class="t">    <span class="str">'hard_swish'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t214" href="#t214">214</a></span><span class="t">    <span class="str">'mish'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t215" href="#t215">215</a></span><span class="t">    <span class="str">'gather_tree'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t216" href="#t216">216</a></span><span class="t">    <span class="str">'uniform_random'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t217" href="#t217">217</a></span><span class="t">    <span class="str">'unbind'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t218" href="#t218">218</a></span><span class="t"><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t219" href="#t219">219</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t220" href="#t220">220</a></span><span class="t"><span class="nam">OP_NAMEMAPPING</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t221" href="#t221">221</a></span><span class="t">    <span class="str">'elementwise_max'</span><span class="op">:</span> <span class="str">'maximum'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t222" href="#t222">222</a></span><span class="t">    <span class="str">'elementwise_min'</span><span class="op">:</span> <span class="str">'minimum'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t223" href="#t223">223</a></span><span class="t">    <span class="str">'elementwise_pow'</span><span class="op">:</span> <span class="str">'elementwise_pow'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t224" href="#t224">224</a></span><span class="t">    <span class="str">'elementwise_floordiv'</span><span class="op">:</span> <span class="str">'floor_divide'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t225" href="#t225">225</a></span><span class="t">    <span class="str">'elementwise_add'</span><span class="op">:</span> <span class="str">'add'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t226" href="#t226">226</a></span><span class="t">    <span class="str">'elementwise_sub'</span><span class="op">:</span> <span class="str">'subtract'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t227" href="#t227">227</a></span><span class="t">    <span class="str">'elementwise_mul'</span><span class="op">:</span> <span class="str">'multiply'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t228" href="#t228">228</a></span><span class="t">    <span class="str">'elementwise_div'</span><span class="op">:</span> <span class="str">'divide'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t229" href="#t229">229</a></span><span class="t">    <span class="str">'elementwise_mod'</span><span class="op">:</span> <span class="str">'remainder'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t230" href="#t230">230</a></span><span class="t"><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t231" href="#t231">231</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t232" href="#t232">232</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t233" href="#t233">233</a></span><span class="t"><span class="op">@</span><span class="nam">dygraph_only</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t234" href="#t234">234</a></span><span class="t"><span class="key">def</span> <span class="nam">_elementwise_op_in_dygraph</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t235" href="#t235">235</a></span><span class="t">    <span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">use_mkldnn</span><span class="op">=</span><span class="key">False</span><span class="op">,</span> <span class="nam">op_name</span><span class="op">=</span><span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t236" href="#t236">236</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t237" href="#t237">237</a></span><span class="t">    <span class="key">def</span> <span class="nam">is_inplace</span><span class="op">(</span><span class="nam">op_name</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t238" href="#t238">238</a></span><span class="t">        <span class="key">return</span> <span class="nam">op_name</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span> <span class="op">==</span> <span class="str">"_"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t239" href="#t239">239</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t240" href="#t240">240</a></span><span class="t">    <span class="key">if</span> <span class="nam">op_name</span> <span class="key">not</span> <span class="key">in</span> <span class="nam">OP_NAMEMAPPING</span><span class="op">.</span><span class="nam">keys</span><span class="op">(</span><span class="op">)</span> <span class="key">or</span> <span class="nam">axis</span> <span class="op">!=</span> <span class="op">-</span><span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t241" href="#t241">241</a></span><span class="t">        <span class="nam">op</span> <span class="op">=</span> <span class="nam">getattr</span><span class="op">(</span><span class="nam">_legacy_C_ops</span><span class="op">,</span> <span class="nam">op_name</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t242" href="#t242">242</a></span><span class="t">        <span class="nam">out</span> <span class="op">=</span> <span class="nam">op</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="str">'axis'</span><span class="op">,</span> <span class="nam">axis</span><span class="op">,</span> <span class="str">'use_mkldnn'</span><span class="op">,</span> <span class="nam">use_mkldnn</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t243" href="#t243">243</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t244" href="#t244">244</a></span><span class="t">        <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">244&#x202F;&#x219B;&#x202F;251</span><span class="annotate long">line 244 didn't jump to line 251, because the condition on line 244 was never false</span></span></p>
    <p class="run"><span class="n"><a id="t245" href="#t245">245</a></span><span class="t">            <span class="nam">op</span> <span class="op">=</span> <span class="nam">getattr</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t246" href="#t246">246</a></span><span class="t">                <span class="nam">_C_ops</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t247" href="#t247">247</a></span><span class="t">                <span class="nam">OP_NAMEMAPPING</span><span class="op">[</span><span class="nam">op_name</span><span class="op">]</span> <span class="key">if</span> <span class="key">not</span> <span class="nam">is_inplace</span><span class="op">(</span><span class="nam">op_name</span><span class="op">)</span> <span class="key">else</span> <span class="nam">op_name</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t248" href="#t248">248</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t249" href="#t249">249</a></span><span class="t">            <span class="nam">out</span> <span class="op">=</span> <span class="nam">op</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t250" href="#t250">250</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t251" href="#t251">251</a></span><span class="t">        <span class="key">if</span> <span class="nam">_in_legacy_dygraph</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">251&#x202F;&#x219B;&#x202F;252</span><span class="annotate long">line 251 didn't jump to line 252, because the condition on line 251 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t252" href="#t252">252</a></span><span class="t">            <span class="nam">op</span> <span class="op">=</span> <span class="nam">getattr</span><span class="op">(</span><span class="nam">_legacy_C_ops</span><span class="op">,</span> <span class="nam">op_name</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t253" href="#t253">253</a></span><span class="t">            <span class="nam">out</span> <span class="op">=</span> <span class="nam">op</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="str">'axis'</span><span class="op">,</span> <span class="nam">axis</span><span class="op">,</span> <span class="str">'use_mkldnn'</span><span class="op">,</span> <span class="nam">use_mkldnn</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t254" href="#t254">254</a></span><span class="t">    <span class="key">return</span> <span class="nam">dygraph_utils</span><span class="op">.</span><span class="nam">_append_activation_in_dygraph</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t255" href="#t255">255</a></span><span class="t">        <span class="nam">out</span><span class="op">,</span> <span class="nam">act</span><span class="op">,</span> <span class="nam">use_mkldnn</span><span class="op">=</span><span class="nam">use_mkldnn</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t256" href="#t256">256</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t257" href="#t257">257</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t258" href="#t258">258</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t259" href="#t259">259</a></span><span class="t"><span class="key">def</span> <span class="nam">fc</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t260" href="#t260">260</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t261" href="#t261">261</a></span><span class="t">    <span class="nam">size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t262" href="#t262">262</a></span><span class="t">    <span class="nam">num_flatten_dims</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t263" href="#t263">263</a></span><span class="t">    <span class="nam">param_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t264" href="#t264">264</a></span><span class="t">    <span class="nam">bias_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t265" href="#t265">265</a></span><span class="t">    <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t266" href="#t266">266</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t267" href="#t267">267</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t268" href="#t268">268</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t269" href="#t269">269</a></span><span class="t"><span class="str">    :api_attr: Static Graph</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t270" href="#t270">270</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t271" href="#t271">271</a></span><span class="t"><span class="str">    **Fully Connected Layer**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t272" href="#t272">272</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t273" href="#t273">273</a></span><span class="t"><span class="str">    This operator creates a fully connected layer in the network. It can take</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t274" href="#t274">274</a></span><span class="t"><span class="str">    a Tensor(or LoDTensor) or a list of Tensor(or LoDTensor) as its inputs(see</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t275" href="#t275">275</a></span><span class="t"><span class="str">    Args in detail). It creates a variable called weight for each input Tensor,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t276" href="#t276">276</a></span><span class="t"><span class="str">    which represents a fully connected weight matrix from each input unit to</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t277" href="#t277">277</a></span><span class="t"><span class="str">    each output unit. The fully connected layer multiplies each input Tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t278" href="#t278">278</a></span><span class="t"><span class="str">    with its corresponding weight to produce an output Tensor with shape :math:`[M, size]` ,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t279" href="#t279">279</a></span><span class="t"><span class="str">    where M is batch size. If a list of Tensor is given, the results of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t280" href="#t280">280</a></span><span class="t"><span class="str">    multiple output Tensors with shape :math:`[M, size]` will be summed up. If :attr:`bias_attr`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t281" href="#t281">281</a></span><span class="t"><span class="str">    is not None, a bias variable will be created and added to the output.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t282" href="#t282">282</a></span><span class="t"><span class="str">    Finally, if :attr:`act` is not None, it will be applied to the output as well.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t283" href="#t283">283</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t284" href="#t284">284</a></span><span class="t"><span class="str">    When the input is a single Tensor(or LoDTensor):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t285" href="#t285">285</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t286" href="#t286">286</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t287" href="#t287">287</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t288" href="#t288">288</a></span><span class="t"><span class="str">        Out = Act({XW + b})</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t289" href="#t289">289</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t290" href="#t290">290</a></span><span class="t"><span class="str">    When the input is a list of Tensor(or LoDTensor):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t291" href="#t291">291</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t292" href="#t292">292</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t293" href="#t293">293</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t294" href="#t294">294</a></span><span class="t"><span class="str">        Out = Act({\sum_{i=0}^{N-1}X_iW_i + b})</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t295" href="#t295">295</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t296" href="#t296">296</a></span><span class="t"><span class="str">    In the above equation:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t297" href="#t297">297</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t298" href="#t298">298</a></span><span class="t"><span class="str">    * :math:`N`: Number of the input. N equals to len(input) if input is list of Variable.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t299" href="#t299">299</a></span><span class="t"><span class="str">    * :math:`X_i`: The i-th input tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t300" href="#t300">300</a></span><span class="t"><span class="str">    * :math:`W_i`: The i-th weights matrix corresponding i-th input tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t301" href="#t301">301</a></span><span class="t"><span class="str">    * :math:`b`: The bias parameter created by this layer (if needed).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t302" href="#t302">302</a></span><span class="t"><span class="str">    * :math:`Act`: The activation function.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t303" href="#t303">303</a></span><span class="t"><span class="str">    * :math:`Out`: The output Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t304" href="#t304">304</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t305" href="#t305">305</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t306" href="#t306">306</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t307" href="#t307">307</a></span><span class="t"><span class="str">        Case 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t308" href="#t308">308</a></span><span class="t"><span class="str">        Given a single Tensor data_1, and num_flatten_dims = 2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t309" href="#t309">309</a></span><span class="t"><span class="str">            data_1.data = [[[0.1, 0.2],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t310" href="#t310">310</a></span><span class="t"><span class="str">                            [0.3, 0.4]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t311" href="#t311">311</a></span><span class="t"><span class="str">            data_1.shape = (1, 2, 2) # 1 is batch_size</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t312" href="#t312">312</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t313" href="#t313">313</a></span><span class="t"><span class="str">            out = fluid.layers.fc(input=data_1, size=1, num_flatten_dims=2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t314" href="#t314">314</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t315" href="#t315">315</a></span><span class="t"><span class="str">        Then output is:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t316" href="#t316">316</a></span><span class="t"><span class="str">            out.data = [[0.83234344], [0.34936576]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t317" href="#t317">317</a></span><span class="t"><span class="str">            out.shape = (1, 2, 1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t318" href="#t318">318</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t319" href="#t319">319</a></span><span class="t"><span class="str">        Case 2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t320" href="#t320">320</a></span><span class="t"><span class="str">        Given a list of Tensor:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t321" href="#t321">321</a></span><span class="t"><span class="str">            data_1.data = [[[0.1, 0.2],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t322" href="#t322">322</a></span><span class="t"><span class="str">                           [0.3, 0.4]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t323" href="#t323">323</a></span><span class="t"><span class="str">            data_1.shape = (1, 2, 2) # 1 is batch_size</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t324" href="#t324">324</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t325" href="#t325">325</a></span><span class="t"><span class="str">            data_2 = [[[0.1, 0.2, 0.3]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t326" href="#t326">326</a></span><span class="t"><span class="str">            data_2.shape = (1, 1, 3)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t327" href="#t327">327</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t328" href="#t328">328</a></span><span class="t"><span class="str">            out = fluid.layers.fc(input=[data_1, data_2], size=2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t329" href="#t329">329</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t330" href="#t330">330</a></span><span class="t"><span class="str">        Then:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t331" href="#t331">331</a></span><span class="t"><span class="str">            out.data = [[0.18669507, 0.1893476]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t332" href="#t332">332</a></span><span class="t"><span class="str">            out.shape = (1, 2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t333" href="#t333">333</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t334" href="#t334">334</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t335" href="#t335">335</a></span><span class="t"><span class="str">        input (Variable|list of Variable): A Tensor(or LoDTensor) with shape :math:`[N_1, N_2,..., N_k]` or</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t336" href="#t336">336</a></span><span class="t"><span class="str">            a list of Tensor(or LoDTensor). The dimensions of the input Tensor is at least 2 and the data</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t337" href="#t337">337</a></span><span class="t"><span class="str">            type should be float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t338" href="#t338">338</a></span><span class="t"><span class="str">        size(int): The number of output units in this layer, which also means the feature size of output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t339" href="#t339">339</a></span><span class="t"><span class="str">            Tensor(or LoDTensor).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t340" href="#t340">340</a></span><span class="t"><span class="str">        num_flatten_dims (int): The fc layer can accept an input Tensor with more than</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t341" href="#t341">341</a></span><span class="t"><span class="str">            two dimensions. If this happens, the multidimensional tensor will first be flattened</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t342" href="#t342">342</a></span><span class="t"><span class="str">            into a 2-D matrix. The parameter :attr:`num_flatten_dims` determines how the input</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t343" href="#t343">343</a></span><span class="t"><span class="str">            Tensor is flattened: the first :attr:`num_flatten_dims` (inclusive, index starts from 1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t344" href="#t344">344</a></span><span class="t"><span class="str">            dimensions will be flatten to form the first dimension of the final matrix (height of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t345" href="#t345">345</a></span><span class="t"><span class="str">            the matrix), and the rest :math:`rank(X) - num\_flatten\_dims` dimensions are flattened to</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t346" href="#t346">346</a></span><span class="t"><span class="str">            form the second dimension of the final matrix (width of the matrix). For example, assuming that</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t347" href="#t347">347</a></span><span class="t"><span class="str">            X is a 5-dimensional Tensor with a shape [2, 3, 4, 5, 6], and :attr:`num_flatten_dims` = 3.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t348" href="#t348">348</a></span><span class="t"><span class="str">            Then, the flattened matrix will have a shape [2 x 3 x 4, 5 x 6] = [24, 30]. Default: 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t349" href="#t349">349</a></span><span class="t"><span class="str">        param_attr (ParamAttr): To specify the weight parameter property. Default: None, which means the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t350" href="#t350">350</a></span><span class="t"><span class="str">            default weight parameter property is used. See usage for details in :ref:`api_fluid_ParamAttr` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t351" href="#t351">351</a></span><span class="t"><span class="str">        bias_attr (ParamAttr): To specify the bias parameter property. Default: None, which means the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t352" href="#t352">352</a></span><span class="t"><span class="str">            default bias parameter property is used. See usage for details in :ref:`api_fluid_ParamAttr` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t353" href="#t353">353</a></span><span class="t"><span class="str">        act (str): Activation to be applied to the output of this layer, such as tanh, softmax,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t354" href="#t354">354</a></span><span class="t"><span class="str">            sigmoid, relu. For more information, please refer to :ref:`api_guide_activations_en` . Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t355" href="#t355">355</a></span><span class="t"><span class="str">        name (str, optional): The default value is None.  Normally there is no need for user to set this property.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t356" href="#t356">356</a></span><span class="t"><span class="str">            For more information, please refer to :ref:`api_guide_Name` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t357" href="#t357">357</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t358" href="#t358">358</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t359" href="#t359">359</a></span><span class="t"><span class="str">        Variable: Tensor or LoDTensor calculated by fc layer. The data type is same with input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t360" href="#t360">360</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t361" href="#t361">361</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t362" href="#t362">362</a></span><span class="t"><span class="str">        ValueError: If dimensions of the input Tensor is less than 2.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t363" href="#t363">363</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t364" href="#t364">364</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t365" href="#t365">365</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t366" href="#t366">366</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t367" href="#t367">367</a></span><span class="t"><span class="str">          import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t368" href="#t368">368</a></span><span class="t"><span class="str">          import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t369" href="#t369">369</a></span><span class="t"><span class="str">          paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t370" href="#t370">370</a></span><span class="t"><span class="str">          # when input is single tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t371" href="#t371">371</a></span><span class="t"><span class="str">          data = fluid.data(name="data", shape=[-1, 32], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t372" href="#t372">372</a></span><span class="t"><span class="str">          fc = fluid.layers.fc(input=data, size=1000, act="tanh")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t373" href="#t373">373</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t374" href="#t374">374</a></span><span class="t"><span class="str">          # when input are multiple tensors</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t375" href="#t375">375</a></span><span class="t"><span class="str">          data_1 = fluid.data(name="data_1", shape=[-1, 32], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t376" href="#t376">376</a></span><span class="t"><span class="str">          data_2 = fluid.data(name="data_2", shape=[-1, 36], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t377" href="#t377">377</a></span><span class="t"><span class="str">          fc = fluid.layers.fc(input=[data_1, data_2], size=1000, act="tanh")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t378" href="#t378">378</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t379" href="#t379">379</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"fc"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t380" href="#t380">380</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">,</span> <span class="str">'fc'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t381" href="#t381">381</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">381&#x202F;&#x219B;&#x202F;382</span><span class="annotate long">line 381 didn't jump to line 382, because the condition on line 381 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t382" href="#t382">382</a></span><span class="t">        <span class="key">for</span> <span class="nam">i</span><span class="op">,</span> <span class="nam">input_x</span> <span class="key">in</span> <span class="nam">enumerate</span><span class="op">(</span><span class="nam">input</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t383" href="#t383">383</a></span><span class="t">            <span class="nam">check_type</span><span class="op">(</span><span class="nam">input_x</span><span class="op">,</span> <span class="str">'input['</span> <span class="op">+</span> <span class="nam">str</span><span class="op">(</span><span class="nam">i</span><span class="op">)</span> <span class="op">+</span> <span class="str">']'</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">,</span> <span class="str">'fc'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t384" href="#t384">384</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t385" href="#t385">385</a></span><span class="t">    <span class="nam">check_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t386" href="#t386">386</a></span><span class="t">        <span class="nam">dtype</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'uint16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'fc'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t387" href="#t387">387</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t388" href="#t388">388</a></span><span class="t">    <span class="nam">mul_results</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t389" href="#t389">389</a></span><span class="t">    <span class="key">for</span> <span class="nam">input_var</span><span class="op">,</span> <span class="nam">param_attr</span> <span class="key">in</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">iter_inputs_and_params</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t390" href="#t390">390</a></span><span class="t">        <span class="nam">input_shape</span> <span class="op">=</span> <span class="nam">input_var</span><span class="op">.</span><span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t391" href="#t391">391</a></span><span class="t">        <span class="key">if</span> <span class="nam">num_flatten_dims</span> <span class="op">==</span> <span class="op">-</span><span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">391&#x202F;&#x219B;&#x202F;392</span><span class="annotate long">line 391 didn't jump to line 392, because the condition on line 391 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t392" href="#t392">392</a></span><span class="t">            <span class="nam">num_flatten_dims</span> <span class="op">=</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input_shape</span><span class="op">)</span> <span class="op">-</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t393" href="#t393">393</a></span><span class="t">        <span class="nam">param_shape</span> <span class="op">=</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t394" href="#t394">394</a></span><span class="t">            <span class="nam">reduce</span><span class="op">(</span><span class="key">lambda</span> <span class="nam">a</span><span class="op">,</span> <span class="nam">b</span><span class="op">:</span> <span class="nam">a</span> <span class="op">*</span> <span class="nam">b</span><span class="op">,</span> <span class="nam">input_shape</span><span class="op">[</span><span class="nam">num_flatten_dims</span><span class="op">:</span><span class="op">]</span><span class="op">,</span> <span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t395" href="#t395">395</a></span><span class="t">        <span class="op">]</span> <span class="op">+</span> <span class="op">[</span><span class="nam">size</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t396" href="#t396">396</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t397" href="#t397">397</a></span><span class="t">        <span class="nam">w</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t398" href="#t398">398</a></span><span class="t">            <span class="nam">attr</span><span class="op">=</span><span class="nam">param_attr</span><span class="op">,</span> <span class="nam">shape</span><span class="op">=</span><span class="nam">param_shape</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">is_bias</span><span class="op">=</span><span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t399" href="#t399">399</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t400" href="#t400">400</a></span><span class="t">        <span class="nam">tmp</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t401" href="#t401">401</a></span><span class="t">        <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t402" href="#t402">402</a></span><span class="t">            <span class="nam">type</span><span class="op">=</span><span class="str">"mul"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t403" href="#t403">403</a></span><span class="t">            <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">input_var</span><span class="op">,</span> <span class="str">"Y"</span><span class="op">:</span> <span class="nam">w</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t404" href="#t404">404</a></span><span class="t">            <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">tmp</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t405" href="#t405">405</a></span><span class="t">            <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">"x_num_col_dims"</span><span class="op">:</span> <span class="nam">num_flatten_dims</span><span class="op">,</span> <span class="str">"y_num_col_dims"</span><span class="op">:</span> <span class="num">1</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t406" href="#t406">406</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t407" href="#t407">407</a></span><span class="t">        <span class="nam">mul_results</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">tmp</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t408" href="#t408">408</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t409" href="#t409">409</a></span><span class="t">    <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">mul_results</span><span class="op">)</span> <span class="op">==</span> <span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">409&#x202F;&#x219B;&#x202F;412</span><span class="annotate long">line 409 didn't jump to line 412, because the condition on line 409 was never false</span></span></p>
    <p class="run"><span class="n"><a id="t410" href="#t410">410</a></span><span class="t">        <span class="nam">pre_bias</span> <span class="op">=</span> <span class="nam">mul_results</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t411" href="#t411">411</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t412" href="#t412">412</a></span><span class="t">        <span class="nam">pre_bias</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t413" href="#t413">413</a></span><span class="t">        <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t414" href="#t414">414</a></span><span class="t">            <span class="nam">type</span><span class="op">=</span><span class="str">"sum"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t415" href="#t415">415</a></span><span class="t">            <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">mul_results</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t416" href="#t416">416</a></span><span class="t">            <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">pre_bias</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t417" href="#t417">417</a></span><span class="t">            <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">"use_mkldnn"</span><span class="op">:</span> <span class="key">False</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t418" href="#t418">418</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t419" href="#t419">419</a></span><span class="t">    <span class="com"># add bias</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t420" href="#t420">420</a></span><span class="t">    <span class="nam">pre_activation</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_bias_op</span><span class="op">(</span><span class="nam">pre_bias</span><span class="op">,</span> <span class="nam">dim_start</span><span class="op">=</span><span class="nam">num_flatten_dims</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t421" href="#t421">421</a></span><span class="t">    <span class="com"># add activation</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t422" href="#t422">422</a></span><span class="t">    <span class="key">return</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_activation</span><span class="op">(</span><span class="nam">pre_activation</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t423" href="#t423">423</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t424" href="#t424">424</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t425" href="#t425">425</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.nn.functional.embedding"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t426" href="#t426">426</a></span><span class="t"><span class="key">def</span> <span class="nam">embedding</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t427" href="#t427">427</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t428" href="#t428">428</a></span><span class="t">    <span class="nam">size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t429" href="#t429">429</a></span><span class="t">    <span class="nam">is_sparse</span><span class="op">=</span><span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t430" href="#t430">430</a></span><span class="t">    <span class="nam">is_distributed</span><span class="op">=</span><span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t431" href="#t431">431</a></span><span class="t">    <span class="nam">padding_idx</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t432" href="#t432">432</a></span><span class="t">    <span class="nam">param_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t433" href="#t433">433</a></span><span class="t">    <span class="nam">dtype</span><span class="op">=</span><span class="str">'float32'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t434" href="#t434">434</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t435" href="#t435">435</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t436" href="#t436">436</a></span><span class="t"><span class="str">    :api_attr: Static Graph</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t437" href="#t437">437</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t438" href="#t438">438</a></span><span class="t"><span class="str">    **WARING:** This OP will be deprecated in a future release. This OP requires the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t439" href="#t439">439</a></span><span class="t"><span class="str">    last dimension of Tensor shape must be equal to 1. It is recommended to use</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t440" href="#t440">440</a></span><span class="t"><span class="str">    fluid. :ref:`api_fluid_embedding` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t441" href="#t441">441</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t442" href="#t442">442</a></span><span class="t"><span class="str">    The operator is used to lookup embeddings vector of ids provided by :attr:`input` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t443" href="#t443">443</a></span><span class="t"><span class="str">    It automatically constructs a 2D embedding matrix based on the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t444" href="#t444">444</a></span><span class="t"><span class="str">    input :attr:`size` (vocab_size, emb_size) and :attr:`dtype` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t445" href="#t445">445</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t446" href="#t446">446</a></span><span class="t"><span class="str">    This OP requires the last dimension of Tensor shape must be equal to 1. The shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t447" href="#t447">447</a></span><span class="t"><span class="str">    of output Tensor is generated by replacing the last dimension of the input Tensor shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t448" href="#t448">448</a></span><span class="t"><span class="str">    with emb_size.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t449" href="#t449">449</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t450" href="#t450">450</a></span><span class="t"><span class="str">    **Note:** The id in :attr:`input` must satisfy :math:`0 =&lt; id &lt; size[0]` ,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t451" href="#t451">451</a></span><span class="t"><span class="str">    otherwise the program will throw an exception and exit.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t452" href="#t452">452</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t453" href="#t453">453</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t454" href="#t454">454</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t455" href="#t455">455</a></span><span class="t"><span class="str">        Case 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t456" href="#t456">456</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t457" href="#t457">457</a></span><span class="t"><span class="str">        input is a Tensor. padding_idx = -1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t458" href="#t458">458</a></span><span class="t"><span class="str">            input.data = [[[1], [3]], [[2], [4]], [[4], [127]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t459" href="#t459">459</a></span><span class="t"><span class="str">            input.shape = [3, 2, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t460" href="#t460">460</a></span><span class="t"><span class="str">        Given size = [128, 16]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t461" href="#t461">461</a></span><span class="t"><span class="str">        output is a Tensor:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t462" href="#t462">462</a></span><span class="t"><span class="str">            out.shape = [3, 2, 16]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t463" href="#t463">463</a></span><span class="t"><span class="str">            out.data = [[[0.129435295, 0.244512452, ..., 0.436322452],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t464" href="#t464">464</a></span><span class="t"><span class="str">                        [0.345421456, 0.524563927, ..., 0.144534654]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t465" href="#t465">465</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t466" href="#t466">466</a></span><span class="t"><span class="str">                        [[0.345249859, 0.124939536, ..., 0.194353745],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t467" href="#t467">467</a></span><span class="t"><span class="str">                        [0.945345345, 0.435394634, ..., 0.435345365]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t468" href="#t468">468</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t469" href="#t469">469</a></span><span class="t"><span class="str">                        [[0.945345345, 0.435394634, ..., 0.435345365],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t470" href="#t470">470</a></span><span class="t"><span class="str">                        [0.0,         0.0,         ..., 0.0        ]]]  # padding data</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t471" href="#t471">471</a></span><span class="t"><span class="str">        The input padding_idx is less than 0, it is automatically converted to padding_idx = -1 + 128 = 127</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t472" href="#t472">472</a></span><span class="t"><span class="str">        It will pad all-zero data when ids is 127.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t473" href="#t473">473</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t474" href="#t474">474</a></span><span class="t"><span class="str">        Case 2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t475" href="#t475">475</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t476" href="#t476">476</a></span><span class="t"><span class="str">        input is a LoDTensor with 1-level LoD. padding_idx = 0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t477" href="#t477">477</a></span><span class="t"><span class="str">            input.lod = [[2, 3]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t478" href="#t478">478</a></span><span class="t"><span class="str">            input.data = [[1], [3], [2], [4], [0]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t479" href="#t479">479</a></span><span class="t"><span class="str">            input.shape = [5, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t480" href="#t480">480</a></span><span class="t"><span class="str">        Given size = [128, 16]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t481" href="#t481">481</a></span><span class="t"><span class="str">        output is a LoDTensor:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t482" href="#t482">482</a></span><span class="t"><span class="str">            out.lod = [[2, 3]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t483" href="#t483">483</a></span><span class="t"><span class="str">            out.shape = [5, 16]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t484" href="#t484">484</a></span><span class="t"><span class="str">            out.data = [[0.129435295, 0.244512452, ..., 0.436322452],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t485" href="#t485">485</a></span><span class="t"><span class="str">                        [0.345421456, 0.524563927, ..., 0.144534654],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t486" href="#t486">486</a></span><span class="t"><span class="str">                        [0.345249859, 0.124939536, ..., 0.194353745],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t487" href="#t487">487</a></span><span class="t"><span class="str">                        [0.945345345, 0.435394634, ..., 0.435345365],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t488" href="#t488">488</a></span><span class="t"><span class="str">                        [0.0,         0.0,         ..., 0.0        ]]  # padding data</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t489" href="#t489">489</a></span><span class="t"><span class="str">        It will pad all-zero data when ids is 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t490" href="#t490">490</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t491" href="#t491">491</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t492" href="#t492">492</a></span><span class="t"><span class="str">        input(Variable): A Tensor or LoDTensor with type int64, which contains the id information.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t493" href="#t493">493</a></span><span class="t"><span class="str">            The last dimension of Tensor shape must be equal to 1. The value of the input id should</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t494" href="#t494">494</a></span><span class="t"><span class="str">            satisfy :math:`0&lt;= id &lt; size[0]` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t495" href="#t495">495</a></span><span class="t"><span class="str">        size(tuple|list): The shape of lookup table parameter. It should have two elements which</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t496" href="#t496">496</a></span><span class="t"><span class="str">            indicates the size of the dictionary of embeddings and the size of each embedding vector respectively.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t497" href="#t497">497</a></span><span class="t"><span class="str">        is_sparse(bool): The flag indicating whether to use sparse update. This parameter only</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t498" href="#t498">498</a></span><span class="t"><span class="str">            affects the performance of the backwards gradient update. It is recommended to set</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t499" href="#t499">499</a></span><span class="t"><span class="str">            True because sparse update is faster. But some optimizer does not support sparse update,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t500" href="#t500">500</a></span><span class="t"><span class="str">            such as :ref:`api_fluid_optimizer_AdadeltaOptimizer` , :ref:`api_fluid_optimizer_AdamaxOptimizer` ,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t501" href="#t501">501</a></span><span class="t"><span class="str">            :ref:`api_fluid_optimizer_DecayedAdagradOptimizer` , :ref:`api_fluid_optimizer_FtrlOptimizer` ,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t502" href="#t502">502</a></span><span class="t"><span class="str">            :ref:`api_fluid_optimizer_LambOptimizer` and :ref:`api_fluid_optimizer_LarsMomentumOptimizer` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t503" href="#t503">503</a></span><span class="t"><span class="str">            In these case, is_sparse must be False. Default: False.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t504" href="#t504">504</a></span><span class="t"><span class="str">        is_distributed(bool): Whether to store the embedding matrix in a distributed manner. Only used</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t505" href="#t505">505</a></span><span class="t"><span class="str">            in multi-machine distributed CPU training. Default: False.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t506" href="#t506">506</a></span><span class="t"><span class="str">        padding_idx(int|long|None): padding_idx needs to be in the interval [-vocab_size, vocab_size).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t507" href="#t507">507</a></span><span class="t"><span class="str">            If :math:`padding\_idx &lt; 0`, the :math:`padding\_idx` will automatically be converted</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t508" href="#t508">508</a></span><span class="t"><span class="str">            to :math:`vocab\_size + padding\_idx` . It will output all-zero padding data whenever lookup</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t509" href="#t509">509</a></span><span class="t"><span class="str">            encounters :math:`padding\_idx` in id. And the padding data will not be updated while training.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t510" href="#t510">510</a></span><span class="t"><span class="str">            If set None, it makes no effect to output. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t511" href="#t511">511</a></span><span class="t"><span class="str">        param_attr(ParamAttr): To specify the weight parameter property. Default: None, which means the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t512" href="#t512">512</a></span><span class="t"><span class="str">            default weight parameter property is used. See usage for details in :ref:`api_fluid_ParamAttr` . In addition,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t513" href="#t513">513</a></span><span class="t"><span class="str">            user-defined or pre-trained word vectors can be loaded with the :attr:`param_attr` parameter.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t514" href="#t514">514</a></span><span class="t"><span class="str">            The local word vector needs to be transformed into numpy format, and the shape of local word</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t515" href="#t515">515</a></span><span class="t"><span class="str">            vector should be consistent with :attr:`size` . Then :ref:`api_fluid_initializer_NumpyArrayInitializer`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t516" href="#t516">516</a></span><span class="t"><span class="str">            is used to load custom or pre-trained word vectors. See code example 2 for details.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t517" href="#t517">517</a></span><span class="t"><span class="str">        dtype(str|core.VarDesc.VarType): It refers to the data type of output Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t518" href="#t518">518</a></span><span class="t"><span class="str">            It must be float32 or float64. Default: float32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t519" href="#t519">519</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t520" href="#t520">520</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t521" href="#t521">521</a></span><span class="t"><span class="str">        Variable: Embedding Tensor or LoDTensor mapped by input. The data type is the same as :attr:`dtype` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t522" href="#t522">522</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t523" href="#t523">523</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t524" href="#t524">524</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t525" href="#t525">525</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t526" href="#t526">526</a></span><span class="t"><span class="str">          import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t527" href="#t527">527</a></span><span class="t"><span class="str">          import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t528" href="#t528">528</a></span><span class="t"><span class="str">          import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t529" href="#t529">529</a></span><span class="t"><span class="str">          paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t530" href="#t530">530</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t531" href="#t531">531</a></span><span class="t"><span class="str">          data = fluid.data(name='x', shape=[None, 1], dtype='int64')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t532" href="#t532">532</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t533" href="#t533">533</a></span><span class="t"><span class="str">          # example 1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t534" href="#t534">534</a></span><span class="t"><span class="str">          emb_1 = fluid.embedding(input=data, size=[128, 64])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t535" href="#t535">535</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t536" href="#t536">536</a></span><span class="t"><span class="str">          # example 2: load custom or pre-trained word vectors</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t537" href="#t537">537</a></span><span class="t"><span class="str">          weight_data = np.random.random(size=(128, 100))  # word vectors with numpy format</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t538" href="#t538">538</a></span><span class="t"><span class="str">          w_param_attrs = fluid.ParamAttr(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t539" href="#t539">539</a></span><span class="t"><span class="str">              name="emb_weight",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t540" href="#t540">540</a></span><span class="t"><span class="str">              learning_rate=0.5,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t541" href="#t541">541</a></span><span class="t"><span class="str">              initializer=fluid.initializer.NumpyArrayInitializer(weight_data),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t542" href="#t542">542</a></span><span class="t"><span class="str">              trainable=True)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t543" href="#t543">543</a></span><span class="t"><span class="str">          emb_2 = fluid.layers.embedding(input=data, size=(128, 100), param_attr=w_param_attrs, dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t544" href="#t544">544</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t545" href="#t545">545</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t546" href="#t546">546</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'embedding'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t547" href="#t547">547</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t548" href="#t548">548</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'int64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'fluid.layers.embedding'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t549" href="#t549">549</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t550" href="#t550">550</a></span><span class="t">    <span class="nam">check_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t551" href="#t551">551</a></span><span class="t">        <span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t552" href="#t552">552</a></span><span class="t">        <span class="str">'dtype'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t553" href="#t553">553</a></span><span class="t">        <span class="op">[</span><span class="str">'uint16'</span><span class="op">,</span> <span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t554" href="#t554">554</a></span><span class="t">        <span class="str">'fluid.layers.embedding'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t555" href="#t555">555</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t556" href="#t556">556</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t557" href="#t557">557</a></span><span class="t">    <span class="key">if</span> <span class="nam">is_distributed</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t558" href="#t558">558</a></span><span class="t">        <span class="nam">is_distributed</span> <span class="op">=</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t559" href="#t559">559</a></span><span class="t">        <span class="nam">warnings</span><span class="op">.</span><span class="nam">warn</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t560" href="#t560">560</a></span><span class="t">            <span class="str">"is_distributed is go out of use, `fluid.contrib.layers.sparse_embedding` is your needed"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t561" href="#t561">561</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t562" href="#t562">562</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t563" href="#t563">563</a></span><span class="t">    <span class="nam">remote_prefetch</span> <span class="op">=</span> <span class="key">True</span> <span class="key">if</span> <span class="nam">is_sparse</span> <span class="key">else</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t564" href="#t564">564</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t565" href="#t565">565</a></span><span class="t">    <span class="nam">w</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t566" href="#t566">566</a></span><span class="t">        <span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">param_attr</span><span class="op">,</span> <span class="nam">shape</span><span class="op">=</span><span class="nam">size</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">is_bias</span><span class="op">=</span><span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t567" href="#t567">567</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t568" href="#t568">568</a></span><span class="t">    <span class="nam">tmp</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t569" href="#t569">569</a></span><span class="t">    <span class="nam">padding_idx</span> <span class="op">=</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t570" href="#t570">570</a></span><span class="t">        <span class="op">-</span><span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t571" href="#t571">571</a></span><span class="t">        <span class="key">if</span> <span class="nam">padding_idx</span> <span class="key">is</span> <span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t572" href="#t572">572</a></span><span class="t">        <span class="key">else</span> <span class="nam">padding_idx</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t573" href="#t573">573</a></span><span class="t">        <span class="key">if</span> <span class="nam">padding_idx</span> <span class="op">>=</span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t574" href="#t574">574</a></span><span class="t">        <span class="key">else</span> <span class="op">(</span><span class="nam">size</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">+</span> <span class="nam">padding_idx</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t575" href="#t575">575</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t576" href="#t576">576</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t577" href="#t577">577</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'lookup_table'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t578" href="#t578">578</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Ids'</span><span class="op">:</span> <span class="nam">input</span><span class="op">,</span> <span class="str">'W'</span><span class="op">:</span> <span class="nam">w</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t579" href="#t579">579</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">tmp</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t580" href="#t580">580</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t581" href="#t581">581</a></span><span class="t">            <span class="str">'is_sparse'</span><span class="op">:</span> <span class="nam">is_sparse</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t582" href="#t582">582</a></span><span class="t">            <span class="str">'is_distributed'</span><span class="op">:</span> <span class="nam">is_distributed</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t583" href="#t583">583</a></span><span class="t">            <span class="str">'remote_prefetch'</span><span class="op">:</span> <span class="nam">remote_prefetch</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t584" href="#t584">584</a></span><span class="t">            <span class="str">'padding_idx'</span><span class="op">:</span> <span class="nam">padding_idx</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t585" href="#t585">585</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t586" href="#t586">586</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t587" href="#t587">587</a></span><span class="t">    <span class="key">return</span> <span class="nam">tmp</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t588" href="#t588">588</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t589" href="#t589">589</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t590" href="#t590">590</a></span><span class="t"><span class="key">def</span> <span class="nam">_pull_sparse</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t591" href="#t591">591</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t592" href="#t592">592</a></span><span class="t">    <span class="nam">size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t593" href="#t593">593</a></span><span class="t">    <span class="nam">table_id</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t594" href="#t594">594</a></span><span class="t">    <span class="nam">accessor_class</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t595" href="#t595">595</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="str">"embedding"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t596" href="#t596">596</a></span><span class="t">    <span class="nam">ctr_label_name</span><span class="op">=</span><span class="str">""</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t597" href="#t597">597</a></span><span class="t">    <span class="nam">padding_id</span><span class="op">=</span><span class="num">0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t598" href="#t598">598</a></span><span class="t">    <span class="nam">dtype</span><span class="op">=</span><span class="str">'float32'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t599" href="#t599">599</a></span><span class="t">    <span class="nam">scale_sparse_grad</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t600" href="#t600">600</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t601" href="#t601">601</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t602" href="#t602">602</a></span><span class="t"><span class="str">    **Pull Fleet Sparse Layer**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t603" href="#t603">603</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t604" href="#t604">604</a></span><span class="t"><span class="str">    This layer is used to lookup embeddings of IDs, provided by :attr:`input`, in</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t605" href="#t605">605</a></span><span class="t"><span class="str">    Fleet lookup table. The result of this lookup is the embedding of each ID in the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t606" href="#t606">606</a></span><span class="t"><span class="str">    :attr:`input`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t607" href="#t607">607</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t608" href="#t608">608</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t609" href="#t609">609</a></span><span class="t"><span class="str">        input(Variable|list of Variable): Input is a Tensor&lt;int64> Variable, which</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t610" href="#t610">610</a></span><span class="t"><span class="str">            contains the IDs information.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t611" href="#t611">611</a></span><span class="t"><span class="str">        size(int): The embedding size parameter, which indicates the size of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t612" href="#t612">612</a></span><span class="t"><span class="str">            each embedding vector respectively.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t613" href="#t613">613</a></span><span class="t"><span class="str">        table_id(int): the fleet table id of this embedding.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t614" href="#t614">614</a></span><span class="t"><span class="str">        accessor_class(str): the pslib accessor of the table, default is DownpourCtrAccessor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t615" href="#t615">615</a></span><span class="t"><span class="str">        ctr_label_name(str): the layer name of click.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t616" href="#t616">616</a></span><span class="t"><span class="str">        padding_id(int): the padding id during lookup, default is 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t617" href="#t617">617</a></span><span class="t"><span class="str">        dtype(str): The dtype refers to the data type of output tensor. Only supports</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t618" href="#t618">618</a></span><span class="t"><span class="str">            float32 now.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t619" href="#t619">619</a></span><span class="t"><span class="str">        scale_sparse_grad(bool): whether to scale sparse gradient with batch size. default</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t620" href="#t620">620</a></span><span class="t"><span class="str">            is True.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t621" href="#t621">621</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t622" href="#t622">622</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t623" href="#t623">623</a></span><span class="t"><span class="str">        Variable|list of Variable: The tensor variable storing the embeddings of the \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t624" href="#t624">624</a></span><span class="t"><span class="str">                  supplied inputs.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t625" href="#t625">625</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t626" href="#t626">626</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t627" href="#t627">627</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t628" href="#t628">628</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t629" href="#t629">629</a></span><span class="t"><span class="str">          import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t630" href="#t630">630</a></span><span class="t"><span class="str">          data = fluid.layers.data(name='sequence', shape=[1], dtype='int64', lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t631" href="#t631">631</a></span><span class="t"><span class="str">          emb = fluid.layers.nn._pull_sparse(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t632" href="#t632">632</a></span><span class="t"><span class="str">              input=data, size=11, table_id=0, accessor_class="DownpourCtrAccessor")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t633" href="#t633">633</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t634" href="#t634">634</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="nam">name</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t635" href="#t635">635</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">multiple_input</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t636" href="#t636">636</a></span><span class="t">    <span class="nam">outs</span> <span class="op">=</span> <span class="op">[</span><span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t637" href="#t637">637</a></span><span class="t">    <span class="nam">input_names</span> <span class="op">=</span> <span class="op">[</span><span class="nam">i</span><span class="op">.</span><span class="nam">name</span> <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span> <span class="nam">inputs</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t638" href="#t638">638</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t639" href="#t639">639</a></span><span class="t">        <span class="str">'EmbeddingDim'</span><span class="op">:</span> <span class="nam">size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t640" href="#t640">640</a></span><span class="t">        <span class="str">'TableId'</span><span class="op">:</span> <span class="nam">table_id</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t641" href="#t641">641</a></span><span class="t">        <span class="str">'AccessorClass'</span><span class="op">:</span> <span class="nam">accessor_class</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t642" href="#t642">642</a></span><span class="t">        <span class="str">'CtrLabelName'</span><span class="op">:</span> <span class="nam">ctr_label_name</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t643" href="#t643">643</a></span><span class="t">        <span class="str">'PaddingId'</span><span class="op">:</span> <span class="nam">padding_id</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t644" href="#t644">644</a></span><span class="t">        <span class="str">'ScaleSparseGrad'</span><span class="op">:</span> <span class="nam">scale_sparse_grad</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t645" href="#t645">645</a></span><span class="t">        <span class="str">'InputNames'</span><span class="op">:</span> <span class="nam">input_names</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t646" href="#t646">646</a></span><span class="t">        <span class="com"># this is only for compatible with embedding op</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t647" href="#t647">647</a></span><span class="t">        <span class="str">'is_distributed'</span><span class="op">:</span> <span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t648" href="#t648">648</a></span><span class="t">    <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t649" href="#t649">649</a></span><span class="t">    <span class="com"># this is only for compatible with embedding op</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t650" href="#t650">650</a></span><span class="t">    <span class="nam">w</span><span class="op">,</span> <span class="nam">_</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_or_get_global_variable</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t651" href="#t651">651</a></span><span class="t">        <span class="nam">name</span><span class="op">=</span><span class="nam">name</span><span class="op">,</span> <span class="nam">shape</span><span class="op">=</span><span class="op">[</span><span class="nam">size</span><span class="op">]</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">is_bias</span><span class="op">=</span><span class="key">False</span><span class="op">,</span> <span class="nam">persistable</span><span class="op">=</span><span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t652" href="#t652">652</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t653" href="#t653">653</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t654" href="#t654">654</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'pull_sparse'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t655" href="#t655">655</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Ids'</span><span class="op">:</span> <span class="nam">inputs</span><span class="op">,</span> <span class="str">'W'</span><span class="op">:</span> <span class="nam">w</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t656" href="#t656">656</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">outs</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t657" href="#t657">657</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t658" href="#t658">658</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t659" href="#t659">659</a></span><span class="t">    <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">outs</span><span class="op">)</span> <span class="op">==</span> <span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t660" href="#t660">660</a></span><span class="t">        <span class="key">return</span> <span class="nam">outs</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t661" href="#t661">661</a></span><span class="t">    <span class="key">return</span> <span class="nam">outs</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t662" href="#t662">662</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t663" href="#t663">663</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t664" href="#t664">664</a></span><span class="t"><span class="key">def</span> <span class="nam">_pull_sparse_v2</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t665" href="#t665">665</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t666" href="#t666">666</a></span><span class="t">    <span class="nam">size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t667" href="#t667">667</a></span><span class="t">    <span class="nam">table_id</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t668" href="#t668">668</a></span><span class="t">    <span class="nam">accessor_class</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t669" href="#t669">669</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="str">"embedding"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t670" href="#t670">670</a></span><span class="t">    <span class="nam">ctr_label_name</span><span class="op">=</span><span class="str">""</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t671" href="#t671">671</a></span><span class="t">    <span class="nam">padding_id</span><span class="op">=</span><span class="num">0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t672" href="#t672">672</a></span><span class="t">    <span class="nam">dtype</span><span class="op">=</span><span class="str">'float32'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t673" href="#t673">673</a></span><span class="t">    <span class="nam">scale_sparse_grad</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t674" href="#t674">674</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t675" href="#t675">675</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t676" href="#t676">676</a></span><span class="t"><span class="str">    **Pull Fleet Sparse Layer**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t677" href="#t677">677</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t678" href="#t678">678</a></span><span class="t"><span class="str">    This layer is used to lookup embeddings of IDs, provided by :attr:`input`, in</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t679" href="#t679">679</a></span><span class="t"><span class="str">    Fleet lookup table. The result of this lookup is the embedding of each ID in the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t680" href="#t680">680</a></span><span class="t"><span class="str">    :attr:`input`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t681" href="#t681">681</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t682" href="#t682">682</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t683" href="#t683">683</a></span><span class="t"><span class="str">        input(Variable|list of Variable): Input is a Tensor&lt;int64> Variable, which</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t684" href="#t684">684</a></span><span class="t"><span class="str">            contains the IDs information.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t685" href="#t685">685</a></span><span class="t"><span class="str">        size(int): The embedding size parameter, which indicates the size of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t686" href="#t686">686</a></span><span class="t"><span class="str">            each embedding vector respectively.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t687" href="#t687">687</a></span><span class="t"><span class="str">        table_id(int): the pslib table id of this embedding.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t688" href="#t688">688</a></span><span class="t"><span class="str">        accessor_class(str): the fleet accessor of the table, default is DownpourCtrAccessor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t689" href="#t689">689</a></span><span class="t"><span class="str">        ctr_label_name(str): the layer name of click.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t690" href="#t690">690</a></span><span class="t"><span class="str">        padding_id(int): the padding id during lookup, default is 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t691" href="#t691">691</a></span><span class="t"><span class="str">        dtype(str): The dtype refers to the data type of output tensor. Only supports</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t692" href="#t692">692</a></span><span class="t"><span class="str">            float32 now.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t693" href="#t693">693</a></span><span class="t"><span class="str">        scale_sparse_grad(bool): whether to scale sparse gradient with batch size. default</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t694" href="#t694">694</a></span><span class="t"><span class="str">            is True.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t695" href="#t695">695</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t696" href="#t696">696</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t697" href="#t697">697</a></span><span class="t"><span class="str">        Variable|list of Variable: The tensor variable storing the embeddings of the \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t698" href="#t698">698</a></span><span class="t"><span class="str">                  supplied inputs.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t699" href="#t699">699</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t700" href="#t700">700</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t701" href="#t701">701</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t702" href="#t702">702</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t703" href="#t703">703</a></span><span class="t"><span class="str">          import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t704" href="#t704">704</a></span><span class="t"><span class="str">          data = fluid.layers.data(name='sequence', shape=[1], dtype='int64', lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t705" href="#t705">705</a></span><span class="t"><span class="str">          emb = fluid.layers.nn._pull_sparse_v2(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t706" href="#t706">706</a></span><span class="t"><span class="str">              input=data, size=11, table_id=0, accessor_class="DownpourCtrAccessor")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t707" href="#t707">707</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t708" href="#t708">708</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="nam">name</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t709" href="#t709">709</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">multiple_input</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t710" href="#t710">710</a></span><span class="t">    <span class="nam">outs</span> <span class="op">=</span> <span class="op">[</span><span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t711" href="#t711">711</a></span><span class="t">    <span class="nam">input_names</span> <span class="op">=</span> <span class="op">[</span><span class="nam">i</span><span class="op">.</span><span class="nam">name</span> <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span> <span class="nam">inputs</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t712" href="#t712">712</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t713" href="#t713">713</a></span><span class="t">        <span class="str">'EmbeddingDim'</span><span class="op">:</span> <span class="nam">size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t714" href="#t714">714</a></span><span class="t">        <span class="str">'TableId'</span><span class="op">:</span> <span class="nam">table_id</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t715" href="#t715">715</a></span><span class="t">        <span class="str">'AccessorClass'</span><span class="op">:</span> <span class="nam">accessor_class</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t716" href="#t716">716</a></span><span class="t">        <span class="str">'CtrLabelName'</span><span class="op">:</span> <span class="nam">ctr_label_name</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t717" href="#t717">717</a></span><span class="t">        <span class="str">'PaddingId'</span><span class="op">:</span> <span class="nam">padding_id</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t718" href="#t718">718</a></span><span class="t">        <span class="str">'ScaleSparseGrad'</span><span class="op">:</span> <span class="nam">scale_sparse_grad</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t719" href="#t719">719</a></span><span class="t">        <span class="str">'InputNames'</span><span class="op">:</span> <span class="nam">input_names</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t720" href="#t720">720</a></span><span class="t">        <span class="com"># this is only for compatible with embedding op</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t721" href="#t721">721</a></span><span class="t">        <span class="str">'is_distributed'</span><span class="op">:</span> <span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t722" href="#t722">722</a></span><span class="t">    <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t723" href="#t723">723</a></span><span class="t">    <span class="com"># this is only for compatible with embedding op</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t724" href="#t724">724</a></span><span class="t">    <span class="nam">w</span><span class="op">,</span> <span class="nam">_</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_or_get_global_variable</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t725" href="#t725">725</a></span><span class="t">        <span class="nam">name</span><span class="op">=</span><span class="nam">name</span><span class="op">,</span> <span class="nam">shape</span><span class="op">=</span><span class="op">[</span><span class="nam">size</span><span class="op">]</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">is_bias</span><span class="op">=</span><span class="key">False</span><span class="op">,</span> <span class="nam">persistable</span><span class="op">=</span><span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t726" href="#t726">726</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t727" href="#t727">727</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t728" href="#t728">728</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'pull_sparse_v2'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t729" href="#t729">729</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Ids'</span><span class="op">:</span> <span class="nam">inputs</span><span class="op">,</span> <span class="str">'W'</span><span class="op">:</span> <span class="nam">w</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t730" href="#t730">730</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">outs</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t731" href="#t731">731</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t732" href="#t732">732</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t733" href="#t733">733</a></span><span class="t">    <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">outs</span><span class="op">)</span> <span class="op">==</span> <span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t734" href="#t734">734</a></span><span class="t">        <span class="key">return</span> <span class="nam">outs</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t735" href="#t735">735</a></span><span class="t">    <span class="key">return</span> <span class="nam">outs</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t736" href="#t736">736</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t737" href="#t737">737</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t738" href="#t738">738</a></span><span class="t"><span class="key">def</span> <span class="nam">_pull_gpups_sparse</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t739" href="#t739">739</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span> <span class="nam">size</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="str">'float32'</span><span class="op">,</span> <span class="nam">is_distributed</span><span class="op">=</span><span class="key">False</span><span class="op">,</span> <span class="nam">is_sparse</span><span class="op">=</span><span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t740" href="#t740">740</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t741" href="#t741">741</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t742" href="#t742">742</a></span><span class="t"><span class="str">    **Pull GpuPS Sparse Layer**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t743" href="#t743">743</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t744" href="#t744">744</a></span><span class="t"><span class="str">    This layer is used to lookup embeddings of IDs, provided by :attr:`input`, in</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t745" href="#t745">745</a></span><span class="t"><span class="str">    GpuPS lookup table. The result of this lookup is the embedding of each ID in the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t746" href="#t746">746</a></span><span class="t"><span class="str">    :attr:`input`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t747" href="#t747">747</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t748" href="#t748">748</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t749" href="#t749">749</a></span><span class="t"><span class="str">        input(Variable|list of Variable): Input is a Tensor&lt;int64> Variable, which</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t750" href="#t750">750</a></span><span class="t"><span class="str">            contains the IDs information.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t751" href="#t751">751</a></span><span class="t"><span class="str">        size(int|list of int): The embedding size parameter of each input, which indicates the size of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t752" href="#t752">752</a></span><span class="t"><span class="str">            each embedding vector respectively.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t753" href="#t753">753</a></span><span class="t"><span class="str">        dtype(str): The dtype refers to the data type of output tensor. Only supports</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t754" href="#t754">754</a></span><span class="t"><span class="str">            float32 now.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t755" href="#t755">755</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t756" href="#t756">756</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t757" href="#t757">757</a></span><span class="t"><span class="str">        Variable|list of Variable: The tensor variable storing the embeddings of the \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t758" href="#t758">758</a></span><span class="t"><span class="str">                  supplied inputs, whose size are indicated by size respectively.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t759" href="#t759">759</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t760" href="#t760">760</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t761" href="#t761">761</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t762" href="#t762">762</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t763" href="#t763">763</a></span><span class="t"><span class="str">          import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t764" href="#t764">764</a></span><span class="t"><span class="str">          slots = []</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t765" href="#t765">765</a></span><span class="t"><span class="str">          data_1 = fluid.layers.data(name='sequence', shape=[1], dtype='int64', lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t766" href="#t766">766</a></span><span class="t"><span class="str">          slots.append(data_1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t767" href="#t767">767</a></span><span class="t"><span class="str">          data_2 = fluid.layers.data(name='sequence', shape=[1], dtype='int64', lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t768" href="#t768">768</a></span><span class="t"><span class="str">          slots.append(data_2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t769" href="#t769">769</a></span><span class="t"><span class="str">          embs = fluid.layers.pull_gpups_sparse(input=slots, size=[11, 35])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t770" href="#t770">770</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t771" href="#t771">771</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'pull_gpups_sparse'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t772" href="#t772">772</a></span><span class="t">    <span class="key">if</span> <span class="nam">dtype</span> <span class="op">!=</span> <span class="str">'float32'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t773" href="#t773">773</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t774" href="#t774">774</a></span><span class="t">            <span class="str">"GpuPS only support float type embedding now, and your type is: "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t775" href="#t775">775</a></span><span class="t">            <span class="op">+</span> <span class="nam">dtype</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t776" href="#t776">776</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t777" href="#t777">777</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t778" href="#t778">778</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">multiple_input</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t779" href="#t779">779</a></span><span class="t">    <span class="nam">outs</span> <span class="op">=</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t780" href="#t780">780</a></span><span class="t">        <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t781" href="#t781">781</a></span><span class="t">        <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">len</span><span class="op">(</span><span class="nam">inputs</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t782" href="#t782">782</a></span><span class="t">    <span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t783" href="#t783">783</a></span><span class="t">    <span class="nam">w</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t784" href="#t784">784</a></span><span class="t">        <span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">param_attr</span><span class="op">,</span> <span class="nam">shape</span><span class="op">=</span><span class="op">[</span><span class="nam">size</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">]</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">is_bias</span><span class="op">=</span><span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t785" href="#t785">785</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t786" href="#t786">786</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t787" href="#t787">787</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'pull_gpups_sparse'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t788" href="#t788">788</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Ids'</span><span class="op">:</span> <span class="nam">inputs</span><span class="op">,</span> <span class="str">'W'</span><span class="op">:</span> <span class="nam">w</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t789" href="#t789">789</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">outs</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t790" href="#t790">790</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t791" href="#t791">791</a></span><span class="t">            <span class="str">'size'</span><span class="op">:</span> <span class="nam">size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t792" href="#t792">792</a></span><span class="t">            <span class="str">'is_distributed'</span><span class="op">:</span> <span class="nam">is_distributed</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t793" href="#t793">793</a></span><span class="t">            <span class="str">'is_sparse'</span><span class="op">:</span> <span class="nam">is_sparse</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t794" href="#t794">794</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t795" href="#t795">795</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t796" href="#t796">796</a></span><span class="t">    <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">outs</span><span class="op">)</span> <span class="op">==</span> <span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t797" href="#t797">797</a></span><span class="t">        <span class="key">return</span> <span class="nam">outs</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t798" href="#t798">798</a></span><span class="t">    <span class="key">return</span> <span class="nam">outs</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t799" href="#t799">799</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t800" href="#t800">800</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t801" href="#t801">801</a></span><span class="t"><span class="key">def</span> <span class="nam">_pull_box_sparse</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t802" href="#t802">802</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span> <span class="nam">size</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="str">'float32'</span><span class="op">,</span> <span class="nam">is_distributed</span><span class="op">=</span><span class="key">False</span><span class="op">,</span> <span class="nam">is_sparse</span><span class="op">=</span><span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t803" href="#t803">803</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t804" href="#t804">804</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t805" href="#t805">805</a></span><span class="t"><span class="str">    **Pull Box Sparse Layer**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t806" href="#t806">806</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t807" href="#t807">807</a></span><span class="t"><span class="str">    This layer is used to lookup embeddings of IDs, provided by :attr:`input`, in</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t808" href="#t808">808</a></span><span class="t"><span class="str">    BoxPS lookup table. The result of this lookup is the embedding of each ID in the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t809" href="#t809">809</a></span><span class="t"><span class="str">    :attr:`input`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t810" href="#t810">810</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t811" href="#t811">811</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t812" href="#t812">812</a></span><span class="t"><span class="str">        input(Variable|list of Variable): Input is a Tensor&lt;int64> Variable, which</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t813" href="#t813">813</a></span><span class="t"><span class="str">            contains the IDs information.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t814" href="#t814">814</a></span><span class="t"><span class="str">        size(int): The embedding size parameter, which indicates the size of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t815" href="#t815">815</a></span><span class="t"><span class="str">            each embedding vector respectively.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t816" href="#t816">816</a></span><span class="t"><span class="str">        dtype(str): The dtype refers to the data type of output tensor. Only supports</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t817" href="#t817">817</a></span><span class="t"><span class="str">            float32 now.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t818" href="#t818">818</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t819" href="#t819">819</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t820" href="#t820">820</a></span><span class="t"><span class="str">        Variable|list of Variable: The tensor variable storing the embeddings of the \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t821" href="#t821">821</a></span><span class="t"><span class="str">                  supplied inputs.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t822" href="#t822">822</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t823" href="#t823">823</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t824" href="#t824">824</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t825" href="#t825">825</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t826" href="#t826">826</a></span><span class="t"><span class="str">          import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t827" href="#t827">827</a></span><span class="t"><span class="str">          data = fluid.layers.data(name='sequence', shape=[1], dtype='int64', lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t828" href="#t828">828</a></span><span class="t"><span class="str">          emb = fluid.layers.pull_box_sparse(input=data, size=[11])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t829" href="#t829">829</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t830" href="#t830">830</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'pull_box_sparse'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t831" href="#t831">831</a></span><span class="t">    <span class="key">if</span> <span class="nam">dtype</span> <span class="op">!=</span> <span class="str">'float32'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t832" href="#t832">832</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t833" href="#t833">833</a></span><span class="t">            <span class="str">"BoxPS only support float type embedding now, and your type is: "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t834" href="#t834">834</a></span><span class="t">            <span class="op">+</span> <span class="nam">dtype</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t835" href="#t835">835</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t836" href="#t836">836</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t837" href="#t837">837</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">multiple_input</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t838" href="#t838">838</a></span><span class="t">    <span class="nam">outs</span> <span class="op">=</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t839" href="#t839">839</a></span><span class="t">        <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t840" href="#t840">840</a></span><span class="t">        <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">len</span><span class="op">(</span><span class="nam">inputs</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t841" href="#t841">841</a></span><span class="t">    <span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t842" href="#t842">842</a></span><span class="t">    <span class="nam">w</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t843" href="#t843">843</a></span><span class="t">        <span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">param_attr</span><span class="op">,</span> <span class="nam">shape</span><span class="op">=</span><span class="op">[</span><span class="nam">size</span><span class="op">]</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">is_bias</span><span class="op">=</span><span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t844" href="#t844">844</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t845" href="#t845">845</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t846" href="#t846">846</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'pull_box_sparse'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t847" href="#t847">847</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Ids'</span><span class="op">:</span> <span class="nam">inputs</span><span class="op">,</span> <span class="str">'W'</span><span class="op">:</span> <span class="nam">w</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t848" href="#t848">848</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">outs</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t849" href="#t849">849</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t850" href="#t850">850</a></span><span class="t">            <span class="str">'size'</span><span class="op">:</span> <span class="nam">size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t851" href="#t851">851</a></span><span class="t">            <span class="str">'is_distributed'</span><span class="op">:</span> <span class="nam">is_distributed</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t852" href="#t852">852</a></span><span class="t">            <span class="str">'is_sparse'</span><span class="op">:</span> <span class="nam">is_sparse</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t853" href="#t853">853</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t854" href="#t854">854</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t855" href="#t855">855</a></span><span class="t">    <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">outs</span><span class="op">)</span> <span class="op">==</span> <span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t856" href="#t856">856</a></span><span class="t">        <span class="key">return</span> <span class="nam">outs</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t857" href="#t857">857</a></span><span class="t">    <span class="key">return</span> <span class="nam">outs</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t858" href="#t858">858</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t859" href="#t859">859</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t860" href="#t860">860</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t861" href="#t861">861</a></span><span class="t"><span class="key">def</span> <span class="nam">linear_chain_crf</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">label</span><span class="op">,</span> <span class="nam">param_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">length</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t862" href="#t862">862</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t863" href="#t863">863</a></span><span class="t"><span class="str">    :api_attr: Static Graph</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t864" href="#t864">864</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t865" href="#t865">865</a></span><span class="t"><span class="str">    Linear Chain CRF.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t866" href="#t866">866</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t867" href="#t867">867</a></span><span class="t"><span class="str">    ${comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t868" href="#t868">868</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t869" href="#t869">869</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t870" href="#t870">870</a></span><span class="t"><span class="str">        input(${emission_type}): ${emission_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t871" href="#t871">871</a></span><span class="t"><span class="str">        label(${label_type}): ${label_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t872" href="#t872">872</a></span><span class="t"><span class="str">        Length(${length_type}): ${length_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t873" href="#t873">873</a></span><span class="t"><span class="str">        param_attr(ParamAttr): The attribute of the learnable parameter for transition parameter.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t874" href="#t874">874</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t875" href="#t875">875</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t876" href="#t876">876</a></span><span class="t"><span class="str">        output(${emission_exps_type}): ${emission_exps_comment} \n</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t877" href="#t877">877</a></span><span class="t"><span class="str">        output(${transition_exps_type}): ${transition_exps_comment} \n</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t878" href="#t878">878</a></span><span class="t"><span class="str">        output(${log_likelihood_type}): ${log_likelihood_comment} \n</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t879" href="#t879">879</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t880" href="#t880">880</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t881" href="#t881">881</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t882" href="#t882">882</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t883" href="#t883">883</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t884" href="#t884">884</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t885" href="#t885">885</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t886" href="#t886">886</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t887" href="#t887">887</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t888" href="#t888">888</a></span><span class="t"><span class="str">            #define net structure, using LodTensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t889" href="#t889">889</a></span><span class="t"><span class="str">            train_program = fluid.Program()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t890" href="#t890">890</a></span><span class="t"><span class="str">            startup_program = fluid.Program()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t891" href="#t891">891</a></span><span class="t"><span class="str">            with fluid.program_guard(train_program, startup_program):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t892" href="#t892">892</a></span><span class="t"><span class="str">                input_data = fluid.data(name='input_data', shape=[-1,10], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t893" href="#t893">893</a></span><span class="t"><span class="str">                label = fluid.data(name='label', shape=[-1,1], dtype='int')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t894" href="#t894">894</a></span><span class="t"><span class="str">                emission= fluid.layers.fc(input=input_data, size=10, act="tanh")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t895" href="#t895">895</a></span><span class="t"><span class="str">                crf_cost = fluid.layers.linear_chain_crf(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t896" href="#t896">896</a></span><span class="t"><span class="str">                    input=emission,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t897" href="#t897">897</a></span><span class="t"><span class="str">                    label=label,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t898" href="#t898">898</a></span><span class="t"><span class="str">                    param_attr=fluid.ParamAttr(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t899" href="#t899">899</a></span><span class="t"><span class="str">                    name='crfw',</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t900" href="#t900">900</a></span><span class="t"><span class="str">                    learning_rate=0.01))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t901" href="#t901">901</a></span><span class="t"><span class="str">            use_cuda = False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t902" href="#t902">902</a></span><span class="t"><span class="str">            place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t903" href="#t903">903</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t904" href="#t904">904</a></span><span class="t"><span class="str">            exe.run(startup_program)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t905" href="#t905">905</a></span><span class="t"><span class="str">            #define data, using LoDTensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t906" href="#t906">906</a></span><span class="t"><span class="str">            a = fluid.create_lod_tensor(np.random.rand(12,10).astype('float32'), [[3,3,4,2]], place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t907" href="#t907">907</a></span><span class="t"><span class="str">            b = fluid.create_lod_tensor(np.array([[1],[1],[2],[3],[1],[1],[1],[3],[1],[1],[1],[1]]),[[3,3,4,2]] , place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t908" href="#t908">908</a></span><span class="t"><span class="str">            feed1 = {'input_data':a,'label':b}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t909" href="#t909">909</a></span><span class="t"><span class="str">            loss= exe.run(train_program,feed=feed1, fetch_list=[crf_cost])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t910" href="#t910">910</a></span><span class="t"><span class="str">            print(loss)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t911" href="#t911">911</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t912" href="#t912">912</a></span><span class="t"><span class="str">            #define net structure, using padding</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t913" href="#t913">913</a></span><span class="t"><span class="str">            train_program = fluid.Program()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t914" href="#t914">914</a></span><span class="t"><span class="str">            startup_program = fluid.Program()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t915" href="#t915">915</a></span><span class="t"><span class="str">            with fluid.program_guard(train_program, startup_program):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t916" href="#t916">916</a></span><span class="t"><span class="str">                input_data2 = fluid.data(name='input_data2', shape=[-1,10,10], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t917" href="#t917">917</a></span><span class="t"><span class="str">                label2 = fluid.data(name='label2', shape=[-1,10,1], dtype='int')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t918" href="#t918">918</a></span><span class="t"><span class="str">                label_length = fluid.data(name='length', shape=[-1,1], dtype='int')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t919" href="#t919">919</a></span><span class="t"><span class="str">                emission2= fluid.layers.fc(input=input_data2, size=10, act="tanh", num_flatten_dims=2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t920" href="#t920">920</a></span><span class="t"><span class="str">                crf_cost2 = fluid.layers.linear_chain_crf(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t921" href="#t921">921</a></span><span class="t"><span class="str">                    input=emission2,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t922" href="#t922">922</a></span><span class="t"><span class="str">                    label=label2,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t923" href="#t923">923</a></span><span class="t"><span class="str">                    length=label_length,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t924" href="#t924">924</a></span><span class="t"><span class="str">                    param_attr=fluid.ParamAttr(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t925" href="#t925">925</a></span><span class="t"><span class="str">                     name='crfw',</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t926" href="#t926">926</a></span><span class="t"><span class="str">                     learning_rate=0.01))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t927" href="#t927">927</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t928" href="#t928">928</a></span><span class="t"><span class="str">            use_cuda = False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t929" href="#t929">929</a></span><span class="t"><span class="str">            place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t930" href="#t930">930</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t931" href="#t931">931</a></span><span class="t"><span class="str">            exe.run(startup_program)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t932" href="#t932">932</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t933" href="#t933">933</a></span><span class="t"><span class="str">            #define data, using padding</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t934" href="#t934">934</a></span><span class="t"><span class="str">            cc=np.random.rand(4,10,10).astype('float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t935" href="#t935">935</a></span><span class="t"><span class="str">            dd=np.random.rand(4,10,1).astype('int64')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t936" href="#t936">936</a></span><span class="t"><span class="str">            ll=np.array([[3],[3],[4],[2]])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t937" href="#t937">937</a></span><span class="t"><span class="str">            feed2 = {'input_data2':cc,'label2':dd,'length':ll}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t938" href="#t938">938</a></span><span class="t"><span class="str">            loss2= exe.run(train_program,feed=feed2, fetch_list=[crf_cost2])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t939" href="#t939">939</a></span><span class="t"><span class="str">            print(loss2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t940" href="#t940">940</a></span><span class="t"><span class="str">            #[array([[ 7.8902354],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t941" href="#t941">941</a></span><span class="t"><span class="str">            #        [ 7.3602567],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t942" href="#t942">942</a></span><span class="t"><span class="str">            #        [ 10.004011],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t943" href="#t943">943</a></span><span class="t"><span class="str">            #        [ 5.86721  ]], dtype=float32)]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t944" href="#t944">944</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t945" href="#t945">945</a></span><span class="t"><span class="str">            #you can use find_var to get transition parameter.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t946" href="#t946">946</a></span><span class="t"><span class="str">            transition=np.array(fluid.global_scope().find_var('crfw').get_tensor())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t947" href="#t947">947</a></span><span class="t"><span class="str">            print(transition)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t948" href="#t948">948</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t949" href="#t949">949</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t950" href="#t950">950</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t951" href="#t951">951</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'linear_chain_crf'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t952" href="#t952">952</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t953" href="#t953">953</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">label</span><span class="op">,</span> <span class="str">'label'</span><span class="op">,</span> <span class="op">[</span><span class="str">'int64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'linear_chain_crf'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t954" href="#t954">954</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'linear_chain_crf'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t955" href="#t955">955</a></span><span class="t">    <span class="nam">size</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">2</span><span class="op">]</span> <span class="key">if</span> <span class="nam">length</span> <span class="key">else</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t956" href="#t956">956</a></span><span class="t">    <span class="nam">transition</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t957" href="#t957">957</a></span><span class="t">        <span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">param_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t958" href="#t958">958</a></span><span class="t">        <span class="nam">shape</span><span class="op">=</span><span class="op">[</span><span class="nam">size</span> <span class="op">+</span> <span class="num">2</span><span class="op">,</span> <span class="nam">size</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t959" href="#t959">959</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t960" href="#t960">960</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t961" href="#t961">961</a></span><span class="t">    <span class="nam">alpha</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t962" href="#t962">962</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t963" href="#t963">963</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t964" href="#t964">964</a></span><span class="t">    <span class="nam">emission_exps</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t965" href="#t965">965</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t966" href="#t966">966</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t967" href="#t967">967</a></span><span class="t">    <span class="nam">transition_exps</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t968" href="#t968">968</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t969" href="#t969">969</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t970" href="#t970">970</a></span><span class="t">    <span class="nam">log_likelihood</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t971" href="#t971">971</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t972" href="#t972">972</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t973" href="#t973">973</a></span><span class="t">    <span class="nam">this_inputs</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t974" href="#t974">974</a></span><span class="t">        <span class="str">"Emission"</span><span class="op">:</span> <span class="op">[</span><span class="nam">input</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t975" href="#t975">975</a></span><span class="t">        <span class="str">"Transition"</span><span class="op">:</span> <span class="nam">transition</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t976" href="#t976">976</a></span><span class="t">        <span class="str">"Label"</span><span class="op">:</span> <span class="op">[</span><span class="nam">label</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t977" href="#t977">977</a></span><span class="t">    <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t978" href="#t978">978</a></span><span class="t">    <span class="key">if</span> <span class="nam">length</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t979" href="#t979">979</a></span><span class="t">        <span class="nam">this_inputs</span><span class="op">[</span><span class="str">'Length'</span><span class="op">]</span> <span class="op">=</span> <span class="op">[</span><span class="nam">length</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t980" href="#t980">980</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t981" href="#t981">981</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'linear_chain_crf'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t982" href="#t982">982</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="nam">this_inputs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t983" href="#t983">983</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t984" href="#t984">984</a></span><span class="t">            <span class="str">"Alpha"</span><span class="op">:</span> <span class="op">[</span><span class="nam">alpha</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t985" href="#t985">985</a></span><span class="t">            <span class="str">"EmissionExps"</span><span class="op">:</span> <span class="op">[</span><span class="nam">emission_exps</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t986" href="#t986">986</a></span><span class="t">            <span class="str">"TransitionExps"</span><span class="op">:</span> <span class="nam">transition_exps</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t987" href="#t987">987</a></span><span class="t">            <span class="str">"LogLikelihood"</span><span class="op">:</span> <span class="nam">log_likelihood</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t988" href="#t988">988</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t989" href="#t989">989</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t990" href="#t990">990</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t991" href="#t991">991</a></span><span class="t">    <span class="key">return</span> <span class="nam">log_likelihood</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t992" href="#t992">992</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t993" href="#t993">993</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t994" href="#t994">994</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t995" href="#t995">995</a></span><span class="t"><span class="key">def</span> <span class="nam">crf_decoding</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">param_attr</span><span class="op">,</span> <span class="nam">label</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">length</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t996" href="#t996">996</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t997" href="#t997">997</a></span><span class="t"><span class="str">    :api_attr: Static Graph</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t998" href="#t998">998</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t999" href="#t999">999</a></span><span class="t"><span class="str">    ${comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1000" href="#t1000">1000</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1001" href="#t1001">1001</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1002" href="#t1002">1002</a></span><span class="t"><span class="str">        input(Tensor): ${emission_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1003" href="#t1003">1003</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1004" href="#t1004">1004</a></span><span class="t"><span class="str">        param_attr (ParamAttr|None): To specify the weight parameter attribute.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1005" href="#t1005">1005</a></span><span class="t"><span class="str">            Default: None, which means the default weight parameter property is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1006" href="#t1006">1006</a></span><span class="t"><span class="str">            used. See usage for details in :ref:`api_paddle_fluid_param_attr_ParamAttr` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1007" href="#t1007">1007</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1008" href="#t1008">1008</a></span><span class="t"><span class="str">        label(${label_type}, optional): ${label_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1009" href="#t1009">1009</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1010" href="#t1010">1010</a></span><span class="t"><span class="str">        length(${length_type}, optional): ${length_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1011" href="#t1011">1011</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1012" href="#t1012">1012</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1013" href="#t1013">1013</a></span><span class="t"><span class="str">        Tensor: ${viterbi_path_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1014" href="#t1014">1014</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1015" href="#t1015">1015</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1016" href="#t1016">1016</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1017" href="#t1017">1017</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1018" href="#t1018">1018</a></span><span class="t"><span class="str">           import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1019" href="#t1019">1019</a></span><span class="t"><span class="str">           paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1020" href="#t1020">1020</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1021" href="#t1021">1021</a></span><span class="t"><span class="str">           # LoDTensor-based example</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1022" href="#t1022">1022</a></span><span class="t"><span class="str">           num_labels = 10</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1023" href="#t1023">1023</a></span><span class="t"><span class="str">           feature = paddle.static.data(name='word_emb', shape=[-1, 784], dtype='float32', lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1024" href="#t1024">1024</a></span><span class="t"><span class="str">           label = paddle.static.data(name='label', shape=[-1, 1], dtype='int64', lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1025" href="#t1025">1025</a></span><span class="t"><span class="str">           emission = paddle.static.nn.fc(feature, size=num_labels)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1026" href="#t1026">1026</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1027" href="#t1027">1027</a></span><span class="t"><span class="str">           crf_cost = paddle.fluid.layers.linear_chain_crf(input=emission, label=label,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1028" href="#t1028">1028</a></span><span class="t"><span class="str">                     param_attr=paddle.ParamAttr(name="crfw"))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1029" href="#t1029">1029</a></span><span class="t"><span class="str">           crf_decode = paddle.static.nn.crf_decoding(input=emission,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1030" href="#t1030">1030</a></span><span class="t"><span class="str">                     param_attr=paddle.ParamAttr(name="crfw"))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1031" href="#t1031">1031</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1032" href="#t1032">1032</a></span><span class="t"><span class="str">           # Common tensor example</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1033" href="#t1033">1033</a></span><span class="t"><span class="str">           num_labels, max_len = 10, 20</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1034" href="#t1034">1034</a></span><span class="t"><span class="str">           feature = paddle.static.data(name='word_emb_pad', shape=[-1, max_len, 784], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1035" href="#t1035">1035</a></span><span class="t"><span class="str">           label = paddle.static.data(name='label_pad', shape=[-1, max_len, 1], dtype='int64')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1036" href="#t1036">1036</a></span><span class="t"><span class="str">           length = paddle.static.data(name='length', shape=[-1, 1], dtype='int64')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1037" href="#t1037">1037</a></span><span class="t"><span class="str">           emission = paddle.static.nn.fc(feature, size=num_labels,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1038" href="#t1038">1038</a></span><span class="t"><span class="str">                                      num_flatten_dims=2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1039" href="#t1039">1039</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1040" href="#t1040">1040</a></span><span class="t"><span class="str">           crf_cost = paddle.fluid.layers.linear_chain_crf(input=emission, label=label, length=length,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1041" href="#t1041">1041</a></span><span class="t"><span class="str">                     param_attr=paddle.ParamAttr(name="crfw_pad"))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1042" href="#t1042">1042</a></span><span class="t"><span class="str">           crf_decode = paddle.static.nn.crf_decoding(input=emission, length=length,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1043" href="#t1043">1043</a></span><span class="t"><span class="str">                     param_attr=paddle.ParamAttr(name="crfw_pad"))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1044" href="#t1044">1044</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1045" href="#t1045">1045</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1046" href="#t1046">1046</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'crf_decoding'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1047" href="#t1047">1047</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1048" href="#t1048">1048</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'crf_decoding'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1049" href="#t1049">1049</a></span><span class="t">    <span class="nam">transition</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">get_parameter</span><span class="op">(</span><span class="nam">param_attr</span><span class="op">.</span><span class="nam">name</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1050" href="#t1050">1050</a></span><span class="t">    <span class="nam">viterbi_path</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1051" href="#t1051">1051</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">core</span><span class="op">.</span><span class="nam">VarDesc</span><span class="op">.</span><span class="nam">VarType</span><span class="op">.</span><span class="nam">INT64</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1052" href="#t1052">1052</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1053" href="#t1053">1053</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">"Emission"</span><span class="op">:</span> <span class="op">[</span><span class="nam">input</span><span class="op">]</span><span class="op">,</span> <span class="str">"Transition"</span><span class="op">:</span> <span class="nam">transition</span><span class="op">,</span> <span class="str">"Label"</span><span class="op">:</span> <span class="nam">label</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1054" href="#t1054">1054</a></span><span class="t">    <span class="key">if</span> <span class="nam">length</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1055" href="#t1055">1055</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">'Length'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">length</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1056" href="#t1056">1056</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1057" href="#t1057">1057</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'crf_decoding'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1058" href="#t1058">1058</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1059" href="#t1059">1059</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"ViterbiPath"</span><span class="op">:</span> <span class="op">[</span><span class="nam">viterbi_path</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1060" href="#t1060">1060</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1061" href="#t1061">1061</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1062" href="#t1062">1062</a></span><span class="t">    <span class="key">return</span> <span class="nam">viterbi_path</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1063" href="#t1063">1063</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1064" href="#t1064">1064</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1065" href="#t1065">1065</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1066" href="#t1066">1066</a></span><span class="t"><span class="key">def</span> <span class="nam">cos_sim</span><span class="op">(</span><span class="nam">X</span><span class="op">,</span> <span class="nam">Y</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1067" href="#t1067">1067</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1068" href="#t1068">1068</a></span><span class="t"><span class="str">    ${comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1069" href="#t1069">1069</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1070" href="#t1070">1070</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1071" href="#t1071">1071</a></span><span class="t"><span class="str">        X (Tensor): ${x_comment}.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1072" href="#t1072">1072</a></span><span class="t"><span class="str">        Y (Tensor): ${y_comment}.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1073" href="#t1073">1073</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1074" href="#t1074">1074</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1075" href="#t1075">1075</a></span><span class="t"><span class="str">        A Tensor representing the output of cosine(X, Y).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1076" href="#t1076">1076</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1077" href="#t1077">1077</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1078" href="#t1078">1078</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1079" href="#t1079">1079</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1080" href="#t1080">1080</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1081" href="#t1081">1081</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1082" href="#t1082">1082</a></span><span class="t"><span class="str">            x = paddle.rand(shape=[3, 7], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1083" href="#t1083">1083</a></span><span class="t"><span class="str">            y = paddle.rand(shape=[1, 7], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1084" href="#t1084">1084</a></span><span class="t"><span class="str">            out = paddle.fluid.layers.cos_sim(x, y)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1085" href="#t1085">1085</a></span><span class="t"><span class="str">            print(out)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1086" href="#t1086">1086</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1087" href="#t1087">1087</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1088" href="#t1088">1088</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">X</span><span class="op">,</span> <span class="str">'X'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">]</span><span class="op">,</span> <span class="str">'cos_sim'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1089" href="#t1089">1089</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">Y</span><span class="op">,</span> <span class="str">'Y'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">]</span><span class="op">,</span> <span class="str">'cos_sim'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1090" href="#t1090">1090</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'cos_sim'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1091" href="#t1091">1091</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">X</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1092" href="#t1092">1092</a></span><span class="t">    <span class="nam">xnorm</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">X</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1093" href="#t1093">1093</a></span><span class="t">    <span class="nam">ynorm</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">X</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1094" href="#t1094">1094</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1095" href="#t1095">1095</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'cos_sim'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1096" href="#t1096">1096</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="op">[</span><span class="nam">X</span><span class="op">]</span><span class="op">,</span> <span class="str">'Y'</span><span class="op">:</span> <span class="op">[</span><span class="nam">Y</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1097" href="#t1097">1097</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="op">[</span><span class="nam">out</span><span class="op">]</span><span class="op">,</span> <span class="str">'XNorm'</span><span class="op">:</span> <span class="op">[</span><span class="nam">xnorm</span><span class="op">]</span><span class="op">,</span> <span class="str">'YNorm'</span><span class="op">:</span> <span class="op">[</span><span class="nam">ynorm</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1098" href="#t1098">1098</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1099" href="#t1099">1099</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1100" href="#t1100">1100</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1101" href="#t1101">1101</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1102" href="#t1102">1102</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.nn.functional.dropout"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1103" href="#t1103">1103</a></span><span class="t"><span class="key">def</span> <span class="nam">dropout</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1104" href="#t1104">1104</a></span><span class="t">    <span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1105" href="#t1105">1105</a></span><span class="t">    <span class="nam">dropout_prob</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1106" href="#t1106">1106</a></span><span class="t">    <span class="nam">is_test</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1107" href="#t1107">1107</a></span><span class="t">    <span class="nam">seed</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1108" href="#t1108">1108</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1109" href="#t1109">1109</a></span><span class="t">    <span class="nam">dropout_implementation</span><span class="op">=</span><span class="str">"downgrade_in_infer"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1110" href="#t1110">1110</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1111" href="#t1111">1111</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1112" href="#t1112">1112</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1113" href="#t1113">1113</a></span><span class="t"><span class="str">    Computes dropout.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1114" href="#t1114">1114</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1115" href="#t1115">1115</a></span><span class="t"><span class="str">    Drop or keep each element of `x` independently. Dropout is a regularization</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1116" href="#t1116">1116</a></span><span class="t"><span class="str">    technique for reducing overfitting by preventing neuron co-adaption during</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1117" href="#t1117">1117</a></span><span class="t"><span class="str">    training. The dropout operator randomly sets (according to the given dropout</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1118" href="#t1118">1118</a></span><span class="t"><span class="str">    probability) the outputs of some units to zero, while others are remain</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1119" href="#t1119">1119</a></span><span class="t"><span class="str">    unchanged.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1120" href="#t1120">1120</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1121" href="#t1121">1121</a></span><span class="t"><span class="str">    dropout op can be removed from the program to make the program more efficient.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1122" href="#t1122">1122</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1123" href="#t1123">1123</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1124" href="#t1124">1124</a></span><span class="t"><span class="str">        x (Variable): The input tensor variable. The data type is float16 or float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1125" href="#t1125">1125</a></span><span class="t"><span class="str">        dropout_prob (float): Probability of setting units to zero.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1126" href="#t1126">1126</a></span><span class="t"><span class="str">        is_test (bool): A flag indicating whether it is in test phrase or not.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1127" href="#t1127">1127</a></span><span class="t"><span class="str">                        Default None, in dynamic graph, it use global tracer mode; in static graph, it means False.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1128" href="#t1128">1128</a></span><span class="t"><span class="str">        seed (int): A Python integer used to create random seeds. If this</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1129" href="#t1129">1129</a></span><span class="t"><span class="str">                    parameter is set to None, a random seed is used.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1130" href="#t1130">1130</a></span><span class="t"><span class="str">                    NOTE: If an integer seed is given, always the same output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1131" href="#t1131">1131</a></span><span class="t"><span class="str">                    units will be dropped. DO NOT use a fixed seed in training.Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1132" href="#t1132">1132</a></span><span class="t"><span class="str">        name (str|None): A name for this layer(optional). If set None, the layer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1133" href="#t1133">1133</a></span><span class="t"><span class="str">                         will be named automatically.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1134" href="#t1134">1134</a></span><span class="t"><span class="str">        dropout_implementation(string): ['downgrade_in_infer'(default)|'upscale_in_train']</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1135" href="#t1135">1135</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1136" href="#t1136">1136</a></span><span class="t"><span class="str">                                        1. downgrade_in_infer(default), downgrade the outcome at inference</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1137" href="#t1137">1137</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1138" href="#t1138">1138</a></span><span class="t"><span class="str">                                           - train: out = input * mask</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1139" href="#t1139">1139</a></span><span class="t"><span class="str">                                           - inference: out = input * (1.0 - dropout_prob)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1140" href="#t1140">1140</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1141" href="#t1141">1141</a></span><span class="t"><span class="str">                                           (mask is a tensor same shape with input, value is 0 or 1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1142" href="#t1142">1142</a></span><span class="t"><span class="str">                                           ratio of 0 is dropout_prob)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1143" href="#t1143">1143</a></span><span class="t"><span class="str">                                        2. upscale_in_train, upscale the outcome at training time</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1144" href="#t1144">1144</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1145" href="#t1145">1145</a></span><span class="t"><span class="str">                                           - train: out = input * mask / ( 1.0 - dropout_prob )</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1146" href="#t1146">1146</a></span><span class="t"><span class="str">                                           - inference: out = input</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1147" href="#t1147">1147</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1148" href="#t1148">1148</a></span><span class="t"><span class="str">                                           (mask is a tensor same shape with input, value is 0 or 1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1149" href="#t1149">1149</a></span><span class="t"><span class="str">                                           ratio of 0 is dropout_prob)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1150" href="#t1150">1150</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1151" href="#t1151">1151</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1152" href="#t1152">1152</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1153" href="#t1153">1153</a></span><span class="t"><span class="str">        A Variable holding Tensor representing the dropout, has same shape and data type with `x`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1154" href="#t1154">1154</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1155" href="#t1155">1155</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1156" href="#t1156">1156</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1157" href="#t1157">1157</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1158" href="#t1158">1158</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1159" href="#t1159">1159</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1160" href="#t1160">1160</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1161" href="#t1161">1161</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1162" href="#t1162">1162</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1163" href="#t1163">1163</a></span><span class="t"><span class="str">            x = fluid.data(name="data", shape=[None, 32, 32], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1164" href="#t1164">1164</a></span><span class="t"><span class="str">            dropped = fluid.layers.dropout(x, dropout_prob=0.5)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1165" href="#t1165">1165</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1166" href="#t1166">1166</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dropout_prob</span><span class="op">,</span> <span class="op">(</span><span class="nam">float</span><span class="op">,</span> <span class="nam">int</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1167" href="#t1167">1167</a></span><span class="t">        <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1168" href="#t1168">1168</a></span><span class="t">            <span class="str">"dropout_prob argument should be a number(int|float) or Variable"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1169" href="#t1169">1169</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1170" href="#t1170">1170</a></span><span class="t">    <span class="com"># fast return for p == 0</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1171" href="#t1171">1171</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dropout_prob</span><span class="op">,</span> <span class="op">(</span><span class="nam">int</span><span class="op">,</span> <span class="nam">float</span><span class="op">)</span><span class="op">)</span> <span class="key">and</span> <span class="nam">dropout_prob</span> <span class="op">==</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1172" href="#t1172">1172</a></span><span class="t">        <span class="key">return</span> <span class="nam">x</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1173" href="#t1173">1173</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1174" href="#t1174">1174</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1175" href="#t1175">1175</a></span><span class="t">        <span class="key">if</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1176" href="#t1176">1176</a></span><span class="t">            <span class="nam">seed</span> <span class="key">is</span> <span class="key">None</span> <span class="key">or</span> <span class="nam">seed</span> <span class="op">==</span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1177" href="#t1177">1177</a></span><span class="t">        <span class="op">)</span> <span class="key">and</span> <span class="nam">default_main_program</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">random_seed</span> <span class="op">!=</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1178" href="#t1178">1178</a></span><span class="t">            <span class="nam">seed</span> <span class="op">=</span> <span class="nam">default_main_program</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">random_seed</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1179" href="#t1179">1179</a></span><span class="t">        <span class="key">if</span> <span class="nam">is_test</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1180" href="#t1180">1180</a></span><span class="t">            <span class="nam">is_test</span> <span class="op">=</span> <span class="key">not</span> <span class="nam">_dygraph_tracer</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">_train_mode</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1181" href="#t1181">1181</a></span><span class="t">        <span class="nam">out</span><span class="op">,</span> <span class="nam">mask</span> <span class="op">=</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">dropout</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1182" href="#t1182">1182</a></span><span class="t">            <span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1183" href="#t1183">1183</a></span><span class="t">            <span class="str">'dropout_prob'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1184" href="#t1184">1184</a></span><span class="t">            <span class="nam">dropout_prob</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1185" href="#t1185">1185</a></span><span class="t">            <span class="str">'is_test'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1186" href="#t1186">1186</a></span><span class="t">            <span class="nam">is_test</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1187" href="#t1187">1187</a></span><span class="t">            <span class="str">'fix_seed'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1188" href="#t1188">1188</a></span><span class="t">            <span class="nam">seed</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1189" href="#t1189">1189</a></span><span class="t">            <span class="str">'seed'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1190" href="#t1190">1190</a></span><span class="t">            <span class="nam">seed</span> <span class="key">if</span> <span class="nam">seed</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span> <span class="key">else</span> <span class="num">0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1191" href="#t1191">1191</a></span><span class="t">            <span class="str">'dropout_implementation'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1192" href="#t1192">1192</a></span><span class="t">            <span class="nam">dropout_implementation</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1193" href="#t1193">1193</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1194" href="#t1194">1194</a></span><span class="t">        <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1195" href="#t1195">1195</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1196" href="#t1196">1196</a></span><span class="t">    <span class="key">def</span> <span class="nam">get_attrs</span><span class="op">(</span><span class="nam">prog</span><span class="op">,</span> <span class="nam">dropout_prob</span><span class="op">,</span> <span class="nam">is_test</span><span class="op">,</span> <span class="nam">seed</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1197" href="#t1197">1197</a></span><span class="t">        <span class="key">if</span> <span class="op">(</span><span class="nam">seed</span> <span class="key">is</span> <span class="key">None</span> <span class="key">or</span> <span class="nam">seed</span> <span class="op">==</span> <span class="num">0</span><span class="op">)</span> <span class="key">and</span> <span class="nam">prog</span><span class="op">.</span><span class="nam">random_seed</span> <span class="op">!=</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1198" href="#t1198">1198</a></span><span class="t">            <span class="nam">seed</span> <span class="op">=</span> <span class="nam">prog</span><span class="op">.</span><span class="nam">random_seed</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1199" href="#t1199">1199</a></span><span class="t">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dropout_prob</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span> <span class="key">and</span> <span class="key">not</span> <span class="nam">dropout_prob</span><span class="op">.</span><span class="nam">shape</span> <span class="op">!=</span> <span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1200" href="#t1200">1200</a></span><span class="t">            <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1201" href="#t1201">1201</a></span><span class="t">                <span class="str">"Required dropout_prob.shape == [1] if type(dropout_prob) is Variable, but received dropout_prob.shape = {}"</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1202" href="#t1202">1202</a></span><span class="t">                    <span class="nam">dropout_prob</span><span class="op">.</span><span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1203" href="#t1203">1203</a></span><span class="t">                <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1204" href="#t1204">1204</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1205" href="#t1205">1205</a></span><span class="t">        <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1206" href="#t1206">1206</a></span><span class="t">            <span class="str">'dropout_prob'</span><span class="op">:</span> <span class="nam">dropout_prob</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1207" href="#t1207">1207</a></span><span class="t">            <span class="str">'is_test'</span><span class="op">:</span> <span class="nam">is_test</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1208" href="#t1208">1208</a></span><span class="t">            <span class="str">'fix_seed'</span><span class="op">:</span> <span class="nam">seed</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1209" href="#t1209">1209</a></span><span class="t">            <span class="str">'seed'</span><span class="op">:</span> <span class="nam">seed</span> <span class="key">if</span> <span class="nam">seed</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span> <span class="key">else</span> <span class="num">0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1210" href="#t1210">1210</a></span><span class="t">            <span class="str">'dropout_implementation'</span><span class="op">:</span> <span class="nam">dropout_implementation</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1211" href="#t1211">1211</a></span><span class="t">        <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1212" href="#t1212">1212</a></span><span class="t">        <span class="key">return</span> <span class="nam">attrs</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1213" href="#t1213">1213</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1214" href="#t1214">1214</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'dropout'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1215" href="#t1215">1215</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1216" href="#t1216">1216</a></span><span class="t">        <span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'dropout'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1217" href="#t1217">1217</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1218" href="#t1218">1218</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1219" href="#t1219">1219</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1220" href="#t1220">1220</a></span><span class="t">    <span class="nam">mask</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1221" href="#t1221">1221</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">core</span><span class="op">.</span><span class="nam">VarDesc</span><span class="op">.</span><span class="nam">VarType</span><span class="op">.</span><span class="nam">UINT8</span><span class="op">,</span> <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1222" href="#t1222">1222</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1223" href="#t1223">1223</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1224" href="#t1224">1224</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="nam">get_attrs</span><span class="op">(</span><span class="nam">helper</span><span class="op">.</span><span class="nam">main_program</span><span class="op">,</span> <span class="nam">dropout_prob</span><span class="op">,</span> <span class="nam">is_test</span><span class="op">,</span> <span class="nam">seed</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1225" href="#t1225">1225</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1226" href="#t1226">1226</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1227" href="#t1227">1227</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'dropout'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1228" href="#t1228">1228</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="op">[</span><span class="nam">x</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1229" href="#t1229">1229</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="op">[</span><span class="nam">out</span><span class="op">]</span><span class="op">,</span> <span class="str">'Mask'</span><span class="op">:</span> <span class="op">[</span><span class="nam">mask</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1230" href="#t1230">1230</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1231" href="#t1231">1231</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1232" href="#t1232">1232</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1233" href="#t1233">1233</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1234" href="#t1234">1234</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1235" href="#t1235">1235</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1236" href="#t1236">1236</a></span><span class="t"><span class="key">def</span> <span class="nam">chunk_eval</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1237" href="#t1237">1237</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1238" href="#t1238">1238</a></span><span class="t">    <span class="nam">label</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1239" href="#t1239">1239</a></span><span class="t">    <span class="nam">chunk_scheme</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1240" href="#t1240">1240</a></span><span class="t">    <span class="nam">num_chunk_types</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1241" href="#t1241">1241</a></span><span class="t">    <span class="nam">excluded_chunk_types</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1242" href="#t1242">1242</a></span><span class="t">    <span class="nam">seq_length</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1243" href="#t1243">1243</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1244" href="#t1244">1244</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1245" href="#t1245">1245</a></span><span class="t"><span class="str">    This operator computes the precision, recall and F1-score for chunk detection.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1246" href="#t1246">1246</a></span><span class="t"><span class="str">    It is often used in sequence tagging tasks, such as Named Entity Recognition(NER).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1247" href="#t1247">1247</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1248" href="#t1248">1248</a></span><span class="t"><span class="str">    For some basics of chunking, please refer to</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1249" href="#t1249">1249</a></span><span class="t"><span class="str">    `Chunking with Support Vector Machines &lt;https://aclanthology.info/pdf/N/N01/N01-1025.pdf>`_ .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1250" href="#t1250">1250</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1251" href="#t1251">1251</a></span><span class="t"><span class="str">    This operator supports IOB, IOE, IOBES and IO (also known as plain) tagging schemes.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1252" href="#t1252">1252</a></span><span class="t"><span class="str">    Here is a NER example for the usage of these tagging schemes:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1253" href="#t1253">1253</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1254" href="#t1254">1254</a></span><span class="t"><span class="str">    .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1255" href="#t1255">1255</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1256" href="#t1256">1256</a></span><span class="t"><span class="str">       ====== ====== ======  =====  ==  ============   =====  ===== =====  ==  =========</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1257" href="#t1257">1257</a></span><span class="t"><span class="str">              Li     Ming    works  at  Agricultural   Bank   of    China  in  Beijing.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1258" href="#t1258">1258</a></span><span class="t"><span class="str">       ====== ====== ======  =====  ==  ============   =====  ===== =====  ==  =========</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1259" href="#t1259">1259</a></span><span class="t"><span class="str">       IO     I-PER  I-PER   O      O   I-ORG          I-ORG  I-ORG I-ORG  O   I-LOC</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1260" href="#t1260">1260</a></span><span class="t"><span class="str">       IOB    B-PER  I-PER   O      O   B-ORG          I-ORG  I-ORG I-ORG  O   B-LOC</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1261" href="#t1261">1261</a></span><span class="t"><span class="str">       IOE    I-PER  E-PER   O      O   I-ORG          I-ORG  I-ORG E-ORG  O   E-LOC</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1262" href="#t1262">1262</a></span><span class="t"><span class="str">       IOBES  B-PER  E-PER   O      O   I-ORG          I-ORG  I-ORG E-ORG  O   S-LOC</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1263" href="#t1263">1263</a></span><span class="t"><span class="str">       ====== ====== ======  =====  ==  ============   =====  ===== =====  ==  =========</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1264" href="#t1264">1264</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1265" href="#t1265">1265</a></span><span class="t"><span class="str">    There are three chunk types(named entity types) including PER(person), ORG(organization)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1266" href="#t1266">1266</a></span><span class="t"><span class="str">    and LOC(location), and we can see that the labels have the form `&lt;tag type>-&lt;chunk type>` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1267" href="#t1267">1267</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1268" href="#t1268">1268</a></span><span class="t"><span class="str">    Since the implementation of this operator actually uses label ids rather than</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1269" href="#t1269">1269</a></span><span class="t"><span class="str">    label strings, to make it work, there should be a way to map label ids to</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1270" href="#t1270">1270</a></span><span class="t"><span class="str">    tag types and chunk types. This operator uses the following way to do mapping:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1271" href="#t1271">1271</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1272" href="#t1272">1272</a></span><span class="t"><span class="str">    .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1273" href="#t1273">1273</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1274" href="#t1274">1274</a></span><span class="t"><span class="str">       tag_type = label % num_tag_type</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1275" href="#t1275">1275</a></span><span class="t"><span class="str">       chunk_type = label / num_tag_type</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1276" href="#t1276">1276</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1277" href="#t1277">1277</a></span><span class="t"><span class="str">    where `num_tag_type` is the num of tag types in the tagging scheme, `num_chunk_type`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1278" href="#t1278">1278</a></span><span class="t"><span class="str">    is the num of chunk types, and `tag_type` get its value from the following table.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1279" href="#t1279">1279</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1280" href="#t1280">1280</a></span><span class="t"><span class="str">    .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1281" href="#t1281">1281</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1282" href="#t1282">1282</a></span><span class="t"><span class="str">       Scheme Begin Inside End   Single</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1283" href="#t1283">1283</a></span><span class="t"><span class="str">        plain   0     -      -     -</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1284" href="#t1284">1284</a></span><span class="t"><span class="str">        IOB     0     1      -     -</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1285" href="#t1285">1285</a></span><span class="t"><span class="str">        IOE     -     0      1     -</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1286" href="#t1286">1286</a></span><span class="t"><span class="str">        IOBES   0     1      2     3</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1287" href="#t1287">1287</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1288" href="#t1288">1288</a></span><span class="t"><span class="str">    Accordingly, in the above NER example, if the tagging scheme is IOB and chunk</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1289" href="#t1289">1289</a></span><span class="t"><span class="str">    types are ORG, PER and LOC, then the label ids would be as follows:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1290" href="#t1290">1290</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1291" href="#t1291">1291</a></span><span class="t"><span class="str">    .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1292" href="#t1292">1292</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1293" href="#t1293">1293</a></span><span class="t"><span class="str">       B-ORG  0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1294" href="#t1294">1294</a></span><span class="t"><span class="str">       I-ORG  1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1295" href="#t1295">1295</a></span><span class="t"><span class="str">       B-PER  2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1296" href="#t1296">1296</a></span><span class="t"><span class="str">       I-PER  3</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1297" href="#t1297">1297</a></span><span class="t"><span class="str">       B-LOC  4</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1298" href="#t1298">1298</a></span><span class="t"><span class="str">       I-LOC  5</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1299" href="#t1299">1299</a></span><span class="t"><span class="str">       O      6</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1300" href="#t1300">1300</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1301" href="#t1301">1301</a></span><span class="t"><span class="str">    With which we can map each label id to the corresponding tag type and chunk</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1302" href="#t1302">1302</a></span><span class="t"><span class="str">    type correctly.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1303" href="#t1303">1303</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1304" href="#t1304">1304</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1305" href="#t1305">1305</a></span><span class="t"><span class="str">        input (Tensor): A Tensor representing the predicted labels</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1306" href="#t1306">1306</a></span><span class="t"><span class="str">            from the network. Its shape would be `[N, M, 1]`,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1307" href="#t1307">1307</a></span><span class="t"><span class="str">            where `N` stands for batch size, `M` for sequence length. </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1308" href="#t1308">1308</a></span><span class="t"><span class="str">            The data type should be int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1309" href="#t1309">1309</a></span><span class="t"><span class="str">        label (Tensor): A Tensor representing the ground-truth labels.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1310" href="#t1310">1310</a></span><span class="t"><span class="str">            It should have the same shape, lod and data type as ``input`` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1311" href="#t1311">1311</a></span><span class="t"><span class="str">        chunk_scheme (str): Indicate the tagging schemes used here. The value must</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1312" href="#t1312">1312</a></span><span class="t"><span class="str">            be IOB, IOE, IOBES or plain.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1313" href="#t1313">1313</a></span><span class="t"><span class="str">        num_chunk_types (int): The number of chunk types.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1314" href="#t1314">1314</a></span><span class="t"><span class="str">        excluded_chunk_types (list, optional): Indicate the chunk types shouldn't</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1315" href="#t1315">1315</a></span><span class="t"><span class="str">            be taken into account. It should be a list of chunk type ids(integer).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1316" href="#t1316">1316</a></span><span class="t"><span class="str">            Default None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1317" href="#t1317">1317</a></span><span class="t"><span class="str">        seq_length(Tensor, optional): A 1D Tensor containing the length of each</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1318" href="#t1318">1318</a></span><span class="t"><span class="str">            sequence when ``input`` and ``label`` are Tensor. Default None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1319" href="#t1319">1319</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1320" href="#t1320">1320</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1321" href="#t1321">1321</a></span><span class="t"><span class="str">        tuple: A tuple including precision, recall, F1-score, chunk number detected, \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1322" href="#t1322">1322</a></span><span class="t"><span class="str">            chunk number in ground-truth, chunk number correctly detected. Each \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1323" href="#t1323">1323</a></span><span class="t"><span class="str">            is a Tensor with shape `[1]`. The data type of precision, recall and \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1324" href="#t1324">1324</a></span><span class="t"><span class="str">            F1-score all is float32, and the others' data type all is int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1325" href="#t1325">1325</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1326" href="#t1326">1326</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1327" href="#t1327">1327</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1328" href="#t1328">1328</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1329" href="#t1329">1329</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1330" href="#t1330">1330</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1331" href="#t1331">1331</a></span><span class="t"><span class="str">            dict_size = 10000</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1332" href="#t1332">1332</a></span><span class="t"><span class="str">            label_dict_len = 7</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1333" href="#t1333">1333</a></span><span class="t"><span class="str">            sequence = fluid.data(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1334" href="#t1334">1334</a></span><span class="t"><span class="str">                name='id', shape=[None, 1], lod_level=1, dtype='int64')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1335" href="#t1335">1335</a></span><span class="t"><span class="str">            embedding = fluid.embedding(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1336" href="#t1336">1336</a></span><span class="t"><span class="str">                input=sequence, size=[dict_size, 512])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1337" href="#t1337">1337</a></span><span class="t"><span class="str">            hidden = fluid.layers.fc(input=embedding, size=512)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1338" href="#t1338">1338</a></span><span class="t"><span class="str">            label = fluid.data(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1339" href="#t1339">1339</a></span><span class="t"><span class="str">                name='label', shape=[None, 1], lod_level=1, dtype='int64')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1340" href="#t1340">1340</a></span><span class="t"><span class="str">            crf = fluid.layers.linear_chain_crf(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1341" href="#t1341">1341</a></span><span class="t"><span class="str">                input=hidden, label=label, param_attr=fluid.ParamAttr(name="crfw"))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1342" href="#t1342">1342</a></span><span class="t"><span class="str">            crf_decode = fluid.layers.crf_decoding(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1343" href="#t1343">1343</a></span><span class="t"><span class="str">                input=hidden, param_attr=fluid.ParamAttr(name="crfw"))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1344" href="#t1344">1344</a></span><span class="t"><span class="str">            fluid.layers.chunk_eval(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1345" href="#t1345">1345</a></span><span class="t"><span class="str">                input=crf_decode,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1346" href="#t1346">1346</a></span><span class="t"><span class="str">                label=label,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1347" href="#t1347">1347</a></span><span class="t"><span class="str">                chunk_scheme="IOB",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1348" href="#t1348">1348</a></span><span class="t"><span class="str">                num_chunk_types=int((label_dict_len - 1) / 2))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1349" href="#t1349">1349</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1350" href="#t1350">1350</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"chunk_eval"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1351" href="#t1351">1351</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1352" href="#t1352">1352</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'int64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'chunk_eval'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1353" href="#t1353">1353</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">label</span><span class="op">,</span> <span class="str">'label'</span><span class="op">,</span> <span class="op">[</span><span class="str">'int64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'chunk_eval'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1354" href="#t1354">1354</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1355" href="#t1355">1355</a></span><span class="t">    <span class="com"># prepare output</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1356" href="#t1356">1356</a></span><span class="t">    <span class="nam">precision</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="str">"float32"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1357" href="#t1357">1357</a></span><span class="t">    <span class="nam">recall</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="str">"float32"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1358" href="#t1358">1358</a></span><span class="t">    <span class="nam">f1_score</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="str">"float32"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1359" href="#t1359">1359</a></span><span class="t">    <span class="nam">num_infer_chunks</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="str">"int64"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1360" href="#t1360">1360</a></span><span class="t">    <span class="nam">num_label_chunks</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="str">"int64"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1361" href="#t1361">1361</a></span><span class="t">    <span class="nam">num_correct_chunks</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1362" href="#t1362">1362</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="str">"int64"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1363" href="#t1363">1363</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1364" href="#t1364">1364</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1365" href="#t1365">1365</a></span><span class="t">    <span class="nam">this_input</span> <span class="op">=</span> <span class="op">{</span><span class="str">"Inference"</span><span class="op">:</span> <span class="op">[</span><span class="nam">input</span><span class="op">]</span><span class="op">,</span> <span class="str">"Label"</span><span class="op">:</span> <span class="op">[</span><span class="nam">label</span><span class="op">]</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1366" href="#t1366">1366</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1367" href="#t1367">1367</a></span><span class="t">    <span class="key">if</span> <span class="nam">seq_length</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1368" href="#t1368">1368</a></span><span class="t">        <span class="nam">this_input</span><span class="op">[</span><span class="str">"SeqLength"</span><span class="op">]</span> <span class="op">=</span> <span class="op">[</span><span class="nam">seq_length</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1369" href="#t1369">1369</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1370" href="#t1370">1370</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1371" href="#t1371">1371</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"chunk_eval"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1372" href="#t1372">1372</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="nam">this_input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1373" href="#t1373">1373</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1374" href="#t1374">1374</a></span><span class="t">            <span class="str">"Precision"</span><span class="op">:</span> <span class="op">[</span><span class="nam">precision</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1375" href="#t1375">1375</a></span><span class="t">            <span class="str">"Recall"</span><span class="op">:</span> <span class="op">[</span><span class="nam">recall</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1376" href="#t1376">1376</a></span><span class="t">            <span class="str">"F1-Score"</span><span class="op">:</span> <span class="op">[</span><span class="nam">f1_score</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1377" href="#t1377">1377</a></span><span class="t">            <span class="str">"NumInferChunks"</span><span class="op">:</span> <span class="op">[</span><span class="nam">num_infer_chunks</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1378" href="#t1378">1378</a></span><span class="t">            <span class="str">"NumLabelChunks"</span><span class="op">:</span> <span class="op">[</span><span class="nam">num_label_chunks</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1379" href="#t1379">1379</a></span><span class="t">            <span class="str">"NumCorrectChunks"</span><span class="op">:</span> <span class="op">[</span><span class="nam">num_correct_chunks</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1380" href="#t1380">1380</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1381" href="#t1381">1381</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1382" href="#t1382">1382</a></span><span class="t">            <span class="str">"num_chunk_types"</span><span class="op">:</span> <span class="nam">num_chunk_types</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1383" href="#t1383">1383</a></span><span class="t">            <span class="str">"chunk_scheme"</span><span class="op">:</span> <span class="nam">chunk_scheme</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1384" href="#t1384">1384</a></span><span class="t">            <span class="str">"excluded_chunk_types"</span><span class="op">:</span> <span class="nam">excluded_chunk_types</span> <span class="key">or</span> <span class="op">[</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1385" href="#t1385">1385</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1386" href="#t1386">1386</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1387" href="#t1387">1387</a></span><span class="t">    <span class="key">return</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1388" href="#t1388">1388</a></span><span class="t">        <span class="nam">precision</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1389" href="#t1389">1389</a></span><span class="t">        <span class="nam">recall</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1390" href="#t1390">1390</a></span><span class="t">        <span class="nam">f1_score</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1391" href="#t1391">1391</a></span><span class="t">        <span class="nam">num_infer_chunks</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1392" href="#t1392">1392</a></span><span class="t">        <span class="nam">num_label_chunks</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1393" href="#t1393">1393</a></span><span class="t">        <span class="nam">num_correct_chunks</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1394" href="#t1394">1394</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1395" href="#t1395">1395</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1396" href="#t1396">1396</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1397" href="#t1397">1397</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.nn.functional.softmax"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1398" href="#t1398">1398</a></span><span class="t"><span class="key">def</span> <span class="nam">softmax</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">use_cudnn</span><span class="op">=</span><span class="key">True</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1399" href="#t1399">1399</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1400" href="#t1400">1400</a></span><span class="t"><span class="str">    This operator implements the softmax layer. The calculation process is as follows:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1401" href="#t1401">1401</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1402" href="#t1402">1402</a></span><span class="t"><span class="str">    1. The dimension :attr:`axis` of the ``input`` will be permuted to the last.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1403" href="#t1403">1403</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1404" href="#t1404">1404</a></span><span class="t"><span class="str">    2. Then the input tensor will be logically flattened to a 2-D matrix. The matrix's</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1405" href="#t1405">1405</a></span><span class="t"><span class="str">    second dimension(row length) is the same as the dimension :attr:`axis` of the input</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1406" href="#t1406">1406</a></span><span class="t"><span class="str">    tensor, and the first dimension(column length) is the product of all other</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1407" href="#t1407">1407</a></span><span class="t"><span class="str">    dimensions of the input tensor. For each row of the matrix, the softmax operator</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1408" href="#t1408">1408</a></span><span class="t"><span class="str">    squashes the K-dimensional(K is the width of the matrix, which is also the size</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1409" href="#t1409">1409</a></span><span class="t"><span class="str">    of the input tensor's dimension :attr:`axis`) vector of arbitrary real values to a</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1410" href="#t1410">1410</a></span><span class="t"><span class="str">    K-dimensional vector of real values in the range [0, 1] that add up to 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1411" href="#t1411">1411</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1412" href="#t1412">1412</a></span><span class="t"><span class="str">    3. After the softmax operation is completed, the inverse operations of steps 1 and 2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1413" href="#t1413">1413</a></span><span class="t"><span class="str">    are performed to restore the two-dimensional matrix to the same dimension as the ``input``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1414" href="#t1414">1414</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1415" href="#t1415">1415</a></span><span class="t"><span class="str">    It computes the exponential of the given dimension and the sum of exponential</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1416" href="#t1416">1416</a></span><span class="t"><span class="str">    values of all the other dimensions in the K-dimensional vector input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1417" href="#t1417">1417</a></span><span class="t"><span class="str">    Then the ratio of the exponential of the given dimension and the sum of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1418" href="#t1418">1418</a></span><span class="t"><span class="str">    exponential values of all the other dimensions is the output of the softmax</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1419" href="#t1419">1419</a></span><span class="t"><span class="str">    operator.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1420" href="#t1420">1420</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1421" href="#t1421">1421</a></span><span class="t"><span class="str">    For each row :math:`i` and each column :math:`j` in the matrix, we have:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1422" href="#t1422">1422</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1423" href="#t1423">1423</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1424" href="#t1424">1424</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1425" href="#t1425">1425</a></span><span class="t"><span class="str">        Out[i, j] = \\frac{\\exp(X[i, j])}{\\sum_j(exp(X[i, j])}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1426" href="#t1426">1426</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1427" href="#t1427">1427</a></span><span class="t"><span class="str">    Example:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1428" href="#t1428">1428</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1429" href="#t1429">1429</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1430" href="#t1430">1430</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1431" href="#t1431">1431</a></span><span class="t"><span class="str">        Case 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1432" href="#t1432">1432</a></span><span class="t"><span class="str">          Input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1433" href="#t1433">1433</a></span><span class="t"><span class="str">            X.shape = [2, 3, 4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1434" href="#t1434">1434</a></span><span class="t"><span class="str">            X.data = [[[2.0, 3.0, 4.0, 5.0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1435" href="#t1435">1435</a></span><span class="t"><span class="str">                       [3.0, 4.0, 5.0, 6.0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1436" href="#t1436">1436</a></span><span class="t"><span class="str">                       [7.0, 8.0, 8.0, 9.0]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1437" href="#t1437">1437</a></span><span class="t"><span class="str">                      [[1.0, 2.0, 3.0, 4.0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1438" href="#t1438">1438</a></span><span class="t"><span class="str">                       [5.0, 6.0, 7.0, 8.0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1439" href="#t1439">1439</a></span><span class="t"><span class="str">                       [6.0, 7.0, 8.0, 9.0]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1440" href="#t1440">1440</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1441" href="#t1441">1441</a></span><span class="t"><span class="str">          Attrs:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1442" href="#t1442">1442</a></span><span class="t"><span class="str">            axis = -1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1443" href="#t1443">1443</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1444" href="#t1444">1444</a></span><span class="t"><span class="str">          Output:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1445" href="#t1445">1445</a></span><span class="t"><span class="str">            Out.shape = [2, 3, 4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1446" href="#t1446">1446</a></span><span class="t"><span class="str">            Out.data = [[[0.0320586 , 0.08714432, 0.23688282, 0.64391426],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1447" href="#t1447">1447</a></span><span class="t"><span class="str">                         [0.0320586 , 0.08714432, 0.23688282, 0.64391426],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1448" href="#t1448">1448</a></span><span class="t"><span class="str">                         [0.07232949, 0.19661193, 0.19661193, 0.53444665]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1449" href="#t1449">1449</a></span><span class="t"><span class="str">                        [[0.0320586 , 0.08714432, 0.23688282, 0.64391426],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1450" href="#t1450">1450</a></span><span class="t"><span class="str">                         [0.0320586 , 0.08714432, 0.23688282, 0.64391426],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1451" href="#t1451">1451</a></span><span class="t"><span class="str">                         [0.0320586 , 0.08714432, 0.23688282, 0.64391426]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1452" href="#t1452">1452</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1453" href="#t1453">1453</a></span><span class="t"><span class="str">        Case 2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1454" href="#t1454">1454</a></span><span class="t"><span class="str">          Input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1455" href="#t1455">1455</a></span><span class="t"><span class="str">            X.shape = [2, 3, 4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1456" href="#t1456">1456</a></span><span class="t"><span class="str">            X.data = [[[2.0, 3.0, 4.0, 5.0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1457" href="#t1457">1457</a></span><span class="t"><span class="str">                       [3.0, 4.0, 5.0, 6.0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1458" href="#t1458">1458</a></span><span class="t"><span class="str">                       [7.0, 8.0, 8.0, 9.0]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1459" href="#t1459">1459</a></span><span class="t"><span class="str">                      [[1.0, 2.0, 3.0, 4.0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1460" href="#t1460">1460</a></span><span class="t"><span class="str">                       [5.0, 6.0, 7.0, 8.0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1461" href="#t1461">1461</a></span><span class="t"><span class="str">                       [6.0, 7.0, 8.0, 9.0]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1462" href="#t1462">1462</a></span><span class="t"><span class="str">          Attrs:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1463" href="#t1463">1463</a></span><span class="t"><span class="str">            axis = 1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1464" href="#t1464">1464</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1465" href="#t1465">1465</a></span><span class="t"><span class="str">          Output:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1466" href="#t1466">1466</a></span><span class="t"><span class="str">            Out.shape = [2, 3, 4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1467" href="#t1467">1467</a></span><span class="t"><span class="str">            Out.data = [[[0.00657326, 0.00657326, 0.01714783, 0.01714783],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1468" href="#t1468">1468</a></span><span class="t"><span class="str">                         [0.01786798, 0.01786798, 0.04661262, 0.04661262],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1469" href="#t1469">1469</a></span><span class="t"><span class="str">                         [0.97555875, 0.97555875, 0.93623955, 0.93623955]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1470" href="#t1470">1470</a></span><span class="t"><span class="str">                        [[0.00490169, 0.00490169, 0.00490169, 0.00490169],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1471" href="#t1471">1471</a></span><span class="t"><span class="str">                         [0.26762315, 0.26762315, 0.26762315, 0.26762315],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1472" href="#t1472">1472</a></span><span class="t"><span class="str">                         [0.72747516, 0.72747516, 0.72747516, 0.72747516]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1473" href="#t1473">1473</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1474" href="#t1474">1474</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1475" href="#t1475">1475</a></span><span class="t"><span class="str">        input (Tensor): The input tensor. A multi-dimension ``Tensor`` with type float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1476" href="#t1476">1476</a></span><span class="t"><span class="str">        use_cudnn (bool, optional): Use cudnn kernel or not, it is valid only when the cudnn \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1477" href="#t1477">1477</a></span><span class="t"><span class="str">            library is installed. To improve performance, set use_cudnn to True by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1478" href="#t1478">1478</a></span><span class="t"><span class="str">        name (str, optional): The default value is None. Normally there is no need for user to set this property. For more information, please refer to :ref:`api_guide_Name` . Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1479" href="#t1479">1479</a></span><span class="t"><span class="str">            will be named automatically. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1480" href="#t1480">1480</a></span><span class="t"><span class="str">        axis (int, optional): The index of dimension to perform softmax calculations, it should</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1481" href="#t1481">1481</a></span><span class="t"><span class="str">            be in range :math:`[-1, rank - 1]`, while :math:`rank` is the rank of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1482" href="#t1482">1482</a></span><span class="t"><span class="str">            input tensor. Default: -1. -1 means the last dimension.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1483" href="#t1483">1483</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1484" href="#t1484">1484</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1485" href="#t1485">1485</a></span><span class="t"><span class="str">        Tensor: ``Tensor`` indicates the output of softmax. The data type and shape are the same as ``input`` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1486" href="#t1486">1486</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1487" href="#t1487">1487</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1488" href="#t1488">1488</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1489" href="#t1489">1489</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1490" href="#t1490">1490</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1491" href="#t1491">1491</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1492" href="#t1492">1492</a></span><span class="t"><span class="str">            import paddle.nn.functional as F</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1493" href="#t1493">1493</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1494" href="#t1494">1494</a></span><span class="t"><span class="str">            x = paddle.to_tensor([[[2.0, 3.0, 4.0, 5.0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1495" href="#t1495">1495</a></span><span class="t"><span class="str">                                [3.0, 4.0, 5.0, 6.0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1496" href="#t1496">1496</a></span><span class="t"><span class="str">                                [7.0, 8.0, 8.0, 9.0]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1497" href="#t1497">1497</a></span><span class="t"><span class="str">                                [[1.0, 2.0, 3.0, 4.0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1498" href="#t1498">1498</a></span><span class="t"><span class="str">                                [5.0, 6.0, 7.0, 8.0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1499" href="#t1499">1499</a></span><span class="t"><span class="str">                                [6.0, 7.0, 8.0, 9.0]]], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1500" href="#t1500">1500</a></span><span class="t"><span class="str">            y = F.softmax(x, axis=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1501" href="#t1501">1501</a></span><span class="t"><span class="str">            print(y)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1502" href="#t1502">1502</a></span><span class="t"><span class="str">            # [[[0.00657326, 0.00657326, 0.01714783, 0.01714783],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1503" href="#t1503">1503</a></span><span class="t"><span class="str">            #   [0.01786798, 0.01786798, 0.04661262, 0.04661262],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1504" href="#t1504">1504</a></span><span class="t"><span class="str">            #   [0.97555870, 0.97555870, 0.93623954, 0.93623954]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1505" href="#t1505">1505</a></span><span class="t"><span class="str">            #  [[0.00490169, 0.00490169, 0.00490169, 0.00490169],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1506" href="#t1506">1506</a></span><span class="t"><span class="str">            #   [0.26762316, 0.26762316, 0.26762316, 0.26762316],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1507" href="#t1507">1507</a></span><span class="t"><span class="str">            #   [0.72747517, 0.72747517, 0.72747517, 0.72747517]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1508" href="#t1508">1508</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1509" href="#t1509">1509</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1510" href="#t1510">1510</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1511" href="#t1511">1511</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1512" href="#t1512">1512</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">softmax</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">axis</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1513" href="#t1513">1513</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1514" href="#t1514">1514</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1515" href="#t1515">1515</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">softmax</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1516" href="#t1516">1516</a></span><span class="t">            <span class="nam">input</span><span class="op">,</span> <span class="str">'axis'</span><span class="op">,</span> <span class="nam">axis</span><span class="op">,</span> <span class="str">'use_cudnn'</span><span class="op">,</span> <span class="nam">use_cudnn</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1517" href="#t1517">1517</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1518" href="#t1518">1518</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1519" href="#t1519">1519</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="op">[</span><span class="nam">input</span><span class="op">]</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1520" href="#t1520">1520</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="str">"axis"</span><span class="op">:</span> <span class="nam">axis</span><span class="op">,</span> <span class="str">"use_cudnn"</span><span class="op">:</span> <span class="nam">use_cudnn</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1521" href="#t1521">1521</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1522" href="#t1522">1522</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'softmax'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1523" href="#t1523">1523</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1524" href="#t1524">1524</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span> <span class="str">'input/x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'softmax'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1525" href="#t1525">1525</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1526" href="#t1526">1526</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1527" href="#t1527">1527</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1528" href="#t1528">1528</a></span><span class="t">    <span class="nam">softmax_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1529" href="#t1529">1529</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1530" href="#t1530">1530</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"softmax"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1531" href="#t1531">1531</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1532" href="#t1532">1532</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">softmax_out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1533" href="#t1533">1533</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1534" href="#t1534">1534</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1535" href="#t1535">1535</a></span><span class="t">    <span class="key">return</span> <span class="nam">softmax_out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1536" href="#t1536">1536</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1537" href="#t1537">1537</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1538" href="#t1538">1538</a></span><span class="t"><span class="key">def</span> <span class="nam">conv2d</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1539" href="#t1539">1539</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1540" href="#t1540">1540</a></span><span class="t">    <span class="nam">num_filters</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1541" href="#t1541">1541</a></span><span class="t">    <span class="nam">filter_size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1542" href="#t1542">1542</a></span><span class="t">    <span class="nam">stride</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1543" href="#t1543">1543</a></span><span class="t">    <span class="nam">padding</span><span class="op">=</span><span class="num">0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1544" href="#t1544">1544</a></span><span class="t">    <span class="nam">dilation</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1545" href="#t1545">1545</a></span><span class="t">    <span class="nam">groups</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1546" href="#t1546">1546</a></span><span class="t">    <span class="nam">param_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1547" href="#t1547">1547</a></span><span class="t">    <span class="nam">bias_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1548" href="#t1548">1548</a></span><span class="t">    <span class="nam">use_cudnn</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1549" href="#t1549">1549</a></span><span class="t">    <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1550" href="#t1550">1550</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1551" href="#t1551">1551</a></span><span class="t">    <span class="nam">data_format</span><span class="op">=</span><span class="str">"NCHW"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1552" href="#t1552">1552</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1553" href="#t1553">1553</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1554" href="#t1554">1554</a></span><span class="t"><span class="str">    :api_attr: Static Graph</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1555" href="#t1555">1555</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1556" href="#t1556">1556</a></span><span class="t"><span class="str">    The convolution2D layer calculates the output based on the input, filter</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1557" href="#t1557">1557</a></span><span class="t"><span class="str">    and strides, paddings, dilations, groups parameters. Input and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1558" href="#t1558">1558</a></span><span class="t"><span class="str">    Output are in NCHW or NHWC format, where N is batch size, C is the number of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1559" href="#t1559">1559</a></span><span class="t"><span class="str">    channels, H is the height of the feature, and W is the width of the feature.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1560" href="#t1560">1560</a></span><span class="t"><span class="str">    Filter is in MCHW format, where M is the number of output image channels,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1561" href="#t1561">1561</a></span><span class="t"><span class="str">    C is the number of input image channels, H is the height of the filter,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1562" href="#t1562">1562</a></span><span class="t"><span class="str">    and W is the width of the filter. If the groups is greater than 1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1563" href="#t1563">1563</a></span><span class="t"><span class="str">    C will equal the number of input image channels divided by the groups.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1564" href="#t1564">1564</a></span><span class="t"><span class="str">    Please refer to UFLDL's `convolution</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1565" href="#t1565">1565</a></span><span class="t"><span class="str">    &lt;http://ufldl.stanford.edu/tutorial/supervised/FeatureExtractionUsingConvolution/>`_</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1566" href="#t1566">1566</a></span><span class="t"><span class="str">    for more details.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1567" href="#t1567">1567</a></span><span class="t"><span class="str">    If bias attribution and activation type are provided, bias is added to the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1568" href="#t1568">1568</a></span><span class="t"><span class="str">    output of the convolution, and the corresponding activation function is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1569" href="#t1569">1569</a></span><span class="t"><span class="str">    applied to the final result.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1570" href="#t1570">1570</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1571" href="#t1571">1571</a></span><span class="t"><span class="str">    For each input :math:`X`, the equation is:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1572" href="#t1572">1572</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1573" href="#t1573">1573</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1574" href="#t1574">1574</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1575" href="#t1575">1575</a></span><span class="t"><span class="str">        Out = \sigma (W \\ast X + b)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1576" href="#t1576">1576</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1577" href="#t1577">1577</a></span><span class="t"><span class="str">    Where:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1578" href="#t1578">1578</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1579" href="#t1579">1579</a></span><span class="t"><span class="str">    * :math:`X`: Input value, a tensor with NCHW or NHWC format.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1580" href="#t1580">1580</a></span><span class="t"><span class="str">    * :math:`W`: Filter value, a tensor with MCHW format.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1581" href="#t1581">1581</a></span><span class="t"><span class="str">    * :math:`\\ast`: Convolution operation.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1582" href="#t1582">1582</a></span><span class="t"><span class="str">    * :math:`b`: Bias value, a 2-D tensor with shape [M, 1].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1583" href="#t1583">1583</a></span><span class="t"><span class="str">    * :math:`\\sigma`: Activation function.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1584" href="#t1584">1584</a></span><span class="t"><span class="str">    * :math:`Out`: Output value, the shape of :math:`Out` and :math:`X` may be different.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1585" href="#t1585">1585</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1586" href="#t1586">1586</a></span><span class="t"><span class="str">    Example:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1587" href="#t1587">1587</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1588" href="#t1588">1588</a></span><span class="t"><span class="str">        - Input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1589" href="#t1589">1589</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1590" href="#t1590">1590</a></span><span class="t"><span class="str">          Input shape: :math:`(N, C_{in}, H_{in}, W_{in})`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1591" href="#t1591">1591</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1592" href="#t1592">1592</a></span><span class="t"><span class="str">          Filter shape: :math:`(C_{out}, C_{in}, H_f, W_f)`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1593" href="#t1593">1593</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1594" href="#t1594">1594</a></span><span class="t"><span class="str">        - Output:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1595" href="#t1595">1595</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1596" href="#t1596">1596</a></span><span class="t"><span class="str">          Output shape: :math:`(N, C_{out}, H_{out}, W_{out})`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1597" href="#t1597">1597</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1598" href="#t1598">1598</a></span><span class="t"><span class="str">        Where</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1599" href="#t1599">1599</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1600" href="#t1600">1600</a></span><span class="t"><span class="str">        .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1601" href="#t1601">1601</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1602" href="#t1602">1602</a></span><span class="t"><span class="str">            H_{out}&amp;= \\frac{(H_{in} + 2 * paddings[0] - (dilations[0] * (H_f - 1) + 1))}{strides[0]} + 1 \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1603" href="#t1603">1603</a></span><span class="t"><span class="str">            W_{out}&amp;= \\frac{(W_{in} + 2 * paddings[1] - (dilations[1] * (W_f - 1) + 1))}{strides[1]} + 1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1604" href="#t1604">1604</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1605" href="#t1605">1605</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1606" href="#t1606">1606</a></span><span class="t"><span class="str">        input (Tensor): The input is 4-D Tensor with shape [N, C, H, W], the data type</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1607" href="#t1607">1607</a></span><span class="t"><span class="str">            of input is float16 or float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1608" href="#t1608">1608</a></span><span class="t"><span class="str">        num_filters(int): The number of filter. It is as same as the output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1609" href="#t1609">1609</a></span><span class="t"><span class="str">            image channel.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1610" href="#t1610">1610</a></span><span class="t"><span class="str">        filter_size (int|tuple): The filter size. If filter_size</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1611" href="#t1611">1611</a></span><span class="t"><span class="str">            is a tuple, it must contain two integers, (filter_size_height,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1612" href="#t1612">1612</a></span><span class="t"><span class="str">            filter_size_width). Otherwise, filter_size_height = filter_size_width =\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1613" href="#t1613">1613</a></span><span class="t"><span class="str">            filter_size.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1614" href="#t1614">1614</a></span><span class="t"><span class="str">        stride (int|tuple): The stride size. It means the stride in convolution.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1615" href="#t1615">1615</a></span><span class="t"><span class="str">            If stride is a tuple, it must contain two integers, (stride_height, stride_width).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1616" href="#t1616">1616</a></span><span class="t"><span class="str">            Otherwise, stride_height = stride_width = stride. Default: stride = 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1617" href="#t1617">1617</a></span><span class="t"><span class="str">        padding (string|int|list|tuple): The padding size. It means the number of zero-paddings</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1618" href="#t1618">1618</a></span><span class="t"><span class="str">            on both sides for each dimension.If `padding` is a string, either 'VALID' or</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1619" href="#t1619">1619</a></span><span class="t"><span class="str">            'SAME' which is the padding algorithm. If padding size is a tuple or list,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1620" href="#t1620">1620</a></span><span class="t"><span class="str">            it could be in three forms: `[pad_height, pad_width]` or</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1621" href="#t1621">1621</a></span><span class="t"><span class="str">            `[pad_height_top, pad_height_bottom, pad_width_left, pad_width_right]`, and when</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1622" href="#t1622">1622</a></span><span class="t"><span class="str">            `data_format` is `"NCHW"`, `padding` can be in the form `[[0,0], [0,0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1623" href="#t1623">1623</a></span><span class="t"><span class="str">            [pad_height_top, pad_height_bottom], [pad_width_left, pad_width_right]]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1624" href="#t1624">1624</a></span><span class="t"><span class="str">            when `data_format` is `"NHWC"`, `pool_padding` can be in the form</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1625" href="#t1625">1625</a></span><span class="t"><span class="str">            `[[0,0], [pad_height_top, pad_height_bottom], [pad_width_left, pad_width_right], [0,0]]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1626" href="#t1626">1626</a></span><span class="t"><span class="str">            Default: padding = 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1627" href="#t1627">1627</a></span><span class="t"><span class="str">        dilation (int|tuple): The dilation size. It means the spacing between the kernel</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1628" href="#t1628">1628</a></span><span class="t"><span class="str">            points. If dilation is a tuple, it must contain two integers, (dilation_height,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1629" href="#t1629">1629</a></span><span class="t"><span class="str">            dilation_width). Otherwise, dilation_height = dilation_width = dilation.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1630" href="#t1630">1630</a></span><span class="t"><span class="str">            Default: dilation = 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1631" href="#t1631">1631</a></span><span class="t"><span class="str">        groups (int): The groups number of the Conv2d Layer. According to grouped</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1632" href="#t1632">1632</a></span><span class="t"><span class="str">            convolution in Alex Krizhevsky's Deep CNN paper: when group=2,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1633" href="#t1633">1633</a></span><span class="t"><span class="str">            the first half of the filters is only connected to the first half</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1634" href="#t1634">1634</a></span><span class="t"><span class="str">            of the input channels, while the second half of the filters is only</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1635" href="#t1635">1635</a></span><span class="t"><span class="str">            connected to the second half of the input channels. Default: groups=1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1636" href="#t1636">1636</a></span><span class="t"><span class="str">        param_attr (ParamAttr|None): The parameter attribute for learnable parameters/weights</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1637" href="#t1637">1637</a></span><span class="t"><span class="str">            of conv2d. If it is set to None or one attribute of ParamAttr, conv2d</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1638" href="#t1638">1638</a></span><span class="t"><span class="str">            will create ParamAttr as param_attr. If the Initializer of the param_attr</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1639" href="#t1639">1639</a></span><span class="t"><span class="str">            is not set, the parameter is initialized with :math:`Normal(0.0, std)`,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1640" href="#t1640">1640</a></span><span class="t"><span class="str">            and the :math:`std` is :math:`(\\frac{2.0 }{filter\_elem\_num})^{0.5}`. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1641" href="#t1641">1641</a></span><span class="t"><span class="str">        bias_attr (ParamAttr|bool|None): The parameter attribute for the bias of conv2d.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1642" href="#t1642">1642</a></span><span class="t"><span class="str">            If it is set to False, no bias will be added to the output units.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1643" href="#t1643">1643</a></span><span class="t"><span class="str">            If it is set to None or one attribute of ParamAttr, conv2d</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1644" href="#t1644">1644</a></span><span class="t"><span class="str">            will create ParamAttr as bias_attr. If the Initializer of the bias_attr</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1645" href="#t1645">1645</a></span><span class="t"><span class="str">            is not set, the bias is initialized zero. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1646" href="#t1646">1646</a></span><span class="t"><span class="str">        use_cudnn (bool): Use cudnn kernel or not, it is valid only when the cudnn</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1647" href="#t1647">1647</a></span><span class="t"><span class="str">            library is installed. Default: True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1648" href="#t1648">1648</a></span><span class="t"><span class="str">        act (str): Activation type, if it is set to None, activation is not appended.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1649" href="#t1649">1649</a></span><span class="t"><span class="str">            Default: None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1650" href="#t1650">1650</a></span><span class="t"><span class="str">        name(str|None): For detailed information, please refer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1651" href="#t1651">1651</a></span><span class="t"><span class="str">           to :ref:`api_guide_Name`. Usually name is no need to set and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1652" href="#t1652">1652</a></span><span class="t"><span class="str">           None by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1653" href="#t1653">1653</a></span><span class="t"><span class="str">        data_format (str, optional): Specify the data format of the input, and the data format of the output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1654" href="#t1654">1654</a></span><span class="t"><span class="str">            will be consistent with that of the input. An optional string from: `"NCHW"`, `"NHWC"`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1655" href="#t1655">1655</a></span><span class="t"><span class="str">            The default is `"NCHW"`. When it is `"NCHW"`, the data is stored in the order of:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1656" href="#t1656">1656</a></span><span class="t"><span class="str">            `[batch_size, input_channels, input_height, input_width]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1657" href="#t1657">1657</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1658" href="#t1658">1658</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1659" href="#t1659">1659</a></span><span class="t"><span class="str">        A Tensor representing the conv2d, whose data type is the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1660" href="#t1660">1660</a></span><span class="t"><span class="str">        same with input. If act is None, the tensor storing the convolution</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1661" href="#t1661">1661</a></span><span class="t"><span class="str">        result, and if act is not None, the tensor storing convolution</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1662" href="#t1662">1662</a></span><span class="t"><span class="str">        and non-linearity activation result.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1663" href="#t1663">1663</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1664" href="#t1664">1664</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1665" href="#t1665">1665</a></span><span class="t"><span class="str">        ValueError: If the type of `use_cudnn` is not bool.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1666" href="#t1666">1666</a></span><span class="t"><span class="str">        ValueError: If `data_format` is not "NCHW" or "NHWC".</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1667" href="#t1667">1667</a></span><span class="t"><span class="str">        ValueError: If the channel dimmention of the input is less than or equal to zero.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1668" href="#t1668">1668</a></span><span class="t"><span class="str">        ValueError: If `padding` is a string, but not "SAME" or "VALID".</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1669" href="#t1669">1669</a></span><span class="t"><span class="str">        ValueError: If `padding` is a tuple, but the element corresponding to the input's batch size is not 0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1670" href="#t1670">1670</a></span><span class="t"><span class="str">            or the element corresponding to the input's channel is not 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1671" href="#t1671">1671</a></span><span class="t"><span class="str">        ShapeError: If the input is not 4-D Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1672" href="#t1672">1672</a></span><span class="t"><span class="str">        ShapeError: If the input's dimension size and filter's dimension size not equal.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1673" href="#t1673">1673</a></span><span class="t"><span class="str">        ShapeError: If the dimension size of input minus the size of `stride` is not 2.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1674" href="#t1674">1674</a></span><span class="t"><span class="str">        ShapeError: If the number of input channels is not equal to filter's channels * groups.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1675" href="#t1675">1675</a></span><span class="t"><span class="str">        ShapeError: If the number of output channels is not be divided by groups.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1676" href="#t1676">1676</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1677" href="#t1677">1677</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1678" href="#t1678">1678</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1679" href="#t1679">1679</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1680" href="#t1680">1680</a></span><span class="t"><span class="str">          import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1681" href="#t1681">1681</a></span><span class="t"><span class="str">          paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1682" href="#t1682">1682</a></span><span class="t"><span class="str">          </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1683" href="#t1683">1683</a></span><span class="t"><span class="str">          data = paddle.static.data(name='data', shape=[None, 3, 32, 32], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1684" href="#t1684">1684</a></span><span class="t"><span class="str">          conv2d = paddle.static.nn.conv2d(input=data, num_filters=2, filter_size=3, act="relu")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1685" href="#t1685">1685</a></span><span class="t"><span class="str">          print(conv2d.shape) # [-1, 2, 30, 30]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1686" href="#t1686">1686</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1687" href="#t1687">1687</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1688" href="#t1688">1688</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1689" href="#t1689">1689</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'conv2d'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1690" href="#t1690">1690</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1691" href="#t1691">1691</a></span><span class="t">    <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">!=</span> <span class="num">4</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1692" href="#t1692">1692</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1693" href="#t1693">1693</a></span><span class="t">            <span class="str">"Input size should be 4, "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1694" href="#t1694">1694</a></span><span class="t">            <span class="str">"but received {}"</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1695" href="#t1695">1695</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1696" href="#t1696">1696</a></span><span class="t">    <span class="nam">num_channels</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t1697" href="#t1697">1697</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">use_cudnn</span><span class="op">,</span> <span class="nam">bool</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">1697&#x202F;&#x219B;&#x202F;1698</span><span class="annotate long">line 1697 didn't jump to line 1698, because the condition on line 1697 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1698" href="#t1698">1698</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1699" href="#t1699">1699</a></span><span class="t">            <span class="str">"Attr(use_cudnn) should be True or False. Received "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1700" href="#t1700">1700</a></span><span class="t">            <span class="str">"Attr(use_cudnn): %s. "</span> <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">use_cudnn</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1701" href="#t1701">1701</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1702" href="#t1702">1702</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t1703" href="#t1703">1703</a></span><span class="t">    <span class="key">if</span> <span class="nam">data_format</span> <span class="key">not</span> <span class="key">in</span> <span class="op">[</span><span class="str">"NCHW"</span><span class="op">,</span> <span class="str">"NHWC"</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">1703&#x202F;&#x219B;&#x202F;1704</span><span class="annotate long">line 1703 didn't jump to line 1704, because the condition on line 1703 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1704" href="#t1704">1704</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1705" href="#t1705">1705</a></span><span class="t">            <span class="str">"Attr(data_format) should be 'NCHW' or 'NHWC'. Received "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1706" href="#t1706">1706</a></span><span class="t">            <span class="str">"Attr(data_format): %s."</span> <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">data_format</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1707" href="#t1707">1707</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1708" href="#t1708">1708</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1709" href="#t1709">1709</a></span><span class="t">    <span class="nam">channel_last</span> <span class="op">=</span> <span class="nam">data_format</span> <span class="op">==</span> <span class="str">"NHWC"</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1710" href="#t1710">1710</a></span><span class="t">    <span class="nam">num_channels</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">3</span><span class="op">]</span> <span class="key">if</span> <span class="nam">channel_last</span> <span class="key">else</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t1711" href="#t1711">1711</a></span><span class="t">    <span class="key">if</span> <span class="nam">num_channels</span> <span class="op">&lt;</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">1711&#x202F;&#x219B;&#x202F;1712</span><span class="annotate long">line 1711 didn't jump to line 1712, because the condition on line 1711 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1712" href="#t1712">1712</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1713" href="#t1713">1713</a></span><span class="t">            <span class="str">"The channel dimmention of the input(%s) should be defined. "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1714" href="#t1714">1714</a></span><span class="t">            <span class="str">"Received: %s."</span> <span class="op">%</span> <span class="op">(</span><span class="nam">str</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span><span class="op">,</span> <span class="nam">str</span><span class="op">(</span><span class="nam">num_channels</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1715" href="#t1715">1715</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1716" href="#t1716">1716</a></span><span class="t">    <span class="key">assert</span> <span class="nam">param_attr</span> <span class="key">is</span> <span class="key">not</span> <span class="key">False</span><span class="op">,</span> <span class="str">"param_attr should not be False here."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1717" href="#t1717">1717</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t1718" href="#t1718">1718</a></span><span class="t">    <span class="key">if</span> <span class="nam">groups</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">1718&#x202F;&#x219B;&#x202F;1719</span><span class="annotate long">line 1718 didn't jump to line 1719, because the condition on line 1718 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1719" href="#t1719">1719</a></span><span class="t">        <span class="nam">num_filter_channels</span> <span class="op">=</span> <span class="nam">num_channels</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t1720" href="#t1720">1720</a></span><span class="t">    <span class="key">elif</span> <span class="nam">groups</span> <span class="op">&lt;=</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">1720&#x202F;&#x219B;&#x202F;1721</span><span class="annotate long">line 1720 didn't jump to line 1721, because the condition on line 1720 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1721" href="#t1721">1721</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1722" href="#t1722">1722</a></span><span class="t">            <span class="str">"the groups of input must be greater than 0, "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1723" href="#t1723">1723</a></span><span class="t">            <span class="str">"but received the groups of input is {}"</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">groups</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1724" href="#t1724">1724</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1725" href="#t1725">1725</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t1726" href="#t1726">1726</a></span><span class="t">        <span class="key">if</span> <span class="nam">num_channels</span> <span class="op">%</span> <span class="nam">groups</span> <span class="op">!=</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">1726&#x202F;&#x219B;&#x202F;1727</span><span class="annotate long">line 1726 didn't jump to line 1727, because the condition on line 1726 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1727" href="#t1727">1727</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1728" href="#t1728">1728</a></span><span class="t">                <span class="str">"the channel of input must be divisible by groups,"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1729" href="#t1729">1729</a></span><span class="t">                <span class="str">"received: the channel of input is {}, the shape of input is {}"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1730" href="#t1730">1730</a></span><span class="t">                <span class="str">", the groups is {}"</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">num_channels</span><span class="op">,</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">,</span> <span class="nam">groups</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1731" href="#t1731">1731</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1732" href="#t1732">1732</a></span><span class="t">        <span class="nam">num_filter_channels</span> <span class="op">=</span> <span class="nam">num_channels</span> <span class="op">//</span> <span class="nam">groups</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1733" href="#t1733">1733</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1734" href="#t1734">1734</a></span><span class="t">    <span class="nam">l_type</span> <span class="op">=</span> <span class="str">'conv2d'</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t1735" href="#t1735">1735</a></span><span class="t">    <span class="key">if</span> <span class="op">(</span>&nbsp;</span><span class="r"><span class="annotate short">1735&#x202F;&#x219B;&#x202F;1740</span><span class="annotate long">line 1735 didn't jump to line 1740</span></span></p>
    <p class="pln"><span class="n"><a id="t1736" href="#t1736">1736</a></span><span class="t">        <span class="nam">num_channels</span> <span class="op">==</span> <span class="nam">groups</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1737" href="#t1737">1737</a></span><span class="t">        <span class="key">and</span> <span class="nam">num_filters</span> <span class="op">%</span> <span class="nam">num_channels</span> <span class="op">==</span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1738" href="#t1738">1738</a></span><span class="t">        <span class="key">and</span> <span class="key">not</span> <span class="nam">use_cudnn</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1739" href="#t1739">1739</a></span><span class="t">    <span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1740" href="#t1740">1740</a></span><span class="t">        <span class="nam">l_type</span> <span class="op">=</span> <span class="str">'depthwise_conv2d'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1741" href="#t1741">1741</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t1742" href="#t1742">1742</a></span><span class="t">    <span class="key">if</span> <span class="op">(</span>&nbsp;</span><span class="r"><span class="annotate short">1742&#x202F;&#x219B;&#x202F;1747</span><span class="annotate long">line 1742 didn't jump to line 1747</span></span></p>
    <p class="pln"><span class="n"><a id="t1743" href="#t1743">1743</a></span><span class="t">        <span class="nam">num_channels</span> <span class="op">==</span> <span class="nam">groups</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1744" href="#t1744">1744</a></span><span class="t">        <span class="key">and</span> <span class="nam">num_filters</span> <span class="op">%</span> <span class="nam">num_channels</span> <span class="op">==</span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1745" href="#t1745">1745</a></span><span class="t">        <span class="key">and</span> <span class="nam">core</span><span class="op">.</span><span class="nam">is_compiled_with_rocm</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1746" href="#t1746">1746</a></span><span class="t">    <span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1747" href="#t1747">1747</a></span><span class="t">        <span class="nam">l_type</span> <span class="op">=</span> <span class="str">'depthwise_conv2d'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1748" href="#t1748">1748</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1749" href="#t1749">1749</a></span><span class="t">    <span class="com"># NPU only supports depthwise_conv2d when  "input_channel = output_channel = groups"</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t1750" href="#t1750">1750</a></span><span class="t">    <span class="key">if</span> <span class="nam">core</span><span class="op">.</span><span class="nam">is_compiled_with_npu</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">1750&#x202F;&#x219B;&#x202F;1751</span><span class="annotate long">line 1750 didn't jump to line 1751, because the condition on line 1750 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1751" href="#t1751">1751</a></span><span class="t">        <span class="key">if</span> <span class="nam">num_channels</span> <span class="op">==</span> <span class="nam">groups</span> <span class="key">and</span> <span class="nam">num_channels</span> <span class="op">==</span> <span class="nam">num_filters</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1752" href="#t1752">1752</a></span><span class="t">            <span class="nam">l_type</span> <span class="op">=</span> <span class="str">'depthwise_conv2d'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1753" href="#t1753">1753</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1754" href="#t1754">1754</a></span><span class="t">            <span class="nam">l_type</span> <span class="op">=</span> <span class="str">'conv2d'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1755" href="#t1755">1755</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1756" href="#t1756">1756</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="nam">l_type</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1757" href="#t1757">1757</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1758" href="#t1758">1758</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1759" href="#t1759">1759</a></span><span class="t">    <span class="nam">filter_size</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">filter_size</span><span class="op">,</span> <span class="num">2</span><span class="op">,</span> <span class="str">'filter_size'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1760" href="#t1760">1760</a></span><span class="t">    <span class="nam">stride</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">stride</span><span class="op">,</span> <span class="num">2</span><span class="op">,</span> <span class="str">'stride'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1761" href="#t1761">1761</a></span><span class="t">    <span class="nam">dilation</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">dilation</span><span class="op">,</span> <span class="num">2</span><span class="op">,</span> <span class="str">'dilation'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1762" href="#t1762">1762</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1763" href="#t1763">1763</a></span><span class="t">    <span class="com"># padding</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1764" href="#t1764">1764</a></span><span class="t">    <span class="key">def</span> <span class="nam">_update_padding</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="nam">data_format</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1765" href="#t1765">1765</a></span><span class="t">        <span class="key">def</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">ele</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t1766" href="#t1766">1766</a></span><span class="t">            <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">ele</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span> <span class="key">or</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">ele</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">1766&#x202F;&#x219B;&#x202F;1767</span><span class="annotate long">line 1766 didn't jump to line 1767, because the condition on line 1766 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1767" href="#t1767">1767</a></span><span class="t">                <span class="key">return</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1768" href="#t1768">1768</a></span><span class="t">            <span class="key">return</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1769" href="#t1769">1769</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t1770" href="#t1770">1770</a></span><span class="t">        <span class="key">if</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span> <span class="key">and</span> <span class="nam">len</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span> <span class="op">==</span> <span class="num">4</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">1770&#x202F;&#x219B;&#x202F;1771</span><span class="annotate long">line 1770 didn't jump to line 1771, because the condition on line 1770 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1771" href="#t1771">1771</a></span><span class="t">            <span class="key">if</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">)</span> <span class="key">and</span> <span class="op">(</span><span class="nam">data_format</span> <span class="op">==</span> <span class="str">"NCHW"</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1772" href="#t1772">1772</a></span><span class="t">                <span class="key">if</span> <span class="key">not</span> <span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">==</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span> <span class="key">and</span> <span class="nam">padding</span><span class="op">[</span><span class="num">1</span><span class="op">]</span> <span class="op">==</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1773" href="#t1773">1773</a></span><span class="t">                    <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1774" href="#t1774">1774</a></span><span class="t">                        <span class="str">"Non-zero padding(%s) in the batch or channel dimensions "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1775" href="#t1775">1775</a></span><span class="t">                        <span class="str">"is not supported."</span> <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1776" href="#t1776">1776</a></span><span class="t">                    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1777" href="#t1777">1777</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="nam">padding</span><span class="op">[</span><span class="num">2</span><span class="op">:</span><span class="num">4</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1778" href="#t1778">1778</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="nam">ele</span> <span class="key">for</span> <span class="nam">a_list</span> <span class="key">in</span> <span class="nam">padding</span> <span class="key">for</span> <span class="nam">ele</span> <span class="key">in</span> <span class="nam">a_list</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1779" href="#t1779">1779</a></span><span class="t">            <span class="key">elif</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">)</span> <span class="key">and</span> <span class="op">(</span><span class="nam">data_format</span> <span class="op">==</span> <span class="str">"NHWC"</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1780" href="#t1780">1780</a></span><span class="t">                <span class="key">if</span> <span class="key">not</span> <span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">==</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span> <span class="key">and</span> <span class="nam">padding</span><span class="op">[</span><span class="num">3</span><span class="op">]</span> <span class="op">==</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1781" href="#t1781">1781</a></span><span class="t">                    <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1782" href="#t1782">1782</a></span><span class="t">                        <span class="str">"Non-zero padding(%s) in the batch or channel dimensions "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1783" href="#t1783">1783</a></span><span class="t">                        <span class="str">"is not supported."</span> <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1784" href="#t1784">1784</a></span><span class="t">                    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1785" href="#t1785">1785</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="nam">padding</span><span class="op">[</span><span class="num">1</span><span class="op">:</span><span class="num">3</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1786" href="#t1786">1786</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="nam">ele</span> <span class="key">for</span> <span class="nam">a_list</span> <span class="key">in</span> <span class="nam">padding</span> <span class="key">for</span> <span class="nam">ele</span> <span class="key">in</span> <span class="nam">a_list</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1787" href="#t1787">1787</a></span><span class="t">            <span class="nam">padding</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="num">4</span><span class="op">,</span> <span class="str">'padding'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1788" href="#t1788">1788</a></span><span class="t">            <span class="key">if</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_is_symmetric_padding</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="num">2</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1789" href="#t1789">1789</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span> <span class="nam">padding</span><span class="op">[</span><span class="num">2</span><span class="op">]</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1790" href="#t1790">1790</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1791" href="#t1791">1791</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1792" href="#t1792">1792</a></span><span class="t">            <span class="nam">padding</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="num">2</span><span class="op">,</span> <span class="str">'padding'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1793" href="#t1793">1793</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1794" href="#t1794">1794</a></span><span class="t">        <span class="key">return</span> <span class="nam">padding</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1795" href="#t1795">1795</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1796" href="#t1796">1796</a></span><span class="t">    <span class="nam">padding_algorithm</span> <span class="op">=</span> <span class="str">"EXPLICIT"</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t1797" href="#t1797">1797</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="nam">str</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">1797&#x202F;&#x219B;&#x202F;1798</span><span class="annotate long">line 1797 didn't jump to line 1798, because the condition on line 1797 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1798" href="#t1798">1798</a></span><span class="t">        <span class="nam">padding</span> <span class="op">=</span> <span class="nam">padding</span><span class="op">.</span><span class="nam">upper</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1799" href="#t1799">1799</a></span><span class="t">        <span class="key">if</span> <span class="nam">padding</span> <span class="key">not</span> <span class="key">in</span> <span class="op">[</span><span class="str">"SAME"</span><span class="op">,</span> <span class="str">"VALID"</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1800" href="#t1800">1800</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1801" href="#t1801">1801</a></span><span class="t">                <span class="str">"Unknown padding: '%s'. It can only be 'SAME' or 'VALID'."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1802" href="#t1802">1802</a></span><span class="t">                <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1803" href="#t1803">1803</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1804" href="#t1804">1804</a></span><span class="t">        <span class="key">if</span> <span class="nam">padding</span> <span class="op">==</span> <span class="str">"VALID"</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1805" href="#t1805">1805</a></span><span class="t">            <span class="nam">padding_algorithm</span> <span class="op">=</span> <span class="str">"VALID"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1806" href="#t1806">1806</a></span><span class="t">            <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1807" href="#t1807">1807</a></span><span class="t">        <span class="key">elif</span> <span class="nam">padding</span> <span class="op">==</span> <span class="str">"SAME"</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1808" href="#t1808">1808</a></span><span class="t">            <span class="nam">padding_algorithm</span> <span class="op">=</span> <span class="str">"SAME"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1809" href="#t1809">1809</a></span><span class="t">            <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1810" href="#t1810">1810</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1811" href="#t1811">1811</a></span><span class="t">    <span class="nam">padding</span> <span class="op">=</span> <span class="nam">_update_padding</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="nam">data_format</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1812" href="#t1812">1812</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1813" href="#t1813">1813</a></span><span class="t">    <span class="nam">filter_shape</span> <span class="op">=</span> <span class="op">[</span><span class="nam">num_filters</span><span class="op">,</span> <span class="nam">int</span><span class="op">(</span><span class="nam">num_filter_channels</span><span class="op">)</span><span class="op">]</span> <span class="op">+</span> <span class="nam">filter_size</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1814" href="#t1814">1814</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1815" href="#t1815">1815</a></span><span class="t">    <span class="key">def</span> <span class="nam">_get_default_param_initializer</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1816" href="#t1816">1816</a></span><span class="t">        <span class="nam">filter_elem_num</span> <span class="op">=</span> <span class="nam">filter_size</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">*</span> <span class="nam">filter_size</span><span class="op">[</span><span class="num">1</span><span class="op">]</span> <span class="op">*</span> <span class="nam">num_channels</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t1817" href="#t1817">1817</a></span><span class="t">        <span class="key">if</span> <span class="nam">filter_elem_num</span> <span class="op">&lt;=</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">1817&#x202F;&#x219B;&#x202F;1818</span><span class="annotate long">line 1817 didn't jump to line 1818, because the condition on line 1817 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1818" href="#t1818">1818</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1819" href="#t1819">1819</a></span><span class="t">                <span class="str">"Invalid filter number, excepted number is larger than 0, but"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1820" href="#t1820">1820</a></span><span class="t">                <span class="str">" received {}, please check the input shape and "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1821" href="#t1821">1821</a></span><span class="t">                <span class="str">"filter size."</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">filter_elem_num</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1822" href="#t1822">1822</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1823" href="#t1823">1823</a></span><span class="t">        <span class="nam">std</span> <span class="op">=</span> <span class="op">(</span><span class="num">2.0</span> <span class="op">/</span> <span class="nam">filter_elem_num</span><span class="op">)</span> <span class="op">**</span> <span class="num">0.5</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1824" href="#t1824">1824</a></span><span class="t">        <span class="key">return</span> <span class="nam">Normal</span><span class="op">(</span><span class="num">0.0</span><span class="op">,</span> <span class="nam">std</span><span class="op">,</span> <span class="num">0</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1825" href="#t1825">1825</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1826" href="#t1826">1826</a></span><span class="t">    <span class="nam">filter_param</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1827" href="#t1827">1827</a></span><span class="t">        <span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">param_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1828" href="#t1828">1828</a></span><span class="t">        <span class="nam">shape</span><span class="op">=</span><span class="nam">filter_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1829" href="#t1829">1829</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1830" href="#t1830">1830</a></span><span class="t">        <span class="nam">default_initializer</span><span class="op">=</span><span class="nam">_get_default_param_initializer</span><span class="op">(</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1831" href="#t1831">1831</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1832" href="#t1832">1832</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1833" href="#t1833">1833</a></span><span class="t">    <span class="nam">pre_bias</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1834" href="#t1834">1834</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1835" href="#t1835">1835</a></span><span class="t">    <span class="key">if</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1836" href="#t1836">1836</a></span><span class="t">        <span class="nam">core</span><span class="op">.</span><span class="nam">is_compiled_with_cuda</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1837" href="#t1837">1837</a></span><span class="t">        <span class="key">and</span> <span class="nam">paddle</span><span class="op">.</span><span class="nam">fluid</span><span class="op">.</span><span class="nam">get_flags</span><span class="op">(</span><span class="str">"FLAGS_conv2d_disable_cudnn"</span><span class="op">)</span><span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1838" href="#t1838">1838</a></span><span class="t">            <span class="str">"FLAGS_conv2d_disable_cudnn"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1839" href="#t1839">1839</a></span><span class="t">        <span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1840" href="#t1840">1840</a></span><span class="t">    <span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1841" href="#t1841">1841</a></span><span class="t">        <span class="nam">use_cudnn</span> <span class="op">=</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1842" href="#t1842">1842</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1843" href="#t1843">1843</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1844" href="#t1844">1844</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="nam">l_type</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1845" href="#t1845">1845</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1846" href="#t1846">1846</a></span><span class="t">            <span class="str">'Input'</span><span class="op">:</span> <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1847" href="#t1847">1847</a></span><span class="t">            <span class="str">'Filter'</span><span class="op">:</span> <span class="nam">filter_param</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1848" href="#t1848">1848</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1849" href="#t1849">1849</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Output"</span><span class="op">:</span> <span class="nam">pre_bias</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1850" href="#t1850">1850</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1851" href="#t1851">1851</a></span><span class="t">            <span class="str">'strides'</span><span class="op">:</span> <span class="nam">stride</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1852" href="#t1852">1852</a></span><span class="t">            <span class="str">'paddings'</span><span class="op">:</span> <span class="nam">padding</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1853" href="#t1853">1853</a></span><span class="t">            <span class="str">'dilations'</span><span class="op">:</span> <span class="nam">dilation</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1854" href="#t1854">1854</a></span><span class="t">            <span class="str">'groups'</span><span class="op">:</span> <span class="nam">groups</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1855" href="#t1855">1855</a></span><span class="t">            <span class="str">'use_cudnn'</span><span class="op">:</span> <span class="nam">use_cudnn</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1856" href="#t1856">1856</a></span><span class="t">            <span class="str">'use_mkldnn'</span><span class="op">:</span> <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1857" href="#t1857">1857</a></span><span class="t">            <span class="str">'fuse_relu_before_depthwise_conv'</span><span class="op">:</span> <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1858" href="#t1858">1858</a></span><span class="t">            <span class="str">"padding_algorithm"</span><span class="op">:</span> <span class="nam">padding_algorithm</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1859" href="#t1859">1859</a></span><span class="t">            <span class="str">"data_format"</span><span class="op">:</span> <span class="nam">data_format</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1860" href="#t1860">1860</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1861" href="#t1861">1861</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1862" href="#t1862">1862</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1863" href="#t1863">1863</a></span><span class="t">    <span class="key">if</span> <span class="nam">data_format</span> <span class="op">==</span> <span class="str">'NCHW'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1864" href="#t1864">1864</a></span><span class="t">        <span class="nam">pre_act</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_bias_op</span><span class="op">(</span><span class="nam">pre_bias</span><span class="op">,</span> <span class="nam">dim_start</span><span class="op">=</span><span class="num">1</span><span class="op">,</span> <span class="nam">dim_end</span><span class="op">=</span><span class="num">2</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1865" href="#t1865">1865</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1866" href="#t1866">1866</a></span><span class="t">        <span class="nam">pre_act</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_bias_op</span><span class="op">(</span><span class="nam">pre_bias</span><span class="op">,</span> <span class="nam">dim_start</span><span class="op">=</span><span class="num">3</span><span class="op">,</span> <span class="nam">dim_end</span><span class="op">=</span><span class="num">4</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1867" href="#t1867">1867</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1868" href="#t1868">1868</a></span><span class="t">    <span class="key">return</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_activation</span><span class="op">(</span><span class="nam">pre_act</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1869" href="#t1869">1869</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1870" href="#t1870">1870</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1871" href="#t1871">1871</a></span><span class="t"><span class="key">def</span> <span class="nam">conv3d</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1872" href="#t1872">1872</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1873" href="#t1873">1873</a></span><span class="t">    <span class="nam">num_filters</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1874" href="#t1874">1874</a></span><span class="t">    <span class="nam">filter_size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1875" href="#t1875">1875</a></span><span class="t">    <span class="nam">stride</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1876" href="#t1876">1876</a></span><span class="t">    <span class="nam">padding</span><span class="op">=</span><span class="num">0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1877" href="#t1877">1877</a></span><span class="t">    <span class="nam">dilation</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1878" href="#t1878">1878</a></span><span class="t">    <span class="nam">groups</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1879" href="#t1879">1879</a></span><span class="t">    <span class="nam">param_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1880" href="#t1880">1880</a></span><span class="t">    <span class="nam">bias_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1881" href="#t1881">1881</a></span><span class="t">    <span class="nam">use_cudnn</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1882" href="#t1882">1882</a></span><span class="t">    <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1883" href="#t1883">1883</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1884" href="#t1884">1884</a></span><span class="t">    <span class="nam">data_format</span><span class="op">=</span><span class="str">"NCDHW"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1885" href="#t1885">1885</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1886" href="#t1886">1886</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1887" href="#t1887">1887</a></span><span class="t"><span class="str">    :api_attr: Static Graph</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1888" href="#t1888">1888</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1889" href="#t1889">1889</a></span><span class="t"><span class="str">    The convolution3D layer calculates the output based on the input, filter</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1890" href="#t1890">1890</a></span><span class="t"><span class="str">    and strides, paddings, dilations, groups parameters. Input(Input) and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1891" href="#t1891">1891</a></span><span class="t"><span class="str">    Output(Output) are in NCDHW or NDHWC format. Where N is batch size C is the number of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1892" href="#t1892">1892</a></span><span class="t"><span class="str">    channels, D is the depth of the feature, H is the height of the feature,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1893" href="#t1893">1893</a></span><span class="t"><span class="str">    and W is the width of the feature. Convlution3D is similar with Convlution2D</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1894" href="#t1894">1894</a></span><span class="t"><span class="str">    but adds one dimension(depth). If bias attribution and activation type are</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1895" href="#t1895">1895</a></span><span class="t"><span class="str">    provided, bias is added to the output of the convolution, and the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1896" href="#t1896">1896</a></span><span class="t"><span class="str">    corresponding activation function is applied to the final result.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1897" href="#t1897">1897</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1898" href="#t1898">1898</a></span><span class="t"><span class="str">    For each input :math:`X`, the equation is:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1899" href="#t1899">1899</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1900" href="#t1900">1900</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1901" href="#t1901">1901</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1902" href="#t1902">1902</a></span><span class="t"><span class="str">        Out = \sigma (W \\ast X + b)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1903" href="#t1903">1903</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1904" href="#t1904">1904</a></span><span class="t"><span class="str">    In the above equation:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1905" href="#t1905">1905</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1906" href="#t1906">1906</a></span><span class="t"><span class="str">    * :math:`X`: Input value, a tensor with NCDHW or NDHWC format.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1907" href="#t1907">1907</a></span><span class="t"><span class="str">    * :math:`W`: Filter value, a tensor with MCDHW format.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1908" href="#t1908">1908</a></span><span class="t"><span class="str">    * :math:`\\ast`: Convolution operation.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1909" href="#t1909">1909</a></span><span class="t"><span class="str">    * :math:`b`: Bias value, a 2-D tensor with shape [M, 1].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1910" href="#t1910">1910</a></span><span class="t"><span class="str">    * :math:`\\sigma`: Activation function.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1911" href="#t1911">1911</a></span><span class="t"><span class="str">    * :math:`Out`: Output value, the shape of :math:`Out` and :math:`X` may be different.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1912" href="#t1912">1912</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1913" href="#t1913">1913</a></span><span class="t"><span class="str">    Example:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1914" href="#t1914">1914</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1915" href="#t1915">1915</a></span><span class="t"><span class="str">        - Input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1916" href="#t1916">1916</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1917" href="#t1917">1917</a></span><span class="t"><span class="str">          Input shape: :math:`(N, C_{in}, D_{in}, H_{in}, W_{in})`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1918" href="#t1918">1918</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1919" href="#t1919">1919</a></span><span class="t"><span class="str">          Filter shape: :math:`(C_{out}, C_{in}, D_f, H_f, W_f)`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1920" href="#t1920">1920</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1921" href="#t1921">1921</a></span><span class="t"><span class="str">        - Output:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1922" href="#t1922">1922</a></span><span class="t"><span class="str">          Output shape: :math:`(N, C_{out}, D_{out}, H_{out}, W_{out})`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1923" href="#t1923">1923</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1924" href="#t1924">1924</a></span><span class="t"><span class="str">        Where</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1925" href="#t1925">1925</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1926" href="#t1926">1926</a></span><span class="t"><span class="str">        .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1927" href="#t1927">1927</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1928" href="#t1928">1928</a></span><span class="t"><span class="str">            D_{out}&amp;= \\frac{(D_{in} + 2 * paddings[0] - (dilations[0] * (D_f - 1) + 1))}{strides[0]} + 1 \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1929" href="#t1929">1929</a></span><span class="t"><span class="str">            H_{out}&amp;= \\frac{(H_{in} + 2 * paddings[1] - (dilations[1] * (H_f - 1) + 1))}{strides[1]} + 1 \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1930" href="#t1930">1930</a></span><span class="t"><span class="str">            W_{out}&amp;= \\frac{(W_{in} + 2 * paddings[2] - (dilations[2] * (W_f - 1) + 1))}{strides[2]} + 1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1931" href="#t1931">1931</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1932" href="#t1932">1932</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1933" href="#t1933">1933</a></span><span class="t"><span class="str">        input (Tensor): The input is 5-D Tensor with shape [N, C, D, H, W], the data</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1934" href="#t1934">1934</a></span><span class="t"><span class="str">            type of input is float16 or float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1935" href="#t1935">1935</a></span><span class="t"><span class="str">        num_filters(int): The number of filter. It is as same as the output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1936" href="#t1936">1936</a></span><span class="t"><span class="str">            image channel.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1937" href="#t1937">1937</a></span><span class="t"><span class="str">        filter_size (int|tuple): The filter size. If filter_size is a tuple,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1938" href="#t1938">1938</a></span><span class="t"><span class="str">            it must contain three integers, (filter_size_depth, filter_size_height,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1939" href="#t1939">1939</a></span><span class="t"><span class="str">            filter_size_width). Otherwise, filter_size_depth = filter_size_height = \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1940" href="#t1940">1940</a></span><span class="t"><span class="str">            filter_size_width = filter_size.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1941" href="#t1941">1941</a></span><span class="t"><span class="str">        stride (int|tuple): The stride size. It means the stride in convolution. If stride is a</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1942" href="#t1942">1942</a></span><span class="t"><span class="str">            tuple, it must contain three integers, (stride_depth, stride_height, stride_width).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1943" href="#t1943">1943</a></span><span class="t"><span class="str">            Otherwise, stride_depth = stride_height = stride_width = stride. Default: stride = 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1944" href="#t1944">1944</a></span><span class="t"><span class="str">        padding (string|int|list|tuple): The padding size. It means the number of zero-paddings</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1945" href="#t1945">1945</a></span><span class="t"><span class="str">            on both sides for each dimension. If `padding` is a string, either 'VALID' or</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1946" href="#t1946">1946</a></span><span class="t"><span class="str">            'SAME' which is the padding algorithm. If padding size is a tuple or list,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1947" href="#t1947">1947</a></span><span class="t"><span class="str">            it could be in three forms: `[pad_depth, pad_height, pad_width]` or</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1948" href="#t1948">1948</a></span><span class="t"><span class="str">            `[pad_depth_front, pad_depth_back, pad_height_top, pad_height_bottom, pad_width_left, pad_width_right]`,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1949" href="#t1949">1949</a></span><span class="t"><span class="str">            and when `data_format` is `"NCDHW"`, `pool_padding` can be in the form</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1950" href="#t1950">1950</a></span><span class="t"><span class="str">            `[[0,0], [0,0], [pad_depth_front, pad_depth_back], [pad_height_top, pad_height_bottom], [pad_width_left, pad_width_right]]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1951" href="#t1951">1951</a></span><span class="t"><span class="str">            when `data_format` is `"NDHWC"`, `pool_padding` can be in the form</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1952" href="#t1952">1952</a></span><span class="t"><span class="str">            `[[0,0], [pad_depth_front, pad_depth_back], [pad_height_top, pad_height_bottom], [pad_width_left, pad_width_right], [0,0]]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1953" href="#t1953">1953</a></span><span class="t"><span class="str">            Default: padding = 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1954" href="#t1954">1954</a></span><span class="t"><span class="str">        dilation (int|tuple): The dilation size. It means the spacing between the kernel points.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1955" href="#t1955">1955</a></span><span class="t"><span class="str">            If dilation is a tuple, it must contain three integers, (dilation_depth, dilation_height,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1956" href="#t1956">1956</a></span><span class="t"><span class="str">            dilation_width). Otherwise, dilation_depth = dilation_height = dilation_width = dilation.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1957" href="#t1957">1957</a></span><span class="t"><span class="str">            Default: dilation = 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1958" href="#t1958">1958</a></span><span class="t"><span class="str">        groups (int): The groups number of the Conv3d Layer. According to grouped</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1959" href="#t1959">1959</a></span><span class="t"><span class="str">            convolution in Alex Krizhevsky's Deep CNN paper: when group=2,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1960" href="#t1960">1960</a></span><span class="t"><span class="str">            the first half of the filters is only connected to the first half</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1961" href="#t1961">1961</a></span><span class="t"><span class="str">            of the input channels, while the second half of the filters is only</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1962" href="#t1962">1962</a></span><span class="t"><span class="str">            connected to the second half of the input channels. Default: groups=1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1963" href="#t1963">1963</a></span><span class="t"><span class="str">        param_attr (ParamAttr|None): The parameter attribute for learnable parameters/weights</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1964" href="#t1964">1964</a></span><span class="t"><span class="str">            of conv3d. If it is set to None or one attribute of ParamAttr, conv3d</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1965" href="#t1965">1965</a></span><span class="t"><span class="str">            will create ParamAttr as param_attr. If it is set to None, the parameter</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1966" href="#t1966">1966</a></span><span class="t"><span class="str">            is initialized with :math:`Normal(0.0, std)`, and the :math:`std` is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1967" href="#t1967">1967</a></span><span class="t"><span class="str">            :math:`(\\frac{2.0 }{filter\_elem\_num})^{0.5}`. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1968" href="#t1968">1968</a></span><span class="t"><span class="str">        bias_attr (ParamAttr|bool|None): The parameter attribute for the bias of conv3d.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1969" href="#t1969">1969</a></span><span class="t"><span class="str">            If it is set to False, no bias will be added to the output units.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1970" href="#t1970">1970</a></span><span class="t"><span class="str">            If it is set to None or one attribute of ParamAttr, conv3d</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1971" href="#t1971">1971</a></span><span class="t"><span class="str">            will create ParamAttr as bias_attr. If the Initializer of the bias_attr</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1972" href="#t1972">1972</a></span><span class="t"><span class="str">            is not set, the bias is initialized zero. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1973" href="#t1973">1973</a></span><span class="t"><span class="str">        use_cudnn (bool): Use cudnn kernel or not, it is valid only when the cudnn</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1974" href="#t1974">1974</a></span><span class="t"><span class="str">            library is installed. Default: True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1975" href="#t1975">1975</a></span><span class="t"><span class="str">        act (str): Activation type, if it is set to None, activation is not appended.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1976" href="#t1976">1976</a></span><span class="t"><span class="str">            Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1977" href="#t1977">1977</a></span><span class="t"><span class="str">        name(str|None): For detailed information, please refer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1978" href="#t1978">1978</a></span><span class="t"><span class="str">           to :ref:`api_guide_Name`. Usually name is no need to set and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1979" href="#t1979">1979</a></span><span class="t"><span class="str">           None by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1980" href="#t1980">1980</a></span><span class="t"><span class="str">        data_format (str, optional): Specify the data format of the input, and the data format of the output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1981" href="#t1981">1981</a></span><span class="t"><span class="str">            will be consistent with that of the input. An optional string from: `"NCHW"`, `"NHWC"`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1982" href="#t1982">1982</a></span><span class="t"><span class="str">            The default is `"NCHW"`. When it is `"NCHW"`, the data is stored in the order of:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1983" href="#t1983">1983</a></span><span class="t"><span class="str">            `[batch_size, input_channels, input_height, input_width]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1984" href="#t1984">1984</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1985" href="#t1985">1985</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1986" href="#t1986">1986</a></span><span class="t"><span class="str">        A Variable holding Tensor representing the conv3d, whose data type is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1987" href="#t1987">1987</a></span><span class="t"><span class="str">        the same with input. If act is None, the tensor variable storing the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1988" href="#t1988">1988</a></span><span class="t"><span class="str">        convolution result, and if act is not None, the tensor variable storing</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1989" href="#t1989">1989</a></span><span class="t"><span class="str">        convolution and non-linearity activation result.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1990" href="#t1990">1990</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1991" href="#t1991">1991</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1992" href="#t1992">1992</a></span><span class="t"><span class="str">        ValueError: If the type of `use_cudnn` is not bool.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1993" href="#t1993">1993</a></span><span class="t"><span class="str">        ValueError: If `data_format` is not "NCDHW" or "NDHWC".</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1994" href="#t1994">1994</a></span><span class="t"><span class="str">        ValueError: If the channel dimmention of the input is less than or equal to zero.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1995" href="#t1995">1995</a></span><span class="t"><span class="str">        ValueError: If `padding` is a string, but not "SAME" or "VALID".</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1996" href="#t1996">1996</a></span><span class="t"><span class="str">        ValueError: If `padding` is a tuple, but the element corresponding to the input's batch size is not 0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1997" href="#t1997">1997</a></span><span class="t"><span class="str">            or the element corresponding to the input's channel is not 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1998" href="#t1998">1998</a></span><span class="t"><span class="str">        ShapeError: If the input is not 5-D Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1999" href="#t1999">1999</a></span><span class="t"><span class="str">        ShapeError: If the input's dimension size and filter's dimension size not equal.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2000" href="#t2000">2000</a></span><span class="t"><span class="str">        ShapeError: If the dimension size of input minus the size of `stride` is not 2.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2001" href="#t2001">2001</a></span><span class="t"><span class="str">        ShapeError: If the number of input channels is not equal to filter's channels * groups.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2002" href="#t2002">2002</a></span><span class="t"><span class="str">        ShapeError: If the number of output channels is not be divided by groups.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2003" href="#t2003">2003</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2004" href="#t2004">2004</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2005" href="#t2005">2005</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2006" href="#t2006">2006</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2007" href="#t2007">2007</a></span><span class="t"><span class="str">          import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2008" href="#t2008">2008</a></span><span class="t"><span class="str">          import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2009" href="#t2009">2009</a></span><span class="t"><span class="str">          </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2010" href="#t2010">2010</a></span><span class="t"><span class="str">          paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2011" href="#t2011">2011</a></span><span class="t"><span class="str">          data = paddle.static.data(name='data', shape=[None, 3, 12, 32, 32], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2012" href="#t2012">2012</a></span><span class="t"><span class="str">          param_attr = paddle.framework.ParamAttr(name='conv3d.weight', initializer=paddle.nn.initializer.XavierNormal(), learning_rate=0.001)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2013" href="#t2013">2013</a></span><span class="t"><span class="str">          res = paddle.static.nn.conv3d(input=data, num_filters=2, filter_size=3, act="relu", param_attr=param_attr)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2014" href="#t2014">2014</a></span><span class="t"><span class="str">          place = paddle.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2015" href="#t2015">2015</a></span><span class="t"><span class="str">          exe = paddle.static.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2016" href="#t2016">2016</a></span><span class="t"><span class="str">          exe.run(paddle.static.default_startup_program())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2017" href="#t2017">2017</a></span><span class="t"><span class="str">          x = np.random.rand(1, 3, 12, 32, 32).astype("float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2018" href="#t2018">2018</a></span><span class="t"><span class="str">          output = exe.run(feed={"data": x}, fetch_list=[res])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2019" href="#t2019">2019</a></span><span class="t"><span class="str">          print(output)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2020" href="#t2020">2020</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2021" href="#t2021">2021</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2022" href="#t2022">2022</a></span><span class="t">    <span class="nam">l_type</span> <span class="op">=</span> <span class="str">'conv3d'</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2023" href="#t2023">2023</a></span><span class="t">    <span class="key">assert</span> <span class="nam">param_attr</span> <span class="key">is</span> <span class="key">not</span> <span class="key">False</span><span class="op">,</span> <span class="str">"param_attr should not be False here."</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2024" href="#t2024">2024</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="nam">l_type</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2025" href="#t2025">2025</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2026" href="#t2026">2026</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2027" href="#t2027">2027</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">use_cudnn</span><span class="op">,</span> <span class="nam">bool</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2028" href="#t2028">2028</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2029" href="#t2029">2029</a></span><span class="t">            <span class="str">"Attr(use_cudnn) should be True or False. Received "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2030" href="#t2030">2030</a></span><span class="t">            <span class="str">"Attr(use_cudnn): %s. "</span> <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">use_cudnn</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2031" href="#t2031">2031</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2032" href="#t2032">2032</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2033" href="#t2033">2033</a></span><span class="t">    <span class="key">if</span> <span class="nam">data_format</span> <span class="key">not</span> <span class="key">in</span> <span class="op">[</span><span class="str">"NCDHW"</span><span class="op">,</span> <span class="str">"NDHWC"</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2034" href="#t2034">2034</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2035" href="#t2035">2035</a></span><span class="t">            <span class="str">"Attr(data_format) should be 'NCDHW' or 'NDHWC'. Received "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2036" href="#t2036">2036</a></span><span class="t">            <span class="str">"Attr(data_format): %s."</span> <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">data_format</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2037" href="#t2037">2037</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2038" href="#t2038">2038</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2039" href="#t2039">2039</a></span><span class="t">    <span class="nam">channel_last</span> <span class="op">=</span> <span class="nam">data_format</span> <span class="op">==</span> <span class="str">"NDHWC"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2040" href="#t2040">2040</a></span><span class="t">    <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">!=</span> <span class="num">5</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2041" href="#t2041">2041</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2042" href="#t2042">2042</a></span><span class="t">            <span class="str">"Input should be 5D tensor, but received input with the shape of {}"</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2043" href="#t2043">2043</a></span><span class="t">                <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2044" href="#t2044">2044</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2045" href="#t2045">2045</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2046" href="#t2046">2046</a></span><span class="t">    <span class="nam">num_channels</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">4</span><span class="op">]</span> <span class="key">if</span> <span class="nam">channel_last</span> <span class="key">else</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2047" href="#t2047">2047</a></span><span class="t">    <span class="key">if</span> <span class="nam">num_channels</span> <span class="op">&lt;</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2048" href="#t2048">2048</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2049" href="#t2049">2049</a></span><span class="t">            <span class="str">"The channel dimmention of the input(%s) should be defined. "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2050" href="#t2050">2050</a></span><span class="t">            <span class="str">"Received: %s."</span> <span class="op">%</span> <span class="op">(</span><span class="nam">str</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span><span class="op">,</span> <span class="nam">str</span><span class="op">(</span><span class="nam">num_channels</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2051" href="#t2051">2051</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2052" href="#t2052">2052</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2053" href="#t2053">2053</a></span><span class="t">    <span class="key">if</span> <span class="nam">groups</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2054" href="#t2054">2054</a></span><span class="t">        <span class="nam">num_filter_channels</span> <span class="op">=</span> <span class="nam">num_channels</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2055" href="#t2055">2055</a></span><span class="t">    <span class="key">elif</span> <span class="nam">groups</span> <span class="op">&lt;=</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2056" href="#t2056">2056</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2057" href="#t2057">2057</a></span><span class="t">            <span class="str">"the groups of conv3d should be greater than 0. Received groups: {}"</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2058" href="#t2058">2058</a></span><span class="t">                <span class="nam">groups</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2059" href="#t2059">2059</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2060" href="#t2060">2060</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2061" href="#t2061">2061</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2062" href="#t2062">2062</a></span><span class="t">        <span class="key">if</span> <span class="nam">num_channels</span> <span class="op">%</span> <span class="nam">groups</span> <span class="op">!=</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2063" href="#t2063">2063</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2064" href="#t2064">2064</a></span><span class="t">                <span class="str">"The number of input channels must be divisible by Attr(groups). "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2065" href="#t2065">2065</a></span><span class="t">                <span class="str">"Received: number of channels(%s), groups(%s)."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2066" href="#t2066">2066</a></span><span class="t">                <span class="op">%</span> <span class="op">(</span><span class="nam">str</span><span class="op">(</span><span class="nam">num_channels</span><span class="op">)</span><span class="op">,</span> <span class="nam">str</span><span class="op">(</span><span class="nam">groups</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2067" href="#t2067">2067</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2068" href="#t2068">2068</a></span><span class="t">        <span class="nam">num_filter_channels</span> <span class="op">=</span> <span class="nam">num_channels</span> <span class="op">//</span> <span class="nam">groups</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2069" href="#t2069">2069</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2070" href="#t2070">2070</a></span><span class="t">    <span class="nam">filter_size</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">filter_size</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="str">'filter_size'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2071" href="#t2071">2071</a></span><span class="t">    <span class="nam">stride</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">stride</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="str">'stride'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2072" href="#t2072">2072</a></span><span class="t">    <span class="nam">dilation</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">dilation</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="str">'dilation'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2073" href="#t2073">2073</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2074" href="#t2074">2074</a></span><span class="t">    <span class="key">def</span> <span class="nam">_update_padding</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="nam">data_format</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2075" href="#t2075">2075</a></span><span class="t">        <span class="key">def</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">ele</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2076" href="#t2076">2076</a></span><span class="t">            <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">ele</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span> <span class="key">or</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">ele</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2077" href="#t2077">2077</a></span><span class="t">                <span class="key">return</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2078" href="#t2078">2078</a></span><span class="t">            <span class="key">return</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2079" href="#t2079">2079</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2080" href="#t2080">2080</a></span><span class="t">        <span class="key">if</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span> <span class="key">and</span> <span class="nam">len</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span> <span class="op">==</span> <span class="num">5</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2081" href="#t2081">2081</a></span><span class="t">            <span class="key">if</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">)</span> <span class="key">and</span> <span class="op">(</span><span class="nam">data_format</span> <span class="op">==</span> <span class="str">"NCDHW"</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2082" href="#t2082">2082</a></span><span class="t">                <span class="key">if</span> <span class="key">not</span> <span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">==</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span> <span class="key">and</span> <span class="nam">padding</span><span class="op">[</span><span class="num">1</span><span class="op">]</span> <span class="op">==</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2083" href="#t2083">2083</a></span><span class="t">                    <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2084" href="#t2084">2084</a></span><span class="t">                        <span class="str">"Non-zero padding(%s) in the batch or channel dimensions "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2085" href="#t2085">2085</a></span><span class="t">                        <span class="str">"is not supported."</span> <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2086" href="#t2086">2086</a></span><span class="t">                    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2087" href="#t2087">2087</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="nam">padding</span><span class="op">[</span><span class="num">2</span><span class="op">:</span><span class="num">5</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2088" href="#t2088">2088</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="nam">ele</span> <span class="key">for</span> <span class="nam">a_list</span> <span class="key">in</span> <span class="nam">padding</span> <span class="key">for</span> <span class="nam">ele</span> <span class="key">in</span> <span class="nam">a_list</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2089" href="#t2089">2089</a></span><span class="t">            <span class="key">elif</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">)</span> <span class="key">and</span> <span class="op">(</span><span class="nam">data_format</span> <span class="op">==</span> <span class="str">"NDHWC"</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2090" href="#t2090">2090</a></span><span class="t">                <span class="key">if</span> <span class="key">not</span> <span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">==</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span> <span class="key">and</span> <span class="nam">padding</span><span class="op">[</span><span class="num">4</span><span class="op">]</span> <span class="op">==</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2091" href="#t2091">2091</a></span><span class="t">                    <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2092" href="#t2092">2092</a></span><span class="t">                        <span class="str">"Non-zero padding(%s) in the batch or channel dimensions "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2093" href="#t2093">2093</a></span><span class="t">                        <span class="str">"is not supported."</span> <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2094" href="#t2094">2094</a></span><span class="t">                    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2095" href="#t2095">2095</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="nam">padding</span><span class="op">[</span><span class="num">1</span><span class="op">:</span><span class="num">4</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2096" href="#t2096">2096</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="nam">ele</span> <span class="key">for</span> <span class="nam">a_list</span> <span class="key">in</span> <span class="nam">padding</span> <span class="key">for</span> <span class="nam">ele</span> <span class="key">in</span> <span class="nam">a_list</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2097" href="#t2097">2097</a></span><span class="t">            <span class="nam">padding</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="num">6</span><span class="op">,</span> <span class="str">'padding'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2098" href="#t2098">2098</a></span><span class="t">            <span class="key">if</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_is_symmetric_padding</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="num">3</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2099" href="#t2099">2099</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span> <span class="nam">padding</span><span class="op">[</span><span class="num">2</span><span class="op">]</span><span class="op">,</span> <span class="nam">padding</span><span class="op">[</span><span class="num">4</span><span class="op">]</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2100" href="#t2100">2100</a></span><span class="t">        <span class="key">elif</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span> <span class="key">and</span> <span class="nam">len</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span> <span class="op">==</span> <span class="num">6</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2101" href="#t2101">2101</a></span><span class="t">            <span class="nam">padding</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="num">6</span><span class="op">,</span> <span class="str">'padding'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2102" href="#t2102">2102</a></span><span class="t">            <span class="key">if</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_is_symmetric_padding</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="num">3</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2103" href="#t2103">2103</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span> <span class="nam">padding</span><span class="op">[</span><span class="num">2</span><span class="op">]</span><span class="op">,</span> <span class="nam">padding</span><span class="op">[</span><span class="num">4</span><span class="op">]</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2104" href="#t2104">2104</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2105" href="#t2105">2105</a></span><span class="t">            <span class="nam">padding</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="str">'padding'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2106" href="#t2106">2106</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2107" href="#t2107">2107</a></span><span class="t">        <span class="key">return</span> <span class="nam">padding</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2108" href="#t2108">2108</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2109" href="#t2109">2109</a></span><span class="t">    <span class="nam">padding_algorithm</span> <span class="op">=</span> <span class="str">"EXPLICIT"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2110" href="#t2110">2110</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="nam">str</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2111" href="#t2111">2111</a></span><span class="t">        <span class="nam">padding</span> <span class="op">=</span> <span class="nam">padding</span><span class="op">.</span><span class="nam">upper</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2112" href="#t2112">2112</a></span><span class="t">        <span class="key">if</span> <span class="nam">padding</span> <span class="key">not</span> <span class="key">in</span> <span class="op">[</span><span class="str">"SAME"</span><span class="op">,</span> <span class="str">"VALID"</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2113" href="#t2113">2113</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2114" href="#t2114">2114</a></span><span class="t">                <span class="str">"Unknown padding: '%s'. It can only be 'SAME' or 'VALID'."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2115" href="#t2115">2115</a></span><span class="t">                <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2116" href="#t2116">2116</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2117" href="#t2117">2117</a></span><span class="t">        <span class="key">if</span> <span class="nam">padding</span> <span class="op">==</span> <span class="str">"VALID"</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2118" href="#t2118">2118</a></span><span class="t">            <span class="nam">padding_algorithm</span> <span class="op">=</span> <span class="str">"VALID"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2119" href="#t2119">2119</a></span><span class="t">            <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2120" href="#t2120">2120</a></span><span class="t">        <span class="key">elif</span> <span class="nam">padding</span> <span class="op">==</span> <span class="str">"SAME"</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2121" href="#t2121">2121</a></span><span class="t">            <span class="nam">padding_algorithm</span> <span class="op">=</span> <span class="str">"SAME"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2122" href="#t2122">2122</a></span><span class="t">            <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2123" href="#t2123">2123</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2124" href="#t2124">2124</a></span><span class="t">    <span class="nam">padding</span> <span class="op">=</span> <span class="nam">_update_padding</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="nam">data_format</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2125" href="#t2125">2125</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2126" href="#t2126">2126</a></span><span class="t">    <span class="nam">input_shape</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2127" href="#t2127">2127</a></span><span class="t">    <span class="nam">filter_shape</span> <span class="op">=</span> <span class="op">[</span><span class="nam">num_filters</span><span class="op">,</span> <span class="nam">num_filter_channels</span><span class="op">]</span> <span class="op">+</span> <span class="nam">filter_size</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2128" href="#t2128">2128</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2129" href="#t2129">2129</a></span><span class="t">    <span class="key">def</span> <span class="nam">_get_default_param_initializer</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2130" href="#t2130">2130</a></span><span class="t">        <span class="nam">filter_elem_num</span> <span class="op">=</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2131" href="#t2131">2131</a></span><span class="t">            <span class="nam">filter_size</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">*</span> <span class="nam">filter_size</span><span class="op">[</span><span class="num">1</span><span class="op">]</span> <span class="op">*</span> <span class="nam">filter_size</span><span class="op">[</span><span class="num">2</span><span class="op">]</span> <span class="op">*</span> <span class="nam">num_channels</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2132" href="#t2132">2132</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2133" href="#t2133">2133</a></span><span class="t">        <span class="key">if</span> <span class="nam">filter_elem_num</span> <span class="op">&lt;=</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2134" href="#t2134">2134</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2135" href="#t2135">2135</a></span><span class="t">                <span class="str">"Invalid filter number, excepted number is larger than 0, but"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2136" href="#t2136">2136</a></span><span class="t">                <span class="str">" received {}, please check the input shape and "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2137" href="#t2137">2137</a></span><span class="t">                <span class="str">"filter size."</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">filter_elem_num</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2138" href="#t2138">2138</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2139" href="#t2139">2139</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2140" href="#t2140">2140</a></span><span class="t">        <span class="nam">std</span> <span class="op">=</span> <span class="op">(</span><span class="num">2.0</span> <span class="op">/</span> <span class="nam">filter_elem_num</span><span class="op">)</span> <span class="op">**</span> <span class="num">0.5</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2141" href="#t2141">2141</a></span><span class="t">        <span class="key">return</span> <span class="nam">Normal</span><span class="op">(</span><span class="num">0.0</span><span class="op">,</span> <span class="nam">std</span><span class="op">,</span> <span class="num">0</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2142" href="#t2142">2142</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2143" href="#t2143">2143</a></span><span class="t">    <span class="nam">filter_param</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2144" href="#t2144">2144</a></span><span class="t">        <span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">param_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2145" href="#t2145">2145</a></span><span class="t">        <span class="nam">shape</span><span class="op">=</span><span class="nam">filter_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2146" href="#t2146">2146</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2147" href="#t2147">2147</a></span><span class="t">        <span class="nam">default_initializer</span><span class="op">=</span><span class="nam">_get_default_param_initializer</span><span class="op">(</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2148" href="#t2148">2148</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2149" href="#t2149">2149</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2150" href="#t2150">2150</a></span><span class="t">    <span class="nam">pre_bias</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2151" href="#t2151">2151</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2152" href="#t2152">2152</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2153" href="#t2153">2153</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="nam">l_type</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2154" href="#t2154">2154</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2155" href="#t2155">2155</a></span><span class="t">            <span class="str">'Input'</span><span class="op">:</span> <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2156" href="#t2156">2156</a></span><span class="t">            <span class="str">'Filter'</span><span class="op">:</span> <span class="nam">filter_param</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2157" href="#t2157">2157</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2158" href="#t2158">2158</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Output"</span><span class="op">:</span> <span class="nam">pre_bias</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2159" href="#t2159">2159</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2160" href="#t2160">2160</a></span><span class="t">            <span class="str">'strides'</span><span class="op">:</span> <span class="nam">stride</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2161" href="#t2161">2161</a></span><span class="t">            <span class="str">'paddings'</span><span class="op">:</span> <span class="nam">padding</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2162" href="#t2162">2162</a></span><span class="t">            <span class="str">'dilations'</span><span class="op">:</span> <span class="nam">dilation</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2163" href="#t2163">2163</a></span><span class="t">            <span class="str">'groups'</span><span class="op">:</span> <span class="nam">groups</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2164" href="#t2164">2164</a></span><span class="t">            <span class="str">'use_cudnn'</span><span class="op">:</span> <span class="nam">use_cudnn</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2165" href="#t2165">2165</a></span><span class="t">            <span class="str">'use_mkldnn'</span><span class="op">:</span> <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2166" href="#t2166">2166</a></span><span class="t">            <span class="str">"padding_algorithm"</span><span class="op">:</span> <span class="nam">padding_algorithm</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2167" href="#t2167">2167</a></span><span class="t">            <span class="str">"data_format"</span><span class="op">:</span> <span class="nam">data_format</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2168" href="#t2168">2168</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2169" href="#t2169">2169</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2170" href="#t2170">2170</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2171" href="#t2171">2171</a></span><span class="t">    <span class="key">if</span> <span class="nam">data_format</span> <span class="op">==</span> <span class="str">'NCDHW'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2172" href="#t2172">2172</a></span><span class="t">        <span class="nam">pre_act</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_bias_op</span><span class="op">(</span><span class="nam">pre_bias</span><span class="op">,</span> <span class="nam">dim_start</span><span class="op">=</span><span class="num">1</span><span class="op">,</span> <span class="nam">dim_end</span><span class="op">=</span><span class="num">2</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2173" href="#t2173">2173</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2174" href="#t2174">2174</a></span><span class="t">        <span class="nam">pre_act</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_bias_op</span><span class="op">(</span><span class="nam">pre_bias</span><span class="op">,</span> <span class="nam">dim_start</span><span class="op">=</span><span class="num">4</span><span class="op">,</span> <span class="nam">dim_end</span><span class="op">=</span><span class="num">5</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2175" href="#t2175">2175</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2176" href="#t2176">2176</a></span><span class="t">    <span class="key">return</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_activation</span><span class="op">(</span><span class="nam">pre_act</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2177" href="#t2177">2177</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2178" href="#t2178">2178</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t2179" href="#t2179">2179</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t2180" href="#t2180">2180</a></span><span class="t"><span class="key">def</span> <span class="nam">pool2d</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2181" href="#t2181">2181</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2182" href="#t2182">2182</a></span><span class="t">    <span class="nam">pool_size</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2183" href="#t2183">2183</a></span><span class="t">    <span class="nam">pool_type</span><span class="op">=</span><span class="str">"max"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2184" href="#t2184">2184</a></span><span class="t">    <span class="nam">pool_stride</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2185" href="#t2185">2185</a></span><span class="t">    <span class="nam">pool_padding</span><span class="op">=</span><span class="num">0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2186" href="#t2186">2186</a></span><span class="t">    <span class="nam">global_pooling</span><span class="op">=</span><span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2187" href="#t2187">2187</a></span><span class="t">    <span class="nam">use_cudnn</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2188" href="#t2188">2188</a></span><span class="t">    <span class="nam">ceil_mode</span><span class="op">=</span><span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2189" href="#t2189">2189</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2190" href="#t2190">2190</a></span><span class="t">    <span class="nam">exclusive</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2191" href="#t2191">2191</a></span><span class="t">    <span class="nam">data_format</span><span class="op">=</span><span class="str">"NCHW"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2192" href="#t2192">2192</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2193" href="#t2193">2193</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2194" href="#t2194">2194</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2195" href="#t2195">2195</a></span><span class="t"><span class="str">    ${comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2196" href="#t2196">2196</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2197" href="#t2197">2197</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2198" href="#t2198">2198</a></span><span class="t"><span class="str">        input (Variable): The input tensor of pooling operator which is a 4-D tensor with</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2199" href="#t2199">2199</a></span><span class="t"><span class="str">                          shape [N, C, H, W]. The format of input tensor is `"NCHW"` or</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2200" href="#t2200">2200</a></span><span class="t"><span class="str">                          `"NHWC"`, where `N` is batch size, `C` is the number of channels,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2201" href="#t2201">2201</a></span><span class="t"><span class="str">                          `H` is the height of the feature, and `W` is the width of the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2202" href="#t2202">2202</a></span><span class="t"><span class="str">                          feature. The data type if float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2203" href="#t2203">2203</a></span><span class="t"><span class="str">        pool_size (int|list|tuple): The pool kernel size. If pool kernel size is a tuple or list,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2204" href="#t2204">2204</a></span><span class="t"><span class="str">            it must contain two integers, (pool_size_Height, pool_size_Width).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2205" href="#t2205">2205</a></span><span class="t"><span class="str">            Otherwise, the pool kernel size will be a square of an int.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2206" href="#t2206">2206</a></span><span class="t"><span class="str">        pool_type: ${pooling_type_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2207" href="#t2207">2207</a></span><span class="t"><span class="str">        pool_stride (int|list|tuple): The pool stride size. If pool stride size is a tuple or list,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2208" href="#t2208">2208</a></span><span class="t"><span class="str">            it must contain two integers, (pool_stride_Height, pool_stride_Width).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2209" href="#t2209">2209</a></span><span class="t"><span class="str">            Otherwise, the pool stride size will be a square of an int.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2210" href="#t2210">2210</a></span><span class="t"><span class="str">        pool_padding (string|int|list|tuple): The pool padding. If `pool_padding` is a string, either 'VALID' or</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2211" href="#t2211">2211</a></span><span class="t"><span class="str">            'SAME' which is the padding algorithm. If pool padding size is a tuple or list,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2212" href="#t2212">2212</a></span><span class="t"><span class="str">            it could be in three forms: `[pad_height, pad_width]` or</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2213" href="#t2213">2213</a></span><span class="t"><span class="str">            `[pad_height_top, pad_height_bottom, pad_width_left, pad_width_right]`, and when `data_format` is `"NCHW"`,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2214" href="#t2214">2214</a></span><span class="t"><span class="str">            `pool_padding` can be in the form `[[0,0], [0,0], [pad_height_top, pad_height_bottom], [pad_width_left, pad_width_right]]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2215" href="#t2215">2215</a></span><span class="t"><span class="str">            when `data_format` is `"NHWC"`, `pool_padding` can be in the form</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2216" href="#t2216">2216</a></span><span class="t"><span class="str">            `[[0,0], [pad_height_top, pad_height_bottom], [pad_width_left, pad_width_right], [0,0]]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2217" href="#t2217">2217</a></span><span class="t"><span class="str">            Otherwise, the pool padding size will be a square of an int.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2218" href="#t2218">2218</a></span><span class="t"><span class="str">        global_pooling (bool): ${global_pooling_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2219" href="#t2219">2219</a></span><span class="t"><span class="str">        use_cudnn (bool): ${use_cudnn_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2220" href="#t2220">2220</a></span><span class="t"><span class="str">        ceil_mode (bool): ${ceil_mode_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2221" href="#t2221">2221</a></span><span class="t"><span class="str">        name(str, optional): For detailed information, please refer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2222" href="#t2222">2222</a></span><span class="t"><span class="str">                             to :ref:`api_guide_Name`. Usually name is no need to set and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2223" href="#t2223">2223</a></span><span class="t"><span class="str">                             None by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2224" href="#t2224">2224</a></span><span class="t"><span class="str">        exclusive (bool): Whether to exclude padding points in average pooling</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2225" href="#t2225">2225</a></span><span class="t"><span class="str">                          mode, default is `true`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2226" href="#t2226">2226</a></span><span class="t"><span class="str">        data_format (string): The data format of the input and output data. An optional string from: `"NCHW"`, `"NHWC"`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2227" href="#t2227">2227</a></span><span class="t"><span class="str">                The default is `"NCHW"`. When it is `"NCHW"`, the data is stored in the order of:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2228" href="#t2228">2228</a></span><span class="t"><span class="str">                `[batch_size, input_channels, input_height, input_width]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2229" href="#t2229">2229</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2230" href="#t2230">2230</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2231" href="#t2231">2231</a></span><span class="t"><span class="str">        Variable: The output tensor of pooling result. The data type is same as input tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2232" href="#t2232">2232</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2233" href="#t2233">2233</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2234" href="#t2234">2234</a></span><span class="t"><span class="str">        ValueError: If `pool_type` is not "max" nor "avg".</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2235" href="#t2235">2235</a></span><span class="t"><span class="str">        ValueError: If `global_pooling` is False and `pool_size` is -1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2236" href="#t2236">2236</a></span><span class="t"><span class="str">        TypeError: If `use_cudnn` is not a bool value.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2237" href="#t2237">2237</a></span><span class="t"><span class="str">        ValueError: If `data_format` is not "NCHW" or "NHWC".</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2238" href="#t2238">2238</a></span><span class="t"><span class="str">        ValueError: If `pool_padding` is a string, but not "SAME" or "VALID".</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2239" href="#t2239">2239</a></span><span class="t"><span class="str">        ValueError: If `pool_padding` is "VALID", but `ceil_mode` is True.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2240" href="#t2240">2240</a></span><span class="t"><span class="str">        ValueError: If `pool_padding` is a list or tuple, but the elements in the batch or channel dimensions are non-zero.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2241" href="#t2241">2241</a></span><span class="t"><span class="str">        ShapeError: If the input is not a 4-D or 5-D Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2242" href="#t2242">2242</a></span><span class="t"><span class="str">        ShapeError: If the dimension of input minus the size of `pool_stride` is not 2.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2243" href="#t2243">2243</a></span><span class="t"><span class="str">        ShapeError: If the size of `pool_size` and `pool_stride` is not equal.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2244" href="#t2244">2244</a></span><span class="t"><span class="str">        ShapeError: If the output's shape calculated is not greater than 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2245" href="#t2245">2245</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2246" href="#t2246">2246</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2247" href="#t2247">2247</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2248" href="#t2248">2248</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2249" href="#t2249">2249</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2250" href="#t2250">2250</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2251" href="#t2251">2251</a></span><span class="t"><span class="str">          import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2252" href="#t2252">2252</a></span><span class="t"><span class="str">          import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2253" href="#t2253">2253</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2254" href="#t2254">2254</a></span><span class="t"><span class="str">          paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2255" href="#t2255">2255</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2256" href="#t2256">2256</a></span><span class="t"><span class="str">          data = fluid.data(name='data', shape=[None, 3, 32, 32], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2257" href="#t2257">2257</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2258" href="#t2258">2258</a></span><span class="t"><span class="str">          # max pool2d</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2259" href="#t2259">2259</a></span><span class="t"><span class="str">          pool2d = fluid.layers.pool2d(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2260" href="#t2260">2260</a></span><span class="t"><span class="str">            input = data,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2261" href="#t2261">2261</a></span><span class="t"><span class="str">            pool_size = 2,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2262" href="#t2262">2262</a></span><span class="t"><span class="str">            pool_type = "max",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2263" href="#t2263">2263</a></span><span class="t"><span class="str">            pool_stride = 1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2264" href="#t2264">2264</a></span><span class="t"><span class="str">            global_pooling=False)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2265" href="#t2265">2265</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2266" href="#t2266">2266</a></span><span class="t"><span class="str">          # average pool2d</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2267" href="#t2267">2267</a></span><span class="t"><span class="str">          pool2d = fluid.layers.pool2d(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2268" href="#t2268">2268</a></span><span class="t"><span class="str">            input = data,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2269" href="#t2269">2269</a></span><span class="t"><span class="str">            pool_size = 2,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2270" href="#t2270">2270</a></span><span class="t"><span class="str">            pool_type = "avg",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2271" href="#t2271">2271</a></span><span class="t"><span class="str">            pool_stride = 1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2272" href="#t2272">2272</a></span><span class="t"><span class="str">            global_pooling=False)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2273" href="#t2273">2273</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2274" href="#t2274">2274</a></span><span class="t"><span class="str">          # global average pool2d</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2275" href="#t2275">2275</a></span><span class="t"><span class="str">          pool2d = fluid.layers.pool2d(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2276" href="#t2276">2276</a></span><span class="t"><span class="str">            input = data,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2277" href="#t2277">2277</a></span><span class="t"><span class="str">            pool_size = 2,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2278" href="#t2278">2278</a></span><span class="t"><span class="str">            pool_type = "avg",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2279" href="#t2279">2279</a></span><span class="t"><span class="str">            pool_stride = 1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2280" href="#t2280">2280</a></span><span class="t"><span class="str">            global_pooling=True)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2281" href="#t2281">2281</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2282" href="#t2282">2282</a></span><span class="t"><span class="str">          # Attr(pool_padding) is a list with 4 elements, Attr(data_format) is "NCHW".</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2283" href="#t2283">2283</a></span><span class="t"><span class="str">          out_1 = fluid.layers.pool2d(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2284" href="#t2284">2284</a></span><span class="t"><span class="str">            input = data,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2285" href="#t2285">2285</a></span><span class="t"><span class="str">            pool_size = 3,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2286" href="#t2286">2286</a></span><span class="t"><span class="str">            pool_type = "avg",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2287" href="#t2287">2287</a></span><span class="t"><span class="str">            pool_stride = 1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2288" href="#t2288">2288</a></span><span class="t"><span class="str">            pool_padding = [1, 2, 1, 0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2289" href="#t2289">2289</a></span><span class="t"><span class="str">            data_format = "NCHW")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2290" href="#t2290">2290</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2291" href="#t2291">2291</a></span><span class="t"><span class="str">          # Attr(pool_padding) is a string, Attr(data_format) is "NCHW".</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2292" href="#t2292">2292</a></span><span class="t"><span class="str">          out_2 = fluid.layers.pool2d(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2293" href="#t2293">2293</a></span><span class="t"><span class="str">            input = data,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2294" href="#t2294">2294</a></span><span class="t"><span class="str">            pool_size = 3,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2295" href="#t2295">2295</a></span><span class="t"><span class="str">            pool_type = "avg",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2296" href="#t2296">2296</a></span><span class="t"><span class="str">            pool_stride = 1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2297" href="#t2297">2297</a></span><span class="t"><span class="str">            pool_padding = "VALID",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2298" href="#t2298">2298</a></span><span class="t"><span class="str">            data_format = "NCHW")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2299" href="#t2299">2299</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2300" href="#t2300">2300</a></span><span class="t">    <span class="key">if</span> <span class="nam">pool_type</span> <span class="key">not</span> <span class="key">in</span> <span class="op">[</span><span class="str">"max"</span><span class="op">,</span> <span class="str">"avg"</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2301" href="#t2301">2301</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2302" href="#t2302">2302</a></span><span class="t">            <span class="str">"Unknown Attr(pool_type): '%s'. It can only be 'max' or 'avg'."</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2303" href="#t2303">2303</a></span><span class="t">            <span class="nam">str</span><span class="op">(</span><span class="nam">pool_type</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2304" href="#t2304">2304</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2305" href="#t2305">2305</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2306" href="#t2306">2306</a></span><span class="t">    <span class="key">if</span> <span class="nam">global_pooling</span> <span class="key">is</span> <span class="key">False</span> <span class="key">and</span> <span class="nam">pool_size</span> <span class="op">==</span> <span class="op">-</span><span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2307" href="#t2307">2307</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2308" href="#t2308">2308</a></span><span class="t">            <span class="str">"When Attr(global_pooling) is False, Attr(pool_size) must be passed "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2309" href="#t2309">2309</a></span><span class="t">            <span class="str">"and be a valid value. Received pool_size: %s."</span> <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">pool_size</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2310" href="#t2310">2310</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2311" href="#t2311">2311</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2312" href="#t2312">2312</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">use_cudnn</span><span class="op">,</span> <span class="nam">bool</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2313" href="#t2313">2313</a></span><span class="t">        <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2314" href="#t2314">2314</a></span><span class="t">            <span class="str">"Attr(use_cudnn) should be True or False. Received "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2315" href="#t2315">2315</a></span><span class="t">            <span class="str">"Attr(use_cudnn): %s."</span> <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">use_cudnn</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2316" href="#t2316">2316</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2317" href="#t2317">2317</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2318" href="#t2318">2318</a></span><span class="t">    <span class="key">if</span> <span class="nam">data_format</span> <span class="key">not</span> <span class="key">in</span> <span class="op">[</span><span class="str">"NCHW"</span><span class="op">,</span> <span class="str">"NHWC"</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2319" href="#t2319">2319</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2320" href="#t2320">2320</a></span><span class="t">            <span class="str">"Attr(data_format) should be 'NCHW' or 'NHWC'. Received "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2321" href="#t2321">2321</a></span><span class="t">            <span class="str">"Attr(data_format): %s."</span> <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">data_format</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2322" href="#t2322">2322</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2323" href="#t2323">2323</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2324" href="#t2324">2324</a></span><span class="t">    <span class="nam">pool_size</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">pool_size</span><span class="op">,</span> <span class="num">2</span><span class="op">,</span> <span class="str">'pool_size'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2325" href="#t2325">2325</a></span><span class="t">    <span class="nam">pool_stride</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">pool_stride</span><span class="op">,</span> <span class="num">2</span><span class="op">,</span> <span class="str">'pool_stride'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2326" href="#t2326">2326</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2327" href="#t2327">2327</a></span><span class="t">    <span class="key">def</span> <span class="nam">update_padding</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="nam">data_format</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2328" href="#t2328">2328</a></span><span class="t">        <span class="key">def</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">ele</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2329" href="#t2329">2329</a></span><span class="t">            <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">ele</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span> <span class="key">or</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">ele</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2330" href="#t2330">2330</a></span><span class="t">                <span class="key">return</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2331" href="#t2331">2331</a></span><span class="t">            <span class="key">return</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2332" href="#t2332">2332</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2333" href="#t2333">2333</a></span><span class="t">        <span class="key">if</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span> <span class="key">and</span> <span class="nam">len</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span> <span class="op">==</span> <span class="num">4</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2334" href="#t2334">2334</a></span><span class="t">            <span class="key">if</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">)</span> <span class="key">and</span> <span class="op">(</span><span class="nam">data_format</span> <span class="op">==</span> <span class="str">"NCHW"</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2335" href="#t2335">2335</a></span><span class="t">                <span class="key">if</span> <span class="key">not</span> <span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">==</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span> <span class="key">and</span> <span class="nam">padding</span><span class="op">[</span><span class="num">1</span><span class="op">]</span> <span class="op">==</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2336" href="#t2336">2336</a></span><span class="t">                    <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2337" href="#t2337">2337</a></span><span class="t">                        <span class="str">"Non-zero pool_padding(%s) in the batch or channel dimensions "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2338" href="#t2338">2338</a></span><span class="t">                        <span class="str">"is not supported."</span> <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2339" href="#t2339">2339</a></span><span class="t">                    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2340" href="#t2340">2340</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="nam">padding</span><span class="op">[</span><span class="num">2</span><span class="op">:</span><span class="num">4</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2341" href="#t2341">2341</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="nam">ele</span> <span class="key">for</span> <span class="nam">a_list</span> <span class="key">in</span> <span class="nam">padding</span> <span class="key">for</span> <span class="nam">ele</span> <span class="key">in</span> <span class="nam">a_list</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2342" href="#t2342">2342</a></span><span class="t">            <span class="key">elif</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">)</span> <span class="key">and</span> <span class="op">(</span><span class="nam">data_format</span> <span class="op">==</span> <span class="str">"NHWC"</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2343" href="#t2343">2343</a></span><span class="t">                <span class="key">if</span> <span class="key">not</span> <span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">==</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span> <span class="key">and</span> <span class="nam">padding</span><span class="op">[</span><span class="num">3</span><span class="op">]</span> <span class="op">==</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2344" href="#t2344">2344</a></span><span class="t">                    <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2345" href="#t2345">2345</a></span><span class="t">                        <span class="str">"Non-zero pool_padding(%s) in the batch or channel dimensions "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2346" href="#t2346">2346</a></span><span class="t">                        <span class="str">"is not supported."</span> <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2347" href="#t2347">2347</a></span><span class="t">                    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2348" href="#t2348">2348</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="nam">padding</span><span class="op">[</span><span class="num">1</span><span class="op">:</span><span class="num">3</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2349" href="#t2349">2349</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="nam">ele</span> <span class="key">for</span> <span class="nam">a_list</span> <span class="key">in</span> <span class="nam">padding</span> <span class="key">for</span> <span class="nam">ele</span> <span class="key">in</span> <span class="nam">a_list</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2350" href="#t2350">2350</a></span><span class="t">            <span class="nam">padding</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="num">4</span><span class="op">,</span> <span class="str">'padding'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2351" href="#t2351">2351</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2352" href="#t2352">2352</a></span><span class="t">            <span class="key">if</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_is_symmetric_padding</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="num">2</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2353" href="#t2353">2353</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span> <span class="nam">padding</span><span class="op">[</span><span class="num">2</span><span class="op">]</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2354" href="#t2354">2354</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2355" href="#t2355">2355</a></span><span class="t">            <span class="nam">padding</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="num">2</span><span class="op">,</span> <span class="str">'padding'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2356" href="#t2356">2356</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2357" href="#t2357">2357</a></span><span class="t">        <span class="key">return</span> <span class="nam">padding</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2358" href="#t2358">2358</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2359" href="#t2359">2359</a></span><span class="t">    <span class="nam">padding_algorithm</span> <span class="op">=</span> <span class="str">"EXPLICIT"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2360" href="#t2360">2360</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">pool_padding</span><span class="op">,</span> <span class="nam">str</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2361" href="#t2361">2361</a></span><span class="t">        <span class="nam">pool_padding</span> <span class="op">=</span> <span class="nam">pool_padding</span><span class="op">.</span><span class="nam">upper</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2362" href="#t2362">2362</a></span><span class="t">        <span class="key">if</span> <span class="nam">pool_padding</span> <span class="key">not</span> <span class="key">in</span> <span class="op">[</span><span class="str">"SAME"</span><span class="op">,</span> <span class="str">"VALID"</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2363" href="#t2363">2363</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2364" href="#t2364">2364</a></span><span class="t">                <span class="str">"Unknown Attr(pool_padding): '%s'. It can only be 'SAME' or 'VALID'."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2365" href="#t2365">2365</a></span><span class="t">                <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">pool_padding</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2366" href="#t2366">2366</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2367" href="#t2367">2367</a></span><span class="t">        <span class="key">if</span> <span class="nam">pool_padding</span> <span class="op">==</span> <span class="str">"VALID"</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2368" href="#t2368">2368</a></span><span class="t">            <span class="nam">padding_algorithm</span> <span class="op">=</span> <span class="str">"VALID"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2369" href="#t2369">2369</a></span><span class="t">            <span class="nam">pool_padding</span> <span class="op">=</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2370" href="#t2370">2370</a></span><span class="t">            <span class="key">if</span> <span class="nam">ceil_mode</span> <span class="op">!=</span> <span class="key">False</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2371" href="#t2371">2371</a></span><span class="t">                <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2372" href="#t2372">2372</a></span><span class="t">                    <span class="str">"When Attr(pool_padding) is \"VALID\", Attr(ceil_mode) must be False. "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2373" href="#t2373">2373</a></span><span class="t">                    <span class="str">"Received ceil_mode: True."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2374" href="#t2374">2374</a></span><span class="t">                <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2375" href="#t2375">2375</a></span><span class="t">        <span class="key">elif</span> <span class="nam">pool_padding</span> <span class="op">==</span> <span class="str">"SAME"</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2376" href="#t2376">2376</a></span><span class="t">            <span class="nam">padding_algorithm</span> <span class="op">=</span> <span class="str">"SAME"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2377" href="#t2377">2377</a></span><span class="t">            <span class="nam">pool_padding</span> <span class="op">=</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2378" href="#t2378">2378</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2379" href="#t2379">2379</a></span><span class="t">    <span class="nam">pool_padding</span> <span class="op">=</span> <span class="nam">update_padding</span><span class="op">(</span><span class="nam">pool_padding</span><span class="op">,</span> <span class="nam">data_format</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2380" href="#t2380">2380</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2381" href="#t2381">2381</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">pool2d</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2382" href="#t2382">2382</a></span><span class="t">            <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2383" href="#t2383">2383</a></span><span class="t">            <span class="nam">pool_size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2384" href="#t2384">2384</a></span><span class="t">            <span class="nam">pool_stride</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2385" href="#t2385">2385</a></span><span class="t">            <span class="nam">pool_padding</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2386" href="#t2386">2386</a></span><span class="t">            <span class="nam">ceil_mode</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2387" href="#t2387">2387</a></span><span class="t">            <span class="nam">exclusive</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2388" href="#t2388">2388</a></span><span class="t">            <span class="nam">data_format</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2389" href="#t2389">2389</a></span><span class="t">            <span class="nam">pool_type</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2390" href="#t2390">2390</a></span><span class="t">            <span class="nam">global_pooling</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2391" href="#t2391">2391</a></span><span class="t">            <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2392" href="#t2392">2392</a></span><span class="t">            <span class="nam">padding_algorithm</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2393" href="#t2393">2393</a></span><span class="t">            <span class="nam">use_cudnn</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2394" href="#t2394">2394</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2395" href="#t2395">2395</a></span><span class="t">    <span class="nam">op_type</span> <span class="op">=</span> <span class="str">'pool2d'</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2396" href="#t2396">2396</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="nam">op_type</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2397" href="#t2397">2397</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2398" href="#t2398">2398</a></span><span class="t">    <span class="nam">pool_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2399" href="#t2399">2399</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2400" href="#t2400">2400</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2401" href="#t2401">2401</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="nam">op_type</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2402" href="#t2402">2402</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2403" href="#t2403">2403</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">pool_out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2404" href="#t2404">2404</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2405" href="#t2405">2405</a></span><span class="t">            <span class="str">"pooling_type"</span><span class="op">:</span> <span class="nam">pool_type</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2406" href="#t2406">2406</a></span><span class="t">            <span class="str">"ksize"</span><span class="op">:</span> <span class="nam">pool_size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2407" href="#t2407">2407</a></span><span class="t">            <span class="str">"global_pooling"</span><span class="op">:</span> <span class="nam">global_pooling</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2408" href="#t2408">2408</a></span><span class="t">            <span class="str">"strides"</span><span class="op">:</span> <span class="nam">pool_stride</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2409" href="#t2409">2409</a></span><span class="t">            <span class="str">"paddings"</span><span class="op">:</span> <span class="nam">pool_padding</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2410" href="#t2410">2410</a></span><span class="t">            <span class="str">"padding_algorithm"</span><span class="op">:</span> <span class="nam">padding_algorithm</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2411" href="#t2411">2411</a></span><span class="t">            <span class="str">"use_cudnn"</span><span class="op">:</span> <span class="nam">use_cudnn</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2412" href="#t2412">2412</a></span><span class="t">            <span class="str">"ceil_mode"</span><span class="op">:</span> <span class="nam">ceil_mode</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2413" href="#t2413">2413</a></span><span class="t">            <span class="str">"use_mkldnn"</span><span class="op">:</span> <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2414" href="#t2414">2414</a></span><span class="t">            <span class="str">"exclusive"</span><span class="op">:</span> <span class="nam">exclusive</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2415" href="#t2415">2415</a></span><span class="t">            <span class="str">"data_format"</span><span class="op">:</span> <span class="nam">data_format</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2416" href="#t2416">2416</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2417" href="#t2417">2417</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2418" href="#t2418">2418</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2419" href="#t2419">2419</a></span><span class="t">    <span class="key">return</span> <span class="nam">pool_out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2420" href="#t2420">2420</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2421" href="#t2421">2421</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t2422" href="#t2422">2422</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t2423" href="#t2423">2423</a></span><span class="t"><span class="key">def</span> <span class="nam">pool3d</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2424" href="#t2424">2424</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2425" href="#t2425">2425</a></span><span class="t">    <span class="nam">pool_size</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2426" href="#t2426">2426</a></span><span class="t">    <span class="nam">pool_type</span><span class="op">=</span><span class="str">"max"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2427" href="#t2427">2427</a></span><span class="t">    <span class="nam">pool_stride</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2428" href="#t2428">2428</a></span><span class="t">    <span class="nam">pool_padding</span><span class="op">=</span><span class="num">0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2429" href="#t2429">2429</a></span><span class="t">    <span class="nam">global_pooling</span><span class="op">=</span><span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2430" href="#t2430">2430</a></span><span class="t">    <span class="nam">use_cudnn</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2431" href="#t2431">2431</a></span><span class="t">    <span class="nam">ceil_mode</span><span class="op">=</span><span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2432" href="#t2432">2432</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2433" href="#t2433">2433</a></span><span class="t">    <span class="nam">exclusive</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2434" href="#t2434">2434</a></span><span class="t">    <span class="nam">data_format</span><span class="op">=</span><span class="str">"NCDHW"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2435" href="#t2435">2435</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2436" href="#t2436">2436</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2437" href="#t2437">2437</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2438" href="#t2438">2438</a></span><span class="t"><span class="str">    ${comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2439" href="#t2439">2439</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2440" href="#t2440">2440</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2441" href="#t2441">2441</a></span><span class="t"><span class="str">        input (Variable): The input tensor of pooling operator, which is a 5-D tensor with</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2442" href="#t2442">2442</a></span><span class="t"><span class="str">                          shape [N, C, D, H, W]. The format of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2443" href="#t2443">2443</a></span><span class="t"><span class="str">                          input tensor is `"NCDHW"` or `"NDHWC"`, where `N` is batch size, `C` is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2444" href="#t2444">2444</a></span><span class="t"><span class="str">                          the number of channels, `D` is the depth of the feature,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2445" href="#t2445">2445</a></span><span class="t"><span class="str">                          `H` is the height of the feature, and `W` is the width</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2446" href="#t2446">2446</a></span><span class="t"><span class="str">                          of the feature.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2447" href="#t2447">2447</a></span><span class="t"><span class="str">        pool_size (int|list|tuple): The pool kernel size. If pool kernel size</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2448" href="#t2448">2448</a></span><span class="t"><span class="str">            is a tuple or list, it must contain three integers,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2449" href="#t2449">2449</a></span><span class="t"><span class="str">            (pool_size_Depth, pool_size_Height, pool_size_Width).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2450" href="#t2450">2450</a></span><span class="t"><span class="str">            Otherwise, the pool kernel size will be the cube of an int.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2451" href="#t2451">2451</a></span><span class="t"><span class="str">        pool_type (string): ${pooling_type_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2452" href="#t2452">2452</a></span><span class="t"><span class="str">        pool_stride (string|int|list|tuple)): The pool padding. If `pool_padding` is a string, either 'VALID' or</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2453" href="#t2453">2453</a></span><span class="t"><span class="str">            'SAME' which is the padding algorithm. If pool stride size is a tuple or list,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2454" href="#t2454">2454</a></span><span class="t"><span class="str">            it must contain three integers, `[stride_Depth, stride_Height, stride_Width]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2455" href="#t2455">2455</a></span><span class="t"><span class="str">            Otherwise, the pool stride size will be a cube of an int.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2456" href="#t2456">2456</a></span><span class="t"><span class="str">        pool_padding (int|list|tuple): The pool padding size. If pool padding size is a tuple or list,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2457" href="#t2457">2457</a></span><span class="t"><span class="str">            it could be in three forms: `[pad_depth, pad_height, pad_width]` or</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2458" href="#t2458">2458</a></span><span class="t"><span class="str">            `[pad_depth_front, pad_depth_back, pad_height_top, pad_height_bottom, pad_width_left, pad_width_right]`,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2459" href="#t2459">2459</a></span><span class="t"><span class="str">            and when `data_format` is `"NCDHW"`, `pool_padding` can be in the form</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2460" href="#t2460">2460</a></span><span class="t"><span class="str">            `[[0,0], [0,0], [pad_depth_front, pad_depth_back], [pad_height_top, pad_height_bottom], [pad_width_left, pad_width_right]]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2461" href="#t2461">2461</a></span><span class="t"><span class="str">            when `data_format` is `"NDHWC"`, `pool_padding` can be in the form</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2462" href="#t2462">2462</a></span><span class="t"><span class="str">            `[[0,0], [pad_depth_front, pad_depth_back], [pad_height_top, pad_height_bottom], [pad_width_left, pad_width_right], [0,0]]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2463" href="#t2463">2463</a></span><span class="t"><span class="str">        global_pooling (bool): ${global_pooling_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2464" href="#t2464">2464</a></span><span class="t"><span class="str">        use_cudnn (bool): ${use_cudnn_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2465" href="#t2465">2465</a></span><span class="t"><span class="str">        ceil_mode (bool): ${ceil_mode_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2466" href="#t2466">2466</a></span><span class="t"><span class="str">        name(str, optional): For detailed information, please refer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2467" href="#t2467">2467</a></span><span class="t"><span class="str">                             to :ref:`api_guide_Name`. Usually name is no need to set and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2468" href="#t2468">2468</a></span><span class="t"><span class="str">                             None by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2469" href="#t2469">2469</a></span><span class="t"><span class="str">        exclusive (bool): Whether to exclude padding points in average pooling</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2470" href="#t2470">2470</a></span><span class="t"><span class="str">                          mode, default is true.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2471" href="#t2471">2471</a></span><span class="t"><span class="str">        data_format (string): The data format of the input and output data. An optional string from: `"NCDHW"`, `"NDHWC"`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2472" href="#t2472">2472</a></span><span class="t"><span class="str">                The default is `"NCDHW"`. When it is `"NCDHW"`, the data is stored in the order of:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2473" href="#t2473">2473</a></span><span class="t"><span class="str">                `[batch_size, input_channels, input_depth, input_height, input_width]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2474" href="#t2474">2474</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2475" href="#t2475">2475</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2476" href="#t2476">2476</a></span><span class="t"><span class="str">        Variable: The output tensor of pooling result. The data type is same as input tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2477" href="#t2477">2477</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2478" href="#t2478">2478</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2479" href="#t2479">2479</a></span><span class="t"><span class="str">        ValueError: If `pool_type` is not "max" nor "avg".</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2480" href="#t2480">2480</a></span><span class="t"><span class="str">        ValueError: If `global_pooling` is False and `pool_size` is -1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2481" href="#t2481">2481</a></span><span class="t"><span class="str">        TypeError: If `use_cudnn` is not a bool value.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2482" href="#t2482">2482</a></span><span class="t"><span class="str">        ValueError: If `data_format` is not "NCDHW" or "NDHWC".</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2483" href="#t2483">2483</a></span><span class="t"><span class="str">        ValueError: If `pool_padding` is a string, but not "SAME" or "VALID".</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2484" href="#t2484">2484</a></span><span class="t"><span class="str">        ValueError: If `pool_padding` is "VALID", but `ceil_mode` is True.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2485" href="#t2485">2485</a></span><span class="t"><span class="str">        ValueError: If `pool_padding` is a list or tuple, but the elements in the batch or channel dimensions are non-zero.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2486" href="#t2486">2486</a></span><span class="t"><span class="str">        ShapeError: If the input is not a 4-D or 5-D Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2487" href="#t2487">2487</a></span><span class="t"><span class="str">        ShapeError: If the dimension of input minus the size of `pool_stride` is not 2.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2488" href="#t2488">2488</a></span><span class="t"><span class="str">        ShapeError: If the size of `pool_size` and `pool_stride` is not equal.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2489" href="#t2489">2489</a></span><span class="t"><span class="str">        ShapeError: If the output's shape calculated is not greater than 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2490" href="#t2490">2490</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2491" href="#t2491">2491</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2492" href="#t2492">2492</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2493" href="#t2493">2493</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2494" href="#t2494">2494</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2495" href="#t2495">2495</a></span><span class="t"><span class="str">          import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2496" href="#t2496">2496</a></span><span class="t"><span class="str">          import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2497" href="#t2497">2497</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2498" href="#t2498">2498</a></span><span class="t"><span class="str">          paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2499" href="#t2499">2499</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2500" href="#t2500">2500</a></span><span class="t"><span class="str">          data = fluid.data(name='data', shape=[None, 3, 32, 32, 32], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2501" href="#t2501">2501</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2502" href="#t2502">2502</a></span><span class="t"><span class="str">          # max pool3d</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2503" href="#t2503">2503</a></span><span class="t"><span class="str">          pool3d = fluid.layers.pool3d(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2504" href="#t2504">2504</a></span><span class="t"><span class="str">            input = data,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2505" href="#t2505">2505</a></span><span class="t"><span class="str">            pool_size = 2,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2506" href="#t2506">2506</a></span><span class="t"><span class="str">            pool_type = "max",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2507" href="#t2507">2507</a></span><span class="t"><span class="str">            pool_stride = 1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2508" href="#t2508">2508</a></span><span class="t"><span class="str">            global_pooling=False)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2509" href="#t2509">2509</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2510" href="#t2510">2510</a></span><span class="t"><span class="str">          # average pool3d</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2511" href="#t2511">2511</a></span><span class="t"><span class="str">          pool3d = fluid.layers.pool3d(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2512" href="#t2512">2512</a></span><span class="t"><span class="str">            input = data,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2513" href="#t2513">2513</a></span><span class="t"><span class="str">            pool_size = 2,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2514" href="#t2514">2514</a></span><span class="t"><span class="str">            pool_type = "avg",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2515" href="#t2515">2515</a></span><span class="t"><span class="str">            pool_stride = 1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2516" href="#t2516">2516</a></span><span class="t"><span class="str">            global_pooling=False)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2517" href="#t2517">2517</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2518" href="#t2518">2518</a></span><span class="t"><span class="str">          # global average pool3d</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2519" href="#t2519">2519</a></span><span class="t"><span class="str">          pool3d = fluid.layers.pool3d(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2520" href="#t2520">2520</a></span><span class="t"><span class="str">            input = data,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2521" href="#t2521">2521</a></span><span class="t"><span class="str">            pool_size = 2,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2522" href="#t2522">2522</a></span><span class="t"><span class="str">            pool_type = "avg",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2523" href="#t2523">2523</a></span><span class="t"><span class="str">            pool_stride = 1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2524" href="#t2524">2524</a></span><span class="t"><span class="str">            global_pooling=True)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2525" href="#t2525">2525</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2526" href="#t2526">2526</a></span><span class="t"><span class="str">          # example 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2527" href="#t2527">2527</a></span><span class="t"><span class="str">          # Attr(pool_padding) is a list with 6 elements, Attr(data_format) is "NCDHW".</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2528" href="#t2528">2528</a></span><span class="t"><span class="str">          out_1 = fluid.layers.pool3d(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2529" href="#t2529">2529</a></span><span class="t"><span class="str">            input = data,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2530" href="#t2530">2530</a></span><span class="t"><span class="str">            pool_size = 2,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2531" href="#t2531">2531</a></span><span class="t"><span class="str">            pool_type = "avg",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2532" href="#t2532">2532</a></span><span class="t"><span class="str">            pool_stride = 1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2533" href="#t2533">2533</a></span><span class="t"><span class="str">            pool_padding = [1, 2, 1, 0, 1, 2],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2534" href="#t2534">2534</a></span><span class="t"><span class="str">            global_pooling = False,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2535" href="#t2535">2535</a></span><span class="t"><span class="str">            data_format = "NCDHW")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2536" href="#t2536">2536</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2537" href="#t2537">2537</a></span><span class="t"><span class="str">          # example 2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2538" href="#t2538">2538</a></span><span class="t"><span class="str">          # Attr(pool_padding) is a string, Attr(data_format) is "NCDHW".</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2539" href="#t2539">2539</a></span><span class="t"><span class="str">          out_2 = fluid.layers.pool3d(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2540" href="#t2540">2540</a></span><span class="t"><span class="str">            input = data,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2541" href="#t2541">2541</a></span><span class="t"><span class="str">            pool_size = 3,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2542" href="#t2542">2542</a></span><span class="t"><span class="str">            pool_type = "avg",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2543" href="#t2543">2543</a></span><span class="t"><span class="str">            pool_stride = 1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2544" href="#t2544">2544</a></span><span class="t"><span class="str">            pool_padding = "VALID",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2545" href="#t2545">2545</a></span><span class="t"><span class="str">            global_pooling = False,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2546" href="#t2546">2546</a></span><span class="t"><span class="str">            data_format = "NCDHW")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2547" href="#t2547">2547</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2548" href="#t2548">2548</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2549" href="#t2549">2549</a></span><span class="t">    <span class="key">if</span> <span class="nam">pool_type</span> <span class="key">not</span> <span class="key">in</span> <span class="op">[</span><span class="str">"max"</span><span class="op">,</span> <span class="str">"avg"</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2550" href="#t2550">2550</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2551" href="#t2551">2551</a></span><span class="t">            <span class="str">"Unknown Attr(pool_type): '%s'. It can only be 'max' or 'avg'."</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2552" href="#t2552">2552</a></span><span class="t">            <span class="nam">str</span><span class="op">(</span><span class="nam">pool_type</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2553" href="#t2553">2553</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2554" href="#t2554">2554</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2555" href="#t2555">2555</a></span><span class="t">    <span class="key">if</span> <span class="nam">global_pooling</span> <span class="key">is</span> <span class="key">False</span> <span class="key">and</span> <span class="nam">pool_size</span> <span class="op">==</span> <span class="op">-</span><span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2556" href="#t2556">2556</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2557" href="#t2557">2557</a></span><span class="t">            <span class="str">"When Attr(global_pooling) is False, Attr(pool_size) must be passed "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2558" href="#t2558">2558</a></span><span class="t">            <span class="str">"and be a valid value. Received Attr(pool_size): %s."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2559" href="#t2559">2559</a></span><span class="t">            <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">pool_size</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2560" href="#t2560">2560</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2561" href="#t2561">2561</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2562" href="#t2562">2562</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">use_cudnn</span><span class="op">,</span> <span class="nam">bool</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2563" href="#t2563">2563</a></span><span class="t">        <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2564" href="#t2564">2564</a></span><span class="t">            <span class="str">"Attr(use_cudnn) should be True or False. Received "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2565" href="#t2565">2565</a></span><span class="t">            <span class="str">"Attr(use_cudnn): %s. "</span> <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">use_cudnn</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2566" href="#t2566">2566</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2567" href="#t2567">2567</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2568" href="#t2568">2568</a></span><span class="t">    <span class="key">if</span> <span class="nam">data_format</span> <span class="key">not</span> <span class="key">in</span> <span class="op">[</span><span class="str">"NCDHW"</span><span class="op">,</span> <span class="str">"NDHWC"</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2569" href="#t2569">2569</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2570" href="#t2570">2570</a></span><span class="t">            <span class="str">"Attr(data_format) should be 'NCDHW' or 'NDHWC'. Received "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2571" href="#t2571">2571</a></span><span class="t">            <span class="str">"Attr(data_format): %s"</span> <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">data_format</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2572" href="#t2572">2572</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2573" href="#t2573">2573</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2574" href="#t2574">2574</a></span><span class="t">    <span class="nam">pool_size</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">pool_size</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="str">'pool_size'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2575" href="#t2575">2575</a></span><span class="t">    <span class="nam">pool_stride</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">pool_stride</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="str">'pool_stride'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2576" href="#t2576">2576</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2577" href="#t2577">2577</a></span><span class="t">    <span class="key">def</span> <span class="nam">update_padding</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="nam">data_format</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2578" href="#t2578">2578</a></span><span class="t">        <span class="key">def</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">ele</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2579" href="#t2579">2579</a></span><span class="t">            <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">ele</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2580" href="#t2580">2580</a></span><span class="t">                <span class="key">return</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2581" href="#t2581">2581</a></span><span class="t">            <span class="key">return</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2582" href="#t2582">2582</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2583" href="#t2583">2583</a></span><span class="t">        <span class="key">if</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span> <span class="key">and</span> <span class="nam">len</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span> <span class="op">==</span> <span class="num">5</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2584" href="#t2584">2584</a></span><span class="t">            <span class="key">if</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">)</span> <span class="key">and</span> <span class="op">(</span><span class="nam">data_format</span> <span class="op">==</span> <span class="str">"NCDHW"</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2585" href="#t2585">2585</a></span><span class="t">                <span class="key">if</span> <span class="key">not</span> <span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">==</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span> <span class="key">and</span> <span class="nam">padding</span><span class="op">[</span><span class="num">1</span><span class="op">]</span> <span class="op">==</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2586" href="#t2586">2586</a></span><span class="t">                    <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2587" href="#t2587">2587</a></span><span class="t">                        <span class="str">"Non-zero pool_padding(%s) in the batch or channel dimensions "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2588" href="#t2588">2588</a></span><span class="t">                        <span class="str">"is not supported."</span> <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2589" href="#t2589">2589</a></span><span class="t">                    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2590" href="#t2590">2590</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="nam">padding</span><span class="op">[</span><span class="num">2</span><span class="op">:</span><span class="num">5</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2591" href="#t2591">2591</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="nam">ele</span> <span class="key">for</span> <span class="nam">a_list</span> <span class="key">in</span> <span class="nam">padding</span> <span class="key">for</span> <span class="nam">ele</span> <span class="key">in</span> <span class="nam">a_list</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2592" href="#t2592">2592</a></span><span class="t">            <span class="key">elif</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">)</span> <span class="key">and</span> <span class="op">(</span><span class="nam">data_format</span> <span class="op">==</span> <span class="str">"NDHWC"</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2593" href="#t2593">2593</a></span><span class="t">                <span class="key">if</span> <span class="key">not</span> <span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">==</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span> <span class="key">and</span> <span class="nam">padding</span><span class="op">[</span><span class="num">4</span><span class="op">]</span> <span class="op">==</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2594" href="#t2594">2594</a></span><span class="t">                    <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2595" href="#t2595">2595</a></span><span class="t">                        <span class="str">"Non-zero pool_padding(%s) in the batch or channel dimensions "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2596" href="#t2596">2596</a></span><span class="t">                        <span class="str">"is not supported."</span> <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2597" href="#t2597">2597</a></span><span class="t">                    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2598" href="#t2598">2598</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="nam">padding</span><span class="op">[</span><span class="num">1</span><span class="op">:</span><span class="num">4</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2599" href="#t2599">2599</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="nam">ele</span> <span class="key">for</span> <span class="nam">a_list</span> <span class="key">in</span> <span class="nam">padding</span> <span class="key">for</span> <span class="nam">ele</span> <span class="key">in</span> <span class="nam">a_list</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2600" href="#t2600">2600</a></span><span class="t">            <span class="nam">padding</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="num">6</span><span class="op">,</span> <span class="str">'padding'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2601" href="#t2601">2601</a></span><span class="t">            <span class="key">if</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_is_symmetric_padding</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="num">3</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2602" href="#t2602">2602</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span> <span class="nam">padding</span><span class="op">[</span><span class="num">2</span><span class="op">]</span><span class="op">,</span> <span class="nam">padding</span><span class="op">[</span><span class="num">4</span><span class="op">]</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2603" href="#t2603">2603</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2604" href="#t2604">2604</a></span><span class="t">        <span class="key">elif</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span> <span class="key">and</span> <span class="nam">len</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span> <span class="op">==</span> <span class="num">6</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2605" href="#t2605">2605</a></span><span class="t">            <span class="nam">padding</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="num">6</span><span class="op">,</span> <span class="str">'padding'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2606" href="#t2606">2606</a></span><span class="t">            <span class="key">if</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_is_symmetric_padding</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="num">3</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2607" href="#t2607">2607</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span> <span class="nam">padding</span><span class="op">[</span><span class="num">2</span><span class="op">]</span><span class="op">,</span> <span class="nam">padding</span><span class="op">[</span><span class="num">4</span><span class="op">]</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2608" href="#t2608">2608</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2609" href="#t2609">2609</a></span><span class="t">            <span class="nam">padding</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="str">'padding'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2610" href="#t2610">2610</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2611" href="#t2611">2611</a></span><span class="t">        <span class="key">return</span> <span class="nam">padding</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2612" href="#t2612">2612</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2613" href="#t2613">2613</a></span><span class="t">    <span class="nam">padding_algorithm</span> <span class="op">=</span> <span class="str">"EXPLICIT"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2614" href="#t2614">2614</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">pool_padding</span><span class="op">,</span> <span class="nam">str</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2615" href="#t2615">2615</a></span><span class="t">        <span class="nam">pool_padding</span> <span class="op">=</span> <span class="nam">pool_padding</span><span class="op">.</span><span class="nam">upper</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2616" href="#t2616">2616</a></span><span class="t">        <span class="key">if</span> <span class="nam">pool_padding</span> <span class="key">not</span> <span class="key">in</span> <span class="op">[</span><span class="str">"SAME"</span><span class="op">,</span> <span class="str">"VALID"</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2617" href="#t2617">2617</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2618" href="#t2618">2618</a></span><span class="t">                <span class="str">"Unknown Attr(pool_padding): '%s'. It can only be 'SAME' or 'VALID'."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2619" href="#t2619">2619</a></span><span class="t">                <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">pool_padding</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2620" href="#t2620">2620</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2621" href="#t2621">2621</a></span><span class="t">        <span class="key">if</span> <span class="nam">pool_padding</span> <span class="op">==</span> <span class="str">"VALID"</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2622" href="#t2622">2622</a></span><span class="t">            <span class="nam">padding_algorithm</span> <span class="op">=</span> <span class="str">"VALID"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2623" href="#t2623">2623</a></span><span class="t">            <span class="nam">pool_padding</span> <span class="op">=</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2624" href="#t2624">2624</a></span><span class="t">            <span class="key">if</span> <span class="nam">ceil_mode</span> <span class="op">!=</span> <span class="key">False</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2625" href="#t2625">2625</a></span><span class="t">                <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2626" href="#t2626">2626</a></span><span class="t">                    <span class="str">"When Attr(pool_padding) is \"VALID\", ceil_mode must be False. "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2627" href="#t2627">2627</a></span><span class="t">                    <span class="str">"Received ceil_mode: True."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2628" href="#t2628">2628</a></span><span class="t">                <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2629" href="#t2629">2629</a></span><span class="t">        <span class="key">elif</span> <span class="nam">pool_padding</span> <span class="op">==</span> <span class="str">"SAME"</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2630" href="#t2630">2630</a></span><span class="t">            <span class="nam">padding_algorithm</span> <span class="op">=</span> <span class="str">"SAME"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2631" href="#t2631">2631</a></span><span class="t">            <span class="nam">pool_padding</span> <span class="op">=</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2632" href="#t2632">2632</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2633" href="#t2633">2633</a></span><span class="t">    <span class="nam">pool_padding</span> <span class="op">=</span> <span class="nam">update_padding</span><span class="op">(</span><span class="nam">pool_padding</span><span class="op">,</span> <span class="nam">data_format</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2634" href="#t2634">2634</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2635" href="#t2635">2635</a></span><span class="t">    <span class="nam">op_type</span> <span class="op">=</span> <span class="str">"pool3d"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2636" href="#t2636">2636</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="nam">op_type</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2637" href="#t2637">2637</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2638" href="#t2638">2638</a></span><span class="t">    <span class="nam">pool_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2639" href="#t2639">2639</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2640" href="#t2640">2640</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2641" href="#t2641">2641</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="nam">op_type</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2642" href="#t2642">2642</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2643" href="#t2643">2643</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">pool_out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2644" href="#t2644">2644</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2645" href="#t2645">2645</a></span><span class="t">            <span class="str">"pooling_type"</span><span class="op">:</span> <span class="nam">pool_type</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2646" href="#t2646">2646</a></span><span class="t">            <span class="str">"ksize"</span><span class="op">:</span> <span class="nam">pool_size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2647" href="#t2647">2647</a></span><span class="t">            <span class="str">"global_pooling"</span><span class="op">:</span> <span class="nam">global_pooling</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2648" href="#t2648">2648</a></span><span class="t">            <span class="str">"strides"</span><span class="op">:</span> <span class="nam">pool_stride</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2649" href="#t2649">2649</a></span><span class="t">            <span class="str">"paddings"</span><span class="op">:</span> <span class="nam">pool_padding</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2650" href="#t2650">2650</a></span><span class="t">            <span class="str">"padding_algorithm"</span><span class="op">:</span> <span class="nam">padding_algorithm</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2651" href="#t2651">2651</a></span><span class="t">            <span class="str">"use_cudnn"</span><span class="op">:</span> <span class="nam">use_cudnn</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2652" href="#t2652">2652</a></span><span class="t">            <span class="str">"ceil_mode"</span><span class="op">:</span> <span class="nam">ceil_mode</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2653" href="#t2653">2653</a></span><span class="t">            <span class="str">"use_mkldnn"</span><span class="op">:</span> <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2654" href="#t2654">2654</a></span><span class="t">            <span class="str">"exclusive"</span><span class="op">:</span> <span class="nam">exclusive</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2655" href="#t2655">2655</a></span><span class="t">            <span class="str">"data_format"</span><span class="op">:</span> <span class="nam">data_format</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2656" href="#t2656">2656</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2657" href="#t2657">2657</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2658" href="#t2658">2658</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2659" href="#t2659">2659</a></span><span class="t">    <span class="key">return</span> <span class="nam">pool_out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2660" href="#t2660">2660</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2661" href="#t2661">2661</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t2662" href="#t2662">2662</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t2663" href="#t2663">2663</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="nam">op_type</span><span class="op">=</span><span class="str">"pool2d"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t2664" href="#t2664">2664</a></span><span class="t"><span class="key">def</span> <span class="nam">adaptive_pool2d</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2665" href="#t2665">2665</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span> <span class="nam">pool_size</span><span class="op">,</span> <span class="nam">pool_type</span><span class="op">=</span><span class="str">"max"</span><span class="op">,</span> <span class="nam">require_index</span><span class="op">=</span><span class="key">False</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2666" href="#t2666">2666</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2667" href="#t2667">2667</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2668" href="#t2668">2668</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2669" href="#t2669">2669</a></span><span class="t"><span class="str">    This operation calculates the output based on the input, pool_size,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2670" href="#t2670">2670</a></span><span class="t"><span class="str">    pool_type parameters. Input(X) and output(Out) are in NCHW format, where N is batch</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2671" href="#t2671">2671</a></span><span class="t"><span class="str">    size, C is the number of channels, H is the height of the feature, and W is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2672" href="#t2672">2672</a></span><span class="t"><span class="str">    the width of the feature. Parameters(pool_size) should contain two elements which</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2673" href="#t2673">2673</a></span><span class="t"><span class="str">    represent height and width, respectively. Also the H and W dimensions of output(Out)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2674" href="#t2674">2674</a></span><span class="t"><span class="str">    is same as Parameter(pool_size). The output tensor shape will be [N, C, pool_size[0], pool_size[1]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2675" href="#t2675">2675</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2676" href="#t2676">2676</a></span><span class="t"><span class="str">    For average adaptive pool2d:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2677" href="#t2677">2677</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2678" href="#t2678">2678</a></span><span class="t"><span class="str">    ..  math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2679" href="#t2679">2679</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2680" href="#t2680">2680</a></span><span class="t"><span class="str">       hstart &amp;= floor(i * H_{in} / H_{out})</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2681" href="#t2681">2681</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2682" href="#t2682">2682</a></span><span class="t"><span class="str">       hend &amp;= ceil((i + 1) * H_{in} / H_{out})</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2683" href="#t2683">2683</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2684" href="#t2684">2684</a></span><span class="t"><span class="str">       wstart &amp;= floor(j * W_{in} / W_{out})</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2685" href="#t2685">2685</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2686" href="#t2686">2686</a></span><span class="t"><span class="str">       wend &amp;= ceil((j + 1) * W_{in} / W_{out})</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2687" href="#t2687">2687</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2688" href="#t2688">2688</a></span><span class="t"><span class="str">       Output(i ,j) &amp;= \\frac{sum(Input[hstart:hend, wstart:wend])}{(hend - hstart) * (wend - wstart)}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2689" href="#t2689">2689</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2690" href="#t2690">2690</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2691" href="#t2691">2691</a></span><span class="t"><span class="str">        input (Tensor): The input tensor of pooling operator, which is a 4-D tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2692" href="#t2692">2692</a></span><span class="t"><span class="str">                          with shape [N, C, H, W].  The format of input tensor is NCHW,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2693" href="#t2693">2693</a></span><span class="t"><span class="str">                          where N is batch size, C is the number of channels, H is the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2694" href="#t2694">2694</a></span><span class="t"><span class="str">                          height of the feature, and W is the width of the feature.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2695" href="#t2695">2695</a></span><span class="t"><span class="str">                          The data type is float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2696" href="#t2696">2696</a></span><span class="t"><span class="str">        pool_size (int|list|tuple): The pool kernel size. If pool kernel size is a tuple or list,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2697" href="#t2697">2697</a></span><span class="t"><span class="str">            it must contain two integers, (pool_size_Height, pool_size_Width).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2698" href="#t2698">2698</a></span><span class="t"><span class="str">        pool_type: ${pooling_type_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2699" href="#t2699">2699</a></span><span class="t"><span class="str">        require_index (bool): If true, the index of max pooling point will be returned along</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2700" href="#t2700">2700</a></span><span class="t"><span class="str">            with outputs. It cannot be set in average pooling type. Default False.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2701" href="#t2701">2701</a></span><span class="t"><span class="str">        name(str, optional): For detailed information, please refer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2702" href="#t2702">2702</a></span><span class="t"><span class="str">                             to :ref:`api_guide_Name`. Usually name is no need to set and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2703" href="#t2703">2703</a></span><span class="t"><span class="str">                             None by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2704" href="#t2704">2704</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2705" href="#t2705">2705</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2706" href="#t2706">2706</a></span><span class="t"><span class="str">        Tensor: The output tensor of adaptive pooling result. The data type is same</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2707" href="#t2707">2707</a></span><span class="t"><span class="str">                  as input tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2708" href="#t2708">2708</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2709" href="#t2709">2709</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2710" href="#t2710">2710</a></span><span class="t"><span class="str">        ValueError: 'pool_type' is not 'max' nor 'avg'.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2711" href="#t2711">2711</a></span><span class="t"><span class="str">        ValueError: invalid setting 'require_index' true when 'pool_type' is 'avg'.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2712" href="#t2712">2712</a></span><span class="t"><span class="str">        ValueError: 'pool_size' should be a list or tuple with length as 2.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2713" href="#t2713">2713</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2714" href="#t2714">2714</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2715" href="#t2715">2715</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2716" href="#t2716">2716</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2717" href="#t2717">2717</a></span><span class="t"><span class="str">          # average adaptive pool2d</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2718" href="#t2718">2718</a></span><span class="t"><span class="str">          # suppose input data in shape of [N, C, H, W], `pool_size` is [m, n],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2719" href="#t2719">2719</a></span><span class="t"><span class="str">          # output shape is [N, C, m, n], adaptive pool divide H and W dimensions</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2720" href="#t2720">2720</a></span><span class="t"><span class="str">          # of input data into m * n grids averagely and performs poolings in each</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2721" href="#t2721">2721</a></span><span class="t"><span class="str">          # grid to get output.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2722" href="#t2722">2722</a></span><span class="t"><span class="str">          # adaptive average pool performs calculations as follow:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2723" href="#t2723">2723</a></span><span class="t"><span class="str">          #</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2724" href="#t2724">2724</a></span><span class="t"><span class="str">          #     for i in range(m):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2725" href="#t2725">2725</a></span><span class="t"><span class="str">          #         for j in range(n):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2726" href="#t2726">2726</a></span><span class="t"><span class="str">          #             hstart = floor(i * H / m)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2727" href="#t2727">2727</a></span><span class="t"><span class="str">          #             hend = ceil((i + 1) * H / m)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2728" href="#t2728">2728</a></span><span class="t"><span class="str">          #             wstart = floor(i * W / n)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2729" href="#t2729">2729</a></span><span class="t"><span class="str">          #             wend = ceil((i + 1) * W / n)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2730" href="#t2730">2730</a></span><span class="t"><span class="str">          #             output[:, :, i, j] = avg(input[:, :, hstart: hend, wstart: wend])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2731" href="#t2731">2731</a></span><span class="t"><span class="str">          #</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2732" href="#t2732">2732</a></span><span class="t"><span class="str">          import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2733" href="#t2733">2733</a></span><span class="t"><span class="str">          paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2734" href="#t2734">2734</a></span><span class="t"><span class="str">          data = paddle.rand(shape=[1,3,32,32])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2735" href="#t2735">2735</a></span><span class="t"><span class="str">          pool_out = paddle.fluid.layers.adaptive_pool2d(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2736" href="#t2736">2736</a></span><span class="t"><span class="str">                            input=data,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2737" href="#t2737">2737</a></span><span class="t"><span class="str">                            pool_size=[3, 3],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2738" href="#t2738">2738</a></span><span class="t"><span class="str">                            pool_type='avg')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2739" href="#t2739">2739</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2740" href="#t2740">2740</a></span><span class="t"><span class="str">          # max adaptive pool2d</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2741" href="#t2741">2741</a></span><span class="t"><span class="str">          # suppose input data in shape of [N, C, H, W], `pool_size` is [m, n],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2742" href="#t2742">2742</a></span><span class="t"><span class="str">          # output shape is [N, C, m, n], adaptive pool divide H and W dimensions</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2743" href="#t2743">2743</a></span><span class="t"><span class="str">          # of input data into m * n grids averagely and performs poolings in each</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2744" href="#t2744">2744</a></span><span class="t"><span class="str">          # grid to get output.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2745" href="#t2745">2745</a></span><span class="t"><span class="str">          # adaptive average pool performs calculations as follow:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2746" href="#t2746">2746</a></span><span class="t"><span class="str">          #</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2747" href="#t2747">2747</a></span><span class="t"><span class="str">          #     for i in range(m):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2748" href="#t2748">2748</a></span><span class="t"><span class="str">          #         for j in range(n):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2749" href="#t2749">2749</a></span><span class="t"><span class="str">          #             hstart = floor(i * H / m)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2750" href="#t2750">2750</a></span><span class="t"><span class="str">          #             hend = ceil((i + 1) * H / m)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2751" href="#t2751">2751</a></span><span class="t"><span class="str">          #             wstart = floor(i * W / n)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2752" href="#t2752">2752</a></span><span class="t"><span class="str">          #             wend = ceil((i + 1) * W / n)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2753" href="#t2753">2753</a></span><span class="t"><span class="str">          #             output[:, :, i, j] = max(input[:, :, hstart: hend, wstart: wend])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2754" href="#t2754">2754</a></span><span class="t"><span class="str">          #</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2755" href="#t2755">2755</a></span><span class="t"><span class="str">          import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2756" href="#t2756">2756</a></span><span class="t"><span class="str">          data = paddle.rand(shape=[1,3,32,32])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2757" href="#t2757">2757</a></span><span class="t"><span class="str">          pool_out = paddle.fluid.layers.adaptive_pool2d(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2758" href="#t2758">2758</a></span><span class="t"><span class="str">                            input=data,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2759" href="#t2759">2759</a></span><span class="t"><span class="str">                            pool_size=[3, 3],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2760" href="#t2760">2760</a></span><span class="t"><span class="str">                            pool_type='max')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2761" href="#t2761">2761</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2762" href="#t2762">2762</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2763" href="#t2763">2763</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2764" href="#t2764">2764</a></span><span class="t">        <span class="str">'input'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2765" href="#t2765">2765</a></span><span class="t">        <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2766" href="#t2766">2766</a></span><span class="t">        <span class="str">'adaptive_pool2d'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2767" href="#t2767">2767</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2768" href="#t2768">2768</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">pool_type</span><span class="op">,</span> <span class="str">'pool_type'</span><span class="op">,</span> <span class="nam">str</span><span class="op">,</span> <span class="str">'adaptive_pool2d'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2769" href="#t2769">2769</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">pool_size</span><span class="op">,</span> <span class="str">'pool_size'</span><span class="op">,</span> <span class="op">(</span><span class="nam">int</span><span class="op">,</span> <span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">,</span> <span class="str">'adaptive_pool2d'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2770" href="#t2770">2770</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">require_index</span><span class="op">,</span> <span class="str">'require_index'</span><span class="op">,</span> <span class="nam">bool</span><span class="op">,</span> <span class="str">'adaptive_pool2d'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2771" href="#t2771">2771</a></span><span class="t">    <span class="key">if</span> <span class="nam">pool_type</span> <span class="key">not</span> <span class="key">in</span> <span class="op">[</span><span class="str">"max"</span><span class="op">,</span> <span class="str">"avg"</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2772" href="#t2772">2772</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2773" href="#t2773">2773</a></span><span class="t">            <span class="str">"Unknown pool_type: '%s'. It can only be 'max' or 'avg'."</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2774" href="#t2774">2774</a></span><span class="t">            <span class="nam">str</span><span class="op">(</span><span class="nam">pool_type</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2775" href="#t2775">2775</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2776" href="#t2776">2776</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2777" href="#t2777">2777</a></span><span class="t">    <span class="key">if</span> <span class="nam">pool_type</span> <span class="op">==</span> <span class="str">"avg"</span> <span class="key">and</span> <span class="nam">require_index</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2778" href="#t2778">2778</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2779" href="#t2779">2779</a></span><span class="t">            <span class="str">"invalid setting 'require_index' true when 'pool_type' is 'avg'."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2780" href="#t2780">2780</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2781" href="#t2781">2781</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2782" href="#t2782">2782</a></span><span class="t">    <span class="nam">pool_size</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">pool_size</span><span class="op">,</span> <span class="num">2</span><span class="op">,</span> <span class="str">'pool_size'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2783" href="#t2783">2783</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2784" href="#t2784">2784</a></span><span class="t">    <span class="key">if</span> <span class="nam">pool_type</span> <span class="op">==</span> <span class="str">"max"</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2785" href="#t2785">2785</a></span><span class="t">        <span class="nam">l_type</span> <span class="op">=</span> <span class="str">'max_pool2d_with_index'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2786" href="#t2786">2786</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2787" href="#t2787">2787</a></span><span class="t">        <span class="nam">l_type</span> <span class="op">=</span> <span class="str">"pool2d"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2788" href="#t2788">2788</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2789" href="#t2789">2789</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="nam">l_type</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2790" href="#t2790">2790</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2791" href="#t2791">2791</a></span><span class="t">    <span class="nam">pool_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2792" href="#t2792">2792</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2793" href="#t2793">2793</a></span><span class="t">    <span class="nam">outputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">pool_out</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2794" href="#t2794">2794</a></span><span class="t">    <span class="key">if</span> <span class="nam">pool_type</span> <span class="op">==</span> <span class="str">"max"</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2795" href="#t2795">2795</a></span><span class="t">        <span class="nam">mask</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2796" href="#t2796">2796</a></span><span class="t">        <span class="nam">outputs</span><span class="op">[</span><span class="str">"Mask"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">mask</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2797" href="#t2797">2797</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2798" href="#t2798">2798</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2799" href="#t2799">2799</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="nam">l_type</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2800" href="#t2800">2800</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2801" href="#t2801">2801</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="nam">outputs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2802" href="#t2802">2802</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2803" href="#t2803">2803</a></span><span class="t">            <span class="str">"pooling_type"</span><span class="op">:</span> <span class="nam">pool_type</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2804" href="#t2804">2804</a></span><span class="t">            <span class="str">"ksize"</span><span class="op">:</span> <span class="nam">pool_size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2805" href="#t2805">2805</a></span><span class="t">            <span class="str">"adaptive"</span><span class="op">:</span> <span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2806" href="#t2806">2806</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2807" href="#t2807">2807</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2808" href="#t2808">2808</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2809" href="#t2809">2809</a></span><span class="t">    <span class="key">return</span> <span class="op">(</span><span class="nam">pool_out</span><span class="op">,</span> <span class="nam">mask</span><span class="op">)</span> <span class="key">if</span> <span class="nam">require_index</span> <span class="key">else</span> <span class="nam">pool_out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2810" href="#t2810">2810</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2811" href="#t2811">2811</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t2812" href="#t2812">2812</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t2813" href="#t2813">2813</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="nam">op_type</span><span class="op">=</span><span class="str">"pool3d"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t2814" href="#t2814">2814</a></span><span class="t"><span class="key">def</span> <span class="nam">adaptive_pool3d</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2815" href="#t2815">2815</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span> <span class="nam">pool_size</span><span class="op">,</span> <span class="nam">pool_type</span><span class="op">=</span><span class="str">"max"</span><span class="op">,</span> <span class="nam">require_index</span><span class="op">=</span><span class="key">False</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2816" href="#t2816">2816</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2817" href="#t2817">2817</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2818" href="#t2818">2818</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2819" href="#t2819">2819</a></span><span class="t"><span class="str">    This operation calculates the output based on the input, pool_size,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2820" href="#t2820">2820</a></span><span class="t"><span class="str">    pool_type parameters. Input(X) and output(Out) are in NCDHW format, where N is batch</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2821" href="#t2821">2821</a></span><span class="t"><span class="str">    size, C is the number of channels, D is the depth of the feature, H is the height of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2822" href="#t2822">2822</a></span><span class="t"><span class="str">    the feature, and W is the width of the feature. Parameters(pool_size) should contain</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2823" href="#t2823">2823</a></span><span class="t"><span class="str">    three elements which represent height and width, respectively. Also the D, H and W</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2824" href="#t2824">2824</a></span><span class="t"><span class="str">    dimensions of output(Out) is same as Parameter(pool_size). The output tensor shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2825" href="#t2825">2825</a></span><span class="t"><span class="str">    will be [N, C, pool_size[0], pool_size[1], pool_size[2]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2826" href="#t2826">2826</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2827" href="#t2827">2827</a></span><span class="t"><span class="str">    For average adaptive pool3d:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2828" href="#t2828">2828</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2829" href="#t2829">2829</a></span><span class="t"><span class="str">    ..  math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2830" href="#t2830">2830</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2831" href="#t2831">2831</a></span><span class="t"><span class="str">      dstart &amp;= floor(i * D_{in} / D_{out})</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2832" href="#t2832">2832</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2833" href="#t2833">2833</a></span><span class="t"><span class="str">      dend &amp;= ceil((i + 1) * D_{in} / D_{out})</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2834" href="#t2834">2834</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2835" href="#t2835">2835</a></span><span class="t"><span class="str">      hstart &amp;= floor(j * H_{in} / H_{out})</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2836" href="#t2836">2836</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2837" href="#t2837">2837</a></span><span class="t"><span class="str">      hend &amp;= ceil((j + 1) * H_{in} / H_{out})</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2838" href="#t2838">2838</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2839" href="#t2839">2839</a></span><span class="t"><span class="str">      wstart &amp;= floor(k * W_{in} / W_{out})</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2840" href="#t2840">2840</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2841" href="#t2841">2841</a></span><span class="t"><span class="str">      wend &amp;= ceil((k + 1) * W_{in} / W_{out})</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2842" href="#t2842">2842</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2843" href="#t2843">2843</a></span><span class="t"><span class="str">      Output(i ,j, k) &amp;= \\frac{sum(Input[dstart:dend, hstart:hend, wstart:wend])}{(dend - dstart) * (hend - hstart) * (wend - wstart)}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2844" href="#t2844">2844</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2845" href="#t2845">2845</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2846" href="#t2846">2846</a></span><span class="t"><span class="str">        input (Tensor): The input tensor of pooling operator, which is a 5-D tensor with</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2847" href="#t2847">2847</a></span><span class="t"><span class="str">                          shape [N, C, D, H, W]. The format of input tensor is NCDHW, where</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2848" href="#t2848">2848</a></span><span class="t"><span class="str">                          N is batch size, C is the number of channels, D is the depth of the feature,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2849" href="#t2849">2849</a></span><span class="t"><span class="str">                          H is the height of the feature, and W is the width of the feature.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2850" href="#t2850">2850</a></span><span class="t"><span class="str">                          The data type is float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2851" href="#t2851">2851</a></span><span class="t"><span class="str">        pool_size (int|list|tuple): The pool kernel size. If pool kernel size is a tuple or list,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2852" href="#t2852">2852</a></span><span class="t"><span class="str">            it must contain three integers, (Depth, Height, Width).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2853" href="#t2853">2853</a></span><span class="t"><span class="str">        pool_type: ${pooling_type_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2854" href="#t2854">2854</a></span><span class="t"><span class="str">        require_index (bool): If true, the index of max pooling point will be returned along</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2855" href="#t2855">2855</a></span><span class="t"><span class="str">            with outputs. It cannot be set in average pooling type. Default False.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2856" href="#t2856">2856</a></span><span class="t"><span class="str">        name(str, optional): For detailed information, please refer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2857" href="#t2857">2857</a></span><span class="t"><span class="str">                             to :ref:`api_guide_Name`. Usually name is no need to set and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2858" href="#t2858">2858</a></span><span class="t"><span class="str">                             None by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2859" href="#t2859">2859</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2860" href="#t2860">2860</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2861" href="#t2861">2861</a></span><span class="t"><span class="str">        Tensor: The output tensor of adaptive pooling result. The data type is same as input tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2862" href="#t2862">2862</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2863" href="#t2863">2863</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2864" href="#t2864">2864</a></span><span class="t"><span class="str">        ValueError: 'pool_type' is not 'max' nor 'avg'.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2865" href="#t2865">2865</a></span><span class="t"><span class="str">        ValueError: invalid setting 'require_index' true when 'pool_type' is 'avg'.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2866" href="#t2866">2866</a></span><span class="t"><span class="str">        ValueError: 'pool_size' should be a list or tuple with length as 2.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2867" href="#t2867">2867</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2868" href="#t2868">2868</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2869" href="#t2869">2869</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2870" href="#t2870">2870</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2871" href="#t2871">2871</a></span><span class="t"><span class="str">          # average adaptive pool3d</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2872" href="#t2872">2872</a></span><span class="t"><span class="str">          # suppose input data in shape of [N, C, D, H, W], `pool_size` is [l, m, n],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2873" href="#t2873">2873</a></span><span class="t"><span class="str">          # output shape is [N, C, l, m, n], adaptive pool divide D, H and W dimensions</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2874" href="#t2874">2874</a></span><span class="t"><span class="str">          # of input data into l * m * n grids averagely and performs poolings in each</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2875" href="#t2875">2875</a></span><span class="t"><span class="str">          # grid to get output.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2876" href="#t2876">2876</a></span><span class="t"><span class="str">          # adaptive average pool performs calculations as follow:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2877" href="#t2877">2877</a></span><span class="t"><span class="str">          #</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2878" href="#t2878">2878</a></span><span class="t"><span class="str">          #     for i in range(l):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2879" href="#t2879">2879</a></span><span class="t"><span class="str">          #         for j in range(m):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2880" href="#t2880">2880</a></span><span class="t"><span class="str">          #             for k in range(n):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2881" href="#t2881">2881</a></span><span class="t"><span class="str">          #                 dstart = floor(i * D / l)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2882" href="#t2882">2882</a></span><span class="t"><span class="str">          #                 dend = ceil((i + 1) * D / l)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2883" href="#t2883">2883</a></span><span class="t"><span class="str">          #                 hstart = floor(j * H / m)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2884" href="#t2884">2884</a></span><span class="t"><span class="str">          #                 hend = ceil((j + 1) * H / m)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2885" href="#t2885">2885</a></span><span class="t"><span class="str">          #                 wstart = floor(k * W / n)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2886" href="#t2886">2886</a></span><span class="t"><span class="str">          #                 wend = ceil((k + 1) * W / n)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2887" href="#t2887">2887</a></span><span class="t"><span class="str">          #                 output[:, :, i, j, k] =</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2888" href="#t2888">2888</a></span><span class="t"><span class="str">          #                     avg(input[:, :, dstart:dend, hstart: hend, wstart: wend])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2889" href="#t2889">2889</a></span><span class="t"><span class="str">          #</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2890" href="#t2890">2890</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2891" href="#t2891">2891</a></span><span class="t"><span class="str">          import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2892" href="#t2892">2892</a></span><span class="t"><span class="str">          paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2893" href="#t2893">2893</a></span><span class="t"><span class="str">          data = paddle.rand(shape=[1,3,32,32,32])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2894" href="#t2894">2894</a></span><span class="t"><span class="str">          pool_out = paddle.fluid.layers.adaptive_pool3d(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2895" href="#t2895">2895</a></span><span class="t"><span class="str">                            input=data,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2896" href="#t2896">2896</a></span><span class="t"><span class="str">                            pool_size=[3, 3, 3],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2897" href="#t2897">2897</a></span><span class="t"><span class="str">                            pool_type='avg')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2898" href="#t2898">2898</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2899" href="#t2899">2899</a></span><span class="t"><span class="str">          # max adaptive pool3d</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2900" href="#t2900">2900</a></span><span class="t"><span class="str">          # suppose input data in shape of [N, C, D, H, W], `pool_size` is [l, m, n],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2901" href="#t2901">2901</a></span><span class="t"><span class="str">          # output shape is [N, C, l, m, n], adaptive pool divide D, H and W dimensions</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2902" href="#t2902">2902</a></span><span class="t"><span class="str">          # of input data into l * m * n grids averagely and performs poolings in each</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2903" href="#t2903">2903</a></span><span class="t"><span class="str">          # grid to get output.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2904" href="#t2904">2904</a></span><span class="t"><span class="str">          # adaptive average pool performs calculations as follow:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2905" href="#t2905">2905</a></span><span class="t"><span class="str">          #</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2906" href="#t2906">2906</a></span><span class="t"><span class="str">          #     for i in range(l):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2907" href="#t2907">2907</a></span><span class="t"><span class="str">          #         for j in range(m):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2908" href="#t2908">2908</a></span><span class="t"><span class="str">          #             for k in range(n):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2909" href="#t2909">2909</a></span><span class="t"><span class="str">          #                 dstart = floor(i * D / l)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2910" href="#t2910">2910</a></span><span class="t"><span class="str">          #                 dend = ceil((i + 1) * D / l)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2911" href="#t2911">2911</a></span><span class="t"><span class="str">          #                 hstart = floor(j * H / m)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2912" href="#t2912">2912</a></span><span class="t"><span class="str">          #                 hend = ceil((j + 1) * H / m)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2913" href="#t2913">2913</a></span><span class="t"><span class="str">          #                 wstart = floor(k * W / n)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2914" href="#t2914">2914</a></span><span class="t"><span class="str">          #                 wend = ceil((k + 1) * W / n)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2915" href="#t2915">2915</a></span><span class="t"><span class="str">          #                 output[:, :, i, j, k] =</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2916" href="#t2916">2916</a></span><span class="t"><span class="str">          #                     avg(input[:, :, dstart:dend, hstart: hend, wstart: wend])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2917" href="#t2917">2917</a></span><span class="t"><span class="str">          #</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2918" href="#t2918">2918</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2919" href="#t2919">2919</a></span><span class="t"><span class="str">          import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2920" href="#t2920">2920</a></span><span class="t"><span class="str">          data = paddle.rand(shape=[1,3,32,32,32])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2921" href="#t2921">2921</a></span><span class="t"><span class="str">          pool_out = paddle.fluid.layers.adaptive_pool3d(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2922" href="#t2922">2922</a></span><span class="t"><span class="str">                            input=data,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2923" href="#t2923">2923</a></span><span class="t"><span class="str">                            pool_size=[3, 3, 3],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2924" href="#t2924">2924</a></span><span class="t"><span class="str">                            pool_type='max')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2925" href="#t2925">2925</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2926" href="#t2926">2926</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2927" href="#t2927">2927</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2928" href="#t2928">2928</a></span><span class="t">        <span class="str">'input'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2929" href="#t2929">2929</a></span><span class="t">        <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2930" href="#t2930">2930</a></span><span class="t">        <span class="str">'adaptive_pool3d'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2931" href="#t2931">2931</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2932" href="#t2932">2932</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">pool_type</span><span class="op">,</span> <span class="str">'pool_type'</span><span class="op">,</span> <span class="nam">str</span><span class="op">,</span> <span class="str">'adaptive_pool3d'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2933" href="#t2933">2933</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">pool_size</span><span class="op">,</span> <span class="str">'pool_size'</span><span class="op">,</span> <span class="op">(</span><span class="nam">int</span><span class="op">,</span> <span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">,</span> <span class="str">'adaptive_pool3d'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2934" href="#t2934">2934</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">require_index</span><span class="op">,</span> <span class="str">'require_index'</span><span class="op">,</span> <span class="nam">bool</span><span class="op">,</span> <span class="str">'adaptive_pool3d'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2935" href="#t2935">2935</a></span><span class="t">    <span class="key">if</span> <span class="nam">pool_type</span> <span class="key">not</span> <span class="key">in</span> <span class="op">[</span><span class="str">"max"</span><span class="op">,</span> <span class="str">"avg"</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2936" href="#t2936">2936</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2937" href="#t2937">2937</a></span><span class="t">            <span class="str">"Unknown pool_type: '%s'. It can only be 'max' or 'avg'."</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2938" href="#t2938">2938</a></span><span class="t">            <span class="nam">str</span><span class="op">(</span><span class="nam">pool_type</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2939" href="#t2939">2939</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2940" href="#t2940">2940</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2941" href="#t2941">2941</a></span><span class="t">    <span class="key">if</span> <span class="nam">pool_type</span> <span class="op">==</span> <span class="str">"avg"</span> <span class="key">and</span> <span class="nam">require_index</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2942" href="#t2942">2942</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2943" href="#t2943">2943</a></span><span class="t">            <span class="str">"invalid setting 'require_index' true when 'pool_type' is 'avg'."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2944" href="#t2944">2944</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2945" href="#t2945">2945</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2946" href="#t2946">2946</a></span><span class="t">    <span class="nam">pool_size</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">pool_size</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="str">'pool_size'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2947" href="#t2947">2947</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2948" href="#t2948">2948</a></span><span class="t">    <span class="key">if</span> <span class="nam">pool_type</span> <span class="op">==</span> <span class="str">"max"</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2949" href="#t2949">2949</a></span><span class="t">        <span class="nam">l_type</span> <span class="op">=</span> <span class="str">'max_pool3d_with_index'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2950" href="#t2950">2950</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2951" href="#t2951">2951</a></span><span class="t">        <span class="nam">l_type</span> <span class="op">=</span> <span class="str">"pool3d"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2952" href="#t2952">2952</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2953" href="#t2953">2953</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="nam">l_type</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2954" href="#t2954">2954</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2955" href="#t2955">2955</a></span><span class="t">    <span class="nam">pool_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2956" href="#t2956">2956</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2957" href="#t2957">2957</a></span><span class="t">    <span class="nam">outputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">pool_out</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2958" href="#t2958">2958</a></span><span class="t">    <span class="key">if</span> <span class="nam">pool_type</span> <span class="op">==</span> <span class="str">"max"</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2959" href="#t2959">2959</a></span><span class="t">        <span class="nam">mask</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2960" href="#t2960">2960</a></span><span class="t">        <span class="nam">outputs</span><span class="op">[</span><span class="str">"Mask"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">mask</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2961" href="#t2961">2961</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2962" href="#t2962">2962</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2963" href="#t2963">2963</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="nam">l_type</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2964" href="#t2964">2964</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2965" href="#t2965">2965</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="nam">outputs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2966" href="#t2966">2966</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2967" href="#t2967">2967</a></span><span class="t">            <span class="str">"pooling_type"</span><span class="op">:</span> <span class="nam">pool_type</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2968" href="#t2968">2968</a></span><span class="t">            <span class="str">"ksize"</span><span class="op">:</span> <span class="nam">pool_size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2969" href="#t2969">2969</a></span><span class="t">            <span class="str">"adaptive"</span><span class="op">:</span> <span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2970" href="#t2970">2970</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2971" href="#t2971">2971</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2972" href="#t2972">2972</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t2973" href="#t2973">2973</a></span><span class="t">    <span class="key">return</span> <span class="op">(</span><span class="nam">pool_out</span><span class="op">,</span> <span class="nam">mask</span><span class="op">)</span> <span class="key">if</span> <span class="nam">require_index</span> <span class="key">else</span> <span class="nam">pool_out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2974" href="#t2974">2974</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2975" href="#t2975">2975</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t2976" href="#t2976">2976</a></span><span class="t"><span class="key">def</span> <span class="nam">batch_norm</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2977" href="#t2977">2977</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2978" href="#t2978">2978</a></span><span class="t">    <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2979" href="#t2979">2979</a></span><span class="t">    <span class="nam">is_test</span><span class="op">=</span><span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2980" href="#t2980">2980</a></span><span class="t">    <span class="nam">momentum</span><span class="op">=</span><span class="num">0.9</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2981" href="#t2981">2981</a></span><span class="t">    <span class="nam">epsilon</span><span class="op">=</span><span class="num">1e-05</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2982" href="#t2982">2982</a></span><span class="t">    <span class="nam">param_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2983" href="#t2983">2983</a></span><span class="t">    <span class="nam">bias_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2984" href="#t2984">2984</a></span><span class="t">    <span class="nam">data_layout</span><span class="op">=</span><span class="str">'NCHW'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2985" href="#t2985">2985</a></span><span class="t">    <span class="nam">in_place</span><span class="op">=</span><span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2986" href="#t2986">2986</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2987" href="#t2987">2987</a></span><span class="t">    <span class="nam">moving_mean_name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2988" href="#t2988">2988</a></span><span class="t">    <span class="nam">moving_variance_name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2989" href="#t2989">2989</a></span><span class="t">    <span class="nam">do_model_average_for_mean_and_var</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2990" href="#t2990">2990</a></span><span class="t">    <span class="nam">use_global_stats</span><span class="op">=</span><span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2991" href="#t2991">2991</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2992" href="#t2992">2992</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2993" href="#t2993">2993</a></span><span class="t"><span class="str">    :api_attr: Static Graph</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2994" href="#t2994">2994</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2995" href="#t2995">2995</a></span><span class="t"><span class="str">    **Batch Normalization Layer**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2996" href="#t2996">2996</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2997" href="#t2997">2997</a></span><span class="t"><span class="str">    Can be used as a normalizer function for convolution or fully_connected operations.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2998" href="#t2998">2998</a></span><span class="t"><span class="str">    The required data format for this layer is one of the following:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2999" href="#t2999">2999</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3000" href="#t3000">3000</a></span><span class="t"><span class="str">    1. NHWC `[batch, in_height, in_width, in_channels]`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3001" href="#t3001">3001</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3002" href="#t3002">3002</a></span><span class="t"><span class="str">    2. NCHW `[batch, in_channels, in_height, in_width]`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3003" href="#t3003">3003</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3004" href="#t3004">3004</a></span><span class="t"><span class="str">    Refer to `Batch Normalization: Accelerating Deep Network Training by Reducing</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3005" href="#t3005">3005</a></span><span class="t"><span class="str">    Internal Covariate Shift &lt;https://arxiv.org/pdf/1502.03167.pdf>`_</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3006" href="#t3006">3006</a></span><span class="t"><span class="str">    for more details.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3007" href="#t3007">3007</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3008" href="#t3008">3008</a></span><span class="t"><span class="str">    :math:`input` is the input features over a mini-batch.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3009" href="#t3009">3009</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3010" href="#t3010">3010</a></span><span class="t"><span class="str">    ..  math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3011" href="#t3011">3011</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3012" href="#t3012">3012</a></span><span class="t"><span class="str">        \\mu_{\\beta} &amp;\\gets \\frac{1}{m} \\sum_{i=1}^{m} x_i \\qquad &amp;//\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3013" href="#t3013">3013</a></span><span class="t"><span class="str">        \ mini-batch\ mean \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3014" href="#t3014">3014</a></span><span class="t"><span class="str">        \\sigma_{\\beta}^{2} &amp;\\gets \\frac{1}{m} \\sum_{i=1}^{m}(x_i - \\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3015" href="#t3015">3015</a></span><span class="t"><span class="str">        \\mu_{\\beta})^2 \\qquad &amp;//\ mini-batch\ variance \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3016" href="#t3016">3016</a></span><span class="t"><span class="str">        \\hat{x_i} &amp;\\gets \\frac{x_i - \\mu_\\beta} {\\sqrt{\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3017" href="#t3017">3017</a></span><span class="t"><span class="str">        \\sigma_{\\beta}^{2} + \\epsilon}} \\qquad &amp;//\ normalize \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3018" href="#t3018">3018</a></span><span class="t"><span class="str">        y_i &amp;\\gets \\gamma \\hat{x_i} + \\beta \\qquad &amp;//\ scale\ and\ shift</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3019" href="#t3019">3019</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3020" href="#t3020">3020</a></span><span class="t"><span class="str">        moving\_mean = moving\_mean * momentum + mini-batch\_mean * (1. - momentum) \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3021" href="#t3021">3021</a></span><span class="t"><span class="str">        moving\_var = moving\_var * momentum + mini-batch\_var * (1. - momentum)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3022" href="#t3022">3022</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3023" href="#t3023">3023</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3024" href="#t3024">3024</a></span><span class="t"><span class="str">    moving_mean is global mean and moving_var is global variance.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3025" href="#t3025">3025</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3026" href="#t3026">3026</a></span><span class="t"><span class="str">    When use_global_stats = True, the :math:`\\mu_{\\beta}`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3027" href="#t3027">3027</a></span><span class="t"><span class="str">    and :math:`\\sigma_{\\beta}^{2}` are not the statistics of one mini-batch.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3028" href="#t3028">3028</a></span><span class="t"><span class="str">    They are global (or running) statistics. (It usually got from the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3029" href="#t3029">3029</a></span><span class="t"><span class="str">    pre-trained model.)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3030" href="#t3030">3030</a></span><span class="t"><span class="str">    The training and testing (or inference) have the same behavior:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3031" href="#t3031">3031</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3032" href="#t3032">3032</a></span><span class="t"><span class="str">    ..  math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3033" href="#t3033">3033</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3034" href="#t3034">3034</a></span><span class="t"><span class="str">        \\hat{x_i} &amp;\\gets \\frac{x_i - \\mu_\\beta} {\\sqrt{\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3035" href="#t3035">3035</a></span><span class="t"><span class="str">        \\sigma_{\\beta}^{2} + \\epsilon}}  \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3036" href="#t3036">3036</a></span><span class="t"><span class="str">        y_i &amp;\\gets \\gamma \\hat{x_i} + \\beta</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3037" href="#t3037">3037</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3038" href="#t3038">3038</a></span><span class="t"><span class="str">    Note:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3039" href="#t3039">3039</a></span><span class="t"><span class="str">        if build_strategy.sync_batch_norm=True, the batch_norm in network will use</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3040" href="#t3040">3040</a></span><span class="t"><span class="str">        sync_batch_norm automatically.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3041" href="#t3041">3041</a></span><span class="t"><span class="str">        `is_test = True` can only be used in test program and inference program, `is_test` CANNOT be set to True in train program, if you want to use global status from pre_train model in train program, please set `use_global_stats = True`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3042" href="#t3042">3042</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3043" href="#t3043">3043</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3044" href="#t3044">3044</a></span><span class="t"><span class="str">        input(Tensor): The rank of input Tensor can be 2, 3, 4, 5. The data type</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3045" href="#t3045">3045</a></span><span class="t"><span class="str">            is float16 or float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3046" href="#t3046">3046</a></span><span class="t"><span class="str">        act(string, Default None): Activation type, linear|relu|prelu|...</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3047" href="#t3047">3047</a></span><span class="t"><span class="str">        is_test (bool, Default False): A flag indicating whether it is in</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3048" href="#t3048">3048</a></span><span class="t"><span class="str">            test phrase or not.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3049" href="#t3049">3049</a></span><span class="t"><span class="str">        momentum(float|Tensor, Default 0.9): The value used for the moving_mean and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3050" href="#t3050">3050</a></span><span class="t"><span class="str">            moving_var computation. This should be a float number or a Tensor with</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3051" href="#t3051">3051</a></span><span class="t"><span class="str">            shape [1] and data type as float32. The updated formula is:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3052" href="#t3052">3052</a></span><span class="t"><span class="str">            :math:`moving\_mean = moving\_mean * momentum + new\_mean * (1. - momentum)`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3053" href="#t3053">3053</a></span><span class="t"><span class="str">            :math:`moving\_var = moving\_var * momentum + new\_var * (1. - momentum)`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3054" href="#t3054">3054</a></span><span class="t"><span class="str">            Default is 0.9.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3055" href="#t3055">3055</a></span><span class="t"><span class="str">        epsilon(float, Default 1e-05): A value added to the denominator for</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3056" href="#t3056">3056</a></span><span class="t"><span class="str">            numerical stability. Default is 1e-5.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3057" href="#t3057">3057</a></span><span class="t"><span class="str">        param_attr(ParamAttr|None): The parameter attribute for Parameter `scale`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3058" href="#t3058">3058</a></span><span class="t"><span class="str">             of batch_norm. If it is set to None or one attribute of ParamAttr, batch_norm</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3059" href="#t3059">3059</a></span><span class="t"><span class="str">             will create ParamAttr as param_attr, the name of scale can be set in ParamAttr.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3060" href="#t3060">3060</a></span><span class="t"><span class="str">             If the Initializer of the param_attr is not set, the parameter is initialized</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3061" href="#t3061">3061</a></span><span class="t"><span class="str">             with Xavier. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3062" href="#t3062">3062</a></span><span class="t"><span class="str">        bias_attr(ParamAttr|None): The parameter attribute for the bias of batch_norm.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3063" href="#t3063">3063</a></span><span class="t"><span class="str">             If it is set to None or one attribute of ParamAttr, batch_norm</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3064" href="#t3064">3064</a></span><span class="t"><span class="str">             will create ParamAttr as bias_attr, the name of bias can be set in ParamAttr.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3065" href="#t3065">3065</a></span><span class="t"><span class="str">             If the Initializer of the bias_attr is not set, the bias is initialized zero.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3066" href="#t3066">3066</a></span><span class="t"><span class="str">             Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3067" href="#t3067">3067</a></span><span class="t"><span class="str">        data_layout (str, optional): Specify the data format of the input, and the data format of the output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3068" href="#t3068">3068</a></span><span class="t"><span class="str">             will be consistent with that of the input. An optional string from: `"NCHW"`, `"NHWC"`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3069" href="#t3069">3069</a></span><span class="t"><span class="str">             The default is `"NCHW"`. When it is `"NCHW"`, the data is stored in the order of:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3070" href="#t3070">3070</a></span><span class="t"><span class="str">             `[batch_size, input_channels, input_height, input_width]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3071" href="#t3071">3071</a></span><span class="t"><span class="str">        in_place(bool, Default False): Make the input and output of batch norm reuse memory.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3072" href="#t3072">3072</a></span><span class="t"><span class="str">        name(str|None): For detailed information, please refer to :ref:`api_guide_Name`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3073" href="#t3073">3073</a></span><span class="t"><span class="str">            Usually name is no need to set and None by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3074" href="#t3074">3074</a></span><span class="t"><span class="str">        moving_mean_name(str, Default None): The name of moving_mean which store the global Mean. If it</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3075" href="#t3075">3075</a></span><span class="t"><span class="str">            is set to None, batch_norm will save global mean with a random name, otherwise, batch_norm</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3076" href="#t3076">3076</a></span><span class="t"><span class="str">            will save global mean with the string.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3077" href="#t3077">3077</a></span><span class="t"><span class="str">        moving_variance_name(str, Default None): The name of the moving_variance which store the global Variance.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3078" href="#t3078">3078</a></span><span class="t"><span class="str">            If it is set to None, batch_norm will save global variance with a random name, otherwise, batch_norm</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3079" href="#t3079">3079</a></span><span class="t"><span class="str">            will save global variance with the string.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3080" href="#t3080">3080</a></span><span class="t"><span class="str">        do_model_average_for_mean_and_var(bool, Default True): Whether parameter mean and variance should do model</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3081" href="#t3081">3081</a></span><span class="t"><span class="str">            average when model average is enabled.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3082" href="#t3082">3082</a></span><span class="t"><span class="str">        use_global_stats(bool, Default False): Whether to use global mean and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3083" href="#t3083">3083</a></span><span class="t"><span class="str">            variance. In inference or test mode, set use_global_stats to true</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3084" href="#t3084">3084</a></span><span class="t"><span class="str">            or is_test to true, and the behavior is equivalent.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3085" href="#t3085">3085</a></span><span class="t"><span class="str">            In train mode, when setting use_global_stats True, the global mean</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3086" href="#t3086">3086</a></span><span class="t"><span class="str">            and variance are also used during train period.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3087" href="#t3087">3087</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3088" href="#t3088">3088</a></span><span class="t"><span class="str">        A Tensor which is the result after applying batch normalization on the input,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3089" href="#t3089">3089</a></span><span class="t"><span class="str">        has same shape and data type with input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3090" href="#t3090">3090</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3091" href="#t3091">3091</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3092" href="#t3092">3092</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3093" href="#t3093">3093</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3094" href="#t3094">3094</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3095" href="#t3095">3095</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3096" href="#t3096">3096</a></span><span class="t"><span class="str">            </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3097" href="#t3097">3097</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3098" href="#t3098">3098</a></span><span class="t"><span class="str">            x = paddle.static.data(name='x', shape=[3, 7, 3, 7], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3099" href="#t3099">3099</a></span><span class="t"><span class="str">            hidden1 = paddle.static.nn.fc(x=x, size=200)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3100" href="#t3100">3100</a></span><span class="t"><span class="str">            print(hidden1.shape)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3101" href="#t3101">3101</a></span><span class="t"><span class="str">            # [3, 200]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3102" href="#t3102">3102</a></span><span class="t"><span class="str">            hidden2 = paddle.static.nn.batch_norm(input=hidden1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3103" href="#t3103">3103</a></span><span class="t"><span class="str">            print(hidden2.shape)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3104" href="#t3104">3104</a></span><span class="t"><span class="str">            # [3, 200]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3105" href="#t3105">3105</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3106" href="#t3106">3106</a></span><span class="t">    <span class="key">assert</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3107" href="#t3107">3107</a></span><span class="t">        <span class="nam">bias_attr</span> <span class="key">is</span> <span class="key">not</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3108" href="#t3108">3108</a></span><span class="t">    <span class="op">)</span><span class="op">,</span> <span class="str">"bias_attr should not be False in batch_norm."</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3109" href="#t3109">3109</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'batch_norm'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3110" href="#t3110">3110</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3111" href="#t3111">3111</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3112" href="#t3112">3112</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'batch_norm'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3113" href="#t3113">3113</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3114" href="#t3114">3114</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3115" href="#t3115">3115</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3116" href="#t3116">3116</a></span><span class="t">    <span class="com"># use fp32 for bn parameter</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3117" href="#t3117">3117</a></span><span class="t">    <span class="key">if</span> <span class="nam">dtype</span> <span class="op">==</span> <span class="nam">core</span><span class="op">.</span><span class="nam">VarDesc</span><span class="op">.</span><span class="nam">VarType</span><span class="op">.</span><span class="nam">FP16</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3118" href="#t3118">3118</a></span><span class="t">        <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">core</span><span class="op">.</span><span class="nam">VarDesc</span><span class="op">.</span><span class="nam">VarType</span><span class="op">.</span><span class="nam">FP32</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3119" href="#t3119">3119</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3120" href="#t3120">3120</a></span><span class="t">    <span class="nam">input_shape</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3121" href="#t3121">3121</a></span><span class="t">    <span class="key">if</span> <span class="nam">data_layout</span> <span class="op">==</span> <span class="str">'NCHW'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3122" href="#t3122">3122</a></span><span class="t">        <span class="nam">channel_num</span> <span class="op">=</span> <span class="nam">input_shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3123" href="#t3123">3123</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3124" href="#t3124">3124</a></span><span class="t">        <span class="key">if</span> <span class="nam">data_layout</span> <span class="op">==</span> <span class="str">'NHWC'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3125" href="#t3125">3125</a></span><span class="t">            <span class="nam">channel_num</span> <span class="op">=</span> <span class="nam">input_shape</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3126" href="#t3126">3126</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3127" href="#t3127">3127</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"unsupported data layout:"</span> <span class="op">+</span> <span class="nam">data_layout</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3128" href="#t3128">3128</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3129" href="#t3129">3129</a></span><span class="t">    <span class="nam">param_shape</span> <span class="op">=</span> <span class="op">[</span><span class="nam">channel_num</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3130" href="#t3130">3130</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3131" href="#t3131">3131</a></span><span class="t">    <span class="com"># create parameter</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3132" href="#t3132">3132</a></span><span class="t">    <span class="nam">scale</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3133" href="#t3133">3133</a></span><span class="t">        <span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">param_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3134" href="#t3134">3134</a></span><span class="t">        <span class="nam">shape</span><span class="op">=</span><span class="nam">param_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3135" href="#t3135">3135</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3136" href="#t3136">3136</a></span><span class="t">        <span class="nam">default_initializer</span><span class="op">=</span><span class="nam">Constant</span><span class="op">(</span><span class="num">1.0</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3137" href="#t3137">3137</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3138" href="#t3138">3138</a></span><span class="t">    <span class="nam">bias</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3139" href="#t3139">3139</a></span><span class="t">        <span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">bias_attr</span><span class="op">,</span> <span class="nam">shape</span><span class="op">=</span><span class="nam">param_shape</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">is_bias</span><span class="op">=</span><span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3140" href="#t3140">3140</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3141" href="#t3141">3141</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3142" href="#t3142">3142</a></span><span class="t">    <span class="nam">mean</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3143" href="#t3143">3143</a></span><span class="t">        <span class="nam">attr</span><span class="op">=</span><span class="nam">ParamAttr</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3144" href="#t3144">3144</a></span><span class="t">            <span class="nam">name</span><span class="op">=</span><span class="nam">moving_mean_name</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3145" href="#t3145">3145</a></span><span class="t">            <span class="nam">initializer</span><span class="op">=</span><span class="nam">Constant</span><span class="op">(</span><span class="num">0.0</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3146" href="#t3146">3146</a></span><span class="t">            <span class="nam">trainable</span><span class="op">=</span><span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3147" href="#t3147">3147</a></span><span class="t">            <span class="nam">do_model_average</span><span class="op">=</span><span class="nam">do_model_average_for_mean_and_var</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3148" href="#t3148">3148</a></span><span class="t">        <span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3149" href="#t3149">3149</a></span><span class="t">        <span class="nam">shape</span><span class="op">=</span><span class="nam">param_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3150" href="#t3150">3150</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3151" href="#t3151">3151</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3152" href="#t3152">3152</a></span><span class="t">    <span class="nam">mean</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3153" href="#t3153">3153</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3154" href="#t3154">3154</a></span><span class="t">    <span class="nam">variance</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3155" href="#t3155">3155</a></span><span class="t">        <span class="nam">attr</span><span class="op">=</span><span class="nam">ParamAttr</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3156" href="#t3156">3156</a></span><span class="t">            <span class="nam">name</span><span class="op">=</span><span class="nam">moving_variance_name</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3157" href="#t3157">3157</a></span><span class="t">            <span class="nam">initializer</span><span class="op">=</span><span class="nam">Constant</span><span class="op">(</span><span class="num">1.0</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3158" href="#t3158">3158</a></span><span class="t">            <span class="nam">trainable</span><span class="op">=</span><span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3159" href="#t3159">3159</a></span><span class="t">            <span class="nam">do_model_average</span><span class="op">=</span><span class="nam">do_model_average_for_mean_and_var</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3160" href="#t3160">3160</a></span><span class="t">        <span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3161" href="#t3161">3161</a></span><span class="t">        <span class="nam">shape</span><span class="op">=</span><span class="nam">param_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3162" href="#t3162">3162</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3163" href="#t3163">3163</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3164" href="#t3164">3164</a></span><span class="t">    <span class="nam">variance</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3165" href="#t3165">3165</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3166" href="#t3166">3166</a></span><span class="t">    <span class="com"># create output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3167" href="#t3167">3167</a></span><span class="t">    <span class="com"># mean and mean_out share the same memory</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3168" href="#t3168">3168</a></span><span class="t">    <span class="nam">mean_out</span> <span class="op">=</span> <span class="nam">mean</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3169" href="#t3169">3169</a></span><span class="t">    <span class="com"># variance and variance_out share the same memory</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3170" href="#t3170">3170</a></span><span class="t">    <span class="nam">variance_out</span> <span class="op">=</span> <span class="nam">variance</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3171" href="#t3171">3171</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3172" href="#t3172">3172</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3173" href="#t3173">3173</a></span><span class="t">        <span class="nam">inputs_has_MomemtumTensor</span> <span class="op">=</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3174" href="#t3174">3174</a></span><span class="t">        <span class="nam">attrs_has_momentum</span> <span class="op">=</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3175" href="#t3175">3175</a></span><span class="t">        <span class="nam">tmp_tensor_type</span> <span class="op">=</span> <span class="nam">core</span><span class="op">.</span><span class="nam">eager</span><span class="op">.</span><span class="nam">Tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3176" href="#t3176">3176</a></span><span class="t">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">momentum</span><span class="op">,</span> <span class="nam">tmp_tensor_type</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3177" href="#t3177">3177</a></span><span class="t">            <span class="nam">inputs_has_MomemtumTensor</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3178" href="#t3178">3178</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3179" href="#t3179">3179</a></span><span class="t">            <span class="nam">attrs_has_momentum</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3180" href="#t3180">3180</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3181" href="#t3181">3181</a></span><span class="t">        <span class="nam">attrs_</span> <span class="op">=</span> <span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3182" href="#t3182">3182</a></span><span class="t">        <span class="key">if</span> <span class="nam">attrs_has_momentum</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3183" href="#t3183">3183</a></span><span class="t">            <span class="nam">attrs_</span> <span class="op">=</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3184" href="#t3184">3184</a></span><span class="t">                <span class="str">'momentum'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3185" href="#t3185">3185</a></span><span class="t">                <span class="nam">momentum</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3186" href="#t3186">3186</a></span><span class="t">                <span class="str">'epsilon'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3187" href="#t3187">3187</a></span><span class="t">                <span class="nam">epsilon</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3188" href="#t3188">3188</a></span><span class="t">                <span class="str">'is_test'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3189" href="#t3189">3189</a></span><span class="t">                <span class="nam">is_test</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3190" href="#t3190">3190</a></span><span class="t">                <span class="str">'data_layout'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3191" href="#t3191">3191</a></span><span class="t">                <span class="nam">data_layout</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3192" href="#t3192">3192</a></span><span class="t">                <span class="str">'use_mkldnn'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3193" href="#t3193">3193</a></span><span class="t">                <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3194" href="#t3194">3194</a></span><span class="t">                <span class="str">'fuse_with_relu'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3195" href="#t3195">3195</a></span><span class="t">                <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3196" href="#t3196">3196</a></span><span class="t">                <span class="str">'use_global_stats'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3197" href="#t3197">3197</a></span><span class="t">                <span class="nam">use_global_stats</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3198" href="#t3198">3198</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3199" href="#t3199">3199</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3200" href="#t3200">3200</a></span><span class="t">            <span class="nam">attrs_</span> <span class="op">=</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3201" href="#t3201">3201</a></span><span class="t">                <span class="str">'epsilon'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3202" href="#t3202">3202</a></span><span class="t">                <span class="nam">epsilon</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3203" href="#t3203">3203</a></span><span class="t">                <span class="str">'is_test'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3204" href="#t3204">3204</a></span><span class="t">                <span class="nam">is_test</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3205" href="#t3205">3205</a></span><span class="t">                <span class="str">'data_layout'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3206" href="#t3206">3206</a></span><span class="t">                <span class="nam">data_layout</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3207" href="#t3207">3207</a></span><span class="t">                <span class="str">'use_mkldnn'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3208" href="#t3208">3208</a></span><span class="t">                <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3209" href="#t3209">3209</a></span><span class="t">                <span class="str">'fuse_with_relu'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3210" href="#t3210">3210</a></span><span class="t">                <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3211" href="#t3211">3211</a></span><span class="t">                <span class="str">'use_global_stats'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3212" href="#t3212">3212</a></span><span class="t">                <span class="nam">use_global_stats</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3213" href="#t3213">3213</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3214" href="#t3214">3214</a></span><span class="t">        <span class="key">if</span> <span class="nam">inputs_has_MomemtumTensor</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3215" href="#t3215">3215</a></span><span class="t">            <span class="nam">batch_norm_out</span><span class="op">,</span> <span class="nam">_</span><span class="op">,</span> <span class="nam">_</span><span class="op">,</span> <span class="nam">_</span><span class="op">,</span> <span class="nam">_</span><span class="op">,</span> <span class="nam">_</span> <span class="op">=</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">batch_norm</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3216" href="#t3216">3216</a></span><span class="t">                <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3217" href="#t3217">3217</a></span><span class="t">                <span class="nam">scale</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3218" href="#t3218">3218</a></span><span class="t">                <span class="nam">bias</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3219" href="#t3219">3219</a></span><span class="t">                <span class="nam">mean</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3220" href="#t3220">3220</a></span><span class="t">                <span class="nam">variance</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3221" href="#t3221">3221</a></span><span class="t">                <span class="nam">momentum</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3222" href="#t3222">3222</a></span><span class="t">                <span class="nam">mean_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3223" href="#t3223">3223</a></span><span class="t">                <span class="nam">variance_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3224" href="#t3224">3224</a></span><span class="t">                <span class="op">*</span><span class="nam">attrs_</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3225" href="#t3225">3225</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3226" href="#t3226">3226</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3227" href="#t3227">3227</a></span><span class="t">            <span class="nam">batch_norm_out</span><span class="op">,</span> <span class="nam">_</span><span class="op">,</span> <span class="nam">_</span><span class="op">,</span> <span class="nam">_</span><span class="op">,</span> <span class="nam">_</span><span class="op">,</span> <span class="nam">_</span> <span class="op">=</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">batch_norm</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3228" href="#t3228">3228</a></span><span class="t">                <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3229" href="#t3229">3229</a></span><span class="t">                <span class="nam">scale</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3230" href="#t3230">3230</a></span><span class="t">                <span class="nam">bias</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3231" href="#t3231">3231</a></span><span class="t">                <span class="nam">mean</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3232" href="#t3232">3232</a></span><span class="t">                <span class="nam">variance</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3233" href="#t3233">3233</a></span><span class="t">                <span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3234" href="#t3234">3234</a></span><span class="t">                <span class="nam">mean_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3235" href="#t3235">3235</a></span><span class="t">                <span class="nam">variance_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3236" href="#t3236">3236</a></span><span class="t">                <span class="op">*</span><span class="nam">attrs_</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3237" href="#t3237">3237</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3238" href="#t3238">3238</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3239" href="#t3239">3239</a></span><span class="t">        <span class="key">return</span> <span class="nam">dygraph_utils</span><span class="op">.</span><span class="nam">_append_activation_in_dygraph</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3240" href="#t3240">3240</a></span><span class="t">            <span class="nam">batch_norm_out</span><span class="op">,</span> <span class="nam">act</span><span class="op">=</span><span class="nam">act</span><span class="op">,</span> <span class="nam">use_mkldnn</span><span class="op">=</span><span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3241" href="#t3241">3241</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3242" href="#t3242">3242</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3243" href="#t3243">3243</a></span><span class="t">    <span class="nam">saved_mean</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3244" href="#t3244">3244</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3245" href="#t3245">3245</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3246" href="#t3246">3246</a></span><span class="t">    <span class="nam">saved_variance</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3247" href="#t3247">3247</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3248" href="#t3248">3248</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3249" href="#t3249">3249</a></span><span class="t">    <span class="nam">reserve_space</span> <span class="op">=</span> <span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3250" href="#t3250">3250</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">is_test</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3251" href="#t3251">3251</a></span><span class="t">        <span class="nam">reserve_space</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3252" href="#t3252">3252</a></span><span class="t">            <span class="nam">dtype</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span><span class="op">,</span> <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3253" href="#t3253">3253</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3254" href="#t3254">3254</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3255" href="#t3255">3255</a></span><span class="t">    <span class="nam">batch_norm_out</span> <span class="op">=</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3256" href="#t3256">3256</a></span><span class="t">        <span class="nam">input</span> <span class="key">if</span> <span class="nam">in_place</span> <span class="key">else</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3257" href="#t3257">3257</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3258" href="#t3258">3258</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3259" href="#t3259">3259</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3260" href="#t3260">3260</a></span><span class="t">        <span class="str">"X"</span><span class="op">:</span> <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3261" href="#t3261">3261</a></span><span class="t">        <span class="str">"Scale"</span><span class="op">:</span> <span class="nam">scale</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3262" href="#t3262">3262</a></span><span class="t">        <span class="str">"Bias"</span><span class="op">:</span> <span class="nam">bias</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3263" href="#t3263">3263</a></span><span class="t">        <span class="str">"Mean"</span><span class="op">:</span> <span class="nam">mean</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3264" href="#t3264">3264</a></span><span class="t">        <span class="str">"Variance"</span><span class="op">:</span> <span class="nam">variance</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3265" href="#t3265">3265</a></span><span class="t">        <span class="str">"MeanOut"</span><span class="op">:</span> <span class="nam">mean_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3266" href="#t3266">3266</a></span><span class="t">        <span class="str">"VarianceOut"</span><span class="op">:</span> <span class="nam">variance_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3267" href="#t3267">3267</a></span><span class="t">    <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3268" href="#t3268">3268</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3269" href="#t3269">3269</a></span><span class="t">        <span class="str">"epsilon"</span><span class="op">:</span> <span class="nam">epsilon</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3270" href="#t3270">3270</a></span><span class="t">        <span class="str">"is_test"</span><span class="op">:</span> <span class="nam">is_test</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3271" href="#t3271">3271</a></span><span class="t">        <span class="str">"data_layout"</span><span class="op">:</span> <span class="nam">data_layout</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3272" href="#t3272">3272</a></span><span class="t">        <span class="str">"use_mkldnn"</span><span class="op">:</span> <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3273" href="#t3273">3273</a></span><span class="t">        <span class="str">"fuse_with_relu"</span><span class="op">:</span> <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3274" href="#t3274">3274</a></span><span class="t">        <span class="str">"use_global_stats"</span><span class="op">:</span> <span class="nam">use_global_stats</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3275" href="#t3275">3275</a></span><span class="t">    <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3276" href="#t3276">3276</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">momentum</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3277" href="#t3277">3277</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">'MomemtumTensor'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">momentum</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3278" href="#t3278">3278</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3279" href="#t3279">3279</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">'momentum'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">momentum</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3280" href="#t3280">3280</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3281" href="#t3281">3281</a></span><span class="t">    <span class="nam">outputs</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3282" href="#t3282">3282</a></span><span class="t">        <span class="str">"Y"</span><span class="op">:</span> <span class="nam">batch_norm_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3283" href="#t3283">3283</a></span><span class="t">        <span class="str">"MeanOut"</span><span class="op">:</span> <span class="nam">mean_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3284" href="#t3284">3284</a></span><span class="t">        <span class="str">"VarianceOut"</span><span class="op">:</span> <span class="nam">variance_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3285" href="#t3285">3285</a></span><span class="t">        <span class="str">"SavedMean"</span><span class="op">:</span> <span class="nam">saved_mean</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3286" href="#t3286">3286</a></span><span class="t">        <span class="str">"SavedVariance"</span><span class="op">:</span> <span class="nam">saved_variance</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3287" href="#t3287">3287</a></span><span class="t">    <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3288" href="#t3288">3288</a></span><span class="t">    <span class="key">if</span> <span class="nam">reserve_space</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3289" href="#t3289">3289</a></span><span class="t">        <span class="nam">outputs</span><span class="op">[</span><span class="str">"ReserveSpace"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">reserve_space</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3290" href="#t3290">3290</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3291" href="#t3291">3291</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3292" href="#t3292">3292</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"batch_norm"</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="nam">outputs</span><span class="op">,</span> <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3293" href="#t3293">3293</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3294" href="#t3294">3294</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3295" href="#t3295">3295</a></span><span class="t">    <span class="key">return</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_activation</span><span class="op">(</span><span class="nam">batch_norm_out</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3296" href="#t3296">3296</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3297" href="#t3297">3297</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t3298" href="#t3298">3298</a></span><span class="t"><span class="key">def</span> <span class="nam">inplace_abn</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3299" href="#t3299">3299</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3300" href="#t3300">3300</a></span><span class="t">    <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3301" href="#t3301">3301</a></span><span class="t">    <span class="nam">is_test</span><span class="op">=</span><span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3302" href="#t3302">3302</a></span><span class="t">    <span class="nam">momentum</span><span class="op">=</span><span class="num">0.9</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3303" href="#t3303">3303</a></span><span class="t">    <span class="nam">epsilon</span><span class="op">=</span><span class="num">1e-05</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3304" href="#t3304">3304</a></span><span class="t">    <span class="nam">param_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3305" href="#t3305">3305</a></span><span class="t">    <span class="nam">bias_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3306" href="#t3306">3306</a></span><span class="t">    <span class="nam">data_layout</span><span class="op">=</span><span class="str">'NCHW'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3307" href="#t3307">3307</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3308" href="#t3308">3308</a></span><span class="t">    <span class="nam">moving_mean_name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3309" href="#t3309">3309</a></span><span class="t">    <span class="nam">moving_variance_name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3310" href="#t3310">3310</a></span><span class="t">    <span class="nam">do_model_average_for_mean_and_var</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3311" href="#t3311">3311</a></span><span class="t">    <span class="nam">use_global_stats</span><span class="op">=</span><span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3312" href="#t3312">3312</a></span><span class="t">    <span class="nam">act_alpha</span><span class="op">=</span><span class="num">1.0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3313" href="#t3313">3313</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3314" href="#t3314">3314</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3315" href="#t3315">3315</a></span><span class="t"><span class="str">    **In-place Activation Batch Normalization Layer**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3316" href="#t3316">3316</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3317" href="#t3317">3317</a></span><span class="t"><span class="str">    This layer calculates batch normalization and activation with in-place memory.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3318" href="#t3318">3318</a></span><span class="t"><span class="str">    For batch normalization calculations, see `fluid.layers.batch_norm`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3319" href="#t3319">3319</a></span><span class="t"><span class="str">    For in-place activation batch normalization, see `In-Place Activated BatchNorm for</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3320" href="#t3320">3320</a></span><span class="t"><span class="str">    Memory-Optimized Training of DNNs &lt;https://arxiv.org/abs/1712.02616>`_</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3321" href="#t3321">3321</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3322" href="#t3322">3322</a></span><span class="t"><span class="str">    `inplace_abn` only support activation type as `None`, `identity`, `leaky_relu`,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3323" href="#t3323">3323</a></span><span class="t"><span class="str">    `elu` currently.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3324" href="#t3324">3324</a></span><span class="t"><span class="str">    `inplace_abn` only support data type as `float32`, `float64` currently.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3325" href="#t3325">3325</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3326" href="#t3326">3326</a></span><span class="t"><span class="str">    Note:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3327" href="#t3327">3327</a></span><span class="t"><span class="str">        if build_strategy.sync_batch_norm=True, the batch_norm in network will use</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3328" href="#t3328">3328</a></span><span class="t"><span class="str">        sync_batch_norm automatically.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3329" href="#t3329">3329</a></span><span class="t"><span class="str">        `is_test = True` can only be used in test program and inference program, `is_test` CANNOT be set to True in train program, if you want to use global status from pre_train model in train program, please set `use_global_stats = True`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3330" href="#t3330">3330</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3331" href="#t3331">3331</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3332" href="#t3332">3332</a></span><span class="t"><span class="str">        input(Variable): The rank of input variable can be 2, 3, 4, 5. The data type</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3333" href="#t3333">3333</a></span><span class="t"><span class="str">            is float16 or float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3334" href="#t3334">3334</a></span><span class="t"><span class="str">        act(string, Default None): Activation type, linear|relu|prelu|...</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3335" href="#t3335">3335</a></span><span class="t"><span class="str">        is_test (bool, Default False): A flag indicating whether it is in</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3336" href="#t3336">3336</a></span><span class="t"><span class="str">            test phrase or not.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3337" href="#t3337">3337</a></span><span class="t"><span class="str">        momentum(float|Variable, Default 0.9): The value used for the moving_mean and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3338" href="#t3338">3338</a></span><span class="t"><span class="str">            moving_var computation. This should be a float number or a Variable with</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3339" href="#t3339">3339</a></span><span class="t"><span class="str">            shape [1] and data type as float32. The updated formula is:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3340" href="#t3340">3340</a></span><span class="t"><span class="str">            :math:`moving\_mean = moving\_mean * momentum + new\_mean * (1. - momentum)`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3341" href="#t3341">3341</a></span><span class="t"><span class="str">            :math:`moving\_var = moving\_var * momentum + new\_var * (1. - momentum)`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3342" href="#t3342">3342</a></span><span class="t"><span class="str">            Default is 0.9.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3343" href="#t3343">3343</a></span><span class="t"><span class="str">        epsilon(float, Default 1e-05): A value added to the denominator for</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3344" href="#t3344">3344</a></span><span class="t"><span class="str">            numerical stability. Default is 1e-5.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3345" href="#t3345">3345</a></span><span class="t"><span class="str">        param_attr(ParamAttr|None): The parameter attribute for Parameter `scale`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3346" href="#t3346">3346</a></span><span class="t"><span class="str">             of inplace_abn. If it is set to None or one attribute of ParamAttr, inplace_abn</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3347" href="#t3347">3347</a></span><span class="t"><span class="str">             will create ParamAttr as param_attr, the name of scale can be set in ParamAttr.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3348" href="#t3348">3348</a></span><span class="t"><span class="str">             If the Initializer of the param_attr is not set, the parameter is initialized</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3349" href="#t3349">3349</a></span><span class="t"><span class="str">             with Xavier. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3350" href="#t3350">3350</a></span><span class="t"><span class="str">        bias_attr(ParamAttr|None): The parameter attribute for the bias of inplace_abn.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3351" href="#t3351">3351</a></span><span class="t"><span class="str">             If it is set to None or one attribute of ParamAttr, inplace_abn</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3352" href="#t3352">3352</a></span><span class="t"><span class="str">             will create ParamAttr as bias_attr, the name of bias can be set in ParamAttr.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3353" href="#t3353">3353</a></span><span class="t"><span class="str">             If the Initializer of the bias_attr is not set, the bias is initialized zero.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3354" href="#t3354">3354</a></span><span class="t"><span class="str">             Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3355" href="#t3355">3355</a></span><span class="t"><span class="str">        data_layout (str, optional): Specify the data format of the input, and the data format of the output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3356" href="#t3356">3356</a></span><span class="t"><span class="str">             will be consistent with that of the input. An optional string from: `"NCHW"`, `"NHWC"`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3357" href="#t3357">3357</a></span><span class="t"><span class="str">             The default is `"NCHW"`. When it is `"NCHW"`, the data is stored in the order of:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3358" href="#t3358">3358</a></span><span class="t"><span class="str">             `[batch_size, input_channels, input_height, input_width]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3359" href="#t3359">3359</a></span><span class="t"><span class="str">        name(str|None): For detailed information, please refer to :ref:`api_guide_Name`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3360" href="#t3360">3360</a></span><span class="t"><span class="str">            Usually name is no need to set and None by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3361" href="#t3361">3361</a></span><span class="t"><span class="str">        moving_mean_name(str, Default None): The name of moving_mean which store the global Mean. If it</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3362" href="#t3362">3362</a></span><span class="t"><span class="str">            is set to None, inplace_abn will save global mean with a random name, otherwise, inplace_abn</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3363" href="#t3363">3363</a></span><span class="t"><span class="str">            will save global mean with the string.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3364" href="#t3364">3364</a></span><span class="t"><span class="str">        moving_variance_name(str, Default None): The name of the moving_variance which store the global Variance.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3365" href="#t3365">3365</a></span><span class="t"><span class="str">            If it is set to None, inplace_abn, will save global variance with a random name, otherwise, inplace_abn</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3366" href="#t3366">3366</a></span><span class="t"><span class="str">            will save global variance with the string.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3367" href="#t3367">3367</a></span><span class="t"><span class="str">        do_model_average_for_mean_and_var(bool, Default True): Whether parameter mean and variance should do model</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3368" href="#t3368">3368</a></span><span class="t"><span class="str">            average when model average is enabled.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3369" href="#t3369">3369</a></span><span class="t"><span class="str">        use_global_stats(bool, Default False): Whether to use global mean and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3370" href="#t3370">3370</a></span><span class="t"><span class="str">            variance. In inference or test mode, set use_global_stats to true</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3371" href="#t3371">3371</a></span><span class="t"><span class="str">            or is_test to true, and the behavior is equivalent.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3372" href="#t3372">3372</a></span><span class="t"><span class="str">            In train mode, when setting use_global_stats True, the global mean</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3373" href="#t3373">3373</a></span><span class="t"><span class="str">            and variance are also used during train period.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3374" href="#t3374">3374</a></span><span class="t"><span class="str">        act_alpha(float, Default 1.0): when activation is in ['elu', 'identity', 'leaky_relu'],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3375" href="#t3375">3375</a></span><span class="t"><span class="str">            inplace activative batch normalization will be used, and alpha parameter for activation</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3376" href="#t3376">3376</a></span><span class="t"><span class="str">            can be given by this parameter.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3377" href="#t3377">3377</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3378" href="#t3378">3378</a></span><span class="t"><span class="str">        A Variable holding Tensor which is the result after applying batch normalization and activation on the input,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3379" href="#t3379">3379</a></span><span class="t"><span class="str">        has same shape and data type with input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3380" href="#t3380">3380</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3381" href="#t3381">3381</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3382" href="#t3382">3382</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3383" href="#t3383">3383</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3384" href="#t3384">3384</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3385" href="#t3385">3385</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3386" href="#t3386">3386</a></span><span class="t"><span class="str">            x = fluid.data(name='x', shape=[3, 7, 3, 7], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3387" href="#t3387">3387</a></span><span class="t"><span class="str">            hidden1 = fluid.layers.fc(input=x, size=200, param_attr='fc1.w')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3388" href="#t3388">3388</a></span><span class="t"><span class="str">            hidden2 = fluid.layers.inplace_abn(input=hidden1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3389" href="#t3389">3389</a></span><span class="t"><span class="str">            hidden3 = fluid.layers.inplace_abn(input=hidden2, act='leaky_relu', act_alpha=0.2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3390" href="#t3390">3390</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3391" href="#t3391">3391</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3392" href="#t3392">3392</a></span><span class="t">    <span class="key">assert</span> <span class="nam">act</span> <span class="key">in</span> <span class="op">[</span><span class="key">None</span><span class="op">,</span> <span class="str">'identity'</span><span class="op">,</span> <span class="str">'leaky_relu'</span><span class="op">,</span> <span class="str">'elu'</span><span class="op">]</span><span class="op">,</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3393" href="#t3393">3393</a></span><span class="t">        <span class="str">"inplace_abn only support act as None, 'identity', "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3394" href="#t3394">3394</a></span><span class="t">        <span class="str">"'leaky_relu', 'elu' currently"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3395" href="#t3395">3395</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3396" href="#t3396">3396</a></span><span class="t">    <span class="key">assert</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3397" href="#t3397">3397</a></span><span class="t">        <span class="nam">bias_attr</span> <span class="key">is</span> <span class="key">not</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3398" href="#t3398">3398</a></span><span class="t">    <span class="op">)</span><span class="op">,</span> <span class="str">"bias_attr should not be False in inplace_abn."</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3399" href="#t3399">3399</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'inplace_abn'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3400" href="#t3400">3400</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3401" href="#t3401">3401</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3402" href="#t3402">3402</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'inplace_abn'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3403" href="#t3403">3403</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3404" href="#t3404">3404</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3405" href="#t3405">3405</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3406" href="#t3406">3406</a></span><span class="t">    <span class="nam">input_shape</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3407" href="#t3407">3407</a></span><span class="t">    <span class="key">if</span> <span class="nam">data_layout</span> <span class="op">==</span> <span class="str">'NCHW'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3408" href="#t3408">3408</a></span><span class="t">        <span class="nam">channel_num</span> <span class="op">=</span> <span class="nam">input_shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3409" href="#t3409">3409</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3410" href="#t3410">3410</a></span><span class="t">        <span class="key">if</span> <span class="nam">data_layout</span> <span class="op">==</span> <span class="str">'NHWC'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3411" href="#t3411">3411</a></span><span class="t">            <span class="nam">channel_num</span> <span class="op">=</span> <span class="nam">input_shape</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3412" href="#t3412">3412</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3413" href="#t3413">3413</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"unsupported data layout:"</span> <span class="op">+</span> <span class="nam">data_layout</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3414" href="#t3414">3414</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3415" href="#t3415">3415</a></span><span class="t">    <span class="nam">param_shape</span> <span class="op">=</span> <span class="op">[</span><span class="nam">channel_num</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3416" href="#t3416">3416</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3417" href="#t3417">3417</a></span><span class="t">    <span class="com"># create parameter</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3418" href="#t3418">3418</a></span><span class="t">    <span class="nam">scale</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3419" href="#t3419">3419</a></span><span class="t">        <span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">param_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3420" href="#t3420">3420</a></span><span class="t">        <span class="nam">shape</span><span class="op">=</span><span class="nam">param_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3421" href="#t3421">3421</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3422" href="#t3422">3422</a></span><span class="t">        <span class="nam">default_initializer</span><span class="op">=</span><span class="nam">Constant</span><span class="op">(</span><span class="num">1.0</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3423" href="#t3423">3423</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3424" href="#t3424">3424</a></span><span class="t">    <span class="nam">bias</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3425" href="#t3425">3425</a></span><span class="t">        <span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">bias_attr</span><span class="op">,</span> <span class="nam">shape</span><span class="op">=</span><span class="nam">param_shape</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">is_bias</span><span class="op">=</span><span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3426" href="#t3426">3426</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3427" href="#t3427">3427</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3428" href="#t3428">3428</a></span><span class="t">    <span class="nam">mean</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3429" href="#t3429">3429</a></span><span class="t">        <span class="nam">attr</span><span class="op">=</span><span class="nam">ParamAttr</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3430" href="#t3430">3430</a></span><span class="t">            <span class="nam">name</span><span class="op">=</span><span class="nam">moving_mean_name</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3431" href="#t3431">3431</a></span><span class="t">            <span class="nam">initializer</span><span class="op">=</span><span class="nam">Constant</span><span class="op">(</span><span class="num">0.0</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3432" href="#t3432">3432</a></span><span class="t">            <span class="nam">trainable</span><span class="op">=</span><span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3433" href="#t3433">3433</a></span><span class="t">            <span class="nam">do_model_average</span><span class="op">=</span><span class="nam">do_model_average_for_mean_and_var</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3434" href="#t3434">3434</a></span><span class="t">        <span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3435" href="#t3435">3435</a></span><span class="t">        <span class="nam">shape</span><span class="op">=</span><span class="nam">param_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3436" href="#t3436">3436</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3437" href="#t3437">3437</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3438" href="#t3438">3438</a></span><span class="t">    <span class="nam">mean</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3439" href="#t3439">3439</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3440" href="#t3440">3440</a></span><span class="t">    <span class="nam">variance</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3441" href="#t3441">3441</a></span><span class="t">        <span class="nam">attr</span><span class="op">=</span><span class="nam">ParamAttr</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3442" href="#t3442">3442</a></span><span class="t">            <span class="nam">name</span><span class="op">=</span><span class="nam">moving_variance_name</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3443" href="#t3443">3443</a></span><span class="t">            <span class="nam">initializer</span><span class="op">=</span><span class="nam">Constant</span><span class="op">(</span><span class="num">1.0</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3444" href="#t3444">3444</a></span><span class="t">            <span class="nam">trainable</span><span class="op">=</span><span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3445" href="#t3445">3445</a></span><span class="t">            <span class="nam">do_model_average</span><span class="op">=</span><span class="nam">do_model_average_for_mean_and_var</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3446" href="#t3446">3446</a></span><span class="t">        <span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3447" href="#t3447">3447</a></span><span class="t">        <span class="nam">shape</span><span class="op">=</span><span class="nam">param_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3448" href="#t3448">3448</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3449" href="#t3449">3449</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3450" href="#t3450">3450</a></span><span class="t">    <span class="nam">variance</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3451" href="#t3451">3451</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3452" href="#t3452">3452</a></span><span class="t">    <span class="com"># create output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3453" href="#t3453">3453</a></span><span class="t">    <span class="com"># mean and mean_out share the same memory</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3454" href="#t3454">3454</a></span><span class="t">    <span class="nam">mean_out</span> <span class="op">=</span> <span class="nam">mean</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3455" href="#t3455">3455</a></span><span class="t">    <span class="com"># variance and variance out share the same memory</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3456" href="#t3456">3456</a></span><span class="t">    <span class="nam">variance_out</span> <span class="op">=</span> <span class="nam">variance</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3457" href="#t3457">3457</a></span><span class="t">    <span class="com"># batch_norm_out and input share the same memory</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3458" href="#t3458">3458</a></span><span class="t">    <span class="nam">batch_norm_out</span> <span class="op">=</span> <span class="nam">input</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3459" href="#t3459">3459</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3460" href="#t3460">3460</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3461" href="#t3461">3461</a></span><span class="t">        <span class="nam">inputs_has_MomemtumTensor</span> <span class="op">=</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3462" href="#t3462">3462</a></span><span class="t">        <span class="nam">attrs_has_momentum</span> <span class="op">=</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3463" href="#t3463">3463</a></span><span class="t">        <span class="nam">tmp_tensor_type</span> <span class="op">=</span> <span class="nam">core</span><span class="op">.</span><span class="nam">eager</span><span class="op">.</span><span class="nam">Tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3464" href="#t3464">3464</a></span><span class="t">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">momentum</span><span class="op">,</span> <span class="nam">tmp_tensor_type</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3465" href="#t3465">3465</a></span><span class="t">            <span class="nam">inputs_has_MomemtumTensor</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3466" href="#t3466">3466</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3467" href="#t3467">3467</a></span><span class="t">            <span class="nam">attrs_has_momentum</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3468" href="#t3468">3468</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3469" href="#t3469">3469</a></span><span class="t">        <span class="nam">attrs__</span> <span class="op">=</span> <span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3470" href="#t3470">3470</a></span><span class="t">        <span class="key">if</span> <span class="nam">attrs_has_momentum</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3471" href="#t3471">3471</a></span><span class="t">            <span class="nam">attrs__</span> <span class="op">=</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3472" href="#t3472">3472</a></span><span class="t">                <span class="str">'momentum'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3473" href="#t3473">3473</a></span><span class="t">                <span class="nam">momentum</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3474" href="#t3474">3474</a></span><span class="t">                <span class="str">'epsilon'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3475" href="#t3475">3475</a></span><span class="t">                <span class="nam">epsilon</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3476" href="#t3476">3476</a></span><span class="t">                <span class="str">'is_test'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3477" href="#t3477">3477</a></span><span class="t">                <span class="nam">is_test</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3478" href="#t3478">3478</a></span><span class="t">                <span class="str">'data_layout'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3479" href="#t3479">3479</a></span><span class="t">                <span class="nam">data_layout</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3480" href="#t3480">3480</a></span><span class="t">                <span class="str">'use_mkldnn'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3481" href="#t3481">3481</a></span><span class="t">                <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3482" href="#t3482">3482</a></span><span class="t">                <span class="str">'fuse_with_relu'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3483" href="#t3483">3483</a></span><span class="t">                <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3484" href="#t3484">3484</a></span><span class="t">                <span class="str">'use_global_stats'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3485" href="#t3485">3485</a></span><span class="t">                <span class="nam">use_global_stats</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3486" href="#t3486">3486</a></span><span class="t">                <span class="str">'activation'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3487" href="#t3487">3487</a></span><span class="t">                <span class="nam">act</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3488" href="#t3488">3488</a></span><span class="t">                <span class="str">'alpha'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3489" href="#t3489">3489</a></span><span class="t">                <span class="nam">act_alpha</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3490" href="#t3490">3490</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3491" href="#t3491">3491</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3492" href="#t3492">3492</a></span><span class="t">            <span class="nam">attrs__</span> <span class="op">=</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3493" href="#t3493">3493</a></span><span class="t">                <span class="str">'epsilon'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3494" href="#t3494">3494</a></span><span class="t">                <span class="nam">epsilon</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3495" href="#t3495">3495</a></span><span class="t">                <span class="str">'is_test'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3496" href="#t3496">3496</a></span><span class="t">                <span class="nam">is_test</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3497" href="#t3497">3497</a></span><span class="t">                <span class="str">'data_layout'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3498" href="#t3498">3498</a></span><span class="t">                <span class="nam">data_layout</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3499" href="#t3499">3499</a></span><span class="t">                <span class="str">'use_mkldnn'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3500" href="#t3500">3500</a></span><span class="t">                <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3501" href="#t3501">3501</a></span><span class="t">                <span class="str">'fuse_with_relu'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3502" href="#t3502">3502</a></span><span class="t">                <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3503" href="#t3503">3503</a></span><span class="t">                <span class="str">'use_global_stats'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3504" href="#t3504">3504</a></span><span class="t">                <span class="nam">use_global_stats</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3505" href="#t3505">3505</a></span><span class="t">                <span class="str">'activation'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3506" href="#t3506">3506</a></span><span class="t">                <span class="nam">act</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3507" href="#t3507">3507</a></span><span class="t">                <span class="str">'alpha'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3508" href="#t3508">3508</a></span><span class="t">                <span class="nam">act_alpha</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3509" href="#t3509">3509</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3510" href="#t3510">3510</a></span><span class="t">        <span class="key">if</span> <span class="nam">inputs_has_MomemtumTensor</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3511" href="#t3511">3511</a></span><span class="t">            <span class="nam">batch_norm_out</span><span class="op">,</span> <span class="nam">_</span><span class="op">,</span> <span class="nam">_</span><span class="op">,</span> <span class="nam">_</span><span class="op">,</span> <span class="nam">_</span><span class="op">,</span> <span class="nam">_</span> <span class="op">=</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">inplace_abn_</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3512" href="#t3512">3512</a></span><span class="t">                <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3513" href="#t3513">3513</a></span><span class="t">                <span class="nam">scale</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3514" href="#t3514">3514</a></span><span class="t">                <span class="nam">bias</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3515" href="#t3515">3515</a></span><span class="t">                <span class="nam">mean</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3516" href="#t3516">3516</a></span><span class="t">                <span class="nam">variance</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3517" href="#t3517">3517</a></span><span class="t">                <span class="nam">momentum</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3518" href="#t3518">3518</a></span><span class="t">                <span class="nam">mean_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3519" href="#t3519">3519</a></span><span class="t">                <span class="nam">variance_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3520" href="#t3520">3520</a></span><span class="t">                <span class="op">*</span><span class="nam">attrs__</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3521" href="#t3521">3521</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3522" href="#t3522">3522</a></span><span class="t">            <span class="key">return</span> <span class="nam">batch_norm_out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3523" href="#t3523">3523</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3524" href="#t3524">3524</a></span><span class="t">            <span class="nam">batch_norm_out</span><span class="op">,</span> <span class="nam">_</span><span class="op">,</span> <span class="nam">_</span><span class="op">,</span> <span class="nam">_</span><span class="op">,</span> <span class="nam">_</span><span class="op">,</span> <span class="nam">_</span> <span class="op">=</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">inplace_abn_</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3525" href="#t3525">3525</a></span><span class="t">                <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3526" href="#t3526">3526</a></span><span class="t">                <span class="nam">scale</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3527" href="#t3527">3527</a></span><span class="t">                <span class="nam">bias</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3528" href="#t3528">3528</a></span><span class="t">                <span class="nam">mean</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3529" href="#t3529">3529</a></span><span class="t">                <span class="nam">variance</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3530" href="#t3530">3530</a></span><span class="t">                <span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3531" href="#t3531">3531</a></span><span class="t">                <span class="nam">mean_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3532" href="#t3532">3532</a></span><span class="t">                <span class="nam">variance_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3533" href="#t3533">3533</a></span><span class="t">                <span class="op">*</span><span class="nam">attrs__</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3534" href="#t3534">3534</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3535" href="#t3535">3535</a></span><span class="t">            <span class="key">return</span> <span class="nam">batch_norm_out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3536" href="#t3536">3536</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3537" href="#t3537">3537</a></span><span class="t">    <span class="nam">saved_mean</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3538" href="#t3538">3538</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3539" href="#t3539">3539</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3540" href="#t3540">3540</a></span><span class="t">    <span class="nam">saved_variance</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3541" href="#t3541">3541</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3542" href="#t3542">3542</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3543" href="#t3543">3543</a></span><span class="t">    <span class="nam">reserve_space</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3544" href="#t3544">3544</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3545" href="#t3545">3545</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3546" href="#t3546">3546</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3547" href="#t3547">3547</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3548" href="#t3548">3548</a></span><span class="t">        <span class="str">"X"</span><span class="op">:</span> <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3549" href="#t3549">3549</a></span><span class="t">        <span class="str">"Scale"</span><span class="op">:</span> <span class="nam">scale</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3550" href="#t3550">3550</a></span><span class="t">        <span class="str">"Bias"</span><span class="op">:</span> <span class="nam">bias</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3551" href="#t3551">3551</a></span><span class="t">        <span class="str">"Mean"</span><span class="op">:</span> <span class="nam">mean</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3552" href="#t3552">3552</a></span><span class="t">        <span class="str">"Variance"</span><span class="op">:</span> <span class="nam">variance</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3553" href="#t3553">3553</a></span><span class="t">    <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3554" href="#t3554">3554</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3555" href="#t3555">3555</a></span><span class="t">        <span class="str">"epsilon"</span><span class="op">:</span> <span class="nam">epsilon</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3556" href="#t3556">3556</a></span><span class="t">        <span class="str">"is_test"</span><span class="op">:</span> <span class="nam">is_test</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3557" href="#t3557">3557</a></span><span class="t">        <span class="str">"data_layout"</span><span class="op">:</span> <span class="nam">data_layout</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3558" href="#t3558">3558</a></span><span class="t">        <span class="str">"use_mkldnn"</span><span class="op">:</span> <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3559" href="#t3559">3559</a></span><span class="t">        <span class="str">"fuse_with_relu"</span><span class="op">:</span> <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3560" href="#t3560">3560</a></span><span class="t">        <span class="str">"use_global_stats"</span><span class="op">:</span> <span class="nam">use_global_stats</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3561" href="#t3561">3561</a></span><span class="t">        <span class="str">"activation"</span><span class="op">:</span> <span class="nam">act</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3562" href="#t3562">3562</a></span><span class="t">        <span class="str">"alpha"</span><span class="op">:</span> <span class="nam">act_alpha</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3563" href="#t3563">3563</a></span><span class="t">    <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3564" href="#t3564">3564</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">momentum</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3565" href="#t3565">3565</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">'MomemtumTensor'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">momentum</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3566" href="#t3566">3566</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3567" href="#t3567">3567</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">'momentum'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">momentum</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3568" href="#t3568">3568</a></span><span class="t">    <span class="nam">outputs</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3569" href="#t3569">3569</a></span><span class="t">        <span class="str">"Y"</span><span class="op">:</span> <span class="nam">batch_norm_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3570" href="#t3570">3570</a></span><span class="t">        <span class="str">"MeanOut"</span><span class="op">:</span> <span class="nam">mean_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3571" href="#t3571">3571</a></span><span class="t">        <span class="str">"VarianceOut"</span><span class="op">:</span> <span class="nam">variance_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3572" href="#t3572">3572</a></span><span class="t">        <span class="str">"SavedMean"</span><span class="op">:</span> <span class="nam">saved_mean</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3573" href="#t3573">3573</a></span><span class="t">        <span class="str">"SavedVariance"</span><span class="op">:</span> <span class="nam">saved_variance</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3574" href="#t3574">3574</a></span><span class="t">    <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3575" href="#t3575">3575</a></span><span class="t">    <span class="key">if</span> <span class="nam">reserve_space</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3576" href="#t3576">3576</a></span><span class="t">        <span class="nam">outputs</span><span class="op">[</span><span class="str">"ReserveSpace"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">reserve_space</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3577" href="#t3577">3577</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3578" href="#t3578">3578</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3579" href="#t3579">3579</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"inplace_abn"</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="nam">outputs</span><span class="op">,</span> <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3580" href="#t3580">3580</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3581" href="#t3581">3581</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3582" href="#t3582">3582</a></span><span class="t">    <span class="key">return</span> <span class="nam">batch_norm_out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3583" href="#t3583">3583</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3584" href="#t3584">3584</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t3585" href="#t3585">3585</a></span><span class="t"><span class="key">def</span> <span class="nam">instance_norm</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3586" href="#t3586">3586</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span> <span class="nam">epsilon</span><span class="op">=</span><span class="num">1e-05</span><span class="op">,</span> <span class="nam">param_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">bias_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3587" href="#t3587">3587</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3588" href="#t3588">3588</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3589" href="#t3589">3589</a></span><span class="t"><span class="str">    :api_attr: Static Graph</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3590" href="#t3590">3590</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3591" href="#t3591">3591</a></span><span class="t"><span class="str">    **Instance Normalization Layer**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3592" href="#t3592">3592</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3593" href="#t3593">3593</a></span><span class="t"><span class="str">    Can be used as a normalizer function for convolution or fully_connected operations.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3594" href="#t3594">3594</a></span><span class="t"><span class="str">    The required data format for this layer is one of the following:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3595" href="#t3595">3595</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3596" href="#t3596">3596</a></span><span class="t"><span class="str">    DataLayout: NCHW `[batch, in_channels, in_height, in_width]`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3597" href="#t3597">3597</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3598" href="#t3598">3598</a></span><span class="t"><span class="str">    Refer to `Instance Normalization: The Missing Ingredient for</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3599" href="#t3599">3599</a></span><span class="t"><span class="str">    Fast Stylization &lt;https://arxiv.org/pdf/1607.08022.pdf>`_</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3600" href="#t3600">3600</a></span><span class="t"><span class="str">    for more details.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3601" href="#t3601">3601</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3602" href="#t3602">3602</a></span><span class="t"><span class="str">    :math:`input` is the input features over a mini-batch.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3603" href="#t3603">3603</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3604" href="#t3604">3604</a></span><span class="t"><span class="str">    ..  math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3605" href="#t3605">3605</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3606" href="#t3606">3606</a></span><span class="t"><span class="str">        \\mu_{\\beta} &amp;\\gets \\frac{1}{HW} \\sum_{i=1}^{HW} x_i \\qquad &amp;//\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3607" href="#t3607">3607</a></span><span class="t"><span class="str">        \\ mean\ of\ one\  feature\ map\ in\ mini-batch \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3608" href="#t3608">3608</a></span><span class="t"><span class="str">        \\sigma_{\\beta}^{2} &amp;\\gets \\frac{1}{HW} \\sum_{i=1}^{HW}(x_i - \\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3609" href="#t3609">3609</a></span><span class="t"><span class="str">        \\mu_{\\beta})^2 \\qquad &amp;//\ variance\ of\ one\ feature\ map\ in\ mini-batch \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3610" href="#t3610">3610</a></span><span class="t"><span class="str">        \\hat{x_i} &amp;\\gets \\frac{x_i - \\mu_\\beta} {\\sqrt{\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3611" href="#t3611">3611</a></span><span class="t"><span class="str">        \\sigma_{\\beta}^{2} + \\epsilon}} \\qquad &amp;//\ normalize \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3612" href="#t3612">3612</a></span><span class="t"><span class="str">        y_i &amp;\\gets \\gamma \\hat{x_i} + \\beta \\qquad &amp;//\ scale\ and\ shift</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3613" href="#t3613">3613</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3614" href="#t3614">3614</a></span><span class="t"><span class="str">    Note:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3615" href="#t3615">3615</a></span><span class="t"><span class="str">        `H` means height of feature map, `W` means width of feature map.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3616" href="#t3616">3616</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3617" href="#t3617">3617</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3618" href="#t3618">3618</a></span><span class="t"><span class="str">        input(Tensor): The rank of input tensor can be 2, 3, 4, 5.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3619" href="#t3619">3619</a></span><span class="t"><span class="str">            The data type is float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3620" href="#t3620">3620</a></span><span class="t"><span class="str">        epsilon(float, Default 1e-05): A value added to the denominator for</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3621" href="#t3621">3621</a></span><span class="t"><span class="str">            numerical stability. Default is 1e-5.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3622" href="#t3622">3622</a></span><span class="t"><span class="str">        param_attr(ParamAttr|None|bool, optional): The parameter attribute for Parameter `scale`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3623" href="#t3623">3623</a></span><span class="t"><span class="str">             of instance_norm. If it is set to None or one attribute of ParamAttr, instance_norm</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3624" href="#t3624">3624</a></span><span class="t"><span class="str">             will create ParamAttr as param_attr, the name of scale can be set in ParamAttr.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3625" href="#t3625">3625</a></span><span class="t"><span class="str">             If the Initializer of the param_attr is not set, the parameter is initialized</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3626" href="#t3626">3626</a></span><span class="t"><span class="str">             with Xavier. If the param_attr is set to False, instance_norm will not create param_attr.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3627" href="#t3627">3627</a></span><span class="t"><span class="str">             Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3628" href="#t3628">3628</a></span><span class="t"><span class="str">        bias_attr(ParamAttr|None|bool, optional): The parameter attribute for the bias of instance_norm.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3629" href="#t3629">3629</a></span><span class="t"><span class="str">             If it is set to None or one attribute of ParamAttr, instance_norm</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3630" href="#t3630">3630</a></span><span class="t"><span class="str">             will create ParamAttr as bias_attr, the name of bias can be set in ParamAttr.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3631" href="#t3631">3631</a></span><span class="t"><span class="str">             If the Initializer of the bias_attr is not set, the bias is initialized zero.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3632" href="#t3632">3632</a></span><span class="t"><span class="str">             If the bias_attr is set to False, instance_norm will not create bias_attr.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3633" href="#t3633">3633</a></span><span class="t"><span class="str">             Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3634" href="#t3634">3634</a></span><span class="t"><span class="str">        name(string, Default None): A name for this layer(optional). If set None, the layer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3635" href="#t3635">3635</a></span><span class="t"><span class="str">            will be named automatically.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3636" href="#t3636">3636</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3637" href="#t3637">3637</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3638" href="#t3638">3638</a></span><span class="t"><span class="str">        A Tensor which is the result after applying instance normalization on the input,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3639" href="#t3639">3639</a></span><span class="t"><span class="str">        has same shape and data type with input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3640" href="#t3640">3640</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3641" href="#t3641">3641</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3642" href="#t3642">3642</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3643" href="#t3643">3643</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3644" href="#t3644">3644</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3645" href="#t3645">3645</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3646" href="#t3646">3646</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3647" href="#t3647">3647</a></span><span class="t"><span class="str">            x = paddle.static.data(name='x', shape=[3, 7, 3, 7], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3648" href="#t3648">3648</a></span><span class="t"><span class="str">            hidden1 = paddle.static.nn.fc(x, size=200)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3649" href="#t3649">3649</a></span><span class="t"><span class="str">            hidden2 = paddle.static.nn.instance_norm(hidden1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3650" href="#t3650">3650</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3651" href="#t3651">3651</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3652" href="#t3652">3652</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'instance_norm'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3653" href="#t3653">3653</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3654" href="#t3654">3654</a></span><span class="t">    <span class="key">if</span> <span class="nam">param_attr</span> <span class="key">is</span> <span class="key">False</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3655" href="#t3655">3655</a></span><span class="t">        <span class="key">assert</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3656" href="#t3656">3656</a></span><span class="t">            <span class="nam">bias_attr</span> <span class="key">is</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3657" href="#t3657">3657</a></span><span class="t">        <span class="op">)</span><span class="op">,</span> <span class="str">"param_attr and bias_attr must be set to Fasle at the same time in instance_norm"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3658" href="#t3658">3658</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3659" href="#t3659">3659</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'instance_norm'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3660" href="#t3660">3660</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3661" href="#t3661">3661</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3662" href="#t3662">3662</a></span><span class="t">    <span class="com"># use fp32 for in parameter</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3663" href="#t3663">3663</a></span><span class="t">    <span class="key">if</span> <span class="nam">dtype</span> <span class="op">==</span> <span class="nam">core</span><span class="op">.</span><span class="nam">VarDesc</span><span class="op">.</span><span class="nam">VarType</span><span class="op">.</span><span class="nam">FP16</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3664" href="#t3664">3664</a></span><span class="t">        <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">core</span><span class="op">.</span><span class="nam">VarDesc</span><span class="op">.</span><span class="nam">VarType</span><span class="op">.</span><span class="nam">FP32</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3665" href="#t3665">3665</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3666" href="#t3666">3666</a></span><span class="t">    <span class="nam">input_shape</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3667" href="#t3667">3667</a></span><span class="t">    <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">&lt;</span> <span class="num">2</span> <span class="key">or</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">></span> <span class="num">5</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3668" href="#t3668">3668</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3669" href="#t3669">3669</a></span><span class="t">            <span class="str">'expected 2D or 3D or 4D or 5D input (got {}D input, input shape is: {})'</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3670" href="#t3670">3670</a></span><span class="t">                <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span><span class="op">,</span> <span class="nam">input_shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3671" href="#t3671">3671</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3672" href="#t3672">3672</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3673" href="#t3673">3673</a></span><span class="t">    <span class="nam">channel_num</span> <span class="op">=</span> <span class="nam">input_shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3674" href="#t3674">3674</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3675" href="#t3675">3675</a></span><span class="t">    <span class="nam">param_shape</span> <span class="op">=</span> <span class="op">[</span><span class="nam">channel_num</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3676" href="#t3676">3676</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3677" href="#t3677">3677</a></span><span class="t">    <span class="key">if</span> <span class="nam">param_attr</span> <span class="op">!=</span> <span class="key">False</span> <span class="key">and</span> <span class="nam">bias_attr</span> <span class="op">!=</span> <span class="key">False</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3678" href="#t3678">3678</a></span><span class="t">        <span class="com"># create parameter</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3679" href="#t3679">3679</a></span><span class="t">        <span class="nam">scale</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3680" href="#t3680">3680</a></span><span class="t">            <span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">param_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3681" href="#t3681">3681</a></span><span class="t">            <span class="nam">shape</span><span class="op">=</span><span class="nam">param_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3682" href="#t3682">3682</a></span><span class="t">            <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3683" href="#t3683">3683</a></span><span class="t">            <span class="nam">default_initializer</span><span class="op">=</span><span class="nam">Constant</span><span class="op">(</span><span class="num">1.0</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3684" href="#t3684">3684</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3685" href="#t3685">3685</a></span><span class="t">        <span class="nam">bias</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3686" href="#t3686">3686</a></span><span class="t">            <span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">bias_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3687" href="#t3687">3687</a></span><span class="t">            <span class="nam">shape</span><span class="op">=</span><span class="nam">param_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3688" href="#t3688">3688</a></span><span class="t">            <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3689" href="#t3689">3689</a></span><span class="t">            <span class="nam">is_bias</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3690" href="#t3690">3690</a></span><span class="t">            <span class="nam">default_initializer</span><span class="op">=</span><span class="nam">Constant</span><span class="op">(</span><span class="num">0.0</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3691" href="#t3691">3691</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3692" href="#t3692">3692</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3693" href="#t3693">3693</a></span><span class="t">    <span class="com"># create output</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3694" href="#t3694">3694</a></span><span class="t">    <span class="nam">saved_mean</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3695" href="#t3695">3695</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3696" href="#t3696">3696</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3697" href="#t3697">3697</a></span><span class="t">    <span class="nam">saved_variance</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3698" href="#t3698">3698</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3699" href="#t3699">3699</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3700" href="#t3700">3700</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3701" href="#t3701">3701</a></span><span class="t">    <span class="nam">instance_norm_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3702" href="#t3702">3702</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3703" href="#t3703">3703</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3704" href="#t3704">3704</a></span><span class="t">    <span class="key">if</span> <span class="nam">param_attr</span> <span class="op">!=</span> <span class="key">False</span> <span class="key">and</span> <span class="nam">bias_attr</span> <span class="op">!=</span> <span class="key">False</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3705" href="#t3705">3705</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">"Scale"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">scale</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3706" href="#t3706">3706</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">"Bias"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">bias</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3707" href="#t3707">3707</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3708" href="#t3708">3708</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3709" href="#t3709">3709</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"instance_norm"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3710" href="#t3710">3710</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3711" href="#t3711">3711</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3712" href="#t3712">3712</a></span><span class="t">            <span class="str">"Y"</span><span class="op">:</span> <span class="nam">instance_norm_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3713" href="#t3713">3713</a></span><span class="t">            <span class="str">"SavedMean"</span><span class="op">:</span> <span class="nam">saved_mean</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3714" href="#t3714">3714</a></span><span class="t">            <span class="str">"SavedVariance"</span><span class="op">:</span> <span class="nam">saved_variance</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3715" href="#t3715">3715</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3716" href="#t3716">3716</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3717" href="#t3717">3717</a></span><span class="t">            <span class="str">"epsilon"</span><span class="op">:</span> <span class="nam">epsilon</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3718" href="#t3718">3718</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3719" href="#t3719">3719</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3720" href="#t3720">3720</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3721" href="#t3721">3721</a></span><span class="t">    <span class="key">return</span> <span class="nam">instance_norm_out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3722" href="#t3722">3722</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3723" href="#t3723">3723</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t3724" href="#t3724">3724</a></span><span class="t"><span class="op">@</span><span class="nam">static_only</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t3725" href="#t3725">3725</a></span><span class="t"><span class="key">def</span> <span class="nam">data_norm</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3726" href="#t3726">3726</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3727" href="#t3727">3727</a></span><span class="t">    <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3728" href="#t3728">3728</a></span><span class="t">    <span class="nam">epsilon</span><span class="op">=</span><span class="num">1e-05</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3729" href="#t3729">3729</a></span><span class="t">    <span class="nam">param_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3730" href="#t3730">3730</a></span><span class="t">    <span class="nam">data_layout</span><span class="op">=</span><span class="str">'NCHW'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3731" href="#t3731">3731</a></span><span class="t">    <span class="nam">in_place</span><span class="op">=</span><span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3732" href="#t3732">3732</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3733" href="#t3733">3733</a></span><span class="t">    <span class="nam">moving_mean_name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3734" href="#t3734">3734</a></span><span class="t">    <span class="nam">moving_variance_name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3735" href="#t3735">3735</a></span><span class="t">    <span class="nam">do_model_average_for_mean_and_var</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3736" href="#t3736">3736</a></span><span class="t">    <span class="nam">slot_dim</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3737" href="#t3737">3737</a></span><span class="t">    <span class="nam">sync_stats</span><span class="op">=</span><span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3738" href="#t3738">3738</a></span><span class="t">    <span class="nam">summary_decay_rate</span><span class="op">=</span><span class="num">0.9999999</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3739" href="#t3739">3739</a></span><span class="t">    <span class="nam">enable_scale_and_shift</span><span class="op">=</span><span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3740" href="#t3740">3740</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3741" href="#t3741">3741</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3742" href="#t3742">3742</a></span><span class="t"><span class="str">    :api_attr: Static Graph</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3743" href="#t3743">3743</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3744" href="#t3744">3744</a></span><span class="t"><span class="str">    **Data Normalization Layer**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3745" href="#t3745">3745</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3746" href="#t3746">3746</a></span><span class="t"><span class="str">    This op can be used as a normalizer function for conv2d and fully_connected operations.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3747" href="#t3747">3747</a></span><span class="t"><span class="str">    The required data format for this layer is one of the following:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3748" href="#t3748">3748</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3749" href="#t3749">3749</a></span><span class="t"><span class="str">    1. NHWC `[batch, in_height, in_width, in_channels]`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3750" href="#t3750">3750</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3751" href="#t3751">3751</a></span><span class="t"><span class="str">    2. NCHW `[batch, in_channels, in_height, in_width]`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3752" href="#t3752">3752</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3753" href="#t3753">3753</a></span><span class="t"><span class="str">    :math:`input` is the input features over a mini-batch.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3754" href="#t3754">3754</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3755" href="#t3755">3755</a></span><span class="t"><span class="str">    ..  math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3756" href="#t3756">3756</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3757" href="#t3757">3757</a></span><span class="t"><span class="str">        \\mu_{\\beta} &amp;\\gets \\frac{1}{m} \\sum_{i=1}^{m} x_i \\qquad &amp;//\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3758" href="#t3758">3758</a></span><span class="t"><span class="str">        \ mini-batch\ mean \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3759" href="#t3759">3759</a></span><span class="t"><span class="str">        \\sigma_{\\beta}^{2} &amp;\\gets \\frac{1}{m} \\sum_{i=1}^{m}(x_i - \\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3760" href="#t3760">3760</a></span><span class="t"><span class="str">        \\mu_{\\beta})^2 \\qquad &amp;//\ mini-batch\ variance \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3761" href="#t3761">3761</a></span><span class="t"><span class="str">        \\hat{x_i} &amp;\\gets \\frac{x_i - \\mu_\\beta} {\\sqrt{\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3762" href="#t3762">3762</a></span><span class="t"><span class="str">        \\sigma_{\\beta}^{2} + \\epsilon}} \\qquad &amp;//\ normalize \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3763" href="#t3763">3763</a></span><span class="t"><span class="str">        y_i &amp;\\gets \\gamma \\hat{x_i} + \\beta \\qquad &amp;//\ scale\ and\ shift</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3764" href="#t3764">3764</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3765" href="#t3765">3765</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3766" href="#t3766">3766</a></span><span class="t"><span class="str">        input(Tensor): The input Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3767" href="#t3767">3767</a></span><span class="t"><span class="str">        act(string, Default None): Activation type, linear|relu|prelu|...</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3768" href="#t3768">3768</a></span><span class="t"><span class="str">        epsilon(float, Default 1e-05):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3769" href="#t3769">3769</a></span><span class="t"><span class="str">        param_attr(ParamAttr): The parameter attribute for Parameter `scale`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3770" href="#t3770">3770</a></span><span class="t"><span class="str">        data_layout (str, optional): Specify the data format of the input, and the data format of the output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3771" href="#t3771">3771</a></span><span class="t"><span class="str">            will be consistent with that of the input. An optional string from: `"NCHW"`, `"NHWC"`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3772" href="#t3772">3772</a></span><span class="t"><span class="str">            The default is `"NCHW"`. When it is `"NCHW"`, the data is stored in the order of:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3773" href="#t3773">3773</a></span><span class="t"><span class="str">            `[batch_size, input_channels, input_height, input_width]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3774" href="#t3774">3774</a></span><span class="t"><span class="str">        in_place(bool, Default False): Make the input and output of batch norm reuse memory.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3775" href="#t3775">3775</a></span><span class="t"><span class="str">        name(string, Default None): A name for this layer(optional). If set None, the layer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3776" href="#t3776">3776</a></span><span class="t"><span class="str">            will be named automatically.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3777" href="#t3777">3777</a></span><span class="t"><span class="str">        moving_mean_name(string, Default None): The name of moving_mean which store the global Mean.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3778" href="#t3778">3778</a></span><span class="t"><span class="str">        moving_variance_name(string, Default None): The name of the moving_variance which store the global Variance.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3779" href="#t3779">3779</a></span><span class="t"><span class="str">        do_model_average_for_mean_and_var(bool, Default True): Whether parameter mean and variance</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3780" href="#t3780">3780</a></span><span class="t"><span class="str">            should do model average when model average is enabled.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3781" href="#t3781">3781</a></span><span class="t"><span class="str">        slot_dim(int): The embedding dimension of one slot. Slot is a set of one specific feature. In pslib mode, we</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3782" href="#t3782">3782</a></span><span class="t"><span class="str">            distinguish feature ids by slot and pull their embeddings from parameter server (pslib). The first</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3783" href="#t3783">3783</a></span><span class="t"><span class="str">            place of the embedding is the historical show number (occurence time of this feature id with a label 0).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3784" href="#t3784">3784</a></span><span class="t"><span class="str">            If the input of this op is concated by slot-wise embeddings, and the show number is zero when this slot</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3785" href="#t3785">3785</a></span><span class="t"><span class="str">            is new or empty, the normalization result may be impractical. To avoid this, we add slot_dim to locate</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3786" href="#t3786">3786</a></span><span class="t"><span class="str">            the show number and judge if the show number is zero. If so, we choose to skip normalization on this</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3787" href="#t3787">3787</a></span><span class="t"><span class="str">            embedding.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3788" href="#t3788">3788</a></span><span class="t"><span class="str">        sync_stats(bool, Default False): When running with multiple GPU cards, using allreduce to sync the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3789" href="#t3789">3789</a></span><span class="t"><span class="str">            summary messages.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3790" href="#t3790">3790</a></span><span class="t"><span class="str">        summary_decay_rate(float, Default 0.9999999): The decay rate when updating summary.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3791" href="#t3791">3791</a></span><span class="t"><span class="str">        enable_scale_and_shift(bool, Default False): do scale&amp;shift after normalization.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3792" href="#t3792">3792</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3793" href="#t3793">3793</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3794" href="#t3794">3794</a></span><span class="t"><span class="str">        Tensor: A tensor which is the result after applying data normalization on the input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3795" href="#t3795">3795</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3796" href="#t3796">3796</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3797" href="#t3797">3797</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3798" href="#t3798">3798</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3799" href="#t3799">3799</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3800" href="#t3800">3800</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3801" href="#t3801">3801</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3802" href="#t3802">3802</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3803" href="#t3803">3803</a></span><span class="t"><span class="str">            x = paddle.randn(shape=[32,100])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3804" href="#t3804">3804</a></span><span class="t"><span class="str">            hidden2 = paddle.static.nn.data_norm(input=x)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3805" href="#t3805">3805</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3806" href="#t3806">3806</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'data_norm'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3807" href="#t3807">3807</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3808" href="#t3808">3808</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3809" href="#t3809">3809</a></span><span class="t">    <span class="nam">input_shape</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3810" href="#t3810">3810</a></span><span class="t">    <span class="key">if</span> <span class="nam">data_layout</span> <span class="op">==</span> <span class="str">'NCHW'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3811" href="#t3811">3811</a></span><span class="t">        <span class="nam">channel_num</span> <span class="op">=</span> <span class="nam">input_shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3812" href="#t3812">3812</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3813" href="#t3813">3813</a></span><span class="t">        <span class="key">if</span> <span class="nam">data_layout</span> <span class="op">==</span> <span class="str">'NHWC'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3814" href="#t3814">3814</a></span><span class="t">            <span class="nam">channel_num</span> <span class="op">=</span> <span class="nam">input_shape</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3815" href="#t3815">3815</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3816" href="#t3816">3816</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"unsupported data layout:"</span> <span class="op">+</span> <span class="nam">data_layout</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3817" href="#t3817">3817</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3818" href="#t3818">3818</a></span><span class="t">    <span class="nam">param_shape</span> <span class="op">=</span> <span class="op">[</span><span class="nam">channel_num</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3819" href="#t3819">3819</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3820" href="#t3820">3820</a></span><span class="t">    <span class="nam">batch_size_default</span> <span class="op">=</span> <span class="num">1e4</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3821" href="#t3821">3821</a></span><span class="t">    <span class="nam">batch_sum_default</span> <span class="op">=</span> <span class="num">0.0</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3822" href="#t3822">3822</a></span><span class="t">    <span class="nam">batch_square_sum_default</span> <span class="op">=</span> <span class="num">1e4</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3823" href="#t3823">3823</a></span><span class="t">    <span class="nam">scale_w_default</span> <span class="op">=</span> <span class="num">1.0</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3824" href="#t3824">3824</a></span><span class="t">    <span class="nam">bias_default</span> <span class="op">=</span> <span class="num">0.0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3825" href="#t3825">3825</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3826" href="#t3826">3826</a></span><span class="t">    <span class="key">if</span> <span class="nam">param_attr</span> <span class="key">and</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">param_attr</span><span class="op">,</span> <span class="nam">dict</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3827" href="#t3827">3827</a></span><span class="t">        <span class="nam">batch_size_default</span> <span class="op">=</span> <span class="nam">param_attr</span><span class="op">.</span><span class="nam">get</span><span class="op">(</span><span class="str">"batch_size"</span><span class="op">,</span> <span class="num">1e4</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3828" href="#t3828">3828</a></span><span class="t">        <span class="nam">batch_sum_default</span> <span class="op">=</span> <span class="nam">param_attr</span><span class="op">.</span><span class="nam">get</span><span class="op">(</span><span class="str">"batch_sum"</span><span class="op">,</span> <span class="num">0.0</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3829" href="#t3829">3829</a></span><span class="t">        <span class="nam">batch_square_sum_default</span> <span class="op">=</span> <span class="nam">param_attr</span><span class="op">.</span><span class="nam">get</span><span class="op">(</span><span class="str">"batch_square"</span><span class="op">,</span> <span class="num">1e4</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3830" href="#t3830">3830</a></span><span class="t">    <span class="key">if</span> <span class="nam">enable_scale_and_shift</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3831" href="#t3831">3831</a></span><span class="t">        <span class="nam">scale_w_default</span> <span class="op">=</span> <span class="nam">param_attr</span><span class="op">.</span><span class="nam">get</span><span class="op">(</span><span class="str">"scale_w"</span><span class="op">,</span> <span class="num">1.0</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3832" href="#t3832">3832</a></span><span class="t">        <span class="nam">bias_default</span> <span class="op">=</span> <span class="nam">param_attr</span><span class="op">.</span><span class="nam">get</span><span class="op">(</span><span class="str">"bias"</span><span class="op">,</span> <span class="num">0.0</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3833" href="#t3833">3833</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3834" href="#t3834">3834</a></span><span class="t">    <span class="com"># create scale and shift(bias) when enable_scale_and_shift is True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3835" href="#t3835">3835</a></span><span class="t">    <span class="key">if</span> <span class="nam">name</span> <span class="op">==</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3836" href="#t3836">3836</a></span><span class="t">        <span class="nam">name</span> <span class="op">=</span> <span class="str">"dn"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3837" href="#t3837">3837</a></span><span class="t">    <span class="key">if</span> <span class="nam">enable_scale_and_shift</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3838" href="#t3838">3838</a></span><span class="t">        <span class="nam">scale_w</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3839" href="#t3839">3839</a></span><span class="t">            <span class="nam">attr</span><span class="op">=</span><span class="nam">ParamAttr</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3840" href="#t3840">3840</a></span><span class="t">                <span class="nam">name</span><span class="op">=</span><span class="nam">name</span> <span class="op">+</span> <span class="str">'.scale_w'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3841" href="#t3841">3841</a></span><span class="t">                <span class="nam">initializer</span><span class="op">=</span><span class="nam">Constant</span><span class="op">(</span><span class="nam">value</span><span class="op">=</span><span class="nam">float</span><span class="op">(</span><span class="nam">scale_w_default</span><span class="op">)</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3842" href="#t3842">3842</a></span><span class="t">                <span class="nam">trainable</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3843" href="#t3843">3843</a></span><span class="t">            <span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3844" href="#t3844">3844</a></span><span class="t">            <span class="nam">shape</span><span class="op">=</span><span class="nam">param_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3845" href="#t3845">3845</a></span><span class="t">            <span class="nam">dtype</span><span class="op">=</span><span class="nam">input</span><span class="op">.</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3846" href="#t3846">3846</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3847" href="#t3847">3847</a></span><span class="t">        <span class="nam">bias</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3848" href="#t3848">3848</a></span><span class="t">            <span class="nam">attr</span><span class="op">=</span><span class="nam">ParamAttr</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3849" href="#t3849">3849</a></span><span class="t">                <span class="nam">name</span><span class="op">=</span><span class="nam">name</span> <span class="op">+</span> <span class="str">'.bias'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3850" href="#t3850">3850</a></span><span class="t">                <span class="nam">initializer</span><span class="op">=</span><span class="nam">Constant</span><span class="op">(</span><span class="nam">value</span><span class="op">=</span><span class="nam">float</span><span class="op">(</span><span class="nam">bias_default</span><span class="op">)</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3851" href="#t3851">3851</a></span><span class="t">                <span class="nam">trainable</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3852" href="#t3852">3852</a></span><span class="t">            <span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3853" href="#t3853">3853</a></span><span class="t">            <span class="nam">shape</span><span class="op">=</span><span class="nam">param_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3854" href="#t3854">3854</a></span><span class="t">            <span class="nam">dtype</span><span class="op">=</span><span class="nam">input</span><span class="op">.</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3855" href="#t3855">3855</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3856" href="#t3856">3856</a></span><span class="t">    <span class="com"># create parameter</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3857" href="#t3857">3857</a></span><span class="t">    <span class="nam">batch_size</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3858" href="#t3858">3858</a></span><span class="t">        <span class="nam">attr</span><span class="op">=</span><span class="nam">ParamAttr</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3859" href="#t3859">3859</a></span><span class="t">            <span class="nam">name</span><span class="op">=</span><span class="nam">name</span> <span class="op">+</span> <span class="str">'.batch_size'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3860" href="#t3860">3860</a></span><span class="t">            <span class="nam">initializer</span><span class="op">=</span><span class="nam">Constant</span><span class="op">(</span><span class="nam">value</span><span class="op">=</span><span class="nam">float</span><span class="op">(</span><span class="nam">batch_size_default</span><span class="op">)</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3861" href="#t3861">3861</a></span><span class="t">            <span class="nam">trainable</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3862" href="#t3862">3862</a></span><span class="t">        <span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3863" href="#t3863">3863</a></span><span class="t">        <span class="nam">shape</span><span class="op">=</span><span class="nam">param_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3864" href="#t3864">3864</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">input</span><span class="op">.</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3865" href="#t3865">3865</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3866" href="#t3866">3866</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3867" href="#t3867">3867</a></span><span class="t">    <span class="nam">batch_sum</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3868" href="#t3868">3868</a></span><span class="t">        <span class="nam">attr</span><span class="op">=</span><span class="nam">ParamAttr</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3869" href="#t3869">3869</a></span><span class="t">            <span class="nam">name</span><span class="op">=</span><span class="nam">name</span> <span class="op">+</span> <span class="str">'.batch_sum'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3870" href="#t3870">3870</a></span><span class="t">            <span class="nam">initializer</span><span class="op">=</span><span class="nam">Constant</span><span class="op">(</span><span class="nam">value</span><span class="op">=</span><span class="nam">float</span><span class="op">(</span><span class="nam">batch_sum_default</span><span class="op">)</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3871" href="#t3871">3871</a></span><span class="t">            <span class="nam">trainable</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3872" href="#t3872">3872</a></span><span class="t">        <span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3873" href="#t3873">3873</a></span><span class="t">        <span class="nam">shape</span><span class="op">=</span><span class="nam">param_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3874" href="#t3874">3874</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">input</span><span class="op">.</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3875" href="#t3875">3875</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3876" href="#t3876">3876</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3877" href="#t3877">3877</a></span><span class="t">    <span class="nam">batch_square_sum</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3878" href="#t3878">3878</a></span><span class="t">        <span class="nam">attr</span><span class="op">=</span><span class="nam">ParamAttr</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3879" href="#t3879">3879</a></span><span class="t">            <span class="nam">name</span><span class="op">=</span><span class="nam">name</span> <span class="op">+</span> <span class="str">'.batch_square_sum'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3880" href="#t3880">3880</a></span><span class="t">            <span class="nam">initializer</span><span class="op">=</span><span class="nam">Constant</span><span class="op">(</span><span class="nam">value</span><span class="op">=</span><span class="nam">float</span><span class="op">(</span><span class="nam">batch_square_sum_default</span><span class="op">)</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3881" href="#t3881">3881</a></span><span class="t">            <span class="nam">trainable</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3882" href="#t3882">3882</a></span><span class="t">        <span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3883" href="#t3883">3883</a></span><span class="t">        <span class="nam">shape</span><span class="op">=</span><span class="nam">param_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3884" href="#t3884">3884</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">input</span><span class="op">.</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3885" href="#t3885">3885</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3886" href="#t3886">3886</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3887" href="#t3887">3887</a></span><span class="t">    <span class="nam">means</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3888" href="#t3888">3888</a></span><span class="t">    <span class="nam">scales</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3889" href="#t3889">3889</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3890" href="#t3890">3890</a></span><span class="t">    <span class="nam">data_norm_out</span> <span class="op">=</span> <span class="nam">input</span> <span class="key">if</span> <span class="nam">in_place</span> <span class="key">else</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3891" href="#t3891">3891</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3892" href="#t3892">3892</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3893" href="#t3893">3893</a></span><span class="t">        <span class="str">"X"</span><span class="op">:</span> <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3894" href="#t3894">3894</a></span><span class="t">        <span class="str">"BatchSize"</span><span class="op">:</span> <span class="nam">batch_size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3895" href="#t3895">3895</a></span><span class="t">        <span class="str">"BatchSum"</span><span class="op">:</span> <span class="nam">batch_sum</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3896" href="#t3896">3896</a></span><span class="t">        <span class="str">"BatchSquareSum"</span><span class="op">:</span> <span class="nam">batch_square_sum</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3897" href="#t3897">3897</a></span><span class="t">    <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3898" href="#t3898">3898</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3899" href="#t3899">3899</a></span><span class="t">        <span class="str">"epsilon"</span><span class="op">:</span> <span class="nam">epsilon</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3900" href="#t3900">3900</a></span><span class="t">        <span class="str">"data_layout"</span><span class="op">:</span> <span class="nam">data_layout</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3901" href="#t3901">3901</a></span><span class="t">        <span class="str">"sync_stats"</span><span class="op">:</span> <span class="nam">sync_stats</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3902" href="#t3902">3902</a></span><span class="t">        <span class="str">"summary_decay_rate"</span><span class="op">:</span> <span class="nam">summary_decay_rate</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3903" href="#t3903">3903</a></span><span class="t">    <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3904" href="#t3904">3904</a></span><span class="t">    <span class="key">if</span> <span class="nam">slot_dim</span> <span class="op">></span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3905" href="#t3905">3905</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">"slot_dim"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">slot_dim</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3906" href="#t3906">3906</a></span><span class="t">    <span class="key">if</span> <span class="nam">enable_scale_and_shift</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3907" href="#t3907">3907</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">"enable_scale_and_shift"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">enable_scale_and_shift</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3908" href="#t3908">3908</a></span><span class="t">    <span class="key">if</span> <span class="nam">enable_scale_and_shift</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3909" href="#t3909">3909</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">"scale_w"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">scale_w</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3910" href="#t3910">3910</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">"bias"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">bias</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3911" href="#t3911">3911</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3912" href="#t3912">3912</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"data_norm"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3913" href="#t3913">3913</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3914" href="#t3914">3914</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3915" href="#t3915">3915</a></span><span class="t">            <span class="str">"Y"</span><span class="op">:</span> <span class="nam">data_norm_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3916" href="#t3916">3916</a></span><span class="t">            <span class="str">"Means"</span><span class="op">:</span> <span class="nam">means</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3917" href="#t3917">3917</a></span><span class="t">            <span class="str">"Scales"</span><span class="op">:</span> <span class="nam">scales</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3918" href="#t3918">3918</a></span><span class="t">            <span class="str">"BatchSize"</span><span class="op">:</span> <span class="nam">batch_size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3919" href="#t3919">3919</a></span><span class="t">            <span class="str">"BatchSum"</span><span class="op">:</span> <span class="nam">batch_sum</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3920" href="#t3920">3920</a></span><span class="t">            <span class="str">"BatchSquareSum"</span><span class="op">:</span> <span class="nam">batch_square_sum</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3921" href="#t3921">3921</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3922" href="#t3922">3922</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3923" href="#t3923">3923</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3924" href="#t3924">3924</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t3925" href="#t3925">3925</a></span><span class="t">    <span class="key">return</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_activation</span><span class="op">(</span><span class="nam">data_norm_out</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3926" href="#t3926">3926</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3927" href="#t3927">3927</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t3928" href="#t3928">3928</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t3929" href="#t3929">3929</a></span><span class="t"><span class="key">def</span> <span class="nam">layer_norm</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3930" href="#t3930">3930</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3931" href="#t3931">3931</a></span><span class="t">    <span class="nam">scale</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3932" href="#t3932">3932</a></span><span class="t">    <span class="nam">shift</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3933" href="#t3933">3933</a></span><span class="t">    <span class="nam">begin_norm_axis</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3934" href="#t3934">3934</a></span><span class="t">    <span class="nam">epsilon</span><span class="op">=</span><span class="num">1e-05</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3935" href="#t3935">3935</a></span><span class="t">    <span class="nam">param_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3936" href="#t3936">3936</a></span><span class="t">    <span class="nam">bias_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3937" href="#t3937">3937</a></span><span class="t">    <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3938" href="#t3938">3938</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3939" href="#t3939">3939</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3940" href="#t3940">3940</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3941" href="#t3941">3941</a></span><span class="t"><span class="str">    :api_attr: Static Graph</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3942" href="#t3942">3942</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3943" href="#t3943">3943</a></span><span class="t"><span class="str">    **Layer Normalization Layer**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3944" href="#t3944">3944</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3945" href="#t3945">3945</a></span><span class="t"><span class="str">    The API implements the function of the Layer Normalization Layer and can be applied to mini-batch input data.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3946" href="#t3946">3946</a></span><span class="t"><span class="str">    Refer to `Layer Normalization &lt;https://arxiv.org/pdf/1607.06450v1.pdf>`_</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3947" href="#t3947">3947</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3948" href="#t3948">3948</a></span><span class="t"><span class="str">    The formula is as follows:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3949" href="#t3949">3949</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3950" href="#t3950">3950</a></span><span class="t"><span class="str">    ..  math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3951" href="#t3951">3951</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3952" href="#t3952">3952</a></span><span class="t"><span class="str">        \\mu &amp; = \\frac{1}{H}\\sum_{i=1}^{H} x_i</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3953" href="#t3953">3953</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3954" href="#t3954">3954</a></span><span class="t"><span class="str">        \\sigma &amp; = \\sqrt{\\frac{1}{H}\sum_{i=1}^{H}{(x_i - \\mu)^2} + \\epsilon}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3955" href="#t3955">3955</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3956" href="#t3956">3956</a></span><span class="t"><span class="str">        y &amp; = f(\\frac{g}{\\sigma}(x - \\mu) + b)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3957" href="#t3957">3957</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3958" href="#t3958">3958</a></span><span class="t"><span class="str">    - :math:`x`: the vector representation of the summed inputs to the neurons in that layer.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3959" href="#t3959">3959</a></span><span class="t"><span class="str">    - :math:`H`: the number of hidden units in a layers</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3960" href="#t3960">3960</a></span><span class="t"><span class="str">    - :math:`\\epsilon`: the small value added to the variance to prevent division by zero.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3961" href="#t3961">3961</a></span><span class="t"><span class="str">    - :math:`g`: the trainable scale parameter.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3962" href="#t3962">3962</a></span><span class="t"><span class="str">    - :math:`b`: the trainable bias parameter.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3963" href="#t3963">3963</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3964" href="#t3964">3964</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3965" href="#t3965">3965</a></span><span class="t"><span class="str">        input(Tensor): A multi-dimension ``Tensor`` , and the data type is float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3966" href="#t3966">3966</a></span><span class="t"><span class="str">        scale(bool, optional): Whether to learn the adaptive gain :math:`g` after</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3967" href="#t3967">3967</a></span><span class="t"><span class="str">            normalization. Default: True.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3968" href="#t3968">3968</a></span><span class="t"><span class="str">        shift(bool, optional): Whether to learn the adaptive bias :math:`b` after</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3969" href="#t3969">3969</a></span><span class="t"><span class="str">            normalization. Default: True.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3970" href="#t3970">3970</a></span><span class="t"><span class="str">        begin_norm_axis(int, optional): The normalization will be performed along</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3971" href="#t3971">3971</a></span><span class="t"><span class="str">            dimensions from :attr:`begin_norm_axis` to :attr:`rank(input)`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3972" href="#t3972">3972</a></span><span class="t"><span class="str">            Default: 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3973" href="#t3973">3973</a></span><span class="t"><span class="str">        epsilon(float, optional): The small value added to the variance to prevent</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3974" href="#t3974">3974</a></span><span class="t"><span class="str">            division by zero. Default: 1e-05.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3975" href="#t3975">3975</a></span><span class="t"><span class="str">        param_attr(ParamAttr, optional): The parameter attribute for the learnable</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3976" href="#t3976">3976</a></span><span class="t"><span class="str">            gain :math:`g`. If :attr:`scale` is False, :attr:`param_attr` is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3977" href="#t3977">3977</a></span><span class="t"><span class="str">            omitted. If :attr:`scale` is True and :attr:`param_attr` is None,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3978" href="#t3978">3978</a></span><span class="t"><span class="str">            a default :code:`ParamAttr` would be added as scale. The</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3979" href="#t3979">3979</a></span><span class="t"><span class="str">            :attr:`param_attr` is initialized as 1 if it is added. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3980" href="#t3980">3980</a></span><span class="t"><span class="str">        bias_attr(ParamAttr, optional): The parameter attribute for the learnable</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3981" href="#t3981">3981</a></span><span class="t"><span class="str">            bias :math:`b`. If :attr:`shift` is False, :attr:`bias_attr` is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3982" href="#t3982">3982</a></span><span class="t"><span class="str">            omitted. If :attr:`shift` is True and :attr:`param_attr` is None,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3983" href="#t3983">3983</a></span><span class="t"><span class="str">            a default :code:`ParamAttr` would be added as bias. The</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3984" href="#t3984">3984</a></span><span class="t"><span class="str">            :attr:`bias_attr` is initialized as 0 if it is added. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3985" href="#t3985">3985</a></span><span class="t"><span class="str">        act(str, optional): Activation to be applied to the output of layer normalization.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3986" href="#t3986">3986</a></span><span class="t"><span class="str">                  Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3987" href="#t3987">3987</a></span><span class="t"><span class="str">        name(str): The default value is None.  Normally there is no need for user to set this property.  For more information, please refer to :ref:`api_guide_Name` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3988" href="#t3988">3988</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3989" href="#t3989">3989</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3990" href="#t3990">3990</a></span><span class="t"><span class="str">        Tensor: ``Tensor``  indicating the normalized result, the data type is the same as  ``input`` , and the return dimension is the same as  ``input`` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3991" href="#t3991">3991</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3992" href="#t3992">3992</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3993" href="#t3993">3993</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3994" href="#t3994">3994</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3995" href="#t3995">3995</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3996" href="#t3996">3996</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3997" href="#t3997">3997</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3998" href="#t3998">3998</a></span><span class="t"><span class="str">            x = paddle.static.data(name='x', shape=[8, 32, 32], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3999" href="#t3999">3999</a></span><span class="t"><span class="str">            output = paddle.static.nn.layer_norm(input=x, begin_norm_axis=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4000" href="#t4000">4000</a></span><span class="t"><span class="str">            print(output.shape)  # [8, 32, 32]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4001" href="#t4001">4001</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4002" href="#t4002">4002</a></span><span class="t">    <span class="key">assert</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4003" href="#t4003">4003</a></span><span class="t">        <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span> <span class="key">is</span> <span class="key">not</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4004" href="#t4004">4004</a></span><span class="t">    <span class="op">)</span><span class="op">,</span> <span class="str">"please use LayerNorm instead of layer_norm in dygraph mode!"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4005" href="#t4005">4005</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'layer_norm'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4006" href="#t4006">4006</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4007" href="#t4007">4007</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'layer_norm'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4008" href="#t4008">4008</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4009" href="#t4009">4009</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4010" href="#t4010">4010</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4011" href="#t4011">4011</a></span><span class="t">    <span class="com"># create intput and parameters</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4012" href="#t4012">4012</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4013" href="#t4013">4013</a></span><span class="t">    <span class="nam">input_shape</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4014" href="#t4014">4014</a></span><span class="t">    <span class="nam">param_shape</span> <span class="op">=</span> <span class="op">[</span><span class="nam">reduce</span><span class="op">(</span><span class="key">lambda</span> <span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">:</span> <span class="nam">x</span> <span class="op">*</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">input_shape</span><span class="op">[</span><span class="nam">begin_norm_axis</span><span class="op">:</span><span class="op">]</span><span class="op">)</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4015" href="#t4015">4015</a></span><span class="t">    <span class="key">if</span> <span class="nam">scale</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4016" href="#t4016">4016</a></span><span class="t">        <span class="key">assert</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4017" href="#t4017">4017</a></span><span class="t">            <span class="nam">param_attr</span> <span class="key">is</span> <span class="key">not</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4018" href="#t4018">4018</a></span><span class="t">        <span class="op">)</span><span class="op">,</span> <span class="str">"param_attr should not be False when using scale."</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4019" href="#t4019">4019</a></span><span class="t">        <span class="nam">scale</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4020" href="#t4020">4020</a></span><span class="t">            <span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">param_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4021" href="#t4021">4021</a></span><span class="t">            <span class="nam">shape</span><span class="op">=</span><span class="nam">param_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4022" href="#t4022">4022</a></span><span class="t">            <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4023" href="#t4023">4023</a></span><span class="t">            <span class="nam">default_initializer</span><span class="op">=</span><span class="nam">Constant</span><span class="op">(</span><span class="num">1.0</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4024" href="#t4024">4024</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4025" href="#t4025">4025</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">'Scale'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">scale</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4026" href="#t4026">4026</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4027" href="#t4027">4027</a></span><span class="t">        <span class="key">if</span> <span class="nam">param_attr</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4028" href="#t4028">4028</a></span><span class="t">            <span class="nam">warnings</span><span class="op">.</span><span class="nam">warn</span><span class="op">(</span><span class="str">"param_attr is only available with scale is True."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4029" href="#t4029">4029</a></span><span class="t">    <span class="key">if</span> <span class="nam">shift</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4030" href="#t4030">4030</a></span><span class="t">        <span class="key">assert</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4031" href="#t4031">4031</a></span><span class="t">            <span class="nam">bias_attr</span> <span class="key">is</span> <span class="key">not</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4032" href="#t4032">4032</a></span><span class="t">        <span class="op">)</span><span class="op">,</span> <span class="str">"bias_attr should not be False when using shift."</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4033" href="#t4033">4033</a></span><span class="t">        <span class="nam">bias</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4034" href="#t4034">4034</a></span><span class="t">            <span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">bias_attr</span><span class="op">,</span> <span class="nam">shape</span><span class="op">=</span><span class="nam">param_shape</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">is_bias</span><span class="op">=</span><span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4035" href="#t4035">4035</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4036" href="#t4036">4036</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">'Bias'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">bias</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4037" href="#t4037">4037</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4038" href="#t4038">4038</a></span><span class="t">        <span class="key">if</span> <span class="nam">bias_attr</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4039" href="#t4039">4039</a></span><span class="t">            <span class="nam">warnings</span><span class="op">.</span><span class="nam">warn</span><span class="op">(</span><span class="str">"bias_attr is only available with shift is True."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4040" href="#t4040">4040</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4041" href="#t4041">4041</a></span><span class="t">    <span class="com"># create output</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4042" href="#t4042">4042</a></span><span class="t">    <span class="nam">mean_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4043" href="#t4043">4043</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4044" href="#t4044">4044</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4045" href="#t4045">4045</a></span><span class="t">    <span class="nam">variance_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4046" href="#t4046">4046</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4047" href="#t4047">4047</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4048" href="#t4048">4048</a></span><span class="t">    <span class="nam">layer_norm_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4049" href="#t4049">4049</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4050" href="#t4050">4050</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4051" href="#t4051">4051</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"layer_norm"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4052" href="#t4052">4052</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4053" href="#t4053">4053</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4054" href="#t4054">4054</a></span><span class="t">            <span class="str">"Y"</span><span class="op">:</span> <span class="nam">layer_norm_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4055" href="#t4055">4055</a></span><span class="t">            <span class="str">"Mean"</span><span class="op">:</span> <span class="nam">mean_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4056" href="#t4056">4056</a></span><span class="t">            <span class="str">"Variance"</span><span class="op">:</span> <span class="nam">variance_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4057" href="#t4057">4057</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4058" href="#t4058">4058</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">"epsilon"</span><span class="op">:</span> <span class="nam">epsilon</span><span class="op">,</span> <span class="str">"begin_norm_axis"</span><span class="op">:</span> <span class="nam">begin_norm_axis</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4059" href="#t4059">4059</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4060" href="#t4060">4060</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4061" href="#t4061">4061</a></span><span class="t">    <span class="key">return</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_activation</span><span class="op">(</span><span class="nam">layer_norm_out</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4062" href="#t4062">4062</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4063" href="#t4063">4063</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t4064" href="#t4064">4064</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t4065" href="#t4065">4065</a></span><span class="t"><span class="key">def</span> <span class="nam">group_norm</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4066" href="#t4066">4066</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4067" href="#t4067">4067</a></span><span class="t">    <span class="nam">groups</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4068" href="#t4068">4068</a></span><span class="t">    <span class="nam">epsilon</span><span class="op">=</span><span class="num">1e-05</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4069" href="#t4069">4069</a></span><span class="t">    <span class="nam">param_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4070" href="#t4070">4070</a></span><span class="t">    <span class="nam">bias_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4071" href="#t4071">4071</a></span><span class="t">    <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4072" href="#t4072">4072</a></span><span class="t">    <span class="nam">data_layout</span><span class="op">=</span><span class="str">'NCHW'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4073" href="#t4073">4073</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4074" href="#t4074">4074</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4075" href="#t4075">4075</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4076" href="#t4076">4076</a></span><span class="t"><span class="str">    :api_attr: Static Graph</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4077" href="#t4077">4077</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4078" href="#t4078">4078</a></span><span class="t"><span class="str">    **Group Normalization Layer**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4079" href="#t4079">4079</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4080" href="#t4080">4080</a></span><span class="t"><span class="str">    Refer to `Group Normalization &lt;https://arxiv.org/abs/1803.08494>`_ .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4081" href="#t4081">4081</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4082" href="#t4082">4082</a></span><span class="t"><span class="str">    Parameters:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4083" href="#t4083">4083</a></span><span class="t"><span class="str">        input(Tensor): Tensor with dimension greater than 1, the data type is float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4084" href="#t4084">4084</a></span><span class="t"><span class="str">        groups(int): The number of groups that divided from channels, the data type</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4085" href="#t4085">4085</a></span><span class="t"><span class="str">            is int32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4086" href="#t4086">4086</a></span><span class="t"><span class="str">        epsilon(float, optional): The small value added to the variance to prevent</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4087" href="#t4087">4087</a></span><span class="t"><span class="str">            division by zero, the data type is float32. Default: 1e-05.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4088" href="#t4088">4088</a></span><span class="t"><span class="str">        param_attr(ParamAttr|bool, optional): ParamAttr object that specifies weight parameter</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4089" href="#t4089">4089</a></span><span class="t"><span class="str">            attribute. If a bool type, only False is supported, which means there is no weight parameter.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4090" href="#t4090">4090</a></span><span class="t"><span class="str">            Default: None, the default weight parameter attribute is used. For more information, please</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4091" href="#t4091">4091</a></span><span class="t"><span class="str">            refer to :ref:`api_guide_ParamAttr` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4092" href="#t4092">4092</a></span><span class="t"><span class="str">        bias_attr(ParamAttr|bool, optional): ParamAttr object that specifies bias parameter</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4093" href="#t4093">4093</a></span><span class="t"><span class="str">            attribute. If a bool type, only False is supported, which means there is no bias parameter.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4094" href="#t4094">4094</a></span><span class="t"><span class="str">            Default: None, the default bias parameter attribute is used. For more information, please</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4095" href="#t4095">4095</a></span><span class="t"><span class="str">            refer to :ref:`api_guide_ParamAttr` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4096" href="#t4096">4096</a></span><span class="t"><span class="str">        act(str, optional): Activation to be applied to the output of group normalization.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4097" href="#t4097">4097</a></span><span class="t"><span class="str">        data_layout(str, optional): Specify the data format of the input, and the data format of the output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4098" href="#t4098">4098</a></span><span class="t"><span class="str">            will be consistent with that of the input. An optional string from: `"NCHW"`, `"NHWC"`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4099" href="#t4099">4099</a></span><span class="t"><span class="str">            The default is `"NCHW"`. When it is `"NCHW"`, the data is stored in the order of:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4100" href="#t4100">4100</a></span><span class="t"><span class="str">            `[batch_size, input_channels, *]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4101" href="#t4101">4101</a></span><span class="t"><span class="str">        name (str, optional): The default value is None. Normally there is no need for user to set this</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4102" href="#t4102">4102</a></span><span class="t"><span class="str">            property. For more information, please refer to :ref:`api_guide_Name` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4103" href="#t4103">4103</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4104" href="#t4104">4104</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4105" href="#t4105">4105</a></span><span class="t"><span class="str">        Tensor: A Tensor has same data type and data format with `input`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4106" href="#t4106">4106</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4107" href="#t4107">4107</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4108" href="#t4108">4108</a></span><span class="t"><span class="str">       .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4109" href="#t4109">4109</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4110" href="#t4110">4110</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4111" href="#t4111">4111</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4112" href="#t4112">4112</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4113" href="#t4113">4113</a></span><span class="t"><span class="str">            data = paddle.static.data(name='data', shape=[2, 8, 32, 32], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4114" href="#t4114">4114</a></span><span class="t"><span class="str">            x = paddle.static.nn.group_norm(input=data, groups=4)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4115" href="#t4115">4115</a></span><span class="t"><span class="str">            print(x.shape) # [2, 8, 32, 32]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4116" href="#t4116">4116</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4117" href="#t4117">4117</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'group_norm'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4118" href="#t4118">4118</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4119" href="#t4119">4119</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4120" href="#t4120">4120</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'group_norm'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4121" href="#t4121">4121</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4122" href="#t4122">4122</a></span><span class="t">    <span class="com"># create intput and parameters</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4123" href="#t4123">4123</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4124" href="#t4124">4124</a></span><span class="t">    <span class="nam">input_shape</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4125" href="#t4125">4125</a></span><span class="t">    <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input_shape</span><span class="op">)</span> <span class="op">&lt;</span> <span class="num">2</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4126" href="#t4126">4126</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4127" href="#t4127">4127</a></span><span class="t">            <span class="str">f"The dimensions of Op(fluid.layers.group_norm)'s input should be more than 1. But received {len(input_shape)}"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4128" href="#t4128">4128</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4129" href="#t4129">4129</a></span><span class="t">    <span class="key">if</span> <span class="nam">data_layout</span> <span class="op">!=</span> <span class="str">'NCHW'</span> <span class="key">and</span> <span class="nam">data_layout</span> <span class="op">!=</span> <span class="str">'NHWC'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4130" href="#t4130">4130</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4131" href="#t4131">4131</a></span><span class="t">            <span class="str">"Param(data_layout) of Op(fluid.layers.group_norm) got wrong value: received "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4132" href="#t4132">4132</a></span><span class="t">            <span class="op">+</span> <span class="nam">data_layout</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4133" href="#t4133">4133</a></span><span class="t">            <span class="op">+</span> <span class="str">" but only NCHW or NHWC supported."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4134" href="#t4134">4134</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4135" href="#t4135">4135</a></span><span class="t">    <span class="nam">channel_num</span> <span class="op">=</span> <span class="nam">input_shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span> <span class="key">if</span> <span class="nam">data_layout</span> <span class="op">==</span> <span class="str">'NCHW'</span> <span class="key">else</span> <span class="nam">input_shape</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4136" href="#t4136">4136</a></span><span class="t">    <span class="nam">param_shape</span> <span class="op">=</span> <span class="op">[</span><span class="nam">channel_num</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4137" href="#t4137">4137</a></span><span class="t">    <span class="key">if</span> <span class="nam">param_attr</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4138" href="#t4138">4138</a></span><span class="t">        <span class="nam">scale</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4139" href="#t4139">4139</a></span><span class="t">            <span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">param_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4140" href="#t4140">4140</a></span><span class="t">            <span class="nam">shape</span><span class="op">=</span><span class="nam">param_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4141" href="#t4141">4141</a></span><span class="t">            <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4142" href="#t4142">4142</a></span><span class="t">            <span class="nam">default_initializer</span><span class="op">=</span><span class="nam">Constant</span><span class="op">(</span><span class="num">1.0</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4143" href="#t4143">4143</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4144" href="#t4144">4144</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">'Scale'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">scale</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4145" href="#t4145">4145</a></span><span class="t">    <span class="key">if</span> <span class="nam">bias_attr</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4146" href="#t4146">4146</a></span><span class="t">        <span class="nam">bias</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4147" href="#t4147">4147</a></span><span class="t">            <span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">bias_attr</span><span class="op">,</span> <span class="nam">shape</span><span class="op">=</span><span class="nam">param_shape</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">is_bias</span><span class="op">=</span><span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4148" href="#t4148">4148</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4149" href="#t4149">4149</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">'Bias'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">bias</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4150" href="#t4150">4150</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4151" href="#t4151">4151</a></span><span class="t">    <span class="com"># create output</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4152" href="#t4152">4152</a></span><span class="t">    <span class="nam">mean_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4153" href="#t4153">4153</a></span><span class="t">    <span class="nam">variance_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4154" href="#t4154">4154</a></span><span class="t">    <span class="nam">group_norm_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4155" href="#t4155">4155</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4156" href="#t4156">4156</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4157" href="#t4157">4157</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"group_norm"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4158" href="#t4158">4158</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4159" href="#t4159">4159</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4160" href="#t4160">4160</a></span><span class="t">            <span class="str">"Y"</span><span class="op">:</span> <span class="nam">group_norm_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4161" href="#t4161">4161</a></span><span class="t">            <span class="str">"Mean"</span><span class="op">:</span> <span class="nam">mean_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4162" href="#t4162">4162</a></span><span class="t">            <span class="str">"Variance"</span><span class="op">:</span> <span class="nam">variance_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4163" href="#t4163">4163</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4164" href="#t4164">4164</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4165" href="#t4165">4165</a></span><span class="t">            <span class="str">"epsilon"</span><span class="op">:</span> <span class="nam">epsilon</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4166" href="#t4166">4166</a></span><span class="t">            <span class="str">"groups"</span><span class="op">:</span> <span class="nam">groups</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4167" href="#t4167">4167</a></span><span class="t">            <span class="str">"data_layout"</span><span class="op">:</span> <span class="nam">data_layout</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4168" href="#t4168">4168</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4169" href="#t4169">4169</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4170" href="#t4170">4170</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4171" href="#t4171">4171</a></span><span class="t">    <span class="key">return</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_activation</span><span class="op">(</span><span class="nam">group_norm_out</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4172" href="#t4172">4172</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4173" href="#t4173">4173</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t4174" href="#t4174">4174</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t4175" href="#t4175">4175</a></span><span class="t"><span class="key">def</span> <span class="nam">spectral_norm</span><span class="op">(</span><span class="nam">weight</span><span class="op">,</span> <span class="nam">dim</span><span class="op">=</span><span class="num">0</span><span class="op">,</span> <span class="nam">power_iters</span><span class="op">=</span><span class="num">1</span><span class="op">,</span> <span class="nam">eps</span><span class="op">=</span><span class="num">1e-12</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4176" href="#t4176">4176</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4177" href="#t4177">4177</a></span><span class="t"><span class="str">    :api_attr: Static Graph</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4178" href="#t4178">4178</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4179" href="#t4179">4179</a></span><span class="t"><span class="str">    **Spectral Normalization Layer**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4180" href="#t4180">4180</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4181" href="#t4181">4181</a></span><span class="t"><span class="str">    This operation calculates the spectral normalization value of weight parameters of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4182" href="#t4182">4182</a></span><span class="t"><span class="str">    fc, conv1d, conv2d, conv3d layers which should be 2-D, 3-D, 4-D, 5-D</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4183" href="#t4183">4183</a></span><span class="t"><span class="str">    Parameters. Output tensor will be in same shape with input tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4184" href="#t4184">4184</a></span><span class="t"><span class="str">    Calculations are showed as follows.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4185" href="#t4185">4185</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4186" href="#t4186">4186</a></span><span class="t"><span class="str">    Step 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4187" href="#t4187">4187</a></span><span class="t"><span class="str">    Generate vector U in shape of [H], and V in shape of [W].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4188" href="#t4188">4188</a></span><span class="t"><span class="str">    While H is the :attr:`dim` th dimension of the input weights,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4189" href="#t4189">4189</a></span><span class="t"><span class="str">    and W is the product result of remaining dimensions.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4190" href="#t4190">4190</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4191" href="#t4191">4191</a></span><span class="t"><span class="str">    Step 2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4192" href="#t4192">4192</a></span><span class="t"><span class="str">    :attr:`power_iters` should be a positive integer, do following</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4193" href="#t4193">4193</a></span><span class="t"><span class="str">    calculations with U and V for :attr:`power_iters` rounds. Calculations</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4194" href="#t4194">4194</a></span><span class="t"><span class="str">    as follows:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4195" href="#t4195">4195</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4196" href="#t4196">4196</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4197" href="#t4197">4197</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4198" href="#t4198">4198</a></span><span class="t"><span class="str">        \mathbf{v} := \\frac{\mathbf{W}^{T} \mathbf{u}}{\|\mathbf{W}^{T} \mathbf{u}\|_2}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4199" href="#t4199">4199</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4200" href="#t4200">4200</a></span><span class="t"><span class="str">        \mathbf{u} := \\frac{\mathbf{W}^{T} \mathbf{v}}{\|\mathbf{W}^{T} \mathbf{v}\|_2}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4201" href="#t4201">4201</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4202" href="#t4202">4202</a></span><span class="t"><span class="str">    Step 3:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4203" href="#t4203">4203</a></span><span class="t"><span class="str">    Calculate :math:`\sigma(\mathbf{W})` and normalize weight values.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4204" href="#t4204">4204</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4205" href="#t4205">4205</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4206" href="#t4206">4206</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4207" href="#t4207">4207</a></span><span class="t"><span class="str">        \sigma(\mathbf{W}) = \mathbf{u}^{T} \mathbf{W} \mathbf{v}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4208" href="#t4208">4208</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4209" href="#t4209">4209</a></span><span class="t"><span class="str">        \mathbf{W} = \\frac{\mathbf{W}}{\sigma(\mathbf{W})}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4210" href="#t4210">4210</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4211" href="#t4211">4211</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4212" href="#t4212">4212</a></span><span class="t"><span class="str">    Refer to `Spectral Normalization &lt;https://arxiv.org/abs/1802.05957>`_ .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4213" href="#t4213">4213</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4214" href="#t4214">4214</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4215" href="#t4215">4215</a></span><span class="t"><span class="str">        weight(Tensor): ${weight_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4216" href="#t4216">4216</a></span><span class="t"><span class="str">        dim(int): ${dim_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4217" href="#t4217">4217</a></span><span class="t"><span class="str">        power_iters(int): ${power_iters_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4218" href="#t4218">4218</a></span><span class="t"><span class="str">        eps(float): ${eps_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4219" href="#t4219">4219</a></span><span class="t"><span class="str">        name(str, optional): For detailed information, please refer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4220" href="#t4220">4220</a></span><span class="t"><span class="str">                             to :ref:`api_guide_Name`. Usually name is no need to set and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4221" href="#t4221">4221</a></span><span class="t"><span class="str">                             None by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4222" href="#t4222">4222</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4223" href="#t4223">4223</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4224" href="#t4224">4224</a></span><span class="t"><span class="str">        Tensor: A tensor of weight parameters after spectral normalization.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4225" href="#t4225">4225</a></span><span class="t"><span class="str">                  The data type and shape is same as input tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4226" href="#t4226">4226</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4227" href="#t4227">4227</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4228" href="#t4228">4228</a></span><span class="t"><span class="str">       .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4229" href="#t4229">4229</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4230" href="#t4230">4230</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4231" href="#t4231">4231</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4232" href="#t4232">4232</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4233" href="#t4233">4233</a></span><span class="t"><span class="str">            weight = paddle.static.data(name='weight', shape=[2, 8, 32, 32], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4234" href="#t4234">4234</a></span><span class="t"><span class="str">            x = paddle.static.nn.spectral_norm(weight=weight, dim=1, power_iters=2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4235" href="#t4235">4235</a></span><span class="t"><span class="str">            print(x.shape) # [2, 8, 32, 32]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4236" href="#t4236">4236</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4237" href="#t4237">4237</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'spectral_norm'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4238" href="#t4238">4238</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4239" href="#t4239">4239</a></span><span class="t">        <span class="nam">weight</span><span class="op">,</span> <span class="str">'weight'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'spectral_norm'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4240" href="#t4240">4240</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4241" href="#t4241">4241</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="str">'dim'</span><span class="op">,</span> <span class="nam">int</span><span class="op">,</span> <span class="str">'spectral_norm'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4242" href="#t4242">4242</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">power_iters</span><span class="op">,</span> <span class="str">'power_iters'</span><span class="op">,</span> <span class="nam">int</span><span class="op">,</span> <span class="str">'spectral_norm'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4243" href="#t4243">4243</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">eps</span><span class="op">,</span> <span class="str">'eps'</span><span class="op">,</span> <span class="nam">float</span><span class="op">,</span> <span class="str">'spectral_norm'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4244" href="#t4244">4244</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">weight</span><span class="op">.</span><span class="nam">dtype</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4245" href="#t4245">4245</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4246" href="#t4246">4246</a></span><span class="t">    <span class="com"># create intput and parameters</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4247" href="#t4247">4247</a></span><span class="t">    <span class="nam">input_shape</span> <span class="op">=</span> <span class="nam">weight</span><span class="op">.</span><span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4248" href="#t4248">4248</a></span><span class="t">    <span class="key">assert</span> <span class="nam">weight</span><span class="op">.</span><span class="nam">numel</span><span class="op">(</span><span class="op">)</span> <span class="op">></span> <span class="num">0</span><span class="op">,</span> <span class="str">"Any dimension of input cannot be equal to 0."</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4249" href="#t4249">4249</a></span><span class="t">    <span class="key">assert</span> <span class="nam">dim</span> <span class="op">&lt;</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input_shape</span><span class="op">)</span><span class="op">,</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4250" href="#t4250">4250</a></span><span class="t">        <span class="str">"The input `dim` should be less than the "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4251" href="#t4251">4251</a></span><span class="t">        <span class="str">"rank of `weight`, but received dim="</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4252" href="#t4252">4252</a></span><span class="t">        <span class="str">"{}"</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">dim</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4253" href="#t4253">4253</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4254" href="#t4254">4254</a></span><span class="t">    <span class="nam">h</span> <span class="op">=</span> <span class="nam">input_shape</span><span class="op">[</span><span class="nam">dim</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4255" href="#t4255">4255</a></span><span class="t">    <span class="nam">w</span> <span class="op">=</span> <span class="nam">np</span><span class="op">.</span><span class="nam">prod</span><span class="op">(</span><span class="nam">input_shape</span><span class="op">)</span> <span class="op">//</span> <span class="nam">h</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4256" href="#t4256">4256</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4257" href="#t4257">4257</a></span><span class="t">    <span class="nam">u</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4258" href="#t4258">4258</a></span><span class="t">        <span class="nam">attr</span><span class="op">=</span><span class="nam">ParamAttr</span><span class="op">(</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4259" href="#t4259">4259</a></span><span class="t">        <span class="nam">shape</span><span class="op">=</span><span class="op">[</span><span class="nam">h</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4260" href="#t4260">4260</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4261" href="#t4261">4261</a></span><span class="t">        <span class="nam">default_initializer</span><span class="op">=</span><span class="nam">Normal</span><span class="op">(</span><span class="num">0.0</span><span class="op">,</span> <span class="num">1.0</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4262" href="#t4262">4262</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4263" href="#t4263">4263</a></span><span class="t">    <span class="nam">u</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4264" href="#t4264">4264</a></span><span class="t">    <span class="nam">v</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4265" href="#t4265">4265</a></span><span class="t">        <span class="nam">attr</span><span class="op">=</span><span class="nam">ParamAttr</span><span class="op">(</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4266" href="#t4266">4266</a></span><span class="t">        <span class="nam">shape</span><span class="op">=</span><span class="op">[</span><span class="nam">w</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4267" href="#t4267">4267</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4268" href="#t4268">4268</a></span><span class="t">        <span class="nam">default_initializer</span><span class="op">=</span><span class="nam">Normal</span><span class="op">(</span><span class="num">0.0</span><span class="op">,</span> <span class="num">1.0</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4269" href="#t4269">4269</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4270" href="#t4270">4270</a></span><span class="t">    <span class="nam">v</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4271" href="#t4271">4271</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4272" href="#t4272">4272</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4273" href="#t4273">4273</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">spectral_norm</span><span class="op">(</span><span class="nam">weight</span><span class="op">,</span> <span class="nam">u</span><span class="op">,</span> <span class="nam">v</span><span class="op">,</span> <span class="nam">dim</span><span class="op">,</span> <span class="nam">power_iters</span><span class="op">,</span> <span class="nam">eps</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4274" href="#t4274">4274</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4275" href="#t4275">4275</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'Weight'</span><span class="op">:</span> <span class="nam">weight</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4276" href="#t4276">4276</a></span><span class="t">    <span class="nam">inputs</span><span class="op">[</span><span class="str">'U'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">u</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4277" href="#t4277">4277</a></span><span class="t">    <span class="nam">inputs</span><span class="op">[</span><span class="str">'V'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">v</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4278" href="#t4278">4278</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4279" href="#t4279">4279</a></span><span class="t">    <span class="com"># create output</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4280" href="#t4280">4280</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4281" href="#t4281">4281</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4282" href="#t4282">4282</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4283" href="#t4283">4283</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"spectral_norm"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4284" href="#t4284">4284</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4285" href="#t4285">4285</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4286" href="#t4286">4286</a></span><span class="t">            <span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4287" href="#t4287">4287</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4288" href="#t4288">4288</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4289" href="#t4289">4289</a></span><span class="t">            <span class="str">"dim"</span><span class="op">:</span> <span class="nam">dim</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4290" href="#t4290">4290</a></span><span class="t">            <span class="str">"power_iters"</span><span class="op">:</span> <span class="nam">power_iters</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4291" href="#t4291">4291</a></span><span class="t">            <span class="str">"eps"</span><span class="op">:</span> <span class="nam">eps</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4292" href="#t4292">4292</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4293" href="#t4293">4293</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4294" href="#t4294">4294</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4295" href="#t4295">4295</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4296" href="#t4296">4296</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4297" href="#t4297">4297</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t4298" href="#t4298">4298</a></span><span class="t"><span class="key">def</span> <span class="nam">conv2d_transpose</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4299" href="#t4299">4299</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4300" href="#t4300">4300</a></span><span class="t">    <span class="nam">num_filters</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4301" href="#t4301">4301</a></span><span class="t">    <span class="nam">output_size</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4302" href="#t4302">4302</a></span><span class="t">    <span class="nam">filter_size</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4303" href="#t4303">4303</a></span><span class="t">    <span class="nam">padding</span><span class="op">=</span><span class="num">0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4304" href="#t4304">4304</a></span><span class="t">    <span class="nam">stride</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4305" href="#t4305">4305</a></span><span class="t">    <span class="nam">dilation</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4306" href="#t4306">4306</a></span><span class="t">    <span class="nam">groups</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4307" href="#t4307">4307</a></span><span class="t">    <span class="nam">param_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4308" href="#t4308">4308</a></span><span class="t">    <span class="nam">bias_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4309" href="#t4309">4309</a></span><span class="t">    <span class="nam">use_cudnn</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4310" href="#t4310">4310</a></span><span class="t">    <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4311" href="#t4311">4311</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4312" href="#t4312">4312</a></span><span class="t">    <span class="nam">data_format</span><span class="op">=</span><span class="str">'NCHW'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4313" href="#t4313">4313</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4314" href="#t4314">4314</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4315" href="#t4315">4315</a></span><span class="t"><span class="str">    :api_attr: Static Graph</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4316" href="#t4316">4316</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4317" href="#t4317">4317</a></span><span class="t"><span class="str">    The convolution2D transpose layer calculates the output based on the input,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4318" href="#t4318">4318</a></span><span class="t"><span class="str">    filter, and dilations, strides, paddings. Input(Input) and output(Output)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4319" href="#t4319">4319</a></span><span class="t"><span class="str">    are in NCHW or NHWC format. Where N is batch size, C is the number of channels,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4320" href="#t4320">4320</a></span><span class="t"><span class="str">    H is the height of the feature, and W is the width of the feature.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4321" href="#t4321">4321</a></span><span class="t"><span class="str">    Parameters(dilations, strides, paddings) are two elements. These two elements</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4322" href="#t4322">4322</a></span><span class="t"><span class="str">    represent height and width, respectively. The details of convolution transpose</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4323" href="#t4323">4323</a></span><span class="t"><span class="str">    layer, please refer to the following explanation and references</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4324" href="#t4324">4324</a></span><span class="t"><span class="str">    `therein &lt;https://arxiv.org/pdf/1603.07285.pdf>`_.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4325" href="#t4325">4325</a></span><span class="t"><span class="str">    If bias attribution and activation type are provided, bias is added to</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4326" href="#t4326">4326</a></span><span class="t"><span class="str">    the output of the convolution, and the corresponding activation function</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4327" href="#t4327">4327</a></span><span class="t"><span class="str">    is applied to the final result.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4328" href="#t4328">4328</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4329" href="#t4329">4329</a></span><span class="t"><span class="str">    For each input :math:`X`, the equation is:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4330" href="#t4330">4330</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4331" href="#t4331">4331</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4332" href="#t4332">4332</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4333" href="#t4333">4333</a></span><span class="t"><span class="str">        Out = \sigma (W \\ast X + b)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4334" href="#t4334">4334</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4335" href="#t4335">4335</a></span><span class="t"><span class="str">    Where:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4336" href="#t4336">4336</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4337" href="#t4337">4337</a></span><span class="t"><span class="str">    * :math:`X`: Input value, a 4-D Tensor with NCHW or NHWC format.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4338" href="#t4338">4338</a></span><span class="t"><span class="str">    * :math:`W`: Filter value, a 4-D Tensor with MCHW format.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4339" href="#t4339">4339</a></span><span class="t"><span class="str">    * :math:`\\ast`: Convolution operation.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4340" href="#t4340">4340</a></span><span class="t"><span class="str">    * :math:`b`: Bias value, a 2-D Tensor with shape [M, 1].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4341" href="#t4341">4341</a></span><span class="t"><span class="str">    * :math:`\\sigma`: Activation function.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4342" href="#t4342">4342</a></span><span class="t"><span class="str">    * :math:`Out`: Output value, a 4-D Tensor with data format 'NCHW' or 'NHWC', the shape of :math:`Out` and :math:`X` may be different.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4343" href="#t4343">4343</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4344" href="#t4344">4344</a></span><span class="t"><span class="str">    Example:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4345" href="#t4345">4345</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4346" href="#t4346">4346</a></span><span class="t"><span class="str">        - Input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4347" href="#t4347">4347</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4348" href="#t4348">4348</a></span><span class="t"><span class="str">          Input shape: :math:`(N, C_{in}, H_{in}, W_{in})`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4349" href="#t4349">4349</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4350" href="#t4350">4350</a></span><span class="t"><span class="str">          Filter shape: :math:`(C_{in}, C_{out}, H_f, W_f)`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4351" href="#t4351">4351</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4352" href="#t4352">4352</a></span><span class="t"><span class="str">        - Output:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4353" href="#t4353">4353</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4354" href="#t4354">4354</a></span><span class="t"><span class="str">          Output shape: :math:`(N, C_{out}, H_{out}, W_{out})`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4355" href="#t4355">4355</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4356" href="#t4356">4356</a></span><span class="t"><span class="str">        Where</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4357" href="#t4357">4357</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4358" href="#t4358">4358</a></span><span class="t"><span class="str">        .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4359" href="#t4359">4359</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4360" href="#t4360">4360</a></span><span class="t"><span class="str">           H^\prime_{out} &amp;= (H_{in} - 1) * strides[0] - pad_height_top - pad_height_bottom + dilations[0] * (H_f - 1) + 1 \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4361" href="#t4361">4361</a></span><span class="t"><span class="str">           W^\prime_{out} &amp;= (W_{in} - 1) * strides[1] - pad_width_left - pad_width_right + dilations[1] * (W_f - 1) + 1 \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4362" href="#t4362">4362</a></span><span class="t"><span class="str">           H_{out} &amp;\in [ H^\prime_{out}, H^\prime_{out} + strides[0] ] \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4363" href="#t4363">4363</a></span><span class="t"><span class="str">           W_{out} &amp;\in [ W^\prime_{out}, W^\prime_{out} + strides[1] ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4364" href="#t4364">4364</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4365" href="#t4365">4365</a></span><span class="t"><span class="str">    Note:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4366" href="#t4366">4366</a></span><span class="t"><span class="str">          The conv2d_transpose can be seen as the backward of the conv2d. For conv2d,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4367" href="#t4367">4367</a></span><span class="t"><span class="str">          when stride > 1, conv2d maps multiple input shape to the same output shape,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4368" href="#t4368">4368</a></span><span class="t"><span class="str">          so for conv2d_transpose, when stride > 1, input shape maps multiple output shape.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4369" href="#t4369">4369</a></span><span class="t"><span class="str">          If output_size is None, :math:`H_{out} = H^\prime_{out}, W_{out} = W^\prime_{out}`;</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4370" href="#t4370">4370</a></span><span class="t"><span class="str">          else, the :math:`H_{out}` of the output size must between :math:`H^\prime_{out}`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4371" href="#t4371">4371</a></span><span class="t"><span class="str">          and :math:`H^\prime_{out} + strides[0]`, and the :math:`W_{out}` of the output size must</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4372" href="#t4372">4372</a></span><span class="t"><span class="str">          between :math:`W^\prime_{out}` and :math:`W^\prime_{out} + strides[1]`,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4373" href="#t4373">4373</a></span><span class="t"><span class="str">          conv2d_transpose can compute the kernel size automatically.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4374" href="#t4374">4374</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4375" href="#t4375">4375</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4376" href="#t4376">4376</a></span><span class="t"><span class="str">        input(Tensor): 4-D Tensor with [N, C, H, W] or [N, H, W, C] format,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4377" href="#t4377">4377</a></span><span class="t"><span class="str">                         its data type is float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4378" href="#t4378">4378</a></span><span class="t"><span class="str">        num_filters(int): The number of the filter. It is as same as the output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4379" href="#t4379">4379</a></span><span class="t"><span class="str">            image channel.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4380" href="#t4380">4380</a></span><span class="t"><span class="str">        output_size(int|tuple, optional): The output image size. If output size is a</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4381" href="#t4381">4381</a></span><span class="t"><span class="str">            tuple, it must contain two integers, (image_height, image_width). None if use</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4382" href="#t4382">4382</a></span><span class="t"><span class="str">            filter_size, padding, and stride to calculate output_size.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4383" href="#t4383">4383</a></span><span class="t"><span class="str">            If output_size and filter_size are specified at the same time, They</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4384" href="#t4384">4384</a></span><span class="t"><span class="str">            should follow the formula above. Default: None. output_size and filter_size</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4385" href="#t4385">4385</a></span><span class="t"><span class="str">            should not be None at the same time.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4386" href="#t4386">4386</a></span><span class="t"><span class="str">        filter_size(int|tuple, optional): The filter size. If filter_size is a tuple,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4387" href="#t4387">4387</a></span><span class="t"><span class="str">            it must contain two integers, (filter_size_height, filter_size_width).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4388" href="#t4388">4388</a></span><span class="t"><span class="str">            Otherwise, filter_size_height = filter_size_width = filter_size. None if</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4389" href="#t4389">4389</a></span><span class="t"><span class="str">            use output size to calculate filter_size. Default: None. filter_size and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4390" href="#t4390">4390</a></span><span class="t"><span class="str">            output_size should not be None at the same time.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4391" href="#t4391">4391</a></span><span class="t"><span class="str">        stride(int|tuple, optional): The stride size. It means the stride in transposed convolution.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4392" href="#t4392">4392</a></span><span class="t"><span class="str">            If stride is a tuple, it must contain two integers, (stride_height, stride_width).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4393" href="#t4393">4393</a></span><span class="t"><span class="str">            Otherwise, stride_height = stride_width = stride. Default: stride = 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4394" href="#t4394">4394</a></span><span class="t"><span class="str">        padding(str|int|list|tuple, optional): The padding size. It means the number of zero-paddings </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4395" href="#t4395">4395</a></span><span class="t"><span class="str">            on both sides for each dimension. If `padding` is a string, either 'VALID' or </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4396" href="#t4396">4396</a></span><span class="t"><span class="str">            'SAME' which is the padding algorithm. If `padding` is a tuple or list,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4397" href="#t4397">4397</a></span><span class="t"><span class="str">            it could be in three forms: `[pad_height, pad_width]` or </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4398" href="#t4398">4398</a></span><span class="t"><span class="str">            `[pad_height_top, pad_height_bottom, pad_width_left, pad_width_right]`,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4399" href="#t4399">4399</a></span><span class="t"><span class="str">            and when `data_format` is `"NCHW"`, `padding` can be in the form </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4400" href="#t4400">4400</a></span><span class="t"><span class="str">            `[[0,0], [0,0], [pad_height_top, pad_height_bottom], [pad_width_left, pad_width_right]]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4401" href="#t4401">4401</a></span><span class="t"><span class="str">            when `data_format` is `"NHWC"`, `padding` can be in the form </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4402" href="#t4402">4402</a></span><span class="t"><span class="str">            `[[0,0], [pad_height_top, pad_height_bottom], [pad_width_left, pad_width_right], [0,0]]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4403" href="#t4403">4403</a></span><span class="t"><span class="str">            Default: padding = 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4404" href="#t4404">4404</a></span><span class="t"><span class="str">        dilation(int|tuple, optional): The dilation size. It means the spacing between the kernel points.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4405" href="#t4405">4405</a></span><span class="t"><span class="str">            If dilation is a tuple, it must contain two integers, (dilation_height, dilation_width).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4406" href="#t4406">4406</a></span><span class="t"><span class="str">            Otherwise, dilation_height = dilation_width = dilation. Default: dilation = 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4407" href="#t4407">4407</a></span><span class="t"><span class="str">        filter_size(int|tuple, optional): The filter size. If filter_size is a tuple,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4408" href="#t4408">4408</a></span><span class="t"><span class="str">            it must contain two integers, (filter_size_height, filter_size_width).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4409" href="#t4409">4409</a></span><span class="t"><span class="str">            Otherwise, filter_size_height = filter_size_width = filter_size. None if</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4410" href="#t4410">4410</a></span><span class="t"><span class="str">            use output size to calculate filter_size. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4411" href="#t4411">4411</a></span><span class="t"><span class="str">        groups(int, optional): The groups number of the Conv2d transpose layer. Inspired by</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4412" href="#t4412">4412</a></span><span class="t"><span class="str">            grouped convolution in Alex Krizhevsky's Deep CNN paper, in which</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4413" href="#t4413">4413</a></span><span class="t"><span class="str">            when group=2, the first half of the filters is only connected to the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4414" href="#t4414">4414</a></span><span class="t"><span class="str">            first half of the input channels, while the second half of the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4415" href="#t4415">4415</a></span><span class="t"><span class="str">            filters is only connected to the second half of the input channels.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4416" href="#t4416">4416</a></span><span class="t"><span class="str">            Default: groups = 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4417" href="#t4417">4417</a></span><span class="t"><span class="str">        param_attr (ParamAttr, optional): The parameter attribute for learnable parameters/weights</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4418" href="#t4418">4418</a></span><span class="t"><span class="str">            of conv2d_transpose. If it is set to None or one attribute of ParamAttr, conv2d_transpose</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4419" href="#t4419">4419</a></span><span class="t"><span class="str">            will create ParamAttr as param_attr. If the Initializer of the param_attr</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4420" href="#t4420">4420</a></span><span class="t"><span class="str">            is not set, the parameter is initialized with Xavier. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4421" href="#t4421">4421</a></span><span class="t"><span class="str">        bias_attr (ParamAttr|bool, optional): The parameter attribute for the bias of conv2d_transpose.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4422" href="#t4422">4422</a></span><span class="t"><span class="str">            If it is set to False, no bias will be added to the output units.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4423" href="#t4423">4423</a></span><span class="t"><span class="str">            If it is set to None or one attribute of ParamAttr, conv2d_transpose</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4424" href="#t4424">4424</a></span><span class="t"><span class="str">            will create ParamAttr as bias_attr. If the Initializer of the bias_attr</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4425" href="#t4425">4425</a></span><span class="t"><span class="str">            is not set, the bias is initialized zero. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4426" href="#t4426">4426</a></span><span class="t"><span class="str">        use_cudnn(bool, optional): Use cudnn kernel or not, it is valid only when the cudnn</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4427" href="#t4427">4427</a></span><span class="t"><span class="str">            library is installed. Default: True.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4428" href="#t4428">4428</a></span><span class="t"><span class="str">        act (str, optional): Activation type, if it is set to None, activation is not appended.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4429" href="#t4429">4429</a></span><span class="t"><span class="str">            Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4430" href="#t4430">4430</a></span><span class="t"><span class="str">        name(str, optional): For detailed information, please refer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4431" href="#t4431">4431</a></span><span class="t"><span class="str">           to :ref:`api_guide_Name`. Usually name is no need to set and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4432" href="#t4432">4432</a></span><span class="t"><span class="str">           None by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4433" href="#t4433">4433</a></span><span class="t"><span class="str">        data_format (str, optional): Specify the data format of the input, and the data format of the output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4434" href="#t4434">4434</a></span><span class="t"><span class="str">            will be consistent with that of the input. An optional string from: `"NCHW"`, `"NHWC"`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4435" href="#t4435">4435</a></span><span class="t"><span class="str">            The default is `"NCHW"`. When it is `"NCHW"`, the data is stored in the order of:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4436" href="#t4436">4436</a></span><span class="t"><span class="str">            `[batch_size, input_channels, input_height, input_width]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4437" href="#t4437">4437</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4438" href="#t4438">4438</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4439" href="#t4439">4439</a></span><span class="t"><span class="str">        A Tensor representing the conv2d_transpose, whose</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4440" href="#t4440">4440</a></span><span class="t"><span class="str">        data type is the same with input and shape is (num_batches, channels, out_h,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4441" href="#t4441">4441</a></span><span class="t"><span class="str">        out_w) or (num_batches, out_h, out_w, channels). If act is None, the tensor </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4442" href="#t4442">4442</a></span><span class="t"><span class="str">        storing the transposed convolution result, and if act is not None, the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4443" href="#t4443">4443</a></span><span class="t"><span class="str">        tensor storing transposed convolution and non-linearity activation</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4444" href="#t4444">4444</a></span><span class="t"><span class="str">        result.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4445" href="#t4445">4445</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4446" href="#t4446">4446</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4447" href="#t4447">4447</a></span><span class="t"><span class="str">        ValueError: If the type of `use_cudnn` is not bool.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4448" href="#t4448">4448</a></span><span class="t"><span class="str">        ValueError: If `data_format` is not "NCHW" or "NHWC".</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4449" href="#t4449">4449</a></span><span class="t"><span class="str">        ValueError: If `padding` is a string, but not "SAME" or "VALID".</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4450" href="#t4450">4450</a></span><span class="t"><span class="str">        ValueError: If `padding` is a tuple, but the element corresponding to the input's batch size is not 0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4451" href="#t4451">4451</a></span><span class="t"><span class="str">            or the element corresponding to the input's channel is not 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4452" href="#t4452">4452</a></span><span class="t"><span class="str">        ValueError: If `output_size` and filter_size are None at the same time.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4453" href="#t4453">4453</a></span><span class="t"><span class="str">        ShapeError: If the input is not 4-D Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4454" href="#t4454">4454</a></span><span class="t"><span class="str">        ShapeError: If the input's dimension size and filter's dimension size not equal.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4455" href="#t4455">4455</a></span><span class="t"><span class="str">        ShapeError: If the dimension size of input minus the size of `stride` is not 2.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4456" href="#t4456">4456</a></span><span class="t"><span class="str">        ShapeError: If the number of input channels is not equal to filter's channels.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4457" href="#t4457">4457</a></span><span class="t"><span class="str">        ShapeError: If the size of `output_size` is not equal to that of `stride`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4458" href="#t4458">4458</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4459" href="#t4459">4459</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4460" href="#t4460">4460</a></span><span class="t"><span class="str">       .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4461" href="#t4461">4461</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4462" href="#t4462">4462</a></span><span class="t"><span class="str">          import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4463" href="#t4463">4463</a></span><span class="t"><span class="str">          paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4464" href="#t4464">4464</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4465" href="#t4465">4465</a></span><span class="t"><span class="str">          data = paddle.static.data(name='data', shape=[None, 3, 32, 32], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4466" href="#t4466">4466</a></span><span class="t"><span class="str">          conv2d_transpose = paddle.static.nn.conv2d_transpose(input=data, num_filters=2, filter_size=3)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4467" href="#t4467">4467</a></span><span class="t"><span class="str">          print(conv2d_transpose.shape) # [-1, 2, 34, 34]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4468" href="#t4468">4468</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4469" href="#t4469">4469</a></span><span class="t">    <span class="key">assert</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4470" href="#t4470">4470</a></span><span class="t">        <span class="nam">param_attr</span> <span class="key">is</span> <span class="key">not</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4471" href="#t4471">4471</a></span><span class="t">    <span class="op">)</span><span class="op">,</span> <span class="str">"param_attr should not be False in conv2d_transpose."</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4472" href="#t4472">4472</a></span><span class="t">    <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">!=</span> <span class="num">4</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4473" href="#t4473">4473</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4474" href="#t4474">4474</a></span><span class="t">            <span class="str">"Input size should be 4, "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4475" href="#t4475">4475</a></span><span class="t">            <span class="str">"but received {}"</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4476" href="#t4476">4476</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4477" href="#t4477">4477</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4478" href="#t4478">4478</a></span><span class="t">    <span class="key">if</span> <span class="nam">data_format</span> <span class="key">not</span> <span class="key">in</span> <span class="op">[</span><span class="str">'NCHW'</span><span class="op">,</span> <span class="str">'NHWC'</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4479" href="#t4479">4479</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4480" href="#t4480">4480</a></span><span class="t">            <span class="str">"Attr(data_format) of Op(fluid.layers.conv2d_transpose) got wrong value: received "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4481" href="#t4481">4481</a></span><span class="t">            <span class="op">+</span> <span class="nam">data_format</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4482" href="#t4482">4482</a></span><span class="t">            <span class="op">+</span> <span class="str">" but only NCHW or NHWC supported."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4483" href="#t4483">4483</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4484" href="#t4484">4484</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4485" href="#t4485">4485</a></span><span class="t">    <span class="nam">input_channel</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span> <span class="key">if</span> <span class="nam">data_format</span> <span class="op">==</span> <span class="str">'NCHW'</span> <span class="key">else</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4486" href="#t4486">4486</a></span><span class="t">    <span class="nam">op_type</span> <span class="op">=</span> <span class="str">'conv2d_transpose'</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4487" href="#t4487">4487</a></span><span class="t">    <span class="key">if</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4488" href="#t4488">4488</a></span><span class="t">        <span class="nam">input_channel</span> <span class="op">==</span> <span class="nam">groups</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4489" href="#t4489">4489</a></span><span class="t">        <span class="key">and</span> <span class="nam">num_filters</span> <span class="op">==</span> <span class="nam">input_channel</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4490" href="#t4490">4490</a></span><span class="t">        <span class="key">and</span> <span class="key">not</span> <span class="nam">use_cudnn</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4491" href="#t4491">4491</a></span><span class="t">    <span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4492" href="#t4492">4492</a></span><span class="t">        <span class="nam">op_type</span> <span class="op">=</span> <span class="str">'depthwise_conv2d_transpose'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4493" href="#t4493">4493</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4494" href="#t4494">4494</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="nam">op_type</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4495" href="#t4495">4495</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4496" href="#t4496">4496</a></span><span class="t">        <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span><span class="str">"Input of conv2d_transpose must be Variable"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4497" href="#t4497">4497</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4498" href="#t4498">4498</a></span><span class="t">    <span class="nam">stride</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">stride</span><span class="op">,</span> <span class="num">2</span><span class="op">,</span> <span class="str">'stride'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4499" href="#t4499">4499</a></span><span class="t">    <span class="nam">dilation</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">dilation</span><span class="op">,</span> <span class="num">2</span><span class="op">,</span> <span class="str">'dilation'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4500" href="#t4500">4500</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4501" href="#t4501">4501</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">use_cudnn</span><span class="op">,</span> <span class="nam">bool</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4502" href="#t4502">4502</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"use_cudnn should be True or False"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4503" href="#t4503">4503</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4504" href="#t4504">4504</a></span><span class="t">    <span class="key">def</span> <span class="nam">_update_padding</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="nam">data_format</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4505" href="#t4505">4505</a></span><span class="t">        <span class="key">def</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">ele</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4506" href="#t4506">4506</a></span><span class="t">            <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">ele</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span> <span class="key">or</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">ele</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4507" href="#t4507">4507</a></span><span class="t">                <span class="key">return</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4508" href="#t4508">4508</a></span><span class="t">            <span class="key">return</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4509" href="#t4509">4509</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4510" href="#t4510">4510</a></span><span class="t">        <span class="key">if</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span> <span class="key">and</span> <span class="nam">len</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span> <span class="op">==</span> <span class="num">4</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4511" href="#t4511">4511</a></span><span class="t">            <span class="key">if</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">)</span> <span class="key">and</span> <span class="op">(</span><span class="nam">data_format</span> <span class="op">==</span> <span class="str">"NCHW"</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4512" href="#t4512">4512</a></span><span class="t">                <span class="key">if</span> <span class="key">not</span> <span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">==</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span> <span class="key">and</span> <span class="nam">padding</span><span class="op">[</span><span class="num">1</span><span class="op">]</span> <span class="op">==</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4513" href="#t4513">4513</a></span><span class="t">                    <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4514" href="#t4514">4514</a></span><span class="t">                        <span class="str">"Non-zero padding(%s) in the batch or channel dimensions "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4515" href="#t4515">4515</a></span><span class="t">                        <span class="str">"is not supported."</span> <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4516" href="#t4516">4516</a></span><span class="t">                    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4517" href="#t4517">4517</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="nam">padding</span><span class="op">[</span><span class="num">2</span><span class="op">:</span><span class="num">4</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4518" href="#t4518">4518</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="nam">ele</span> <span class="key">for</span> <span class="nam">a_list</span> <span class="key">in</span> <span class="nam">padding</span> <span class="key">for</span> <span class="nam">ele</span> <span class="key">in</span> <span class="nam">a_list</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4519" href="#t4519">4519</a></span><span class="t">            <span class="key">elif</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">)</span> <span class="key">and</span> <span class="op">(</span><span class="nam">data_format</span> <span class="op">==</span> <span class="str">"NHWC"</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4520" href="#t4520">4520</a></span><span class="t">                <span class="key">if</span> <span class="key">not</span> <span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">==</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span> <span class="key">and</span> <span class="nam">padding</span><span class="op">[</span><span class="num">3</span><span class="op">]</span> <span class="op">==</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4521" href="#t4521">4521</a></span><span class="t">                    <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4522" href="#t4522">4522</a></span><span class="t">                        <span class="str">"Non-zero padding(%s) in the batch or channel dimensions "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4523" href="#t4523">4523</a></span><span class="t">                        <span class="str">"is not supported."</span> <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4524" href="#t4524">4524</a></span><span class="t">                    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4525" href="#t4525">4525</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="nam">padding</span><span class="op">[</span><span class="num">1</span><span class="op">:</span><span class="num">3</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4526" href="#t4526">4526</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="nam">ele</span> <span class="key">for</span> <span class="nam">a_list</span> <span class="key">in</span> <span class="nam">padding</span> <span class="key">for</span> <span class="nam">ele</span> <span class="key">in</span> <span class="nam">a_list</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4527" href="#t4527">4527</a></span><span class="t">            <span class="nam">padding</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="num">4</span><span class="op">,</span> <span class="str">'padding'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4528" href="#t4528">4528</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4529" href="#t4529">4529</a></span><span class="t">            <span class="nam">padding</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="num">2</span><span class="op">,</span> <span class="str">'padding'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4530" href="#t4530">4530</a></span><span class="t">            <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span> <span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span> <span class="nam">padding</span><span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">,</span> <span class="nam">padding</span><span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4531" href="#t4531">4531</a></span><span class="t">        <span class="key">return</span> <span class="nam">padding</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4532" href="#t4532">4532</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4533" href="#t4533">4533</a></span><span class="t">    <span class="nam">padding_algorithm</span> <span class="op">=</span> <span class="str">"EXPLICIT"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4534" href="#t4534">4534</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="nam">str</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4535" href="#t4535">4535</a></span><span class="t">        <span class="nam">padding</span> <span class="op">=</span> <span class="nam">padding</span><span class="op">.</span><span class="nam">upper</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4536" href="#t4536">4536</a></span><span class="t">        <span class="key">if</span> <span class="nam">padding</span> <span class="key">not</span> <span class="key">in</span> <span class="op">[</span><span class="str">"SAME"</span><span class="op">,</span> <span class="str">"VALID"</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4537" href="#t4537">4537</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4538" href="#t4538">4538</a></span><span class="t">                <span class="str">"Unknown padding: '%s'. It can only be 'SAME' or 'VALID'."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4539" href="#t4539">4539</a></span><span class="t">                <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4540" href="#t4540">4540</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4541" href="#t4541">4541</a></span><span class="t">        <span class="key">if</span> <span class="nam">padding</span> <span class="op">==</span> <span class="str">"VALID"</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4542" href="#t4542">4542</a></span><span class="t">            <span class="nam">padding_algorithm</span> <span class="op">=</span> <span class="str">"VALID"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4543" href="#t4543">4543</a></span><span class="t">            <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4544" href="#t4544">4544</a></span><span class="t">        <span class="key">elif</span> <span class="nam">padding</span> <span class="op">==</span> <span class="str">"SAME"</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4545" href="#t4545">4545</a></span><span class="t">            <span class="nam">padding_algorithm</span> <span class="op">=</span> <span class="str">"SAME"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4546" href="#t4546">4546</a></span><span class="t">            <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4547" href="#t4547">4547</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4548" href="#t4548">4548</a></span><span class="t">    <span class="nam">padding</span> <span class="op">=</span> <span class="nam">_update_padding</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="nam">data_format</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4549" href="#t4549">4549</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4550" href="#t4550">4550</a></span><span class="t">    <span class="key">if</span> <span class="nam">output_size</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4551" href="#t4551">4551</a></span><span class="t">        <span class="nam">output_size</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4552" href="#t4552">4552</a></span><span class="t">    <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">output_size</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4553" href="#t4553">4553</a></span><span class="t">        <span class="key">if</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_contain_var</span><span class="op">(</span><span class="nam">output_size</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4554" href="#t4554">4554</a></span><span class="t">            <span class="nam">output_size</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_convert_to_tensor_list</span><span class="op">(</span><span class="nam">output_size</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4555" href="#t4555">4555</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4556" href="#t4556">4556</a></span><span class="t">            <span class="nam">output_size</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">output_size</span><span class="op">,</span> <span class="num">2</span><span class="op">,</span> <span class="str">'output_size'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4557" href="#t4557">4557</a></span><span class="t">    <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">output_size</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4558" href="#t4558">4558</a></span><span class="t">        <span class="nam">output_size</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">output_size</span><span class="op">,</span> <span class="num">2</span><span class="op">,</span> <span class="str">'output_size'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4559" href="#t4559">4559</a></span><span class="t">    <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">output_size</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4560" href="#t4560">4560</a></span><span class="t">        <span class="nam">check_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4561" href="#t4561">4561</a></span><span class="t">            <span class="nam">output_size</span><span class="op">.</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4562" href="#t4562">4562</a></span><span class="t">            <span class="str">'output_size'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4563" href="#t4563">4563</a></span><span class="t">            <span class="op">[</span><span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4564" href="#t4564">4564</a></span><span class="t">            <span class="str">'conv2d_transpose'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4565" href="#t4565">4565</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4566" href="#t4566">4566</a></span><span class="t">        <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">output_size</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">==</span> <span class="num">1</span> <span class="key">and</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4567" href="#t4567">4567</a></span><span class="t">            <span class="nam">output_size</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">==</span> <span class="num">1</span> <span class="key">or</span> <span class="nam">output_size</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">==</span> <span class="num">2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4568" href="#t4568">4568</a></span><span class="t">        <span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4569" href="#t4569">4569</a></span><span class="t">            <span class="key">if</span> <span class="nam">output_size</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">==</span> <span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4570" href="#t4570">4570</a></span><span class="t">                <span class="nam">output_size</span> <span class="op">=</span> <span class="op">[</span><span class="nam">output_size</span><span class="op">,</span> <span class="nam">output_size</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4571" href="#t4571">4571</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4572" href="#t4572">4572</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"output_size must contain one or two integers."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4573" href="#t4573">4573</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4574" href="#t4574">4574</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4575" href="#t4575">4575</a></span><span class="t">            <span class="str">"output_size should be int, list[int] or tuple[int] or Tensor"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4576" href="#t4576">4576</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4577" href="#t4577">4577</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4578" href="#t4578">4578</a></span><span class="t">    <span class="key">if</span> <span class="nam">filter_size</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4579" href="#t4579">4579</a></span><span class="t">        <span class="key">if</span> <span class="nam">output_size</span> <span class="key">is</span> <span class="op">[</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4580" href="#t4580">4580</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"output_size must be set when filter_size is None"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4581" href="#t4581">4581</a></span><span class="t">        <span class="key">if</span> <span class="key">not</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4582" href="#t4582">4582</a></span><span class="t">            <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">output_size</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span> <span class="key">or</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_contain_var</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4583" href="#t4583">4583</a></span><span class="t">                <span class="nam">output_size</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4584" href="#t4584">4584</a></span><span class="t">            <span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4585" href="#t4585">4585</a></span><span class="t">                <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4586" href="#t4586">4586</a></span><span class="t">                    <span class="str">"filter_size should not be None when output_size is Variable or contain Variable in static mode."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4587" href="#t4587">4587</a></span><span class="t">                <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4588" href="#t4588">4588</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4589" href="#t4589">4589</a></span><span class="t">            <span class="nam">output_size</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_shape_to_list</span><span class="op">(</span><span class="nam">output_size</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4590" href="#t4590">4590</a></span><span class="t">            <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">output_size</span><span class="op">)</span> <span class="op">==</span> <span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4591" href="#t4591">4591</a></span><span class="t">                <span class="nam">output_size</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4592" href="#t4592">4592</a></span><span class="t">                    <span class="nam">output_size</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span> <span class="num">2</span><span class="op">,</span> <span class="str">'output_size'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4593" href="#t4593">4593</a></span><span class="t">                <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4594" href="#t4594">4594</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4595" href="#t4595">4595</a></span><span class="t">        <span class="nam">h_in</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">2</span><span class="op">]</span> <span class="key">if</span> <span class="nam">data_format</span> <span class="op">==</span> <span class="str">'NCHW'</span> <span class="key">else</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4596" href="#t4596">4596</a></span><span class="t">        <span class="nam">w_in</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">3</span><span class="op">]</span> <span class="key">if</span> <span class="nam">data_format</span> <span class="op">==</span> <span class="str">'NCHW'</span> <span class="key">else</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">2</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4597" href="#t4597">4597</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4598" href="#t4598">4598</a></span><span class="t">        <span class="nam">filter_size_h</span> <span class="op">=</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4599" href="#t4599">4599</a></span><span class="t">            <span class="nam">output_size</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4600" href="#t4600">4600</a></span><span class="t">            <span class="op">-</span> <span class="op">(</span><span class="nam">h_in</span> <span class="op">-</span> <span class="num">1</span><span class="op">)</span> <span class="op">*</span> <span class="nam">stride</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4601" href="#t4601">4601</a></span><span class="t">            <span class="op">+</span> <span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4602" href="#t4602">4602</a></span><span class="t">            <span class="op">+</span> <span class="nam">padding</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4603" href="#t4603">4603</a></span><span class="t">            <span class="op">-</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4604" href="#t4604">4604</a></span><span class="t">        <span class="op">)</span> <span class="op">//</span> <span class="nam">dilation</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">+</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4605" href="#t4605">4605</a></span><span class="t">        <span class="nam">filter_size_w</span> <span class="op">=</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4606" href="#t4606">4606</a></span><span class="t">            <span class="nam">output_size</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4607" href="#t4607">4607</a></span><span class="t">            <span class="op">-</span> <span class="op">(</span><span class="nam">w_in</span> <span class="op">-</span> <span class="num">1</span><span class="op">)</span> <span class="op">*</span> <span class="nam">stride</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4608" href="#t4608">4608</a></span><span class="t">            <span class="op">+</span> <span class="nam">padding</span><span class="op">[</span><span class="num">2</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4609" href="#t4609">4609</a></span><span class="t">            <span class="op">+</span> <span class="nam">padding</span><span class="op">[</span><span class="num">3</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4610" href="#t4610">4610</a></span><span class="t">            <span class="op">-</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4611" href="#t4611">4611</a></span><span class="t">        <span class="op">)</span> <span class="op">//</span> <span class="nam">dilation</span><span class="op">[</span><span class="num">1</span><span class="op">]</span> <span class="op">+</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4612" href="#t4612">4612</a></span><span class="t">        <span class="nam">filter_size</span> <span class="op">=</span> <span class="op">[</span><span class="nam">filter_size_h</span><span class="op">,</span> <span class="nam">filter_size_w</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4613" href="#t4613">4613</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4614" href="#t4614">4614</a></span><span class="t">        <span class="nam">filter_size</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4615" href="#t4615">4615</a></span><span class="t">            <span class="nam">filter_size</span><span class="op">,</span> <span class="num">2</span><span class="op">,</span> <span class="str">'conv2d_transpose.filter_size'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4616" href="#t4616">4616</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4617" href="#t4617">4617</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4618" href="#t4618">4618</a></span><span class="t">    <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span> <span class="op">==</span> <span class="num">4</span> <span class="key">and</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_is_symmetric_padding</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="num">2</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4619" href="#t4619">4619</a></span><span class="t">        <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span> <span class="nam">padding</span><span class="op">[</span><span class="num">2</span><span class="op">]</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4620" href="#t4620">4620</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4621" href="#t4621">4621</a></span><span class="t">    <span class="key">if</span> <span class="nam">groups</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4622" href="#t4622">4622</a></span><span class="t">        <span class="nam">groups</span> <span class="op">=</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4623" href="#t4623">4623</a></span><span class="t">    <span class="key">elif</span> <span class="nam">groups</span> <span class="op">&lt;=</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4624" href="#t4624">4624</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4625" href="#t4625">4625</a></span><span class="t">            <span class="str">"the groups of input must be greater than 0, "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4626" href="#t4626">4626</a></span><span class="t">            <span class="str">"but received the groups of input is {}"</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">groups</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4627" href="#t4627">4627</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4628" href="#t4628">4628</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4629" href="#t4629">4629</a></span><span class="t">    <span class="nam">filter_shape</span> <span class="op">=</span> <span class="op">[</span><span class="nam">input_channel</span><span class="op">,</span> <span class="nam">num_filters</span> <span class="op">//</span> <span class="nam">groups</span><span class="op">]</span> <span class="op">+</span> <span class="nam">filter_size</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4630" href="#t4630">4630</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4631" href="#t4631">4631</a></span><span class="t">    <span class="nam">img_filter</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4632" href="#t4632">4632</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">input</span><span class="op">.</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">shape</span><span class="op">=</span><span class="nam">filter_shape</span><span class="op">,</span> <span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">param_attr</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4633" href="#t4633">4633</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4634" href="#t4634">4634</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4635" href="#t4635">4635</a></span><span class="t">    <span class="nam">pre_bias</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">input</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4636" href="#t4636">4636</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4637" href="#t4637">4637</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="nam">op_type</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4638" href="#t4638">4638</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Input'</span><span class="op">:</span> <span class="op">[</span><span class="nam">input</span><span class="op">]</span><span class="op">,</span> <span class="str">'Filter'</span><span class="op">:</span> <span class="op">[</span><span class="nam">img_filter</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4639" href="#t4639">4639</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Output'</span><span class="op">:</span> <span class="nam">pre_bias</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4640" href="#t4640">4640</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4641" href="#t4641">4641</a></span><span class="t">            <span class="str">'output_size'</span><span class="op">:</span> <span class="nam">output_size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4642" href="#t4642">4642</a></span><span class="t">            <span class="str">'strides'</span><span class="op">:</span> <span class="nam">stride</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4643" href="#t4643">4643</a></span><span class="t">            <span class="str">'paddings'</span><span class="op">:</span> <span class="nam">padding</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4644" href="#t4644">4644</a></span><span class="t">            <span class="str">'padding_algorithm'</span><span class="op">:</span> <span class="nam">padding_algorithm</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4645" href="#t4645">4645</a></span><span class="t">            <span class="str">'dilations'</span><span class="op">:</span> <span class="nam">dilation</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4646" href="#t4646">4646</a></span><span class="t">            <span class="str">'groups'</span><span class="op">:</span> <span class="nam">groups</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4647" href="#t4647">4647</a></span><span class="t">            <span class="str">'use_cudnn'</span><span class="op">:</span> <span class="nam">use_cudnn</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4648" href="#t4648">4648</a></span><span class="t">            <span class="str">'data_format'</span><span class="op">:</span> <span class="nam">data_format</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4649" href="#t4649">4649</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4650" href="#t4650">4650</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4651" href="#t4651">4651</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4652" href="#t4652">4652</a></span><span class="t">    <span class="key">if</span> <span class="nam">data_format</span> <span class="op">==</span> <span class="str">'NCHW'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4653" href="#t4653">4653</a></span><span class="t">        <span class="nam">pre_act</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_bias_op</span><span class="op">(</span><span class="nam">pre_bias</span><span class="op">,</span> <span class="nam">dim_start</span><span class="op">=</span><span class="num">1</span><span class="op">,</span> <span class="nam">dim_end</span><span class="op">=</span><span class="num">2</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4654" href="#t4654">4654</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4655" href="#t4655">4655</a></span><span class="t">        <span class="nam">pre_act</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_bias_op</span><span class="op">(</span><span class="nam">pre_bias</span><span class="op">,</span> <span class="nam">dim_start</span><span class="op">=</span><span class="num">3</span><span class="op">,</span> <span class="nam">dim_end</span><span class="op">=</span><span class="num">4</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4656" href="#t4656">4656</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_activation</span><span class="op">(</span><span class="nam">pre_act</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4657" href="#t4657">4657</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4658" href="#t4658">4658</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4659" href="#t4659">4659</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t4660" href="#t4660">4660</a></span><span class="t"><span class="key">def</span> <span class="nam">conv3d_transpose</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4661" href="#t4661">4661</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4662" href="#t4662">4662</a></span><span class="t">    <span class="nam">num_filters</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4663" href="#t4663">4663</a></span><span class="t">    <span class="nam">output_size</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4664" href="#t4664">4664</a></span><span class="t">    <span class="nam">filter_size</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4665" href="#t4665">4665</a></span><span class="t">    <span class="nam">padding</span><span class="op">=</span><span class="num">0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4666" href="#t4666">4666</a></span><span class="t">    <span class="nam">stride</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4667" href="#t4667">4667</a></span><span class="t">    <span class="nam">dilation</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4668" href="#t4668">4668</a></span><span class="t">    <span class="nam">groups</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4669" href="#t4669">4669</a></span><span class="t">    <span class="nam">param_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4670" href="#t4670">4670</a></span><span class="t">    <span class="nam">bias_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4671" href="#t4671">4671</a></span><span class="t">    <span class="nam">use_cudnn</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4672" href="#t4672">4672</a></span><span class="t">    <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4673" href="#t4673">4673</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4674" href="#t4674">4674</a></span><span class="t">    <span class="nam">data_format</span><span class="op">=</span><span class="str">'NCDHW'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4675" href="#t4675">4675</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4676" href="#t4676">4676</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4677" href="#t4677">4677</a></span><span class="t"><span class="str">    :api_attr: Static Graph</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4678" href="#t4678">4678</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4679" href="#t4679">4679</a></span><span class="t"><span class="str">    The convolution3D transpose layer calculates the output based on the input,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4680" href="#t4680">4680</a></span><span class="t"><span class="str">    filter, and dilations, strides, paddings. Input(Input) and output(Output)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4681" href="#t4681">4681</a></span><span class="t"><span class="str">    are in NCDHW or NDHWC format. Where N is batch size, C is the number of channels,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4682" href="#t4682">4682</a></span><span class="t"><span class="str">    D is the depth of the feature, H is the height of the feature, and W</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4683" href="#t4683">4683</a></span><span class="t"><span class="str">    is the width of the feature. Parameters(dilations, strides, paddings) are</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4684" href="#t4684">4684</a></span><span class="t"><span class="str">    two elements. These two elements represent height and width, respectively.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4685" href="#t4685">4685</a></span><span class="t"><span class="str">    The details of convolution transpose layer, please refer to the following</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4686" href="#t4686">4686</a></span><span class="t"><span class="str">    explanation and references `therein &lt;https://arxiv.org/pdf/1603.07285.pdf>`_.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4687" href="#t4687">4687</a></span><span class="t"><span class="str">    If bias attribution and activation type are provided, bias is added to</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4688" href="#t4688">4688</a></span><span class="t"><span class="str">    the output of the convolution, and the corresponding activation function</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4689" href="#t4689">4689</a></span><span class="t"><span class="str">    is applied to the final result.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4690" href="#t4690">4690</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4691" href="#t4691">4691</a></span><span class="t"><span class="str">    For each input :math:`X`, the equation is:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4692" href="#t4692">4692</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4693" href="#t4693">4693</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4694" href="#t4694">4694</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4695" href="#t4695">4695</a></span><span class="t"><span class="str">        Out = \sigma (W \ast X + b)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4696" href="#t4696">4696</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4697" href="#t4697">4697</a></span><span class="t"><span class="str">    In the above equation:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4698" href="#t4698">4698</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4699" href="#t4699">4699</a></span><span class="t"><span class="str">    * :math:`X`: Input value, a Tensor with NCDHW or NDHWC format.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4700" href="#t4700">4700</a></span><span class="t"><span class="str">    * :math:`W`: Filter value, a Tensor with MCDHW format.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4701" href="#t4701">4701</a></span><span class="t"><span class="str">    * :math:`\ast`: Convolution operation.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4702" href="#t4702">4702</a></span><span class="t"><span class="str">    * :math:`b`: Bias value, a 2-D Tensor with shape [M, 1].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4703" href="#t4703">4703</a></span><span class="t"><span class="str">    * :math:`\sigma`: Activation function.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4704" href="#t4704">4704</a></span><span class="t"><span class="str">    * :math:`Out`: Output value, the shape of :math:`Out` and :math:`X` may be different.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4705" href="#t4705">4705</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4706" href="#t4706">4706</a></span><span class="t"><span class="str">    Example:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4707" href="#t4707">4707</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4708" href="#t4708">4708</a></span><span class="t"><span class="str">        - Input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4709" href="#t4709">4709</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4710" href="#t4710">4710</a></span><span class="t"><span class="str">          Input shape: :math:`(N, C_{in}, D_{in}, H_{in}, W_{in})`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4711" href="#t4711">4711</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4712" href="#t4712">4712</a></span><span class="t"><span class="str">          Filter shape: :math:`(C_{in}, C_{out}, D_f, H_f, W_f)`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4713" href="#t4713">4713</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4714" href="#t4714">4714</a></span><span class="t"><span class="str">        - Output:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4715" href="#t4715">4715</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4716" href="#t4716">4716</a></span><span class="t"><span class="str">          Output shape: :math:`(N, C_{out}, D_{out}, H_{out}, W_{out})`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4717" href="#t4717">4717</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4718" href="#t4718">4718</a></span><span class="t"><span class="str">        Where</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4719" href="#t4719">4719</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4720" href="#t4720">4720</a></span><span class="t"><span class="str">        .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4721" href="#t4721">4721</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4722" href="#t4722">4722</a></span><span class="t"><span class="str">           D^\prime_{out} &amp;= (D_{in} - 1) * strides[0] - 2 * paddings[0] + dilations[0] * (D_f - 1) + 1 \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4723" href="#t4723">4723</a></span><span class="t"><span class="str">           H^\prime_{out} &amp;= (H_{in} - 1) * strides[1] - 2 * paddings[1] + dilations[1] * (H_f - 1) + 1 \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4724" href="#t4724">4724</a></span><span class="t"><span class="str">           W^\prime_{out} &amp;= (W_{in} - 1) * strides[2] - 2 * paddings[2] + dilations[2] * (W_f - 1) + 1 \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4725" href="#t4725">4725</a></span><span class="t"><span class="str">           D_{out} &amp;\in [ D^\prime_{out}, D^\prime_{out} + strides[0] ] \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4726" href="#t4726">4726</a></span><span class="t"><span class="str">           H_{out} &amp;\in [ H^\prime_{out}, H^\prime_{out} + strides[1] ] \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4727" href="#t4727">4727</a></span><span class="t"><span class="str">           W_{out} &amp;\in [ W^\prime_{out}, W^\prime_{out} + strides[2] ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4728" href="#t4728">4728</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4729" href="#t4729">4729</a></span><span class="t"><span class="str">    Note:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4730" href="#t4730">4730</a></span><span class="t"><span class="str">          The conv3d_transpose can be seen as the backward of the conv3d. For conv3d,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4731" href="#t4731">4731</a></span><span class="t"><span class="str">          when stride > 1, conv3d maps multiple input shape to the same output shape,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4732" href="#t4732">4732</a></span><span class="t"><span class="str">          so for conv3d_transpose, when stride > 1, input shape maps multiple output shape.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4733" href="#t4733">4733</a></span><span class="t"><span class="str">          If output_size is None, :math:`H_{out} = H^\prime_{out}, :math:`H_{out} = \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4734" href="#t4734">4734</a></span><span class="t"><span class="str">          H^\prime_{out}, W_{out} = W^\prime_{out}`; else, the :math:`D_{out}` of the output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4735" href="#t4735">4735</a></span><span class="t"><span class="str">          size must between :math:`D^\prime_{out}` and :math:`D^\prime_{out} + strides[0]`,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4736" href="#t4736">4736</a></span><span class="t"><span class="str">          the :math:`H_{out}` of the output size must between :math:`H^\prime_{out}`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4737" href="#t4737">4737</a></span><span class="t"><span class="str">          and :math:`H^\prime_{out} + strides[1]`, and the :math:`W_{out}` of the output size must</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4738" href="#t4738">4738</a></span><span class="t"><span class="str">          between :math:`W^\prime_{out}` and :math:`W^\prime_{out} + strides[2]`,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4739" href="#t4739">4739</a></span><span class="t"><span class="str">          conv3d_transpose can compute the kernel size automatically.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4740" href="#t4740">4740</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4741" href="#t4741">4741</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4742" href="#t4742">4742</a></span><span class="t"><span class="str">        input(Tensor): The input is 5-D Tensor with shape [N, C, D, H, W] or [N, D, H, W, C], the data type</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4743" href="#t4743">4743</a></span><span class="t"><span class="str">            of input is float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4744" href="#t4744">4744</a></span><span class="t"><span class="str">        num_filters(int): The number of the filter. It is as same as the output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4745" href="#t4745">4745</a></span><span class="t"><span class="str">            image channel.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4746" href="#t4746">4746</a></span><span class="t"><span class="str">        output_size(int|tuple, optional): The output image size. If output size is a</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4747" href="#t4747">4747</a></span><span class="t"><span class="str">            tuple, it must contain three integers, (image_depth, image_height, image_width). This</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4748" href="#t4748">4748</a></span><span class="t"><span class="str">            parameter only works when filter_size is None. If output_size and filter_size are</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4749" href="#t4749">4749</a></span><span class="t"><span class="str">            specified at the same time, They should follow the formula above. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4750" href="#t4750">4750</a></span><span class="t"><span class="str">            Output_size and filter_size should not be None at the same time.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4751" href="#t4751">4751</a></span><span class="t"><span class="str">        filter_size(int|tuple, optional): The filter size. If filter_size is a tuple,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4752" href="#t4752">4752</a></span><span class="t"><span class="str">            it must contain three integers, (filter_size_depth, filter_size_height,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4753" href="#t4753">4753</a></span><span class="t"><span class="str">            filter_size_width). Otherwise, filter_size_depth = filter_size_height = \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4754" href="#t4754">4754</a></span><span class="t"><span class="str">            filter_size_width = filter_size. None if use output size to</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4755" href="#t4755">4755</a></span><span class="t"><span class="str">            calculate filter_size. Default: None. filter_size and output_size should not be</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4756" href="#t4756">4756</a></span><span class="t"><span class="str">            None at the same time.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4757" href="#t4757">4757</a></span><span class="t"><span class="str">        padding(int|list|str|tuple, optional): The padding size. The padding argument effectively</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4758" href="#t4758">4758</a></span><span class="t"><span class="str">            adds `dilation * (kernel - 1)` amount of zero-padding on both sides of input. If `padding` is a string,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4759" href="#t4759">4759</a></span><span class="t"><span class="str">            either 'VALID' or 'SAME' supported, which is the padding algorithm. If `padding`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4760" href="#t4760">4760</a></span><span class="t"><span class="str">            is a tuple or list, it could be in three forms: `[pad_depth, pad_height, pad_width]` or</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4761" href="#t4761">4761</a></span><span class="t"><span class="str">            `[pad_depth_front, pad_depth_back, pad_height_top, pad_height_bottom, pad_width_left, pad_width_right]`,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4762" href="#t4762">4762</a></span><span class="t"><span class="str">            and when `data_format` is `'NCDHW'`, `padding` can be in the form</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4763" href="#t4763">4763</a></span><span class="t"><span class="str">            `[[0,0], [0,0], [pad_depth_front, pad_depth_back], [pad_height_top, pad_height_bottom], [pad_width_left, pad_width_right]]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4764" href="#t4764">4764</a></span><span class="t"><span class="str">            when `data_format` is `'NDHWC'`, `padding` can be in the form</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4765" href="#t4765">4765</a></span><span class="t"><span class="str">            `[[0,0], [pad_depth_front, pad_depth_back], [pad_height_top, pad_height_bottom], [pad_width_left, pad_width_right], [0,0]]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4766" href="#t4766">4766</a></span><span class="t"><span class="str">            Default: padding = 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4767" href="#t4767">4767</a></span><span class="t"><span class="str">        stride(int|tuple, optional): The stride size. It means the stride in transposed convolution.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4768" href="#t4768">4768</a></span><span class="t"><span class="str">            If stride is a tuple, it must contain three integers, (stride_depth, stride_height,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4769" href="#t4769">4769</a></span><span class="t"><span class="str">            stride_width). Otherwise, stride_depth = stride_height = stride_width = stride.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4770" href="#t4770">4770</a></span><span class="t"><span class="str">            Default: stride = 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4771" href="#t4771">4771</a></span><span class="t"><span class="str">        dilation(int|tuple, optional): The dilation size. It means the spacing between the kernel points.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4772" href="#t4772">4772</a></span><span class="t"><span class="str">            If dilation is a tuple, it must contain three integers, (dilation_depth, dilation_height,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4773" href="#t4773">4773</a></span><span class="t"><span class="str">            dilation_width). Otherwise, dilation_depth = dilation_height = dilation_width = dilation.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4774" href="#t4774">4774</a></span><span class="t"><span class="str">            Default: dilation = 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4775" href="#t4775">4775</a></span><span class="t"><span class="str">        groups(int, optional): The groups number of the Conv3d transpose layer. Inspired by</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4776" href="#t4776">4776</a></span><span class="t"><span class="str">            grouped convolution in Alex Krizhevsky's Deep CNN paper, in which</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4777" href="#t4777">4777</a></span><span class="t"><span class="str">            when group=2, the first half of the filters is only connected to the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4778" href="#t4778">4778</a></span><span class="t"><span class="str">            first half of the input channels, while the second half of the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4779" href="#t4779">4779</a></span><span class="t"><span class="str">            filters is only connected to the second half of the input channels.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4780" href="#t4780">4780</a></span><span class="t"><span class="str">            Default: groups=1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4781" href="#t4781">4781</a></span><span class="t"><span class="str">        param_attr (ParamAttr, optional): The parameter attribute for learnable parameters/weights</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4782" href="#t4782">4782</a></span><span class="t"><span class="str">            of conv3d_transpose. If it is set to None or one attribute of ParamAttr, conv3d_transpose</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4783" href="#t4783">4783</a></span><span class="t"><span class="str">            will create ParamAttr as param_attr. If the Initializer of the param_attr</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4784" href="#t4784">4784</a></span><span class="t"><span class="str">            is not set, the parameter is initialized with Xavier. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4785" href="#t4785">4785</a></span><span class="t"><span class="str">        bias_attr (ParamAttr|bool, optional): The parameter attribute for the bias of conv3d_transpose.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4786" href="#t4786">4786</a></span><span class="t"><span class="str">            If it is set to False, no bias will be added to the output units.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4787" href="#t4787">4787</a></span><span class="t"><span class="str">            If it is set to None or one attribute of ParamAttr, conv3d_transpose</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4788" href="#t4788">4788</a></span><span class="t"><span class="str">            will create ParamAttr as bias_attr. If the Initializer of the bias_attr</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4789" href="#t4789">4789</a></span><span class="t"><span class="str">            is not set, the bias is initialized zero. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4790" href="#t4790">4790</a></span><span class="t"><span class="str">        use_cudnn(bool, optional): Use cudnn kernel or not, it is valid only when the cudnn</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4791" href="#t4791">4791</a></span><span class="t"><span class="str">            library is installed. Default: True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4792" href="#t4792">4792</a></span><span class="t"><span class="str">        act (str, optional): Activation type, if it is set to None, activation is not appended.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4793" href="#t4793">4793</a></span><span class="t"><span class="str">            Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4794" href="#t4794">4794</a></span><span class="t"><span class="str">        name(str, optional): For detailed information, please refer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4795" href="#t4795">4795</a></span><span class="t"><span class="str">           to :ref:`api_guide_Name`. Usually name is no need to set and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4796" href="#t4796">4796</a></span><span class="t"><span class="str">           None by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4797" href="#t4797">4797</a></span><span class="t"><span class="str">        data_format (str, optional): Specify the data format of the input, and the data format of the output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4798" href="#t4798">4798</a></span><span class="t"><span class="str">            will be consistent with that of the input. An optional string from: `"NCHW"`, `"NHWC"`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4799" href="#t4799">4799</a></span><span class="t"><span class="str">            The default is `"NCHW"`. When it is `"NCHW"`, the data is stored in the order of:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4800" href="#t4800">4800</a></span><span class="t"><span class="str">            `[batch_size, input_channels, input_height, input_width]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4801" href="#t4801">4801</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4802" href="#t4802">4802</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4803" href="#t4803">4803</a></span><span class="t"><span class="str">        A Variable holding Tensor representing the conv3d_transpose, whose data</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4804" href="#t4804">4804</a></span><span class="t"><span class="str">        type is the same with input and shape is (num_batches, channels, out_d, out_h,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4805" href="#t4805">4805</a></span><span class="t"><span class="str">        out_w) or (num_batches, out_d, out_h, out_w, channels). If act is None, the tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4806" href="#t4806">4806</a></span><span class="t"><span class="str">        variable storing the transposed convolution result, and if act is not None, the tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4807" href="#t4807">4807</a></span><span class="t"><span class="str">        variable storing transposed convolution and non-linearity activation result.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4808" href="#t4808">4808</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4809" href="#t4809">4809</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4810" href="#t4810">4810</a></span><span class="t"><span class="str">        ValueError: If the type of `use_cudnn` is not bool.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4811" href="#t4811">4811</a></span><span class="t"><span class="str">        ValueError: If `data_format` is not "NCDHW" or "NDHWC".</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4812" href="#t4812">4812</a></span><span class="t"><span class="str">        ValueError: If `padding` is a string, but not "SAME" or "VALID".</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4813" href="#t4813">4813</a></span><span class="t"><span class="str">        ValueError: If `padding` is a tuple, but the element corresponding to the input's batch size is not 0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4814" href="#t4814">4814</a></span><span class="t"><span class="str">            or the element corresponding to the input's channel is not 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4815" href="#t4815">4815</a></span><span class="t"><span class="str">        ValueError: If `output_size` and filter_size are None at the same time.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4816" href="#t4816">4816</a></span><span class="t"><span class="str">        ShapeError: If the input is not 5-D Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4817" href="#t4817">4817</a></span><span class="t"><span class="str">        ShapeError: If the input's dimension size and filter's dimension size not equal.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4818" href="#t4818">4818</a></span><span class="t"><span class="str">        ShapeError: If the dimension size of input minus the size of `stride` is not 2.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4819" href="#t4819">4819</a></span><span class="t"><span class="str">        ShapeError: If the number of input channels is not equal to filter's channels.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4820" href="#t4820">4820</a></span><span class="t"><span class="str">        ShapeError: If the size of `output_size` is not equal to that of `stride`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4821" href="#t4821">4821</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4822" href="#t4822">4822</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4823" href="#t4823">4823</a></span><span class="t"><span class="str">       .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4824" href="#t4824">4824</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4825" href="#t4825">4825</a></span><span class="t"><span class="str">          import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4826" href="#t4826">4826</a></span><span class="t"><span class="str">          import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4827" href="#t4827">4827</a></span><span class="t"><span class="str">            </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4828" href="#t4828">4828</a></span><span class="t"><span class="str">          paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4829" href="#t4829">4829</a></span><span class="t"><span class="str">          data = paddle.static.data(name='data', shape=[None, 3, 12, 32, 32], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4830" href="#t4830">4830</a></span><span class="t"><span class="str">          param_attr = paddle.framework.ParamAttr(name='conv3d.weight', initializer=paddle.nn.initializer.XavierNormal(), learning_rate=0.001)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4831" href="#t4831">4831</a></span><span class="t"><span class="str">          res = paddle.static.nn.conv3d_transpose(input=data, num_filters=2, filter_size=3, act="relu", param_attr=param_attr)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4832" href="#t4832">4832</a></span><span class="t"><span class="str">          place = paddle.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4833" href="#t4833">4833</a></span><span class="t"><span class="str">          exe = paddle.static.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4834" href="#t4834">4834</a></span><span class="t"><span class="str">          exe.run(paddle.static.default_startup_program())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4835" href="#t4835">4835</a></span><span class="t"><span class="str">          x = np.random.rand(1, 3, 12, 32, 32).astype("float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4836" href="#t4836">4836</a></span><span class="t"><span class="str">          output = exe.run(feed={"data": x}, fetch_list=[res])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4837" href="#t4837">4837</a></span><span class="t"><span class="str">          print(output)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4838" href="#t4838">4838</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4839" href="#t4839">4839</a></span><span class="t">    <span class="key">assert</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4840" href="#t4840">4840</a></span><span class="t">        <span class="nam">param_attr</span> <span class="key">is</span> <span class="key">not</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4841" href="#t4841">4841</a></span><span class="t">    <span class="op">)</span><span class="op">,</span> <span class="str">"param_attr should not be False in conv3d_transpose."</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4842" href="#t4842">4842</a></span><span class="t">    <span class="key">if</span> <span class="nam">data_format</span> <span class="key">not</span> <span class="key">in</span> <span class="op">[</span><span class="str">'NCDHW'</span><span class="op">,</span> <span class="str">'NDHWC'</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4843" href="#t4843">4843</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4844" href="#t4844">4844</a></span><span class="t">            <span class="str">"Param(data_format) of Op(fluid.layers.conv3d_transpose) got wrong value: received "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4845" href="#t4845">4845</a></span><span class="t">            <span class="op">+</span> <span class="nam">data_format</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4846" href="#t4846">4846</a></span><span class="t">            <span class="op">+</span> <span class="str">" but only NCDHW or NDHWC supported."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4847" href="#t4847">4847</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4848" href="#t4848">4848</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4849" href="#t4849">4849</a></span><span class="t">    <span class="nam">l_type</span> <span class="op">=</span> <span class="str">"conv3d_transpose"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4850" href="#t4850">4850</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="nam">l_type</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4851" href="#t4851">4851</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4852" href="#t4852">4852</a></span><span class="t">        <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span><span class="str">"Input of conv3d_transpose must be Variable"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4853" href="#t4853">4853</a></span><span class="t">    <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">!=</span> <span class="num">5</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4854" href="#t4854">4854</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4855" href="#t4855">4855</a></span><span class="t">            <span class="str">"Input should be 5D tensor, but received input with the shape of {}"</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4856" href="#t4856">4856</a></span><span class="t">                <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4857" href="#t4857">4857</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4858" href="#t4858">4858</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4859" href="#t4859">4859</a></span><span class="t">    <span class="nam">input_channel</span> <span class="op">=</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4860" href="#t4860">4860</a></span><span class="t">        <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span> <span class="key">if</span> <span class="nam">data_format</span> <span class="op">==</span> <span class="str">'NCDHW'</span> <span class="key">else</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4861" href="#t4861">4861</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4862" href="#t4862">4862</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4863" href="#t4863">4863</a></span><span class="t">    <span class="nam">stride</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">stride</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="str">'stride'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4864" href="#t4864">4864</a></span><span class="t">    <span class="nam">dilation</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">dilation</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="str">'dilation'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4865" href="#t4865">4865</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4866" href="#t4866">4866</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">use_cudnn</span><span class="op">,</span> <span class="nam">bool</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4867" href="#t4867">4867</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"use_cudnn should be True or False"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4868" href="#t4868">4868</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4869" href="#t4869">4869</a></span><span class="t">    <span class="key">def</span> <span class="nam">_update_padding</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="nam">data_format</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4870" href="#t4870">4870</a></span><span class="t">        <span class="key">def</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">ele</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4871" href="#t4871">4871</a></span><span class="t">            <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">ele</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span> <span class="key">or</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">ele</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4872" href="#t4872">4872</a></span><span class="t">                <span class="key">return</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4873" href="#t4873">4873</a></span><span class="t">            <span class="key">return</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4874" href="#t4874">4874</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4875" href="#t4875">4875</a></span><span class="t">        <span class="key">if</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span> <span class="key">and</span> <span class="nam">len</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span> <span class="op">==</span> <span class="num">5</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4876" href="#t4876">4876</a></span><span class="t">            <span class="key">if</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">)</span> <span class="key">and</span> <span class="op">(</span><span class="nam">data_format</span> <span class="op">==</span> <span class="str">"NCDHW"</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4877" href="#t4877">4877</a></span><span class="t">                <span class="key">if</span> <span class="key">not</span> <span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">==</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span> <span class="key">and</span> <span class="nam">padding</span><span class="op">[</span><span class="num">1</span><span class="op">]</span> <span class="op">==</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4878" href="#t4878">4878</a></span><span class="t">                    <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4879" href="#t4879">4879</a></span><span class="t">                        <span class="str">"Non-zero padding(%s) in the batch or channel dimensions "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4880" href="#t4880">4880</a></span><span class="t">                        <span class="str">"is not supported."</span> <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4881" href="#t4881">4881</a></span><span class="t">                    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4882" href="#t4882">4882</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="nam">padding</span><span class="op">[</span><span class="num">2</span><span class="op">:</span><span class="num">5</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4883" href="#t4883">4883</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="nam">ele</span> <span class="key">for</span> <span class="nam">a_list</span> <span class="key">in</span> <span class="nam">padding</span> <span class="key">for</span> <span class="nam">ele</span> <span class="key">in</span> <span class="nam">a_list</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4884" href="#t4884">4884</a></span><span class="t">            <span class="key">elif</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">)</span> <span class="key">and</span> <span class="op">(</span><span class="nam">data_format</span> <span class="op">==</span> <span class="str">"NDHWC"</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4885" href="#t4885">4885</a></span><span class="t">                <span class="key">if</span> <span class="key">not</span> <span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">==</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span> <span class="key">and</span> <span class="nam">padding</span><span class="op">[</span><span class="num">4</span><span class="op">]</span> <span class="op">==</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4886" href="#t4886">4886</a></span><span class="t">                    <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4887" href="#t4887">4887</a></span><span class="t">                        <span class="str">"Non-zero padding(%s) in the batch or channel dimensions "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4888" href="#t4888">4888</a></span><span class="t">                        <span class="str">"is not supported."</span> <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4889" href="#t4889">4889</a></span><span class="t">                    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4890" href="#t4890">4890</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="nam">padding</span><span class="op">[</span><span class="num">1</span><span class="op">:</span><span class="num">4</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4891" href="#t4891">4891</a></span><span class="t">                <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="nam">ele</span> <span class="key">for</span> <span class="nam">a_list</span> <span class="key">in</span> <span class="nam">padding</span> <span class="key">for</span> <span class="nam">ele</span> <span class="key">in</span> <span class="nam">a_list</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4892" href="#t4892">4892</a></span><span class="t">            <span class="nam">padding</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="num">6</span><span class="op">,</span> <span class="str">'padding'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4893" href="#t4893">4893</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4894" href="#t4894">4894</a></span><span class="t">        <span class="key">elif</span> <span class="nam">is_list_or_tuple</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span> <span class="key">and</span> <span class="nam">len</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span> <span class="op">==</span> <span class="num">6</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4895" href="#t4895">4895</a></span><span class="t">            <span class="nam">padding</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="num">6</span><span class="op">,</span> <span class="str">'padding'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4896" href="#t4896">4896</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4897" href="#t4897">4897</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4898" href="#t4898">4898</a></span><span class="t">            <span class="nam">padding</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="str">'padding'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4899" href="#t4899">4899</a></span><span class="t">            <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4900" href="#t4900">4900</a></span><span class="t">                <span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4901" href="#t4901">4901</a></span><span class="t">                <span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4902" href="#t4902">4902</a></span><span class="t">                <span class="nam">padding</span><span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4903" href="#t4903">4903</a></span><span class="t">                <span class="nam">padding</span><span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4904" href="#t4904">4904</a></span><span class="t">                <span class="nam">padding</span><span class="op">[</span><span class="num">2</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4905" href="#t4905">4905</a></span><span class="t">                <span class="nam">padding</span><span class="op">[</span><span class="num">2</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4906" href="#t4906">4906</a></span><span class="t">            <span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4907" href="#t4907">4907</a></span><span class="t">        <span class="key">return</span> <span class="nam">padding</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4908" href="#t4908">4908</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4909" href="#t4909">4909</a></span><span class="t">    <span class="nam">padding_algorithm</span> <span class="op">=</span> <span class="str">"EXPLICIT"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4910" href="#t4910">4910</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="nam">str</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4911" href="#t4911">4911</a></span><span class="t">        <span class="nam">padding</span> <span class="op">=</span> <span class="nam">padding</span><span class="op">.</span><span class="nam">upper</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4912" href="#t4912">4912</a></span><span class="t">        <span class="key">if</span> <span class="nam">padding</span> <span class="key">not</span> <span class="key">in</span> <span class="op">[</span><span class="str">"SAME"</span><span class="op">,</span> <span class="str">"VALID"</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4913" href="#t4913">4913</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4914" href="#t4914">4914</a></span><span class="t">                <span class="str">"Unknown padding: '%s'. It can only be 'SAME' or 'VALID'."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4915" href="#t4915">4915</a></span><span class="t">                <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4916" href="#t4916">4916</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4917" href="#t4917">4917</a></span><span class="t">        <span class="key">if</span> <span class="nam">padding</span> <span class="op">==</span> <span class="str">"VALID"</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4918" href="#t4918">4918</a></span><span class="t">            <span class="nam">padding_algorithm</span> <span class="op">=</span> <span class="str">"VALID"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4919" href="#t4919">4919</a></span><span class="t">            <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4920" href="#t4920">4920</a></span><span class="t">        <span class="key">elif</span> <span class="nam">padding</span> <span class="op">==</span> <span class="str">"SAME"</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4921" href="#t4921">4921</a></span><span class="t">            <span class="nam">padding_algorithm</span> <span class="op">=</span> <span class="str">"SAME"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4922" href="#t4922">4922</a></span><span class="t">            <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4923" href="#t4923">4923</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4924" href="#t4924">4924</a></span><span class="t">    <span class="nam">padding</span> <span class="op">=</span> <span class="nam">_update_padding</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="nam">data_format</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4925" href="#t4925">4925</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4926" href="#t4926">4926</a></span><span class="t">    <span class="key">if</span> <span class="nam">filter_size</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4927" href="#t4927">4927</a></span><span class="t">        <span class="key">if</span> <span class="nam">output_size</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4928" href="#t4928">4928</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"output_size must be set when filter_size is None"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4929" href="#t4929">4929</a></span><span class="t">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">output_size</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4930" href="#t4930">4930</a></span><span class="t">            <span class="nam">output_size</span> <span class="op">=</span> <span class="op">[</span><span class="nam">output_size</span><span class="op">,</span> <span class="nam">output_size</span><span class="op">,</span> <span class="nam">output_size</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4931" href="#t4931">4931</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4932" href="#t4932">4932</a></span><span class="t">        <span class="nam">d_in</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">2</span><span class="op">]</span> <span class="key">if</span> <span class="nam">data_format</span> <span class="op">==</span> <span class="str">'NCDHW'</span> <span class="key">else</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4933" href="#t4933">4933</a></span><span class="t">        <span class="nam">h_in</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">3</span><span class="op">]</span> <span class="key">if</span> <span class="nam">data_format</span> <span class="op">==</span> <span class="str">'NCDHW'</span> <span class="key">else</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">2</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4934" href="#t4934">4934</a></span><span class="t">        <span class="nam">w_in</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">4</span><span class="op">]</span> <span class="key">if</span> <span class="nam">data_format</span> <span class="op">==</span> <span class="str">'NCDHW'</span> <span class="key">else</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">3</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4935" href="#t4935">4935</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4936" href="#t4936">4936</a></span><span class="t">        <span class="nam">filter_size_d</span> <span class="op">=</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4937" href="#t4937">4937</a></span><span class="t">            <span class="nam">output_size</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4938" href="#t4938">4938</a></span><span class="t">            <span class="op">-</span> <span class="op">(</span><span class="nam">d_in</span> <span class="op">-</span> <span class="num">1</span><span class="op">)</span> <span class="op">*</span> <span class="nam">stride</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4939" href="#t4939">4939</a></span><span class="t">            <span class="op">+</span> <span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4940" href="#t4940">4940</a></span><span class="t">            <span class="op">+</span> <span class="nam">padding</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4941" href="#t4941">4941</a></span><span class="t">            <span class="op">-</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4942" href="#t4942">4942</a></span><span class="t">        <span class="op">)</span> <span class="op">//</span> <span class="nam">dilation</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">+</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4943" href="#t4943">4943</a></span><span class="t">        <span class="nam">filter_size_h</span> <span class="op">=</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4944" href="#t4944">4944</a></span><span class="t">            <span class="nam">output_size</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4945" href="#t4945">4945</a></span><span class="t">            <span class="op">-</span> <span class="op">(</span><span class="nam">h_in</span> <span class="op">-</span> <span class="num">1</span><span class="op">)</span> <span class="op">*</span> <span class="nam">stride</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4946" href="#t4946">4946</a></span><span class="t">            <span class="op">+</span> <span class="nam">padding</span><span class="op">[</span><span class="num">2</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4947" href="#t4947">4947</a></span><span class="t">            <span class="op">+</span> <span class="nam">padding</span><span class="op">[</span><span class="num">3</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4948" href="#t4948">4948</a></span><span class="t">            <span class="op">-</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4949" href="#t4949">4949</a></span><span class="t">        <span class="op">)</span> <span class="op">//</span> <span class="nam">dilation</span><span class="op">[</span><span class="num">1</span><span class="op">]</span> <span class="op">+</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4950" href="#t4950">4950</a></span><span class="t">        <span class="nam">filter_size_w</span> <span class="op">=</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4951" href="#t4951">4951</a></span><span class="t">            <span class="nam">output_size</span><span class="op">[</span><span class="num">2</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4952" href="#t4952">4952</a></span><span class="t">            <span class="op">-</span> <span class="op">(</span><span class="nam">w_in</span> <span class="op">-</span> <span class="num">1</span><span class="op">)</span> <span class="op">*</span> <span class="nam">stride</span><span class="op">[</span><span class="num">2</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4953" href="#t4953">4953</a></span><span class="t">            <span class="op">+</span> <span class="nam">padding</span><span class="op">[</span><span class="num">4</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4954" href="#t4954">4954</a></span><span class="t">            <span class="op">+</span> <span class="nam">padding</span><span class="op">[</span><span class="num">5</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4955" href="#t4955">4955</a></span><span class="t">            <span class="op">-</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4956" href="#t4956">4956</a></span><span class="t">        <span class="op">)</span> <span class="op">//</span> <span class="nam">dilation</span><span class="op">[</span><span class="num">2</span><span class="op">]</span> <span class="op">+</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4957" href="#t4957">4957</a></span><span class="t">        <span class="nam">filter_size</span> <span class="op">=</span> <span class="op">[</span><span class="nam">filter_size_d</span><span class="op">,</span> <span class="nam">filter_size_h</span><span class="op">,</span> <span class="nam">filter_size_w</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4958" href="#t4958">4958</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4959" href="#t4959">4959</a></span><span class="t">        <span class="nam">filter_size</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4960" href="#t4960">4960</a></span><span class="t">            <span class="nam">filter_size</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="str">'conv3d_transpose.filter_size'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4961" href="#t4961">4961</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4962" href="#t4962">4962</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4963" href="#t4963">4963</a></span><span class="t">    <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span> <span class="op">==</span> <span class="num">6</span> <span class="key">and</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_is_symmetric_padding</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="num">3</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4964" href="#t4964">4964</a></span><span class="t">        <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span> <span class="nam">padding</span><span class="op">[</span><span class="num">2</span><span class="op">]</span><span class="op">,</span> <span class="nam">padding</span><span class="op">[</span><span class="num">4</span><span class="op">]</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4965" href="#t4965">4965</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4966" href="#t4966">4966</a></span><span class="t">    <span class="key">if</span> <span class="nam">output_size</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4967" href="#t4967">4967</a></span><span class="t">        <span class="nam">output_size</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4968" href="#t4968">4968</a></span><span class="t">    <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">output_size</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4969" href="#t4969">4969</a></span><span class="t">        <span class="nam">output_size</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">output_size</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="str">'output_size'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4970" href="#t4970">4970</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4971" href="#t4971">4971</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"output_size should be int, list[int] or tuple[int]"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4972" href="#t4972">4972</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4973" href="#t4973">4973</a></span><span class="t">    <span class="nam">groups</span> <span class="op">=</span> <span class="num">1</span> <span class="key">if</span> <span class="nam">groups</span> <span class="key">is</span> <span class="key">None</span> <span class="key">else</span> <span class="nam">groups</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4974" href="#t4974">4974</a></span><span class="t">    <span class="key">if</span> <span class="nam">groups</span> <span class="op">&lt;=</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4975" href="#t4975">4975</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4976" href="#t4976">4976</a></span><span class="t">            <span class="str">"the groups of conv3d_transpose should be greater than 0. Received groups: {}"</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4977" href="#t4977">4977</a></span><span class="t">                <span class="nam">groups</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4978" href="#t4978">4978</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4979" href="#t4979">4979</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4980" href="#t4980">4980</a></span><span class="t">    <span class="key">if</span> <span class="nam">num_filters</span> <span class="op">%</span> <span class="nam">groups</span> <span class="op">!=</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4981" href="#t4981">4981</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4982" href="#t4982">4982</a></span><span class="t">            <span class="str">"Attr(num_filters) must be divisible by groups,"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4983" href="#t4983">4983</a></span><span class="t">            <span class="str">"Received: Attr(num_filters) is {}, the groups is {}"</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4984" href="#t4984">4984</a></span><span class="t">                <span class="nam">num_filters</span><span class="op">,</span> <span class="nam">groups</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4985" href="#t4985">4985</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4986" href="#t4986">4986</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4987" href="#t4987">4987</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4988" href="#t4988">4988</a></span><span class="t">    <span class="nam">filter_shape</span> <span class="op">=</span> <span class="op">[</span><span class="nam">input_channel</span><span class="op">,</span> <span class="nam">num_filters</span> <span class="op">//</span> <span class="nam">groups</span><span class="op">]</span> <span class="op">+</span> <span class="nam">filter_size</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4989" href="#t4989">4989</a></span><span class="t">    <span class="nam">img_filter</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4990" href="#t4990">4990</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">input</span><span class="op">.</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">shape</span><span class="op">=</span><span class="nam">filter_shape</span><span class="op">,</span> <span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">param_attr</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4991" href="#t4991">4991</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4992" href="#t4992">4992</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4993" href="#t4993">4993</a></span><span class="t">    <span class="key">if</span> <span class="nam">data_format</span> <span class="op">==</span> <span class="str">'NCDHW'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4994" href="#t4994">4994</a></span><span class="t">        <span class="nam">data_format</span> <span class="op">=</span> <span class="str">'NCHW'</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4995" href="#t4995">4995</a></span><span class="t">    <span class="key">if</span> <span class="nam">data_format</span> <span class="op">==</span> <span class="str">'NDHWC'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4996" href="#t4996">4996</a></span><span class="t">        <span class="nam">data_format</span> <span class="op">=</span> <span class="str">'NHWC'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4997" href="#t4997">4997</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4998" href="#t4998">4998</a></span><span class="t">    <span class="nam">pre_bias</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">input</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t4999" href="#t4999">4999</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5000" href="#t5000">5000</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="nam">l_type</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5001" href="#t5001">5001</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Input'</span><span class="op">:</span> <span class="op">[</span><span class="nam">input</span><span class="op">]</span><span class="op">,</span> <span class="str">'Filter'</span><span class="op">:</span> <span class="op">[</span><span class="nam">img_filter</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5002" href="#t5002">5002</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Output'</span><span class="op">:</span> <span class="nam">pre_bias</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5003" href="#t5003">5003</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5004" href="#t5004">5004</a></span><span class="t">            <span class="str">'output_size'</span><span class="op">:</span> <span class="nam">output_size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5005" href="#t5005">5005</a></span><span class="t">            <span class="str">'strides'</span><span class="op">:</span> <span class="nam">stride</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5006" href="#t5006">5006</a></span><span class="t">            <span class="str">'paddings'</span><span class="op">:</span> <span class="nam">padding</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5007" href="#t5007">5007</a></span><span class="t">            <span class="str">'padding_algorithm'</span><span class="op">:</span> <span class="nam">padding_algorithm</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5008" href="#t5008">5008</a></span><span class="t">            <span class="str">'dilations'</span><span class="op">:</span> <span class="nam">dilation</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5009" href="#t5009">5009</a></span><span class="t">            <span class="str">'groups'</span><span class="op">:</span> <span class="nam">groups</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5010" href="#t5010">5010</a></span><span class="t">            <span class="str">'use_cudnn'</span><span class="op">:</span> <span class="nam">use_cudnn</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5011" href="#t5011">5011</a></span><span class="t">            <span class="str">'data_format'</span><span class="op">:</span> <span class="nam">data_format</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5012" href="#t5012">5012</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5013" href="#t5013">5013</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5014" href="#t5014">5014</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5015" href="#t5015">5015</a></span><span class="t">    <span class="key">if</span> <span class="nam">data_format</span> <span class="op">==</span> <span class="str">'NCHW'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5016" href="#t5016">5016</a></span><span class="t">        <span class="nam">pre_act</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_bias_op</span><span class="op">(</span><span class="nam">pre_bias</span><span class="op">,</span> <span class="nam">dim_start</span><span class="op">=</span><span class="num">1</span><span class="op">,</span> <span class="nam">dim_end</span><span class="op">=</span><span class="num">2</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5017" href="#t5017">5017</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5018" href="#t5018">5018</a></span><span class="t">        <span class="nam">pre_act</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_bias_op</span><span class="op">(</span><span class="nam">pre_bias</span><span class="op">,</span> <span class="nam">dim_start</span><span class="op">=</span><span class="num">4</span><span class="op">,</span> <span class="nam">dim_end</span><span class="op">=</span><span class="num">5</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5019" href="#t5019">5019</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_activation</span><span class="op">(</span><span class="nam">pre_act</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5020" href="#t5020">5020</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5021" href="#t5021">5021</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5022" href="#t5022">5022</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5023" href="#t5023">5023</a></span><span class="t"><span class="key">def</span> <span class="nam">reduce_sum</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">dim</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">keep_dim</span><span class="op">=</span><span class="key">False</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5024" href="#t5024">5024</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5025" href="#t5025">5025</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5026" href="#t5026">5026</a></span><span class="t"><span class="str">    Computes the sum of tensor elements over the given dimension.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5027" href="#t5027">5027</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5028" href="#t5028">5028</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5029" href="#t5029">5029</a></span><span class="t"><span class="str">        input (Variable): The input variable which is a Tensor, the data type is float32,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5030" href="#t5030">5030</a></span><span class="t"><span class="str">            float64, int32, int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5031" href="#t5031">5031</a></span><span class="t"><span class="str">        dim (list|int, optional): The dimensions along which the sum is performed. If</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5032" href="#t5032">5032</a></span><span class="t"><span class="str">            :attr:`None`, sum all elements of :attr:`input` and return a</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5033" href="#t5033">5033</a></span><span class="t"><span class="str">            Tensor variable with a single element, otherwise must be in the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5034" href="#t5034">5034</a></span><span class="t"><span class="str">            range :math:`[-rank(input), rank(input))`. If :math:`dim[i] &lt; 0`,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5035" href="#t5035">5035</a></span><span class="t"><span class="str">            the dimension to reduce is :math:`rank + dim[i]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5036" href="#t5036">5036</a></span><span class="t"><span class="str">        keep_dim (bool, optional): Whether to reserve the reduced dimension in the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5037" href="#t5037">5037</a></span><span class="t"><span class="str">            output Tensor. The result tensor will have one fewer dimension</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5038" href="#t5038">5038</a></span><span class="t"><span class="str">            than the :attr:`input` unless :attr:`keep_dim` is true, default</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5039" href="#t5039">5039</a></span><span class="t"><span class="str">            value is False.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5040" href="#t5040">5040</a></span><span class="t"><span class="str">        name(str, optional): The default value is None.  Normally there is no need for</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5041" href="#t5041">5041</a></span><span class="t"><span class="str">            user to set this property.  For more information, please refer to :ref:`api_guide_Name`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5042" href="#t5042">5042</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5043" href="#t5043">5043</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5044" href="#t5044">5044</a></span><span class="t"><span class="str">        Variable: Tensor, results of summation operation on the specified dim of input tensor,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5045" href="#t5045">5045</a></span><span class="t"><span class="str">        it's data type is the same as input's Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5046" href="#t5046">5046</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5047" href="#t5047">5047</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5048" href="#t5048">5048</a></span><span class="t"><span class="str">        TypeError, if out data type is different with the input data type.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5049" href="#t5049">5049</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5050" href="#t5050">5050</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5051" href="#t5051">5051</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5052" href="#t5052">5052</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5053" href="#t5053">5053</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5054" href="#t5054">5054</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5055" href="#t5055">5055</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5056" href="#t5056">5056</a></span><span class="t"><span class="str">            # x is a Tensor variable with following elements:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5057" href="#t5057">5057</a></span><span class="t"><span class="str">            #    [[0.2, 0.3, 0.5, 0.9]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5058" href="#t5058">5058</a></span><span class="t"><span class="str">            #     [0.1, 0.2, 0.6, 0.7]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5059" href="#t5059">5059</a></span><span class="t"><span class="str">            # Each example is followed by the corresponding output tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5060" href="#t5060">5060</a></span><span class="t"><span class="str">            x = fluid.data(name='x', shape=[2, 4], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5061" href="#t5061">5061</a></span><span class="t"><span class="str">            fluid.layers.reduce_sum(x)  # [3.5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5062" href="#t5062">5062</a></span><span class="t"><span class="str">            fluid.layers.reduce_sum(x, dim=0)  # [0.3, 0.5, 1.1, 1.6]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5063" href="#t5063">5063</a></span><span class="t"><span class="str">            fluid.layers.reduce_sum(x, dim=-1)  # [1.9, 1.6]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5064" href="#t5064">5064</a></span><span class="t"><span class="str">            fluid.layers.reduce_sum(x, dim=1, keep_dim=True)  # [[1.9], [1.6]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5065" href="#t5065">5065</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5066" href="#t5066">5066</a></span><span class="t"><span class="str">            # y is a Tensor variable with shape [2, 2, 2] and elements as below:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5067" href="#t5067">5067</a></span><span class="t"><span class="str">            #      [[[1, 2], [3, 4]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5068" href="#t5068">5068</a></span><span class="t"><span class="str">            #      [[5, 6], [7, 8]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5069" href="#t5069">5069</a></span><span class="t"><span class="str">            # Each example is followed by the corresponding output tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5070" href="#t5070">5070</a></span><span class="t"><span class="str">            y = fluid.data(name='y', shape=[2, 2, 2], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5071" href="#t5071">5071</a></span><span class="t"><span class="str">            fluid.layers.reduce_sum(y, dim=[1, 2]) # [10, 26]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5072" href="#t5072">5072</a></span><span class="t"><span class="str">            fluid.layers.reduce_sum(y, dim=[0, 1]) # [16, 20]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5073" href="#t5073">5073</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5074" href="#t5074">5074</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t5075" href="#t5075">5075</a></span><span class="t">    <span class="key">if</span> <span class="nam">dim</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span> <span class="key">and</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">5075&#x202F;&#x219B;&#x202F;5076</span><span class="annotate long">line 5075 didn't jump to line 5076, because the condition on line 5075 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5076" href="#t5076">5076</a></span><span class="t">        <span class="nam">dim</span> <span class="op">=</span> <span class="op">[</span><span class="nam">dim</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5077" href="#t5077">5077</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t5078" href="#t5078">5078</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">5078&#x202F;&#x219B;&#x202F;5079</span><span class="annotate long">line 5078 didn't jump to line 5079</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5079" href="#t5079">5079</a></span><span class="t">        <span class="nam">reduce_all</span> <span class="op">=</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5080" href="#t5080">5080</a></span><span class="t">            <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5081" href="#t5081">5081</a></span><span class="t">            <span class="key">if</span> <span class="nam">dim</span> <span class="op">==</span> <span class="key">None</span> <span class="key">or</span> <span class="nam">dim</span> <span class="op">==</span> <span class="op">[</span><span class="op">]</span> <span class="key">or</span> <span class="nam">len</span><span class="op">(</span><span class="nam">dim</span><span class="op">)</span> <span class="op">==</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5082" href="#t5082">5082</a></span><span class="t">            <span class="key">else</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5083" href="#t5083">5083</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5084" href="#t5084">5084</a></span><span class="t">        <span class="nam">dim</span> <span class="op">=</span> <span class="nam">dim</span> <span class="key">if</span> <span class="nam">dim</span> <span class="op">!=</span> <span class="key">None</span> <span class="key">and</span> <span class="nam">dim</span> <span class="op">!=</span> <span class="op">[</span><span class="op">]</span> <span class="key">else</span> <span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5085" href="#t5085">5085</a></span><span class="t">        <span class="key">if</span> <span class="nam">reduce_all</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5086" href="#t5086">5086</a></span><span class="t">            <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">sum</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="op">[</span><span class="op">]</span><span class="op">,</span> <span class="key">None</span><span class="op">,</span> <span class="nam">keep_dim</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5087" href="#t5087">5087</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5088" href="#t5088">5088</a></span><span class="t">            <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">sum</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">dim</span><span class="op">,</span> <span class="key">None</span><span class="op">,</span> <span class="nam">keep_dim</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t5089" href="#t5089">5089</a></span><span class="t">    <span class="key">elif</span> <span class="nam">_in_legacy_dygraph</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">5089&#x202F;&#x219B;&#x202F;5090</span><span class="annotate long">line 5089 didn't jump to line 5090</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5090" href="#t5090">5090</a></span><span class="t">        <span class="nam">reduce_all</span> <span class="op">=</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5091" href="#t5091">5091</a></span><span class="t">            <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5092" href="#t5092">5092</a></span><span class="t">            <span class="key">if</span> <span class="nam">dim</span> <span class="op">==</span> <span class="key">None</span> <span class="key">or</span> <span class="nam">dim</span> <span class="op">==</span> <span class="op">[</span><span class="op">]</span> <span class="key">or</span> <span class="nam">len</span><span class="op">(</span><span class="nam">dim</span><span class="op">)</span> <span class="op">==</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5093" href="#t5093">5093</a></span><span class="t">            <span class="key">else</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5094" href="#t5094">5094</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5095" href="#t5095">5095</a></span><span class="t">        <span class="nam">dim</span> <span class="op">=</span> <span class="nam">dim</span> <span class="key">if</span> <span class="nam">dim</span> <span class="op">!=</span> <span class="key">None</span> <span class="key">and</span> <span class="nam">dim</span> <span class="op">!=</span> <span class="op">[</span><span class="op">]</span> <span class="key">else</span> <span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5096" href="#t5096">5096</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">reduce_sum</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5097" href="#t5097">5097</a></span><span class="t">            <span class="nam">input</span><span class="op">,</span> <span class="str">'dim'</span><span class="op">,</span> <span class="nam">dim</span><span class="op">,</span> <span class="str">'keep_dim'</span><span class="op">,</span> <span class="nam">keep_dim</span><span class="op">,</span> <span class="str">'reduce_all'</span><span class="op">,</span> <span class="nam">reduce_all</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5098" href="#t5098">5098</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5099" href="#t5099">5099</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5100" href="#t5100">5100</a></span><span class="t">        <span class="str">'dim'</span><span class="op">:</span> <span class="nam">dim</span> <span class="key">if</span> <span class="nam">dim</span> <span class="op">!=</span> <span class="key">None</span> <span class="key">and</span> <span class="nam">dim</span> <span class="op">!=</span> <span class="op">[</span><span class="op">]</span> <span class="key">else</span> <span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5101" href="#t5101">5101</a></span><span class="t">        <span class="str">'keep_dim'</span><span class="op">:</span> <span class="nam">keep_dim</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5102" href="#t5102">5102</a></span><span class="t">        <span class="str">'reduce_all'</span><span class="op">:</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5103" href="#t5103">5103</a></span><span class="t">        <span class="key">if</span> <span class="nam">dim</span> <span class="op">==</span> <span class="key">None</span> <span class="key">or</span> <span class="nam">dim</span> <span class="op">==</span> <span class="op">[</span><span class="op">]</span> <span class="key">or</span> <span class="nam">len</span><span class="op">(</span><span class="nam">dim</span><span class="op">)</span> <span class="op">==</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5104" href="#t5104">5104</a></span><span class="t">        <span class="key">else</span> <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5105" href="#t5105">5105</a></span><span class="t">    <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5106" href="#t5106">5106</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5107" href="#t5107">5107</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5108" href="#t5108">5108</a></span><span class="t">        <span class="str">'input'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5109" href="#t5109">5109</a></span><span class="t">        <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5110" href="#t5110">5110</a></span><span class="t">        <span class="str">'reduce_sum'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5111" href="#t5111">5111</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5112" href="#t5112">5112</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'reduce_sum'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5113" href="#t5113">5113</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5114" href="#t5114">5114</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5115" href="#t5115">5115</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'reduce_sum'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5116" href="#t5116">5116</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5117" href="#t5117">5117</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5118" href="#t5118">5118</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5119" href="#t5119">5119</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5120" href="#t5120">5120</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5121" href="#t5121">5121</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5122" href="#t5122">5122</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5123" href="#t5123">5123</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.mean"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5124" href="#t5124">5124</a></span><span class="t"><span class="key">def</span> <span class="nam">reduce_mean</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">dim</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">keep_dim</span><span class="op">=</span><span class="key">False</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5125" href="#t5125">5125</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5126" href="#t5126">5126</a></span><span class="t"><span class="str">    Computes the mean of the input tensor's elements along the given dimension.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5127" href="#t5127">5127</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5128" href="#t5128">5128</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5129" href="#t5129">5129</a></span><span class="t"><span class="str">        input (Variable): The input variable which is a Tensor, the data type is float32,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5130" href="#t5130">5130</a></span><span class="t"><span class="str">            float64, int32, int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5131" href="#t5131">5131</a></span><span class="t"><span class="str">        dim (list|int, optional): The dimension along which the mean is computed. If</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5132" href="#t5132">5132</a></span><span class="t"><span class="str">            `None`, compute the mean over all elements of :attr:`input`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5133" href="#t5133">5133</a></span><span class="t"><span class="str">            and return a variable with a single element, otherwise it</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5134" href="#t5134">5134</a></span><span class="t"><span class="str">            must be in the range :math:`[-rank(input), rank(input))`. If</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5135" href="#t5135">5135</a></span><span class="t"><span class="str">            :math:`dim[i] &lt; 0`, the dimension to reduce is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5136" href="#t5136">5136</a></span><span class="t"><span class="str">            :math:`rank(input) + dim[i]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5137" href="#t5137">5137</a></span><span class="t"><span class="str">        keep_dim (bool, optional): Whether to reserve the reduced dimension in the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5138" href="#t5138">5138</a></span><span class="t"><span class="str">            output Tensor. The result tensor will have one fewer dimension</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5139" href="#t5139">5139</a></span><span class="t"><span class="str">            than the :attr:`input` unless :attr:`keep_dim` is true, default</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5140" href="#t5140">5140</a></span><span class="t"><span class="str">            value is False.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5141" href="#t5141">5141</a></span><span class="t"><span class="str">        name(str, optional): The default value is None.  Normally there is no need for</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5142" href="#t5142">5142</a></span><span class="t"><span class="str">            user to set this property.  For more information, please refer to :ref:`api_guide_Name`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5143" href="#t5143">5143</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5144" href="#t5144">5144</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5145" href="#t5145">5145</a></span><span class="t"><span class="str">        Variable: Tensor, results of average on the specified dim of input tensor,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5146" href="#t5146">5146</a></span><span class="t"><span class="str">        it's data type is the same as input's Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5147" href="#t5147">5147</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5148" href="#t5148">5148</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5149" href="#t5149">5149</a></span><span class="t"><span class="str">        TypeError, if out data type is different with the input data type.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5150" href="#t5150">5150</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5151" href="#t5151">5151</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5152" href="#t5152">5152</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5153" href="#t5153">5153</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5154" href="#t5154">5154</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5155" href="#t5155">5155</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5156" href="#t5156">5156</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5157" href="#t5157">5157</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5158" href="#t5158">5158</a></span><span class="t"><span class="str">            # x is a Tensor variable with following elements:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5159" href="#t5159">5159</a></span><span class="t"><span class="str">            #    [[0.2, 0.3, 0.5, 0.9]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5160" href="#t5160">5160</a></span><span class="t"><span class="str">            #     [0.1, 0.2, 0.6, 0.7]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5161" href="#t5161">5161</a></span><span class="t"><span class="str">            # Each example is followed by the corresponding output tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5162" href="#t5162">5162</a></span><span class="t"><span class="str">            x = fluid.data(name='x', shape=[2, 4], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5163" href="#t5163">5163</a></span><span class="t"><span class="str">            fluid.layers.reduce_mean(x)  # [0.4375]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5164" href="#t5164">5164</a></span><span class="t"><span class="str">            fluid.layers.reduce_mean(x, dim=0)  # [0.15, 0.25, 0.55, 0.8]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5165" href="#t5165">5165</a></span><span class="t"><span class="str">            fluid.layers.reduce_mean(x, dim=-1)  # [0.475, 0.4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5166" href="#t5166">5166</a></span><span class="t"><span class="str">            fluid.layers.reduce_mean(x, dim=1, keep_dim=True)  # [[0.475], [0.4]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5167" href="#t5167">5167</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5168" href="#t5168">5168</a></span><span class="t"><span class="str">            # y is a Tensor variable with shape [2, 2, 2] and elements as below:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5169" href="#t5169">5169</a></span><span class="t"><span class="str">            #      [[[1.0, 2.0], [3.0, 4.0]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5170" href="#t5170">5170</a></span><span class="t"><span class="str">            #      [[5.0, 6.0], [7.0, 8.0]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5171" href="#t5171">5171</a></span><span class="t"><span class="str">            # Each example is followed by the corresponding output tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5172" href="#t5172">5172</a></span><span class="t"><span class="str">            y = fluid.data(name='y', shape=[2, 2, 2], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5173" href="#t5173">5173</a></span><span class="t"><span class="str">            fluid.layers.reduce_mean(y, dim=[1, 2]) # [2.5, 6.5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5174" href="#t5174">5174</a></span><span class="t"><span class="str">            fluid.layers.reduce_mean(y, dim=[0, 1]) # [4.0, 5.0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5175" href="#t5175">5175</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5176" href="#t5176">5176</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5177" href="#t5177">5177</a></span><span class="t">    <span class="key">return</span> <span class="nam">paddle</span><span class="op">.</span><span class="nam">mean</span><span class="op">(</span><span class="nam">x</span><span class="op">=</span><span class="nam">input</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="nam">dim</span><span class="op">,</span> <span class="nam">keepdim</span><span class="op">=</span><span class="nam">keep_dim</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="nam">name</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5178" href="#t5178">5178</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5179" href="#t5179">5179</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5180" href="#t5180">5180</a></span><span class="t"><span class="key">def</span> <span class="nam">reduce_max</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">dim</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">keep_dim</span><span class="op">=</span><span class="key">False</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5181" href="#t5181">5181</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5182" href="#t5182">5182</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5183" href="#t5183">5183</a></span><span class="t"><span class="str">    Computes the maximum of tensor elements over the given dimension.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5184" href="#t5184">5184</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5185" href="#t5185">5185</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5186" href="#t5186">5186</a></span><span class="t"><span class="str">        input (Variable): The input variable which is a Tensor, the data type is float32,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5187" href="#t5187">5187</a></span><span class="t"><span class="str">            float64, int32, int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5188" href="#t5188">5188</a></span><span class="t"><span class="str">        dim (list|int, optional): The dimension along which the maximum is computed.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5189" href="#t5189">5189</a></span><span class="t"><span class="str">            If :attr:`None`, compute the maximum over all elements of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5190" href="#t5190">5190</a></span><span class="t"><span class="str">            :attr:`input` and return a Tensor variable with a single element,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5191" href="#t5191">5191</a></span><span class="t"><span class="str">            otherwise must be in the range :math:`[-rank(input), rank(input))`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5192" href="#t5192">5192</a></span><span class="t"><span class="str">            If :math:`dim[i] &lt; 0`, the dimension to reduce is :math:`rank + dim[i]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5193" href="#t5193">5193</a></span><span class="t"><span class="str">        keep_dim (bool, optional): Whether to reserve the reduced dimension in the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5194" href="#t5194">5194</a></span><span class="t"><span class="str">            output Tensor. The result tensor will have one fewer dimension</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5195" href="#t5195">5195</a></span><span class="t"><span class="str">            than the :attr:`input` unless :attr:`keep_dim` is true, default</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5196" href="#t5196">5196</a></span><span class="t"><span class="str">            value is False.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5197" href="#t5197">5197</a></span><span class="t"><span class="str">        name(str, optional): The default value is None.  Normally there is no need for</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5198" href="#t5198">5198</a></span><span class="t"><span class="str">            user to set this property.  For more information, please refer to :ref:`api_guide_Name`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5199" href="#t5199">5199</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5200" href="#t5200">5200</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5201" href="#t5201">5201</a></span><span class="t"><span class="str">        Variable: Tensor, results of maximum on the specified dim of input tensor,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5202" href="#t5202">5202</a></span><span class="t"><span class="str">        it's data type is the same as input's Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5203" href="#t5203">5203</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5204" href="#t5204">5204</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5205" href="#t5205">5205</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5206" href="#t5206">5206</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5207" href="#t5207">5207</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5208" href="#t5208">5208</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5209" href="#t5209">5209</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5210" href="#t5210">5210</a></span><span class="t"><span class="str">            # x is a Tensor variable with following elements:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5211" href="#t5211">5211</a></span><span class="t"><span class="str">            #    [[0.2, 0.3, 0.5, 0.9]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5212" href="#t5212">5212</a></span><span class="t"><span class="str">            #     [0.1, 0.2, 0.6, 0.7]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5213" href="#t5213">5213</a></span><span class="t"><span class="str">            # Each example is followed by the corresponding output tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5214" href="#t5214">5214</a></span><span class="t"><span class="str">            x = fluid.data(name='x', shape=[2, 4], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5215" href="#t5215">5215</a></span><span class="t"><span class="str">            fluid.layers.reduce_max(x)  # [0.9]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5216" href="#t5216">5216</a></span><span class="t"><span class="str">            fluid.layers.reduce_max(x, dim=0)  # [0.2, 0.3, 0.6, 0.9]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5217" href="#t5217">5217</a></span><span class="t"><span class="str">            fluid.layers.reduce_max(x, dim=-1)  # [0.9, 0.7]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5218" href="#t5218">5218</a></span><span class="t"><span class="str">            fluid.layers.reduce_max(x, dim=1, keep_dim=True)  # [[0.9], [0.7]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5219" href="#t5219">5219</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5220" href="#t5220">5220</a></span><span class="t"><span class="str">            # y is a Tensor variable with shape [2, 2, 2] and elements as below:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5221" href="#t5221">5221</a></span><span class="t"><span class="str">            #      [[[1.0, 2.0], [3.0, 4.0]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5222" href="#t5222">5222</a></span><span class="t"><span class="str">            #      [[5.0, 6.0], [7.0, 8.0]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5223" href="#t5223">5223</a></span><span class="t"><span class="str">            # Each example is followed by the corresponding output tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5224" href="#t5224">5224</a></span><span class="t"><span class="str">            y = fluid.data(name='y', shape=[2, 2, 2], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5225" href="#t5225">5225</a></span><span class="t"><span class="str">            fluid.layers.reduce_max(y, dim=[1, 2]) # [4.0, 8.0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5226" href="#t5226">5226</a></span><span class="t"><span class="str">            fluid.layers.reduce_max(y, dim=[0, 1]) # [7.0, 8.0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5227" href="#t5227">5227</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5228" href="#t5228">5228</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'reduce_max'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5229" href="#t5229">5229</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5230" href="#t5230">5230</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t5231" href="#t5231">5231</a></span><span class="t">    <span class="key">if</span> <span class="nam">dim</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span> <span class="key">and</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">5231&#x202F;&#x219B;&#x202F;5234</span><span class="annotate long">line 5231 didn't jump to line 5234, because the condition on line 5231 was never false</span></span></p>
    <p class="run"><span class="n"><a id="t5232" href="#t5232">5232</a></span><span class="t">        <span class="nam">dim</span> <span class="op">=</span> <span class="op">[</span><span class="nam">dim</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5233" href="#t5233">5233</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t5234" href="#t5234">5234</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">5234&#x202F;&#x219B;&#x202F;5235</span><span class="annotate long">line 5234 didn't jump to line 5235, because the condition on line 5234 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5235" href="#t5235">5235</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">max</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">dim</span> <span class="key">if</span> <span class="nam">dim</span> <span class="op">!=</span> <span class="key">None</span> <span class="key">else</span> <span class="op">[</span><span class="op">]</span><span class="op">,</span> <span class="nam">keep_dim</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5236" href="#t5236">5236</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5237" href="#t5237">5237</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5238" href="#t5238">5238</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'reduce_max'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5239" href="#t5239">5239</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5240" href="#t5240">5240</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5241" href="#t5241">5241</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5242" href="#t5242">5242</a></span><span class="t">            <span class="str">'dim'</span><span class="op">:</span> <span class="nam">dim</span> <span class="key">if</span> <span class="nam">dim</span> <span class="op">!=</span> <span class="key">None</span> <span class="key">and</span> <span class="nam">dim</span> <span class="op">!=</span> <span class="op">[</span><span class="op">]</span> <span class="key">else</span> <span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5243" href="#t5243">5243</a></span><span class="t">            <span class="str">'keep_dim'</span><span class="op">:</span> <span class="nam">keep_dim</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5244" href="#t5244">5244</a></span><span class="t">            <span class="str">'reduce_all'</span><span class="op">:</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5245" href="#t5245">5245</a></span><span class="t">            <span class="key">if</span> <span class="nam">dim</span> <span class="op">==</span> <span class="key">None</span> <span class="key">or</span> <span class="nam">dim</span> <span class="op">==</span> <span class="op">[</span><span class="op">]</span> <span class="key">or</span> <span class="nam">len</span><span class="op">(</span><span class="nam">dim</span><span class="op">)</span> <span class="op">==</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5246" href="#t5246">5246</a></span><span class="t">            <span class="key">else</span> <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5247" href="#t5247">5247</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5248" href="#t5248">5248</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5249" href="#t5249">5249</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5250" href="#t5250">5250</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5251" href="#t5251">5251</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5252" href="#t5252">5252</a></span><span class="t"><span class="key">def</span> <span class="nam">reduce_min</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">dim</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">keep_dim</span><span class="op">=</span><span class="key">False</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5253" href="#t5253">5253</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5254" href="#t5254">5254</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5255" href="#t5255">5255</a></span><span class="t"><span class="str">    Computes the minimum of tensor elements over the given dimension.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5256" href="#t5256">5256</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5257" href="#t5257">5257</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5258" href="#t5258">5258</a></span><span class="t"><span class="str">        input (Variable): The input variable which is a Tensor, the data type is float32,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5259" href="#t5259">5259</a></span><span class="t"><span class="str">            float64, int32, int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5260" href="#t5260">5260</a></span><span class="t"><span class="str">        dim (list|int, optional): The dimensions along which the minimum is computed.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5261" href="#t5261">5261</a></span><span class="t"><span class="str">            If :attr:`None`, compute the minimum over all elements of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5262" href="#t5262">5262</a></span><span class="t"><span class="str">            :attr:`input` and return a Tensor variable with a single element,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5263" href="#t5263">5263</a></span><span class="t"><span class="str">            otherwise must be in the range :math:`[-rank(input), rank(input))`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5264" href="#t5264">5264</a></span><span class="t"><span class="str">            If :math:`dim[i] &lt; 0`, the dimension to reduce is :math:`rank + dim[i]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5265" href="#t5265">5265</a></span><span class="t"><span class="str">        keep_dim (bool, optional): Whether to reserve the reduced dimension in the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5266" href="#t5266">5266</a></span><span class="t"><span class="str">            output Tensor. The result tensor will have one fewer dimension</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5267" href="#t5267">5267</a></span><span class="t"><span class="str">            than the :attr:`input` unless :attr:`keep_dim` is true, default</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5268" href="#t5268">5268</a></span><span class="t"><span class="str">            value is False.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5269" href="#t5269">5269</a></span><span class="t"><span class="str">        name(str, optional): The default value is None.  Normally there is no need for</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5270" href="#t5270">5270</a></span><span class="t"><span class="str">            user to set this property.  For more information, please refer to :ref:`api_guide_Name`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5271" href="#t5271">5271</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5272" href="#t5272">5272</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5273" href="#t5273">5273</a></span><span class="t"><span class="str">        Variable: Tensor, result of minimum on the specified dim of input tensor,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5274" href="#t5274">5274</a></span><span class="t"><span class="str">        it's data type is the same as input's Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5275" href="#t5275">5275</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5276" href="#t5276">5276</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5277" href="#t5277">5277</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5278" href="#t5278">5278</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5279" href="#t5279">5279</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5280" href="#t5280">5280</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5281" href="#t5281">5281</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5282" href="#t5282">5282</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5283" href="#t5283">5283</a></span><span class="t"><span class="str">            # x is a Tensor variable with following elements:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5284" href="#t5284">5284</a></span><span class="t"><span class="str">            #    [[0.2, 0.3, 0.5, 0.9]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5285" href="#t5285">5285</a></span><span class="t"><span class="str">            #     [0.1, 0.2, 0.6, 0.7]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5286" href="#t5286">5286</a></span><span class="t"><span class="str">            # Each example is followed by the corresponding output tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5287" href="#t5287">5287</a></span><span class="t"><span class="str">            x = fluid.data(name='x', shape=[2, 4], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5288" href="#t5288">5288</a></span><span class="t"><span class="str">            fluid.layers.reduce_min(x)  # [0.1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5289" href="#t5289">5289</a></span><span class="t"><span class="str">            fluid.layers.reduce_min(x, dim=0)  # [0.1, 0.2, 0.5, 0.7]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5290" href="#t5290">5290</a></span><span class="t"><span class="str">            fluid.layers.reduce_min(x, dim=-1)  # [0.2, 0.1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5291" href="#t5291">5291</a></span><span class="t"><span class="str">            fluid.layers.reduce_min(x, dim=1, keep_dim=True)  # [[0.2], [0.1]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5292" href="#t5292">5292</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5293" href="#t5293">5293</a></span><span class="t"><span class="str">            # y is a Tensor variable with shape [2, 2, 2] and elements as below:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5294" href="#t5294">5294</a></span><span class="t"><span class="str">            #      [[[1.0, 2.0], [3.0, 4.0]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5295" href="#t5295">5295</a></span><span class="t"><span class="str">            #      [[5.0, 6.0], [7.0, 8.0]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5296" href="#t5296">5296</a></span><span class="t"><span class="str">            # Each example is followed by the corresponding output tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5297" href="#t5297">5297</a></span><span class="t"><span class="str">            y = fluid.data(name='y', shape=[2, 2, 2], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5298" href="#t5298">5298</a></span><span class="t"><span class="str">            fluid.layers.reduce_min(y, dim=[1, 2]) # [1.0, 5.0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5299" href="#t5299">5299</a></span><span class="t"><span class="str">            fluid.layers.reduce_min(y, dim=[0, 1]) # [1.0, 2.0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5300" href="#t5300">5300</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5301" href="#t5301">5301</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'reduce_min'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5302" href="#t5302">5302</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5303" href="#t5303">5303</a></span><span class="t">    <span class="key">if</span> <span class="nam">dim</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span> <span class="key">and</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5304" href="#t5304">5304</a></span><span class="t">        <span class="nam">dim</span> <span class="op">=</span> <span class="op">[</span><span class="nam">dim</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5305" href="#t5305">5305</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5306" href="#t5306">5306</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5307" href="#t5307">5307</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">min</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">dim</span> <span class="key">if</span> <span class="nam">dim</span> <span class="op">!=</span> <span class="key">None</span> <span class="key">else</span> <span class="op">[</span><span class="op">]</span><span class="op">,</span> <span class="nam">keep_dim</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5308" href="#t5308">5308</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5309" href="#t5309">5309</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5310" href="#t5310">5310</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'reduce_min'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5311" href="#t5311">5311</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5312" href="#t5312">5312</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5313" href="#t5313">5313</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5314" href="#t5314">5314</a></span><span class="t">            <span class="str">'dim'</span><span class="op">:</span> <span class="nam">dim</span> <span class="key">if</span> <span class="nam">dim</span> <span class="op">!=</span> <span class="key">None</span> <span class="key">and</span> <span class="nam">dim</span> <span class="op">!=</span> <span class="op">[</span><span class="op">]</span> <span class="key">else</span> <span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5315" href="#t5315">5315</a></span><span class="t">            <span class="str">'keep_dim'</span><span class="op">:</span> <span class="nam">keep_dim</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5316" href="#t5316">5316</a></span><span class="t">            <span class="str">'reduce_all'</span><span class="op">:</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5317" href="#t5317">5317</a></span><span class="t">            <span class="key">if</span> <span class="nam">dim</span> <span class="op">==</span> <span class="key">None</span> <span class="key">or</span> <span class="nam">dim</span> <span class="op">==</span> <span class="op">[</span><span class="op">]</span> <span class="key">or</span> <span class="nam">len</span><span class="op">(</span><span class="nam">dim</span><span class="op">)</span> <span class="op">==</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5318" href="#t5318">5318</a></span><span class="t">            <span class="key">else</span> <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5319" href="#t5319">5319</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5320" href="#t5320">5320</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5321" href="#t5321">5321</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5322" href="#t5322">5322</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5323" href="#t5323">5323</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5324" href="#t5324">5324</a></span><span class="t"><span class="key">def</span> <span class="nam">reduce_prod</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">dim</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">keep_dim</span><span class="op">=</span><span class="key">False</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5325" href="#t5325">5325</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5326" href="#t5326">5326</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5327" href="#t5327">5327</a></span><span class="t"><span class="str">    Computes the product of tensor elements over the given dimension.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5328" href="#t5328">5328</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5329" href="#t5329">5329</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5330" href="#t5330">5330</a></span><span class="t"><span class="str">        input (Variable): The input variable which is a Tensor, the data type is float32,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5331" href="#t5331">5331</a></span><span class="t"><span class="str">            float64, int32, int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5332" href="#t5332">5332</a></span><span class="t"><span class="str">        dim (int|list|tuple, optional): The dimensions along which the product is performed. If</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5333" href="#t5333">5333</a></span><span class="t"><span class="str">            :attr:`None`, multiply all elements of :attr:`input` and return a</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5334" href="#t5334">5334</a></span><span class="t"><span class="str">            Tensor variable with a single element, otherwise must be in the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5335" href="#t5335">5335</a></span><span class="t"><span class="str">            range :math:`[-rank(input), rank(input))`. If :math:`dim[i] &lt; 0`,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5336" href="#t5336">5336</a></span><span class="t"><span class="str">            the dimension to reduce is :math:`rank + dim[i]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5337" href="#t5337">5337</a></span><span class="t"><span class="str">        keep_dim (bool, optional): Whether to reserve the reduced dimension in the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5338" href="#t5338">5338</a></span><span class="t"><span class="str">            output Tensor. The result tensor will have one fewer dimension</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5339" href="#t5339">5339</a></span><span class="t"><span class="str">            than the :attr:`input` unless :attr:`keep_dim` is true, default</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5340" href="#t5340">5340</a></span><span class="t"><span class="str">            value is False.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5341" href="#t5341">5341</a></span><span class="t"><span class="str">        name(str, optional): The default value is None.  Normally there is no need for</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5342" href="#t5342">5342</a></span><span class="t"><span class="str">            user to set this property.  For more information, please refer to :ref:`api_guide_Name`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5343" href="#t5343">5343</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5344" href="#t5344">5344</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5345" href="#t5345">5345</a></span><span class="t"><span class="str">        Variable: Tensor, result of product on the specified dim of input tensor,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5346" href="#t5346">5346</a></span><span class="t"><span class="str">        it's data type is the same as input's Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5347" href="#t5347">5347</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5348" href="#t5348">5348</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5349" href="#t5349">5349</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5350" href="#t5350">5350</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5351" href="#t5351">5351</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5352" href="#t5352">5352</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5353" href="#t5353">5353</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5354" href="#t5354">5354</a></span><span class="t"><span class="str">            # x is a Tensor variable with following elements:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5355" href="#t5355">5355</a></span><span class="t"><span class="str">            #    [[0.2, 0.3, 0.5, 0.9]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5356" href="#t5356">5356</a></span><span class="t"><span class="str">            #     [0.1, 0.2, 0.6, 0.7]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5357" href="#t5357">5357</a></span><span class="t"><span class="str">            # Each example is followed by the corresponding output tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5358" href="#t5358">5358</a></span><span class="t"><span class="str">            x = fluid.data(name='x', shape=[2, 4], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5359" href="#t5359">5359</a></span><span class="t"><span class="str">            fluid.layers.reduce_prod(x)  # [0.0002268]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5360" href="#t5360">5360</a></span><span class="t"><span class="str">            fluid.layers.reduce_prod(x, dim=0)  # [0.02, 0.06, 0.3, 0.63]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5361" href="#t5361">5361</a></span><span class="t"><span class="str">            fluid.layers.reduce_prod(x, dim=-1)  # [0.027, 0.0084]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5362" href="#t5362">5362</a></span><span class="t"><span class="str">            fluid.layers.reduce_prod(x, dim=1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5363" href="#t5363">5363</a></span><span class="t"><span class="str">                                     keep_dim=True)  # [[0.027], [0.0084]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5364" href="#t5364">5364</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5365" href="#t5365">5365</a></span><span class="t"><span class="str">            # y is a Tensor variable with shape [2, 2, 2] and elements as below:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5366" href="#t5366">5366</a></span><span class="t"><span class="str">            #      [[[1.0, 2.0], [3.0, 4.0]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5367" href="#t5367">5367</a></span><span class="t"><span class="str">            #      [[5.0, 6.0], [7.0, 8.0]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5368" href="#t5368">5368</a></span><span class="t"><span class="str">            # Each example is followed by the corresponding output tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5369" href="#t5369">5369</a></span><span class="t"><span class="str">            y = fluid.data(name='y', shape=[2, 2, 2], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5370" href="#t5370">5370</a></span><span class="t"><span class="str">            fluid.layers.reduce_prod(y, dim=[1, 2]) # [24.0, 1680.0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5371" href="#t5371">5371</a></span><span class="t"><span class="str">            fluid.layers.reduce_prod(y, dim=[0, 1]) # [105.0, 384.0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5372" href="#t5372">5372</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5373" href="#t5373">5373</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5374" href="#t5374">5374</a></span><span class="t">    <span class="key">if</span> <span class="nam">dim</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span> <span class="key">and</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5375" href="#t5375">5375</a></span><span class="t">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5376" href="#t5376">5376</a></span><span class="t">            <span class="nam">dim</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="nam">dim</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5377" href="#t5377">5377</a></span><span class="t">        <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5378" href="#t5378">5378</a></span><span class="t">            <span class="nam">dim</span> <span class="op">=</span> <span class="op">[</span><span class="nam">dim</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5379" href="#t5379">5379</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5380" href="#t5380">5380</a></span><span class="t">            <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5381" href="#t5381">5381</a></span><span class="t">                <span class="str">"The type of axis must be int, list or tuple, but received {}"</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5382" href="#t5382">5382</a></span><span class="t">                    <span class="nam">type</span><span class="op">(</span><span class="nam">dim</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5383" href="#t5383">5383</a></span><span class="t">                <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5384" href="#t5384">5384</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5385" href="#t5385">5385</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5386" href="#t5386">5386</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">reduce_prod</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5387" href="#t5387">5387</a></span><span class="t">            <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5388" href="#t5388">5388</a></span><span class="t">            <span class="nam">dim</span> <span class="key">if</span> <span class="nam">dim</span> <span class="op">!=</span> <span class="key">None</span> <span class="key">and</span> <span class="nam">dim</span> <span class="op">!=</span> <span class="op">[</span><span class="op">]</span> <span class="key">else</span> <span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5389" href="#t5389">5389</a></span><span class="t">            <span class="nam">keep_dim</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5390" href="#t5390">5390</a></span><span class="t">            <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5391" href="#t5391">5391</a></span><span class="t">            <span class="key">if</span> <span class="nam">dim</span> <span class="op">==</span> <span class="key">None</span> <span class="key">or</span> <span class="nam">dim</span> <span class="op">==</span> <span class="op">[</span><span class="op">]</span> <span class="key">or</span> <span class="nam">len</span><span class="op">(</span><span class="nam">dim</span><span class="op">)</span> <span class="op">==</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5392" href="#t5392">5392</a></span><span class="t">            <span class="key">else</span> <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5393" href="#t5393">5393</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5394" href="#t5394">5394</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5395" href="#t5395">5395</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'reduce_prod'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5396" href="#t5396">5396</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5397" href="#t5397">5397</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'reduce_prod'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5398" href="#t5398">5398</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5399" href="#t5399">5399</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5400" href="#t5400">5400</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5401" href="#t5401">5401</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'reduce_prod'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5402" href="#t5402">5402</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5403" href="#t5403">5403</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5404" href="#t5404">5404</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5405" href="#t5405">5405</a></span><span class="t">            <span class="str">'dim'</span><span class="op">:</span> <span class="nam">dim</span> <span class="key">if</span> <span class="nam">dim</span> <span class="op">!=</span> <span class="key">None</span> <span class="key">and</span> <span class="nam">dim</span> <span class="op">!=</span> <span class="op">[</span><span class="op">]</span> <span class="key">else</span> <span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5406" href="#t5406">5406</a></span><span class="t">            <span class="str">'keep_dim'</span><span class="op">:</span> <span class="nam">keep_dim</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5407" href="#t5407">5407</a></span><span class="t">            <span class="str">'reduce_all'</span><span class="op">:</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5408" href="#t5408">5408</a></span><span class="t">            <span class="key">if</span> <span class="nam">dim</span> <span class="op">==</span> <span class="key">None</span> <span class="key">or</span> <span class="nam">dim</span> <span class="op">==</span> <span class="op">[</span><span class="op">]</span> <span class="key">or</span> <span class="nam">len</span><span class="op">(</span><span class="nam">dim</span><span class="op">)</span> <span class="op">==</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5409" href="#t5409">5409</a></span><span class="t">            <span class="key">else</span> <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5410" href="#t5410">5410</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5411" href="#t5411">5411</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5412" href="#t5412">5412</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5413" href="#t5413">5413</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5414" href="#t5414">5414</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5415" href="#t5415">5415</a></span><span class="t"><span class="key">def</span> <span class="nam">reduce_all</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">dim</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">keep_dim</span><span class="op">=</span><span class="key">False</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5416" href="#t5416">5416</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5417" href="#t5417">5417</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5418" href="#t5418">5418</a></span><span class="t"><span class="str">    This OP computes the ``logical and`` of tensor elements over the given dimension, and output the result.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5419" href="#t5419">5419</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5420" href="#t5420">5420</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5421" href="#t5421">5421</a></span><span class="t"><span class="str">        input (Tensor): the input tensor, it's data type should be `bool`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5422" href="#t5422">5422</a></span><span class="t"><span class="str">        dim (list|int|optional): The dimension along which the logical and is computed.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5423" href="#t5423">5423</a></span><span class="t"><span class="str">            If :attr:`None`, compute the logical and over all elements of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5424" href="#t5424">5424</a></span><span class="t"><span class="str">            :attr:`input` and return a Tensor variable with a single element,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5425" href="#t5425">5425</a></span><span class="t"><span class="str">            otherwise must be in the range :math:`[-rank(input), rank(input))`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5426" href="#t5426">5426</a></span><span class="t"><span class="str">            If :math:`dim[i] &lt; 0`, the dimension to reduce is :math:`rank + dim[i]`. The default value is None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5427" href="#t5427">5427</a></span><span class="t"><span class="str">        keep_dim (bool): Whether to reserve the reduced dimension in the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5428" href="#t5428">5428</a></span><span class="t"><span class="str">            output Tensor. The result tensor will have one fewer dimension</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5429" href="#t5429">5429</a></span><span class="t"><span class="str">            than the :attr:`input` unless :attr:`keep_dim` is true. The default value is False.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5430" href="#t5430">5430</a></span><span class="t"><span class="str">        name(str|None): A name for this layer(optional). If set None, the layer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5431" href="#t5431">5431</a></span><span class="t"><span class="str">                       will be named automatically. The default value is None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5432" href="#t5432">5432</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5433" href="#t5433">5433</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5434" href="#t5434">5434</a></span><span class="t"><span class="str">        Tensor, the output data type is bool. : The reduced tensor variable with ``logical and`` in given dims.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5435" href="#t5435">5435</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5436" href="#t5436">5436</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5437" href="#t5437">5437</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5438" href="#t5438">5438</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5439" href="#t5439">5439</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5440" href="#t5440">5440</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5441" href="#t5441">5441</a></span><span class="t"><span class="str">            import paddle.fluid.layers as layers</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5442" href="#t5442">5442</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5443" href="#t5443">5443</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5444" href="#t5444">5444</a></span><span class="t"><span class="str">            # x is a bool Tensor variable with following elements:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5445" href="#t5445">5445</a></span><span class="t"><span class="str">            #    [[True, False]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5446" href="#t5446">5446</a></span><span class="t"><span class="str">            #     [True, True]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5447" href="#t5447">5447</a></span><span class="t"><span class="str">            x = fluid.layers.assign(np.array([[1, 0], [1, 1]], dtype='int32'))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5448" href="#t5448">5448</a></span><span class="t"><span class="str">            x = fluid.layers.cast(x, 'bool')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5449" href="#t5449">5449</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5450" href="#t5450">5450</a></span><span class="t"><span class="str">            out = fluid.layers.reduce_all(x)  # False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5451" href="#t5451">5451</a></span><span class="t"><span class="str">            out = fluid.layers.reduce_all(x, dim=0)  # [True, False]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5452" href="#t5452">5452</a></span><span class="t"><span class="str">            out = fluid.layers.reduce_all(x, dim=-1)  # [False, True]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5453" href="#t5453">5453</a></span><span class="t"><span class="str">            # keep_dim=False, x.shape=(2,2), out.shape=(2,)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5454" href="#t5454">5454</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5455" href="#t5455">5455</a></span><span class="t"><span class="str">            out = fluid.layers.reduce_all(x, dim=1, keep_dim=True)  # [[False], [True]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5456" href="#t5456">5456</a></span><span class="t"><span class="str">            # keep_dim=True, x.shape=(2,2), out.shape=(2,1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5457" href="#t5457">5457</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5458" href="#t5458">5458</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t5459" href="#t5459">5459</a></span><span class="t">    <span class="key">if</span> <span class="nam">dim</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span> <span class="key">and</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">5459&#x202F;&#x219B;&#x202F;5460</span><span class="annotate long">line 5459 didn't jump to line 5460, because the condition on line 5459 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5460" href="#t5460">5460</a></span><span class="t">        <span class="nam">dim</span> <span class="op">=</span> <span class="op">[</span><span class="nam">dim</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5461" href="#t5461">5461</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t5462" href="#t5462">5462</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">5462&#x202F;&#x219B;&#x202F;5463</span><span class="annotate long">line 5462 didn't jump to line 5463, because the condition on line 5462 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5463" href="#t5463">5463</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">all</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">dim</span> <span class="key">if</span> <span class="nam">dim</span> <span class="op">!=</span> <span class="key">None</span> <span class="key">else</span> <span class="op">[</span><span class="op">]</span><span class="op">,</span> <span class="nam">keep_dim</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5464" href="#t5464">5464</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5465" href="#t5465">5465</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">(</span><span class="str">'bool'</span><span class="op">)</span><span class="op">,</span> <span class="str">'reduce_all'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5466" href="#t5466">5466</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'reduce_all'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5467" href="#t5467">5467</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5468" href="#t5468">5468</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5469" href="#t5469">5469</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'reduce_all'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5470" href="#t5470">5470</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5471" href="#t5471">5471</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5472" href="#t5472">5472</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5473" href="#t5473">5473</a></span><span class="t">            <span class="str">'dim'</span><span class="op">:</span> <span class="nam">dim</span> <span class="key">if</span> <span class="nam">dim</span> <span class="op">!=</span> <span class="key">None</span> <span class="key">and</span> <span class="nam">dim</span> <span class="op">!=</span> <span class="op">[</span><span class="op">]</span> <span class="key">else</span> <span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5474" href="#t5474">5474</a></span><span class="t">            <span class="str">'keep_dim'</span><span class="op">:</span> <span class="nam">keep_dim</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5475" href="#t5475">5475</a></span><span class="t">            <span class="str">'reduce_all'</span><span class="op">:</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5476" href="#t5476">5476</a></span><span class="t">            <span class="key">if</span> <span class="nam">dim</span> <span class="op">==</span> <span class="key">None</span> <span class="key">or</span> <span class="nam">dim</span> <span class="op">==</span> <span class="op">[</span><span class="op">]</span> <span class="key">or</span> <span class="nam">len</span><span class="op">(</span><span class="nam">dim</span><span class="op">)</span> <span class="op">==</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5477" href="#t5477">5477</a></span><span class="t">            <span class="key">else</span> <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5478" href="#t5478">5478</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5479" href="#t5479">5479</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5480" href="#t5480">5480</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5481" href="#t5481">5481</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5482" href="#t5482">5482</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5483" href="#t5483">5483</a></span><span class="t"><span class="key">def</span> <span class="nam">reduce_any</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">dim</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">keep_dim</span><span class="op">=</span><span class="key">False</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5484" href="#t5484">5484</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5485" href="#t5485">5485</a></span><span class="t"><span class="str">    This OP computes the ``logical or`` of tensor elements over the given dimension, and output the result.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5486" href="#t5486">5486</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5487" href="#t5487">5487</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5488" href="#t5488">5488</a></span><span class="t"><span class="str">        input (Tensor): the input tensor, it's data type should be `bool`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5489" href="#t5489">5489</a></span><span class="t"><span class="str">        dim (list|int|optional): The dimension along which the logical and is computed.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5490" href="#t5490">5490</a></span><span class="t"><span class="str">            If :attr:`None`, compute the logical and over all elements of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5491" href="#t5491">5491</a></span><span class="t"><span class="str">            :attr:`input` and return a Tensor variable with a single element,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5492" href="#t5492">5492</a></span><span class="t"><span class="str">            otherwise must be in the range :math:`[-rank(input), rank(input))`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5493" href="#t5493">5493</a></span><span class="t"><span class="str">            If :math:`dim[i] &lt; 0`, the dimension to reduce is :math:`rank + dim[i]`. The default value is None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5494" href="#t5494">5494</a></span><span class="t"><span class="str">        keep_dim (bool): Whether to reserve the reduced dimension in the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5495" href="#t5495">5495</a></span><span class="t"><span class="str">            output Tensor. The result tensor will have one fewer dimension</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5496" href="#t5496">5496</a></span><span class="t"><span class="str">            than the :attr:`input` unless :attr:`keep_dim` is true. The default value is False.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5497" href="#t5497">5497</a></span><span class="t"><span class="str">        name (str, optional): Name for the operation (optional, default is None). For more information, please refer to :ref:`api_guide_Name`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5498" href="#t5498">5498</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5499" href="#t5499">5499</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5500" href="#t5500">5500</a></span><span class="t"><span class="str">        Tensor, the output data type is bool. : The reduced tensor variable with ``logical or`` in given dims.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5501" href="#t5501">5501</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5502" href="#t5502">5502</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5503" href="#t5503">5503</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5504" href="#t5504">5504</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5505" href="#t5505">5505</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5506" href="#t5506">5506</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5507" href="#t5507">5507</a></span><span class="t"><span class="str">            import paddle.fluid.layers as layers</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5508" href="#t5508">5508</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5509" href="#t5509">5509</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5510" href="#t5510">5510</a></span><span class="t"><span class="str">            # x is a bool Tensor variable with following elements:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5511" href="#t5511">5511</a></span><span class="t"><span class="str">            #    [[True, False]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5512" href="#t5512">5512</a></span><span class="t"><span class="str">            #     [False, False]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5513" href="#t5513">5513</a></span><span class="t"><span class="str">            x = fluid.layers.assign(np.array([[1, 0], [0, 0]], dtype='int32'))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5514" href="#t5514">5514</a></span><span class="t"><span class="str">            x = fluid.layers.cast(x, 'bool')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5515" href="#t5515">5515</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5516" href="#t5516">5516</a></span><span class="t"><span class="str">            out = fluid.layers.reduce_any(x)  # True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5517" href="#t5517">5517</a></span><span class="t"><span class="str">            out = fluid.layers.reduce_any(x, dim=0)  # [True, False]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5518" href="#t5518">5518</a></span><span class="t"><span class="str">            out = fluid.layers.reduce_any(x, dim=-1)  # [True, False]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5519" href="#t5519">5519</a></span><span class="t"><span class="str">            # keep_dim=False, x.shape=(2,2), out.shape=(2,)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5520" href="#t5520">5520</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5521" href="#t5521">5521</a></span><span class="t"><span class="str">            out = fluid.layers.reduce_any(x, dim=1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5522" href="#t5522">5522</a></span><span class="t"><span class="str">                                     keep_dim=True)  # [[True], [False]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5523" href="#t5523">5523</a></span><span class="t"><span class="str">            # keep_dim=True, x.shape=(2,2), out.shape=(2,1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5524" href="#t5524">5524</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5525" href="#t5525">5525</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5526" href="#t5526">5526</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">(</span><span class="str">'bool'</span><span class="op">)</span><span class="op">,</span> <span class="str">'reduce_any'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5527" href="#t5527">5527</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'reduce_any'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5528" href="#t5528">5528</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5529" href="#t5529">5529</a></span><span class="t">    <span class="key">if</span> <span class="nam">dim</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span> <span class="key">and</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5530" href="#t5530">5530</a></span><span class="t">        <span class="nam">dim</span> <span class="op">=</span> <span class="op">[</span><span class="nam">dim</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5531" href="#t5531">5531</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5532" href="#t5532">5532</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'reduce_any'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5533" href="#t5533">5533</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5534" href="#t5534">5534</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5535" href="#t5535">5535</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5536" href="#t5536">5536</a></span><span class="t">            <span class="str">'dim'</span><span class="op">:</span> <span class="nam">dim</span> <span class="key">if</span> <span class="nam">dim</span> <span class="op">!=</span> <span class="key">None</span> <span class="key">and</span> <span class="nam">dim</span> <span class="op">!=</span> <span class="op">[</span><span class="op">]</span> <span class="key">else</span> <span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5537" href="#t5537">5537</a></span><span class="t">            <span class="str">'keep_dim'</span><span class="op">:</span> <span class="nam">keep_dim</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5538" href="#t5538">5538</a></span><span class="t">            <span class="str">'reduce_all'</span><span class="op">:</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5539" href="#t5539">5539</a></span><span class="t">            <span class="key">if</span> <span class="nam">dim</span> <span class="op">==</span> <span class="key">None</span> <span class="key">or</span> <span class="nam">dim</span> <span class="op">==</span> <span class="op">[</span><span class="op">]</span> <span class="key">or</span> <span class="nam">len</span><span class="op">(</span><span class="nam">dim</span><span class="op">)</span> <span class="op">==</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5540" href="#t5540">5540</a></span><span class="t">            <span class="key">else</span> <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5541" href="#t5541">5541</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5542" href="#t5542">5542</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5543" href="#t5543">5543</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5544" href="#t5544">5544</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5545" href="#t5545">5545</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5546" href="#t5546">5546</a></span><span class="t"><span class="key">def</span> <span class="nam">split</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">num_or_sections</span><span class="op">,</span> <span class="nam">dim</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5547" href="#t5547">5547</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5548" href="#t5548">5548</a></span><span class="t"><span class="str">    Split the input tensor into multiple sub-Tensors.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5549" href="#t5549">5549</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5550" href="#t5550">5550</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5551" href="#t5551">5551</a></span><span class="t"><span class="str">        input (Tensor): A N-D Tensor. The data type is bool, float16, float32, float64, int32 or int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5552" href="#t5552">5552</a></span><span class="t"><span class="str">        num_or_sections (int|list|tuple): If ``num_or_sections`` is int, then the ``num_or_sections``</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5553" href="#t5553">5553</a></span><span class="t"><span class="str">            indicates the number of equal sized sub-Tensors that the ``input``</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5554" href="#t5554">5554</a></span><span class="t"><span class="str">            will be divided into. If ``num_or_sections`` is a list or tuple, the length of it</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5555" href="#t5555">5555</a></span><span class="t"><span class="str">            indicates the number of sub-Tensors and the elements in it indicate the sizes of sub-Tensors'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5556" href="#t5556">5556</a></span><span class="t"><span class="str">            dimension orderly. The length of the list mustn't be larger than the ``input`` 's size of specified dim.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5557" href="#t5557">5557</a></span><span class="t"><span class="str">        dim (int|Tensor, optional): The dimension along which to split, it can be a scalar with type ``int`` or</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5558" href="#t5558">5558</a></span><span class="t"><span class="str">            a ``Tensor`` with shape [1] and data type ``int32`` or ``int64``. If :math:`dim &lt; 0`,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5559" href="#t5559">5559</a></span><span class="t"><span class="str">            the dimension to split along is :math:`rank(input) + dim`. Default is -1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5560" href="#t5560">5560</a></span><span class="t"><span class="str">        name (str, optional): The default value is None.  Normally there is no need for user to set this property.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5561" href="#t5561">5561</a></span><span class="t"><span class="str">            For more information, please refer to :ref:`api_guide_Name` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5562" href="#t5562">5562</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5563" href="#t5563">5563</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5564" href="#t5564">5564</a></span><span class="t"><span class="str">        list(Tensor): The list of segmented Tensors.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5565" href="#t5565">5565</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5566" href="#t5566">5566</a></span><span class="t"><span class="str">    Example:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5567" href="#t5567">5567</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5568" href="#t5568">5568</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5569" href="#t5569">5569</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5570" href="#t5570">5570</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5571" href="#t5571">5571</a></span><span class="t"><span class="str">            # input is a Tensor which shape is [3, 9, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5572" href="#t5572">5572</a></span><span class="t"><span class="str">            input = fluid.data(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5573" href="#t5573">5573</a></span><span class="t"><span class="str">                 name="input", shape=[3, 9, 5], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5574" href="#t5574">5574</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5575" href="#t5575">5575</a></span><span class="t"><span class="str">            out0, out1, out2 = fluid.layers.split(input, num_or_sections=3, dim=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5576" href="#t5576">5576</a></span><span class="t"><span class="str">            # out0.shape [3, 3, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5577" href="#t5577">5577</a></span><span class="t"><span class="str">            # out1.shape [3, 3, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5578" href="#t5578">5578</a></span><span class="t"><span class="str">            # out2.shape [3, 3, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5579" href="#t5579">5579</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5580" href="#t5580">5580</a></span><span class="t"><span class="str">            out0, out1, out2 = fluid.layers.split(input, num_or_sections=[2, 3, 4], dim=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5581" href="#t5581">5581</a></span><span class="t"><span class="str">            # out0.shape [3, 2, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5582" href="#t5582">5582</a></span><span class="t"><span class="str">            # out1.shape [3, 3, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5583" href="#t5583">5583</a></span><span class="t"><span class="str">            # out2.shape [3, 4, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5584" href="#t5584">5584</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5585" href="#t5585">5585</a></span><span class="t"><span class="str">            out0, out1, out2 = fluid.layers.split(input, num_or_sections=[2, 3, -1], dim=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5586" href="#t5586">5586</a></span><span class="t"><span class="str">            # out0.shape [3, 2, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5587" href="#t5587">5587</a></span><span class="t"><span class="str">            # out1.shape [3, 3, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5588" href="#t5588">5588</a></span><span class="t"><span class="str">            # out2.shape [3, 4, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5589" href="#t5589">5589</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5590" href="#t5590">5590</a></span><span class="t"><span class="str">            # dim is negative, the real dim is (rank(input) + axis) which real</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5591" href="#t5591">5591</a></span><span class="t"><span class="str">            # value is 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5592" href="#t5592">5592</a></span><span class="t"><span class="str">            out0, out1, out2 = fluid.layers.split(input, num_or_sections=3, dim=-2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5593" href="#t5593">5593</a></span><span class="t"><span class="str">            # out0.shape [3, 3, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5594" href="#t5594">5594</a></span><span class="t"><span class="str">            # out1.shape [3, 3, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5595" href="#t5595">5595</a></span><span class="t"><span class="str">            # out2.shape [3, 3, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5596" href="#t5596">5596</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5597" href="#t5597">5597</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t5598" href="#t5598">5598</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">5598&#x202F;&#x219B;&#x202F;5599</span><span class="annotate long">line 5598 didn't jump to line 5599, because the condition on line 5598 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5599" href="#t5599">5599</a></span><span class="t">        <span class="nam">num</span> <span class="op">=</span> <span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5600" href="#t5600">5600</a></span><span class="t">        <span class="nam">attrs</span> <span class="op">=</span> <span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5601" href="#t5601">5601</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5602" href="#t5602">5602</a></span><span class="t">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5603" href="#t5603">5603</a></span><span class="t">            <span class="nam">dim</span> <span class="op">=</span> <span class="nam">dim</span><span class="op">.</span><span class="nam">numpy</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5604" href="#t5604">5604</a></span><span class="t">            <span class="nam">dim</span> <span class="op">=</span> <span class="nam">dim</span><span class="op">.</span><span class="nam">item</span><span class="op">(</span><span class="num">0</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5605" href="#t5605">5605</a></span><span class="t">        <span class="key">assert</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">+</span> <span class="nam">dim</span> <span class="op">>=</span> <span class="num">0</span><span class="op">,</span> <span class="str">"(rank(x) + axis) must >= 0"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5606" href="#t5606">5606</a></span><span class="t">        <span class="nam">dim</span> <span class="op">=</span> <span class="op">(</span><span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">+</span> <span class="nam">dim</span><span class="op">)</span> <span class="key">if</span> <span class="nam">dim</span> <span class="op">&lt;</span> <span class="num">0</span> <span class="key">else</span> <span class="nam">dim</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5607" href="#t5607">5607</a></span><span class="t">        <span class="nam">attrs</span> <span class="op">+=</span> <span class="op">(</span><span class="str">'axis'</span><span class="op">,</span> <span class="nam">dim</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5608" href="#t5608">5608</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5609" href="#t5609">5609</a></span><span class="t">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">num_or_sections</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5610" href="#t5610">5610</a></span><span class="t">            <span class="nam">num</span> <span class="op">=</span> <span class="nam">num_or_sections</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5611" href="#t5611">5611</a></span><span class="t">            <span class="nam">attrs</span> <span class="op">+=</span> <span class="op">(</span><span class="str">'num'</span><span class="op">,</span> <span class="nam">num_or_sections</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5612" href="#t5612">5612</a></span><span class="t">        <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">num_or_sections</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5613" href="#t5613">5613</a></span><span class="t">            <span class="nam">num</span> <span class="op">=</span> <span class="nam">len</span><span class="op">(</span><span class="nam">num_or_sections</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5614" href="#t5614">5614</a></span><span class="t">            <span class="key">if</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_contain_var</span><span class="op">(</span><span class="nam">num_or_sections</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5615" href="#t5615">5615</a></span><span class="t">                <span class="key">for</span> <span class="nam">index</span><span class="op">,</span> <span class="nam">item</span> <span class="key">in</span> <span class="nam">enumerate</span><span class="op">(</span><span class="nam">num_or_sections</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5616" href="#t5616">5616</a></span><span class="t">                    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">item</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5617" href="#t5617">5617</a></span><span class="t">                        <span class="nam">num_or_sections</span><span class="op">[</span><span class="nam">index</span><span class="op">]</span> <span class="op">=</span> <span class="nam">num_or_sections</span><span class="op">[</span><span class="nam">index</span><span class="op">]</span><span class="op">.</span><span class="nam">numpy</span><span class="op">(</span><span class="op">)</span><span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5618" href="#t5618">5618</a></span><span class="t">                            <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5619" href="#t5619">5619</a></span><span class="t">                        <span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5620" href="#t5620">5620</a></span><span class="t">                <span class="nam">attrs</span> <span class="op">+=</span> <span class="op">(</span><span class="str">'sections'</span><span class="op">,</span> <span class="nam">list</span><span class="op">(</span><span class="nam">num_or_sections</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5621" href="#t5621">5621</a></span><span class="t">            <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5622" href="#t5622">5622</a></span><span class="t">                <span class="nam">attrs</span> <span class="op">+=</span> <span class="op">(</span><span class="str">'sections'</span><span class="op">,</span> <span class="nam">list</span><span class="op">(</span><span class="nam">num_or_sections</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5623" href="#t5623">5623</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5624" href="#t5624">5624</a></span><span class="t">            <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5625" href="#t5625">5625</a></span><span class="t">                <span class="str">"The type of 'num_or_sections' in split must be int, list or tuple in imperative mode, but "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5626" href="#t5626">5626</a></span><span class="t">                <span class="str">"received %s."</span> <span class="op">%</span> <span class="op">(</span><span class="nam">type</span><span class="op">(</span><span class="nam">num_or_sections</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5627" href="#t5627">5627</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5628" href="#t5628">5628</a></span><span class="t">        <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5629" href="#t5629">5629</a></span><span class="t">            <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">num_or_sections</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5630" href="#t5630">5630</a></span><span class="t">                <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">split_with_num</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">num_or_sections</span><span class="op">,</span> <span class="nam">dim</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5631" href="#t5631">5631</a></span><span class="t">            <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5632" href="#t5632">5632</a></span><span class="t">                <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">split</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">num_or_sections</span><span class="op">,</span> <span class="nam">dim</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5633" href="#t5633">5633</a></span><span class="t">        <span class="key">elif</span> <span class="nam">_in_legacy_dygraph</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5634" href="#t5634">5634</a></span><span class="t">            <span class="nam">out</span> <span class="op">=</span> <span class="op">[</span><span class="nam">_varbase_creator</span><span class="op">(</span><span class="op">)</span> <span class="key">for</span> <span class="nam">n</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">num</span><span class="op">)</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5635" href="#t5635">5635</a></span><span class="t">            <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">split</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">out</span><span class="op">,</span> <span class="op">*</span><span class="nam">attrs</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5636" href="#t5636">5636</a></span><span class="t">            <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5637" href="#t5637">5637</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5638" href="#t5638">5638</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5639" href="#t5639">5639</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5640" href="#t5640">5640</a></span><span class="t">        <span class="str">'input'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5641" href="#t5641">5641</a></span><span class="t">        <span class="op">[</span><span class="str">'bool'</span><span class="op">,</span> <span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5642" href="#t5642">5642</a></span><span class="t">        <span class="str">'split'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5643" href="#t5643">5643</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5644" href="#t5644">5644</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">num_or_sections</span><span class="op">,</span> <span class="str">'num_or_sections'</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">int</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">,</span> <span class="str">'split'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5645" href="#t5645">5645</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="str">'dim'</span><span class="op">,</span> <span class="op">(</span><span class="nam">int</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">,</span> <span class="str">'split'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t5646" href="#t5646">5646</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">5646&#x202F;&#x219B;&#x202F;5647</span><span class="annotate long">line 5646 didn't jump to line 5647, because the condition on line 5646 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5647" href="#t5647">5647</a></span><span class="t">        <span class="nam">check_dtype</span><span class="op">(</span><span class="nam">dim</span><span class="op">.</span><span class="nam">dtype</span><span class="op">,</span> <span class="str">'dim'</span><span class="op">,</span> <span class="op">[</span><span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'split'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5648" href="#t5648">5648</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5649" href="#t5649">5649</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'split'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5650" href="#t5650">5650</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5651" href="#t5651">5651</a></span><span class="t">    <span class="nam">input_shape</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5652" href="#t5652">5652</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5653" href="#t5653">5653</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'num'</span><span class="op">:</span> <span class="nam">num_or_sections</span> <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">num_or_sections</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span> <span class="key">else</span> <span class="num">0</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5654" href="#t5654">5654</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5655" href="#t5655">5655</a></span><span class="t">    <span class="key">def</span> <span class="nam">_get_SectionsTensorList</span><span class="op">(</span><span class="nam">one_list</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5656" href="#t5656">5656</a></span><span class="t">        <span class="nam">tensor_list</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5657" href="#t5657">5657</a></span><span class="t">        <span class="nam">unk_dim_idx</span> <span class="op">=</span> <span class="op">-</span><span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5658" href="#t5658">5658</a></span><span class="t">        <span class="key">for</span> <span class="nam">idx</span><span class="op">,</span> <span class="nam">dim_size</span> <span class="key">in</span> <span class="nam">enumerate</span><span class="op">(</span><span class="nam">one_list</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5659" href="#t5659">5659</a></span><span class="t">            <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim_size</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5660" href="#t5660">5660</a></span><span class="t">                <span class="nam">dim_size</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5661" href="#t5661">5661</a></span><span class="t">                <span class="nam">tensor_list</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">dim_size</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5662" href="#t5662">5662</a></span><span class="t">            <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5663" href="#t5663">5663</a></span><span class="t">                <span class="key">assert</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim_size</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5664" href="#t5664">5664</a></span><span class="t">                <span class="key">if</span> <span class="nam">dim_size</span> <span class="op">==</span> <span class="op">-</span><span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5665" href="#t5665">5665</a></span><span class="t">                    <span class="key">assert</span> <span class="nam">unk_dim_idx</span> <span class="op">==</span> <span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5666" href="#t5666">5666</a></span><span class="t">                        <span class="str">"Only one value of 'num_or_section' in split can "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5667" href="#t5667">5667</a></span><span class="t">                        <span class="str">"be -1. But received num_or_section[%d] is also -1."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5668" href="#t5668">5668</a></span><span class="t">                        <span class="op">%</span> <span class="nam">idx</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5669" href="#t5669">5669</a></span><span class="t">                    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5670" href="#t5670">5670</a></span><span class="t">                    <span class="nam">unk_dim_idx</span> <span class="op">=</span> <span class="nam">idx</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5671" href="#t5671">5671</a></span><span class="t">                <span class="nam">temp_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="str">'int32'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5672" href="#t5672">5672</a></span><span class="t">                <span class="nam">fill_constant</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5673" href="#t5673">5673</a></span><span class="t">                    <span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="nam">dim_size</span><span class="op">,</span> <span class="nam">force_cpu</span><span class="op">=</span><span class="key">True</span><span class="op">,</span> <span class="nam">out</span><span class="op">=</span><span class="nam">temp_out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5674" href="#t5674">5674</a></span><span class="t">                <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5675" href="#t5675">5675</a></span><span class="t">                <span class="nam">tensor_list</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">temp_out</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5676" href="#t5676">5676</a></span><span class="t">        <span class="key">return</span> <span class="nam">tensor_list</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5677" href="#t5677">5677</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t5678" href="#t5678">5678</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">5678&#x202F;&#x219B;&#x202F;5679</span><span class="annotate long">line 5678 didn't jump to line 5679, because the condition on line 5678 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5679" href="#t5679">5679</a></span><span class="t">        <span class="nam">dim</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5680" href="#t5680">5680</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">'AxisTensor'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">dim</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5681" href="#t5681">5681</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5682" href="#t5682">5682</a></span><span class="t">        <span class="key">assert</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">+</span> <span class="nam">dim</span> <span class="op">>=</span> <span class="num">0</span><span class="op">,</span> <span class="str">"(rank(x) + axis) must >= 0"</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5683" href="#t5683">5683</a></span><span class="t">        <span class="nam">dim</span> <span class="op">=</span> <span class="op">(</span><span class="nam">len</span><span class="op">(</span><span class="nam">input_shape</span><span class="op">)</span> <span class="op">+</span> <span class="nam">dim</span><span class="op">)</span> <span class="key">if</span> <span class="nam">dim</span> <span class="op">&lt;</span> <span class="num">0</span> <span class="key">else</span> <span class="nam">dim</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5684" href="#t5684">5684</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">'axis'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">dim</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5685" href="#t5685">5685</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t5686" href="#t5686">5686</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">num_or_sections</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">5686&#x202F;&#x219B;&#x202F;5697</span><span class="annotate long">line 5686 didn't jump to line 5697, because the condition on line 5686 was never false</span></span></p>
    <p class="run"><span class="n"><a id="t5687" href="#t5687">5687</a></span><span class="t">        <span class="key">assert</span> <span class="nam">num_or_sections</span> <span class="op">></span> <span class="num">1</span><span class="op">,</span> <span class="str">'num_or_sections must be more than 1.'</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t5688" href="#t5688">5688</a></span><span class="t">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span> <span class="key">and</span> <span class="nam">input_shape</span><span class="op">[</span><span class="nam">dim</span><span class="op">]</span> <span class="op">></span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">5688&#x202F;&#x219B;&#x202F;5695</span><span class="annotate long">line 5688 didn't jump to line 5695, because the condition on line 5688 was never false</span></span></p>
    <p class="run"><span class="n"><a id="t5689" href="#t5689">5689</a></span><span class="t">            <span class="key">assert</span> <span class="nam">input_shape</span><span class="op">[</span><span class="nam">dim</span><span class="op">]</span> <span class="op">%</span> <span class="nam">num_or_sections</span> <span class="op">==</span> <span class="num">0</span><span class="op">,</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5690" href="#t5690">5690</a></span><span class="t">                <span class="str">"The input's size along the split dimension "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5691" href="#t5691">5691</a></span><span class="t">                <span class="str">"must be evenly divisible by Attr(num_or_sections). "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5692" href="#t5692">5692</a></span><span class="t">                <span class="str">"But %d is not evenly divisible by %d. "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5693" href="#t5693">5693</a></span><span class="t">                <span class="op">%</span> <span class="op">(</span><span class="nam">num_or_sections</span><span class="op">,</span> <span class="nam">input_shape</span><span class="op">[</span><span class="nam">dim</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5694" href="#t5694">5694</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5695" href="#t5695">5695</a></span><span class="t">        <span class="nam">num</span> <span class="op">=</span> <span class="nam">num_or_sections</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5696" href="#t5696">5696</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5697" href="#t5697">5697</a></span><span class="t">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span> <span class="key">and</span> <span class="nam">input_shape</span><span class="op">[</span><span class="nam">dim</span><span class="op">]</span> <span class="op">></span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5698" href="#t5698">5698</a></span><span class="t">            <span class="key">assert</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5699" href="#t5699">5699</a></span><span class="t">                <span class="nam">len</span><span class="op">(</span><span class="nam">num_or_sections</span><span class="op">)</span> <span class="op">&lt;=</span> <span class="nam">input_shape</span><span class="op">[</span><span class="nam">dim</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5700" href="#t5700">5700</a></span><span class="t">            <span class="op">)</span><span class="op">,</span> <span class="str">'len(num_or_sections) must not be more than input.shape[dim].'</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5701" href="#t5701">5701</a></span><span class="t">        <span class="nam">num</span> <span class="op">=</span> <span class="nam">len</span><span class="op">(</span><span class="nam">num_or_sections</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5702" href="#t5702">5702</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">'sections'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5703" href="#t5703">5703</a></span><span class="t">            <span class="nam">map</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5704" href="#t5704">5704</a></span><span class="t">                <span class="key">lambda</span> <span class="nam">ele</span><span class="op">:</span> <span class="op">-</span><span class="num">1</span> <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">ele</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span> <span class="key">else</span> <span class="nam">ele</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5705" href="#t5705">5705</a></span><span class="t">                <span class="nam">num_or_sections</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5706" href="#t5706">5706</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5707" href="#t5707">5707</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5708" href="#t5708">5708</a></span><span class="t">        <span class="key">if</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_contain_var</span><span class="op">(</span><span class="nam">num_or_sections</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5709" href="#t5709">5709</a></span><span class="t">            <span class="nam">inputs</span><span class="op">[</span><span class="str">'SectionsTensorList'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">_get_SectionsTensorList</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5710" href="#t5710">5710</a></span><span class="t">                <span class="nam">num_or_sections</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5711" href="#t5711">5711</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5712" href="#t5712">5712</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5713" href="#t5713">5713</a></span><span class="t">    <span class="nam">outs</span> <span class="op">=</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5714" href="#t5714">5714</a></span><span class="t">        <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5715" href="#t5715">5715</a></span><span class="t">        <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">num</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5716" href="#t5716">5716</a></span><span class="t">    <span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5717" href="#t5717">5717</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5718" href="#t5718">5718</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'split'</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">outs</span><span class="op">}</span><span class="op">,</span> <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5719" href="#t5719">5719</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5720" href="#t5720">5720</a></span><span class="t">    <span class="key">return</span> <span class="nam">outs</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5721" href="#t5721">5721</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5722" href="#t5722">5722</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5723" href="#t5723">5723</a></span><span class="t"><span class="key">def</span> <span class="nam">l2_normalize</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">axis</span><span class="op">,</span> <span class="nam">epsilon</span><span class="op">=</span><span class="num">1e-12</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5724" href="#t5724">5724</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5725" href="#t5725">5725</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5726" href="#t5726">5726</a></span><span class="t"><span class="str">    This op normalizes `x` along dimension `axis` using an L2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5727" href="#t5727">5727</a></span><span class="t"><span class="str">    norm. For a 1-D tensor (`dim` is fixed to 0), this layer computes</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5728" href="#t5728">5728</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5729" href="#t5729">5729</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5730" href="#t5730">5730</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5731" href="#t5731">5731</a></span><span class="t"><span class="str">        y = \\frac{x}{ \sqrt{\sum {x^2} + epsion }}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5732" href="#t5732">5732</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5733" href="#t5733">5733</a></span><span class="t"><span class="str">    For `x` with more dimensions, this layer independently normalizes each 1-D</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5734" href="#t5734">5734</a></span><span class="t"><span class="str">    slice along dimension `axis`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5735" href="#t5735">5735</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5736" href="#t5736">5736</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5737" href="#t5737">5737</a></span><span class="t"><span class="str">        x(Variable|list): The input tensor could be N-D tensor, and the input data type could be float16, float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5738" href="#t5738">5738</a></span><span class="t"><span class="str">        axis(int): The axis on which to apply normalization. If `axis &lt; 0`, \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5739" href="#t5739">5739</a></span><span class="t"><span class="str">            the dimension to normalization is rank(X) + axis. -1 is the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5740" href="#t5740">5740</a></span><span class="t"><span class="str">            last dimension.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5741" href="#t5741">5741</a></span><span class="t"><span class="str">        epsilon(float): The epsilon value is used to avoid division by zero, \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5742" href="#t5742">5742</a></span><span class="t"><span class="str">            the default value is 1e-12.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5743" href="#t5743">5743</a></span><span class="t"><span class="str">    name(str, optional): The default value is None.  Normally there is no need for user to set this property.  For more information, please refer to :ref:`api_guide_Name`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5744" href="#t5744">5744</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5745" href="#t5745">5745</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5746" href="#t5746">5746</a></span><span class="t"><span class="str">        Variable: The output has the same shape and data type with `x`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5747" href="#t5747">5747</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5748" href="#t5748">5748</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5749" href="#t5749">5749</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5750" href="#t5750">5750</a></span><span class="t"><span class="str">    .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5751" href="#t5751">5751</a></span><span class="t"><span class="str">        :name: code-example1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5752" href="#t5752">5752</a></span><span class="t"><span class="str">        </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5753" href="#t5753">5753</a></span><span class="t"><span class="str">        import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5754" href="#t5754">5754</a></span><span class="t"><span class="str">        </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5755" href="#t5755">5755</a></span><span class="t"><span class="str">        X = paddle.randn(shape=[3, 5], dtype='float64')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5756" href="#t5756">5756</a></span><span class="t"><span class="str">        out = paddle.fluid.layers.l2_normalize(X, axis=-1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5757" href="#t5757">5757</a></span><span class="t"><span class="str">        print(out)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5758" href="#t5758">5758</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5759" href="#t5759">5759</a></span><span class="t"><span class="str">        # [[ 0.21558504  0.56360189  0.47466096  0.46269539 -0.44326736]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5760" href="#t5760">5760</a></span><span class="t"><span class="str">        #  [-0.70602414 -0.52745777  0.37771788 -0.2804768  -0.04449922]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5761" href="#t5761">5761</a></span><span class="t"><span class="str">        #  [-0.33972208 -0.43014923  0.31772556  0.76617881 -0.10761525]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5762" href="#t5762">5762</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5763" href="#t5763">5763</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5764" href="#t5764">5764</a></span><span class="t">    <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">==</span> <span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5765" href="#t5765">5765</a></span><span class="t">        <span class="nam">axis</span> <span class="op">=</span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5766" href="#t5766">5766</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5767" href="#t5767">5767</a></span><span class="t">        <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5768" href="#t5768">5768</a></span><span class="t">            <span class="nam">out</span><span class="op">,</span> <span class="nam">_</span> <span class="op">=</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">norm</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="num">1</span> <span class="key">if</span> <span class="nam">axis</span> <span class="key">is</span> <span class="key">None</span> <span class="key">else</span> <span class="nam">axis</span><span class="op">,</span> <span class="nam">epsilon</span><span class="op">,</span> <span class="key">False</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5769" href="#t5769">5769</a></span><span class="t">        <span class="key">elif</span> <span class="nam">_in_legacy_dygraph</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5770" href="#t5770">5770</a></span><span class="t">            <span class="nam">_</span><span class="op">,</span> <span class="nam">out</span> <span class="op">=</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">norm</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5771" href="#t5771">5771</a></span><span class="t">                <span class="nam">x</span><span class="op">,</span> <span class="str">'axis'</span><span class="op">,</span> <span class="num">1</span> <span class="key">if</span> <span class="nam">axis</span> <span class="key">is</span> <span class="key">None</span> <span class="key">else</span> <span class="nam">axis</span><span class="op">,</span> <span class="str">'epsilon'</span><span class="op">,</span> <span class="nam">epsilon</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5772" href="#t5772">5772</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5773" href="#t5773">5773</a></span><span class="t">        <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5774" href="#t5774">5774</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5775" href="#t5775">5775</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">"X"</span><span class="op">,</span> <span class="op">(</span><span class="str">"float16"</span><span class="op">,</span> <span class="str">"float32"</span><span class="op">,</span> <span class="str">"float64"</span><span class="op">)</span><span class="op">,</span> <span class="str">"norm"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5776" href="#t5776">5776</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5777" href="#t5777">5777</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"l2_normalize"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5778" href="#t5778">5778</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5779" href="#t5779">5779</a></span><span class="t">    <span class="nam">norm</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5780" href="#t5780">5780</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5781" href="#t5781">5781</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"norm"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5782" href="#t5782">5782</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5783" href="#t5783">5783</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">,</span> <span class="str">"Norm"</span><span class="op">:</span> <span class="nam">norm</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5784" href="#t5784">5784</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5785" href="#t5785">5785</a></span><span class="t">            <span class="str">"axis"</span><span class="op">:</span> <span class="num">1</span> <span class="key">if</span> <span class="nam">axis</span> <span class="key">is</span> <span class="key">None</span> <span class="key">else</span> <span class="nam">axis</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5786" href="#t5786">5786</a></span><span class="t">            <span class="str">"epsilon"</span><span class="op">:</span> <span class="nam">epsilon</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5787" href="#t5787">5787</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5788" href="#t5788">5788</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5789" href="#t5789">5789</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5790" href="#t5790">5790</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5791" href="#t5791">5791</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5792" href="#t5792">5792</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.matmul"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5793" href="#t5793">5793</a></span><span class="t"><span class="key">def</span> <span class="nam">matmul</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">transpose_x</span><span class="op">=</span><span class="key">False</span><span class="op">,</span> <span class="nam">transpose_y</span><span class="op">=</span><span class="key">False</span><span class="op">,</span> <span class="nam">alpha</span><span class="op">=</span><span class="num">1.0</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5794" href="#t5794">5794</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5795" href="#t5795">5795</a></span><span class="t"><span class="str">    Applies matrix multiplication to two tensors.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5796" href="#t5796">5796</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5797" href="#t5797">5797</a></span><span class="t"><span class="str">    Currently, the input tensors' rank can be any, but when the rank of any</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5798" href="#t5798">5798</a></span><span class="t"><span class="str">    inputs is bigger than 3, this two inputs' rank should be equal.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5799" href="#t5799">5799</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5800" href="#t5800">5800</a></span><span class="t"><span class="str">    The actual behavior depends on the shapes of :math:`x`, :math:`y` and the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5801" href="#t5801">5801</a></span><span class="t"><span class="str">    flag values of :attr:`transpose_x`, :attr:`transpose_y`. Specifically:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5802" href="#t5802">5802</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5803" href="#t5803">5803</a></span><span class="t"><span class="str">    - If a transpose flag is specified, the last two dimensions of the tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5804" href="#t5804">5804</a></span><span class="t"><span class="str">      are transposed. If the tensor is rank-1 of shape :math:`[D]`, then for</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5805" href="#t5805">5805</a></span><span class="t"><span class="str">      :math:`x` it is treated as :math:`[1, D]` in nontransposed form and as</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5806" href="#t5806">5806</a></span><span class="t"><span class="str">      :math:`[D, 1]` in transposed form, whereas for :math:`y` it is the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5807" href="#t5807">5807</a></span><span class="t"><span class="str">      opposite: It is treated as :math:`[D, 1]` in nontransposed form and as</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5808" href="#t5808">5808</a></span><span class="t"><span class="str">      :math:`[1, D]` in transposed form.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5809" href="#t5809">5809</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5810" href="#t5810">5810</a></span><span class="t"><span class="str">    - After transpose, the two tensors are 2-D or n-D and matrix multiplication</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5811" href="#t5811">5811</a></span><span class="t"><span class="str">      performs in the following way.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5812" href="#t5812">5812</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5813" href="#t5813">5813</a></span><span class="t"><span class="str">      - If both are 2-D, they are multiplied like conventional matrices.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5814" href="#t5814">5814</a></span><span class="t"><span class="str">      - If either is n-D, it is treated as a stack of matrices residing in the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5815" href="#t5815">5815</a></span><span class="t"><span class="str">        last two dimensions and a batched matrix multiply supporting broadcast</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5816" href="#t5816">5816</a></span><span class="t"><span class="str">        applies on the two tensors.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5817" href="#t5817">5817</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5818" href="#t5818">5818</a></span><span class="t"><span class="str">    Also note that if the raw tensor :math:`x` or :math:`y` is rank-1 and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5819" href="#t5819">5819</a></span><span class="t"><span class="str">    nontransposed, the prepended or appended dimension :math:`1` will be</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5820" href="#t5820">5820</a></span><span class="t"><span class="str">    removed after matrix multiplication.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5821" href="#t5821">5821</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5822" href="#t5822">5822</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5823" href="#t5823">5823</a></span><span class="t"><span class="str">        x (Variable): The input variable which is a Tensor or LoDTensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5824" href="#t5824">5824</a></span><span class="t"><span class="str">        y (Variable): The input variable which is a Tensor or LoDTensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5825" href="#t5825">5825</a></span><span class="t"><span class="str">        transpose_x (bool): Whether to transpose :math:`x` before multiplication.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5826" href="#t5826">5826</a></span><span class="t"><span class="str">        transpose_y (bool): Whether to transpose :math:`y` before multiplication.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5827" href="#t5827">5827</a></span><span class="t"><span class="str">        alpha (float): The scale of output. Default 1.0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5828" href="#t5828">5828</a></span><span class="t"><span class="str">        name(str|None): A name for this layer(optional). If set None, the layer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5829" href="#t5829">5829</a></span><span class="t"><span class="str">            will be named automatically.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5830" href="#t5830">5830</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5831" href="#t5831">5831</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5832" href="#t5832">5832</a></span><span class="t"><span class="str">        Variable: The product Tensor (or LoDTensor) variable.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5833" href="#t5833">5833</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5834" href="#t5834">5834</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5835" href="#t5835">5835</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5836" href="#t5836">5836</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5837" href="#t5837">5837</a></span><span class="t"><span class="str">            # Examples to clarify shapes of the inputs and output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5838" href="#t5838">5838</a></span><span class="t"><span class="str">            # x: [B, ..., M, K], y: [B, ..., K, N]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5839" href="#t5839">5839</a></span><span class="t"><span class="str">            # fluid.layers.matmul(x, y)  # out: [B, ..., M, N]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5840" href="#t5840">5840</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5841" href="#t5841">5841</a></span><span class="t"><span class="str">            # x: [B, M, K], y: [B, K, N]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5842" href="#t5842">5842</a></span><span class="t"><span class="str">            # fluid.layers.matmul(x, y)  # out: [B, M, N]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5843" href="#t5843">5843</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5844" href="#t5844">5844</a></span><span class="t"><span class="str">            # x: [B, M, K], y: [K, N]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5845" href="#t5845">5845</a></span><span class="t"><span class="str">            # fluid.layers.matmul(x, y)  # out: [B, M, N]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5846" href="#t5846">5846</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5847" href="#t5847">5847</a></span><span class="t"><span class="str">            # x: [M, K], y: [K, N]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5848" href="#t5848">5848</a></span><span class="t"><span class="str">            # fluid.layers.matmul(x, y)  # out: [M, N]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5849" href="#t5849">5849</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5850" href="#t5850">5850</a></span><span class="t"><span class="str">            # x: [B, M, K], y: [K]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5851" href="#t5851">5851</a></span><span class="t"><span class="str">            # fluid.layers.matmul(x, y)  # out: [B, M]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5852" href="#t5852">5852</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5853" href="#t5853">5853</a></span><span class="t"><span class="str">            # x: [K], y: [K]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5854" href="#t5854">5854</a></span><span class="t"><span class="str">            # fluid.layers.matmul(x, y)  # out: [1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5855" href="#t5855">5855</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5856" href="#t5856">5856</a></span><span class="t"><span class="str">            # x: [M], y: [N]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5857" href="#t5857">5857</a></span><span class="t"><span class="str">            # fluid.layers.matmul(x, y, True, True)  # out: [M, N]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5858" href="#t5858">5858</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5859" href="#t5859">5859</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5860" href="#t5860">5860</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5861" href="#t5861">5861</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5862" href="#t5862">5862</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5863" href="#t5863">5863</a></span><span class="t"><span class="str">            x = fluid.layers.data(name='x', shape=[2, 3], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5864" href="#t5864">5864</a></span><span class="t"><span class="str">            y = fluid.layers.data(name='y', shape=[3, 2], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5865" href="#t5865">5865</a></span><span class="t"><span class="str">            out = fluid.layers.matmul(x, y, True, True)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5866" href="#t5866">5866</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t5867" href="#t5867">5867</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">5867&#x202F;&#x219B;&#x202F;5868</span><span class="annotate long">line 5867 didn't jump to line 5868, because the condition on line 5867 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5868" href="#t5868">5868</a></span><span class="t">        <span class="nam">out</span> <span class="op">=</span> <span class="nam">_varbase_creator</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5869" href="#t5869">5869</a></span><span class="t">        <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">matmul</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5870" href="#t5870">5870</a></span><span class="t">            <span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5871" href="#t5871">5871</a></span><span class="t">            <span class="nam">y</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5872" href="#t5872">5872</a></span><span class="t">            <span class="nam">out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5873" href="#t5873">5873</a></span><span class="t">            <span class="str">'transpose_X'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5874" href="#t5874">5874</a></span><span class="t">            <span class="nam">transpose_x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5875" href="#t5875">5875</a></span><span class="t">            <span class="str">'transpose_Y'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5876" href="#t5876">5876</a></span><span class="t">            <span class="nam">transpose_y</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5877" href="#t5877">5877</a></span><span class="t">            <span class="str">'alpha'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5878" href="#t5878">5878</a></span><span class="t">            <span class="nam">float</span><span class="op">(</span><span class="nam">alpha</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5879" href="#t5879">5879</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5880" href="#t5880">5880</a></span><span class="t">        <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5881" href="#t5881">5881</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5882" href="#t5882">5882</a></span><span class="t">    <span class="key">def</span> <span class="nam">__check_input</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5883" href="#t5883">5883</a></span><span class="t">        <span class="nam">var_names</span> <span class="op">=</span> <span class="op">{</span><span class="str">'x'</span><span class="op">:</span> <span class="nam">x</span><span class="op">,</span> <span class="str">'y'</span><span class="op">:</span> <span class="nam">y</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5884" href="#t5884">5884</a></span><span class="t">        <span class="key">for</span> <span class="nam">name</span><span class="op">,</span> <span class="nam">val</span> <span class="key">in</span> <span class="nam">var_names</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5885" href="#t5885">5885</a></span><span class="t">            <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5886" href="#t5886">5886</a></span><span class="t">                <span class="nam">val</span><span class="op">,</span> <span class="nam">name</span><span class="op">,</span> <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'matmul'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5887" href="#t5887">5887</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5888" href="#t5888">5888</a></span><span class="t">        <span class="nam">x_shape</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5889" href="#t5889">5889</a></span><span class="t">        <span class="nam">y_shape</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="nam">y</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t5890" href="#t5890">5890</a></span><span class="t">        <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">x_shape</span><span class="op">)</span> <span class="op">==</span> <span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">5890&#x202F;&#x219B;&#x202F;5891</span><span class="annotate long">line 5890 didn't jump to line 5891, because the condition on line 5890 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5891" href="#t5891">5891</a></span><span class="t">            <span class="nam">x_shape</span> <span class="op">=</span> <span class="op">[</span><span class="num">1</span><span class="op">]</span> <span class="op">+</span> <span class="nam">x_shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t5892" href="#t5892">5892</a></span><span class="t">        <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">y_shape</span><span class="op">)</span> <span class="op">==</span> <span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">5892&#x202F;&#x219B;&#x202F;5893</span><span class="annotate long">line 5892 didn't jump to line 5893, because the condition on line 5892 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5893" href="#t5893">5893</a></span><span class="t">            <span class="nam">y_shape</span> <span class="op">=</span> <span class="nam">y_shape</span> <span class="op">+</span> <span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5894" href="#t5894">5894</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5895" href="#t5895">5895</a></span><span class="t">        <span class="com"># check the inner 2 dimensions</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t5896" href="#t5896">5896</a></span><span class="t">        <span class="key">if</span> <span class="nam">transpose_x</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">5896&#x202F;&#x219B;&#x202F;5897</span><span class="annotate long">line 5896 didn't jump to line 5897, because the condition on line 5896 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5897" href="#t5897">5897</a></span><span class="t">            <span class="nam">x_shape</span><span class="op">[</span><span class="op">-</span><span class="num">2</span><span class="op">]</span><span class="op">,</span> <span class="nam">x_shape</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span> <span class="op">=</span> <span class="nam">x_shape</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span><span class="op">,</span> <span class="nam">x_shape</span><span class="op">[</span><span class="op">-</span><span class="num">2</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5898" href="#t5898">5898</a></span><span class="t">        <span class="key">if</span> <span class="nam">transpose_y</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5899" href="#t5899">5899</a></span><span class="t">            <span class="nam">y_shape</span><span class="op">[</span><span class="op">-</span><span class="num">2</span><span class="op">]</span><span class="op">,</span> <span class="nam">y_shape</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span> <span class="op">=</span> <span class="nam">y_shape</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span><span class="op">,</span> <span class="nam">y_shape</span><span class="op">[</span><span class="op">-</span><span class="num">2</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5900" href="#t5900">5900</a></span><span class="t">        <span class="key">if</span> <span class="nam">x_shape</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span> <span class="op">!=</span> <span class="nam">y_shape</span><span class="op">[</span><span class="op">-</span><span class="num">2</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5901" href="#t5901">5901</a></span><span class="t">            <span class="key">assert</span> <span class="op">(</span><span class="nam">x_shape</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span> <span class="op">==</span> <span class="op">-</span><span class="num">1</span><span class="op">)</span> <span class="key">or</span> <span class="op">(</span><span class="nam">y_shape</span><span class="op">[</span><span class="op">-</span><span class="num">2</span><span class="op">]</span> <span class="op">==</span> <span class="op">-</span><span class="num">1</span><span class="op">)</span><span class="op">,</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5902" href="#t5902">5902</a></span><span class="t">                <span class="str">"After performing an optional transpose, Input X's width should be "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5903" href="#t5903">5903</a></span><span class="t">                <span class="str">"equal to Y's width for multiplication "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5904" href="#t5904">5904</a></span><span class="t">                <span class="str">"prerequisites. But received X's shape: %s, Y's shape: %s\n"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5905" href="#t5905">5905</a></span><span class="t">                <span class="op">%</span> <span class="op">(</span><span class="nam">x_shape</span><span class="op">,</span> <span class="nam">y_shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5906" href="#t5906">5906</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5907" href="#t5907">5907</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t5908" href="#t5908">5908</a></span><span class="t">        <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">y_shape</span><span class="op">)</span> <span class="op">></span> <span class="num">2</span> <span class="key">and</span> <span class="nam">len</span><span class="op">(</span><span class="nam">x_shape</span><span class="op">)</span> <span class="op">></span> <span class="num">2</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">5908&#x202F;&#x219B;&#x202F;5909</span><span class="annotate long">line 5908 didn't jump to line 5909, because the condition on line 5908 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5909" href="#t5909">5909</a></span><span class="t">            <span class="key">for</span> <span class="nam">i</span><span class="op">,</span> <span class="nam">dim_x</span> <span class="key">in</span> <span class="nam">enumerate</span><span class="op">(</span><span class="nam">x_shape</span><span class="op">[</span><span class="op">:</span><span class="op">-</span><span class="num">2</span><span class="op">]</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5910" href="#t5910">5910</a></span><span class="t">                <span class="com"># don't check neg shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5911" href="#t5911">5911</a></span><span class="t">                <span class="key">if</span> <span class="nam">dim_x</span> <span class="op">&lt;</span> <span class="num">0</span> <span class="key">or</span> <span class="nam">y_shape</span><span class="op">[</span><span class="nam">i</span><span class="op">]</span> <span class="op">&lt;</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5912" href="#t5912">5912</a></span><span class="t">                    <span class="key">continue</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5913" href="#t5913">5913</a></span><span class="t">                <span class="key">if</span> <span class="nam">dim_x</span> <span class="op">!=</span> <span class="nam">y_shape</span><span class="op">[</span><span class="nam">i</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t5914" href="#t5914">5914</a></span><span class="t">                    <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5915" href="#t5915">5915</a></span><span class="t">                        <span class="str">"When the matrix is larger than 2 dimensions, the higher "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5916" href="#t5916">5916</a></span><span class="t">                        <span class="str">"dimensional values of the two matrices need to be equal. "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5917" href="#t5917">5917</a></span><span class="t">                        <span class="str">"But received x_shape[%d] != y_shape[%d]. X's shape: %s, "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5918" href="#t5918">5918</a></span><span class="t">                        <span class="str">"Y's shape: %s.\n"</span> <span class="op">%</span> <span class="op">(</span><span class="nam">i</span><span class="op">,</span> <span class="nam">i</span><span class="op">,</span> <span class="nam">x_shape</span><span class="op">,</span> <span class="nam">y_shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5919" href="#t5919">5919</a></span><span class="t">                    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5920" href="#t5920">5920</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5921" href="#t5921">5921</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5922" href="#t5922">5922</a></span><span class="t">        <span class="str">'transpose_X'</span><span class="op">:</span> <span class="nam">transpose_x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5923" href="#t5923">5923</a></span><span class="t">        <span class="str">'transpose_Y'</span><span class="op">:</span> <span class="nam">transpose_y</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5924" href="#t5924">5924</a></span><span class="t">        <span class="str">'alpha'</span><span class="op">:</span> <span class="nam">float</span><span class="op">(</span><span class="nam">alpha</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5925" href="#t5925">5925</a></span><span class="t">    <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5926" href="#t5926">5926</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5927" href="#t5927">5927</a></span><span class="t">    <span class="nam">__check_input</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5928" href="#t5928">5928</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5929" href="#t5929">5929</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'matmul'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5930" href="#t5930">5930</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5931" href="#t5931">5931</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5932" href="#t5932">5932</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'matmul'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5933" href="#t5933">5933</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">,</span> <span class="str">'Y'</span><span class="op">:</span> <span class="nam">y</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5934" href="#t5934">5934</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5935" href="#t5935">5935</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5936" href="#t5936">5936</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5937" href="#t5937">5937</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5938" href="#t5938">5938</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5939" href="#t5939">5939</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t5940" href="#t5940">5940</a></span><span class="t"><span class="key">def</span> <span class="nam">topk</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">k</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5941" href="#t5941">5941</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5942" href="#t5942">5942</a></span><span class="t"><span class="str">    :alias_main: paddle.topk</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5943" href="#t5943">5943</a></span><span class="t"><span class="str">        :alias: paddle.topk,paddle.tensor.topk,paddle.tensor.search.topk</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5944" href="#t5944">5944</a></span><span class="t"><span class="str">        :old_api: paddle.fluid.layers.topk</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5945" href="#t5945">5945</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5946" href="#t5946">5946</a></span><span class="t"><span class="str">    This OP is used to find values and indices of the k largest entries</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5947" href="#t5947">5947</a></span><span class="t"><span class="str">    for the last dimension.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5948" href="#t5948">5948</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5949" href="#t5949">5949</a></span><span class="t"><span class="str">    If the input is a 1-D Tensor, finds the k largest entries and outputs</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5950" href="#t5950">5950</a></span><span class="t"><span class="str">    their values and indices.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5951" href="#t5951">5951</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5952" href="#t5952">5952</a></span><span class="t"><span class="str">    If the input is a Tensor with higher rank, this operator computes the top k</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5953" href="#t5953">5953</a></span><span class="t"><span class="str">    entries along the last dimension.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5954" href="#t5954">5954</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5955" href="#t5955">5955</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5956" href="#t5956">5956</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5957" href="#t5957">5957</a></span><span class="t"><span class="str">        Case 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5958" href="#t5958">5958</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5959" href="#t5959">5959</a></span><span class="t"><span class="str">          Input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5960" href="#t5960">5960</a></span><span class="t"><span class="str">            input.shape = [3, 4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5961" href="#t5961">5961</a></span><span class="t"><span class="str">            input.data = [[5, 4, 2, 3],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5962" href="#t5962">5962</a></span><span class="t"><span class="str">                     [9, 7, 10, 25],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5963" href="#t5963">5963</a></span><span class="t"><span class="str">                     [6, 2, 10, 1]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5964" href="#t5964">5964</a></span><span class="t"><span class="str">            k = 2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5965" href="#t5965">5965</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5966" href="#t5966">5966</a></span><span class="t"><span class="str">          Output:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5967" href="#t5967">5967</a></span><span class="t"><span class="str">            The first output:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5968" href="#t5968">5968</a></span><span class="t"><span class="str">            values.shape = [3, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5969" href="#t5969">5969</a></span><span class="t"><span class="str">            values.data = [[5, 4],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5970" href="#t5970">5970</a></span><span class="t"><span class="str">                      [10, 25],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5971" href="#t5971">5971</a></span><span class="t"><span class="str">                      [6, 10]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5972" href="#t5972">5972</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5973" href="#t5973">5973</a></span><span class="t"><span class="str">            The second output:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5974" href="#t5974">5974</a></span><span class="t"><span class="str">            indices.shape = [3, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5975" href="#t5975">5975</a></span><span class="t"><span class="str">            indices.data = [[0, 1],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5976" href="#t5976">5976</a></span><span class="t"><span class="str">                       [2, 3],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5977" href="#t5977">5977</a></span><span class="t"><span class="str">                       [0, 2]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5978" href="#t5978">5978</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5979" href="#t5979">5979</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5980" href="#t5980">5980</a></span><span class="t"><span class="str">        input(Variable): The input tensor. Support data types: float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5981" href="#t5981">5981</a></span><span class="t"><span class="str">        k(int | Variable): The number of top elements to look for along the last dimension</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5982" href="#t5982">5982</a></span><span class="t"><span class="str">                           of input tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5983" href="#t5983">5983</a></span><span class="t"><span class="str">        name (str, optional): Please refer to :ref:`api_guide_Name`, Default None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5984" href="#t5984">5984</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5985" href="#t5985">5985</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5986" href="#t5986">5986</a></span><span class="t"><span class="str">        Values (Variable): Input tensor's k largest elements along each last dimensional slice. The dimension is: :math:`input.shape[:-1]+[k]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5987" href="#t5987">5987</a></span><span class="t"><span class="str">        Indices (Variable): Indices of k largest elements alone the last dimension of input. The dimension is same as values.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5988" href="#t5988">5988</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5989" href="#t5989">5989</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5990" href="#t5990">5990</a></span><span class="t"><span class="str">        ValueError: If :math:`k &lt; 1` or :math:`k > last dimension of input`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5991" href="#t5991">5991</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5992" href="#t5992">5992</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5993" href="#t5993">5993</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5994" href="#t5994">5994</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5995" href="#t5995">5995</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5996" href="#t5996">5996</a></span><span class="t"><span class="str">            import paddle.fluid.layers as layers</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5997" href="#t5997">5997</a></span><span class="t"><span class="str">            # set batch size=None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5998" href="#t5998">5998</a></span><span class="t"><span class="str">            input = fluid.data(name="input", shape=[None, 13, 11], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5999" href="#t5999">5999</a></span><span class="t"><span class="str">            top5_values, top5_indices = layers.topk(input, k=5) # top5_values.shape[None, 13, 5], top5_indices.shape=[None, 13, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6000" href="#t6000">6000</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6001" href="#t6001">6001</a></span><span class="t"><span class="str">            # 1D Tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6002" href="#t6002">6002</a></span><span class="t"><span class="str">            input1 = fluid.data(name="input1", shape=[None, 13], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6003" href="#t6003">6003</a></span><span class="t"><span class="str">            top5_values, top5_indices = layers.topk(input1, k=5) #top5_values.shape=[None, 5], top5_indices.shape=[None, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6004" href="#t6004">6004</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6005" href="#t6005">6005</a></span><span class="t"><span class="str">            # k=Variable</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6006" href="#t6006">6006</a></span><span class="t"><span class="str">            input2 = fluid.data(name="input2", shape=[None, 13, 11], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6007" href="#t6007">6007</a></span><span class="t"><span class="str">            vk = fluid.data(name="vk", shape=[None, 1], dtype='int32') # save k in vk.data[0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6008" href="#t6008">6008</a></span><span class="t"><span class="str">            vk_values, vk_indices = layers.topk(input2, k=vk) #vk_values.shape=[None, 13, k], vk_indices.shape=[None, 13, k]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6009" href="#t6009">6009</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6010" href="#t6010">6010</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t6011" href="#t6011">6011</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">6011&#x202F;&#x219B;&#x202F;6012</span><span class="annotate long">line 6011 didn't jump to line 6012, because the condition on line 6011 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6012" href="#t6012">6012</a></span><span class="t">        <span class="nam">_k</span> <span class="op">=</span> <span class="nam">k</span><span class="op">.</span><span class="nam">numpy</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">item</span><span class="op">(</span><span class="num">0</span><span class="op">)</span> <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">k</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span> <span class="key">else</span> <span class="nam">k</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6013" href="#t6013">6013</a></span><span class="t">        <span class="nam">out</span><span class="op">,</span> <span class="nam">indices</span> <span class="op">=</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">top_k</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="str">'k'</span><span class="op">,</span> <span class="nam">_k</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6014" href="#t6014">6014</a></span><span class="t">        <span class="nam">out</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6015" href="#t6015">6015</a></span><span class="t">        <span class="nam">indices</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6016" href="#t6016">6016</a></span><span class="t">        <span class="key">return</span> <span class="nam">out</span><span class="op">,</span> <span class="nam">indices</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6017" href="#t6017">6017</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6018" href="#t6018">6018</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="op">[</span><span class="nam">input</span><span class="op">]</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6019" href="#t6019">6019</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t6020" href="#t6020">6020</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">k</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">6020&#x202F;&#x219B;&#x202F;6021</span><span class="annotate long">line 6020 didn't jump to line 6021, because the condition on line 6020 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6021" href="#t6021">6021</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">'K'</span><span class="op">]</span> <span class="op">=</span> <span class="op">[</span><span class="nam">k</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6022" href="#t6022">6022</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6023" href="#t6023">6023</a></span><span class="t">        <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'k'</span><span class="op">:</span> <span class="nam">k</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6024" href="#t6024">6024</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6025" href="#t6025">6025</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"top_k"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6026" href="#t6026">6026</a></span><span class="t">    <span class="nam">values</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">input</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6027" href="#t6027">6027</a></span><span class="t">    <span class="nam">indices</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="str">"int64"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6028" href="#t6028">6028</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6029" href="#t6029">6029</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6030" href="#t6030">6030</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"top_k"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6031" href="#t6031">6031</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6032" href="#t6032">6032</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="op">[</span><span class="nam">values</span><span class="op">]</span><span class="op">,</span> <span class="str">"Indices"</span><span class="op">:</span> <span class="op">[</span><span class="nam">indices</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6033" href="#t6033">6033</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6034" href="#t6034">6034</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6035" href="#t6035">6035</a></span><span class="t">    <span class="nam">values</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6036" href="#t6036">6036</a></span><span class="t">    <span class="nam">indices</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6037" href="#t6037">6037</a></span><span class="t">    <span class="key">return</span> <span class="nam">values</span><span class="op">,</span> <span class="nam">indices</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6038" href="#t6038">6038</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6039" href="#t6039">6039</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6040" href="#t6040">6040</a></span><span class="t"><span class="key">def</span> <span class="nam">ctc_greedy_decoder</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6041" href="#t6041">6041</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span> <span class="nam">blank</span><span class="op">,</span> <span class="nam">input_length</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">padding_value</span><span class="op">=</span><span class="num">0</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6042" href="#t6042">6042</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6043" href="#t6043">6043</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6044" href="#t6044">6044</a></span><span class="t"><span class="str">    This op is used to decode sequences by greedy policy by the following steps:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6045" href="#t6045">6045</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6046" href="#t6046">6046</a></span><span class="t"><span class="str">    1. Get the indexes of maximum value for each row in input. a.k.a.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6047" href="#t6047">6047</a></span><span class="t"><span class="str">       numpy.argmax(input, axis=0).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6048" href="#t6048">6048</a></span><span class="t"><span class="str">    2. For each sequence in result of step1, merge repeated tokens between two</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6049" href="#t6049">6049</a></span><span class="t"><span class="str">       blanks and delete all blanks.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6050" href="#t6050">6050</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6051" href="#t6051">6051</a></span><span class="t"><span class="str">    This op is implemented in two modes: lod and padding, either of them can be used.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6052" href="#t6052">6052</a></span><span class="t"><span class="str">    The input can be either LoDTensor or Tensor, corresponding to lod and padding</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6053" href="#t6053">6053</a></span><span class="t"><span class="str">    mode respectively.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6054" href="#t6054">6054</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6055" href="#t6055">6055</a></span><span class="t"><span class="str">    A simple example as below:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6056" href="#t6056">6056</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6057" href="#t6057">6057</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6058" href="#t6058">6058</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6059" href="#t6059">6059</a></span><span class="t"><span class="str">        Given:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6060" href="#t6060">6060</a></span><span class="t"><span class="str">        (1) for lod mode:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6061" href="#t6061">6061</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6062" href="#t6062">6062</a></span><span class="t"><span class="str">        input.data = [[0.6, 0.1, 0.3, 0.1],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6063" href="#t6063">6063</a></span><span class="t"><span class="str">                      [0.3, 0.2, 0.4, 0.1],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6064" href="#t6064">6064</a></span><span class="t"><span class="str">                      [0.1, 0.5, 0.1, 0.3],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6065" href="#t6065">6065</a></span><span class="t"><span class="str">                      [0.5, 0.1, 0.3, 0.1],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6066" href="#t6066">6066</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6067" href="#t6067">6067</a></span><span class="t"><span class="str">                      [0.5, 0.1, 0.3, 0.1],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6068" href="#t6068">6068</a></span><span class="t"><span class="str">                      [0.2, 0.2, 0.2, 0.4],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6069" href="#t6069">6069</a></span><span class="t"><span class="str">                      [0.2, 0.2, 0.1, 0.5],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6070" href="#t6070">6070</a></span><span class="t"><span class="str">                      [0.5, 0.1, 0.3, 0.1]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6071" href="#t6071">6071</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6072" href="#t6072">6072</a></span><span class="t"><span class="str">        input.lod = [[4, 4]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6073" href="#t6073">6073</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6074" href="#t6074">6074</a></span><span class="t"><span class="str">        Computation:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6075" href="#t6075">6075</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6076" href="#t6076">6076</a></span><span class="t"><span class="str">        step1: Apply argmax to first input sequence which is input.data[0:4]. Then we get:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6077" href="#t6077">6077</a></span><span class="t"><span class="str">               [[0], [2], [1], [0]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6078" href="#t6078">6078</a></span><span class="t"><span class="str">        step2: merge repeated tokens and remove blank which is 0. Then we get first output sequence:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6079" href="#t6079">6079</a></span><span class="t"><span class="str">               [[2], [1]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6080" href="#t6080">6080</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6081" href="#t6081">6081</a></span><span class="t"><span class="str">        Finally:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6082" href="#t6082">6082</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6083" href="#t6083">6083</a></span><span class="t"><span class="str">        output.data = [[2],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6084" href="#t6084">6084</a></span><span class="t"><span class="str">                       [1],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6085" href="#t6085">6085</a></span><span class="t"><span class="str">                       [3]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6086" href="#t6086">6086</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6087" href="#t6087">6087</a></span><span class="t"><span class="str">        output.lod = [[2, 1]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6088" href="#t6088">6088</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6089" href="#t6089">6089</a></span><span class="t"><span class="str">        (2) for padding mode:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6090" href="#t6090">6090</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6091" href="#t6091">6091</a></span><span class="t"><span class="str">         input.data = [[[0.6, 0.1, 0.3, 0.1],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6092" href="#t6092">6092</a></span><span class="t"><span class="str">                        [0.3, 0.2, 0.4, 0.1],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6093" href="#t6093">6093</a></span><span class="t"><span class="str">                        [0.1, 0.5, 0.1, 0.3],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6094" href="#t6094">6094</a></span><span class="t"><span class="str">                        [0.5, 0.1, 0.3, 0.1]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6095" href="#t6095">6095</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6096" href="#t6096">6096</a></span><span class="t"><span class="str">                       [[0.5, 0.1, 0.3, 0.1],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6097" href="#t6097">6097</a></span><span class="t"><span class="str">                        [0.2, 0.2, 0.2, 0.4],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6098" href="#t6098">6098</a></span><span class="t"><span class="str">                        [0.2, 0.2, 0.1, 0.5],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6099" href="#t6099">6099</a></span><span class="t"><span class="str">                        [0.5, 0.1, 0.3, 0.1]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6100" href="#t6100">6100</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6101" href="#t6101">6101</a></span><span class="t"><span class="str">        input_length.data = [[4], [4]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6102" href="#t6102">6102</a></span><span class="t"><span class="str">        input.shape = [2, 4, 4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6103" href="#t6103">6103</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6104" href="#t6104">6104</a></span><span class="t"><span class="str">        step1: Apply argmax to first input sequence which is input.data[0:4]. Then we get:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6105" href="#t6105">6105</a></span><span class="t"><span class="str">               [[0], [2], [1], [0]], for input.data[4:8] is [[0], [3], [3], [0]], shape is [2,4,1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6106" href="#t6106">6106</a></span><span class="t"><span class="str">        step2: Change the argmax result to use padding mode, then argmax result is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6107" href="#t6107">6107</a></span><span class="t"><span class="str">                [[0, 2, 1, 0], [0, 3, 3, 0]], shape is [2, 4], lod is [], input_length is [[4], [4]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6108" href="#t6108">6108</a></span><span class="t"><span class="str">        step3: Apply ctc_align to padding argmax result, padding_value is 0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6109" href="#t6109">6109</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6110" href="#t6110">6110</a></span><span class="t"><span class="str">        Finally:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6111" href="#t6111">6111</a></span><span class="t"><span class="str">        output.data = [[2, 1, 0, 0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6112" href="#t6112">6112</a></span><span class="t"><span class="str">                       [3, 0, 0, 0]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6113" href="#t6113">6113</a></span><span class="t"><span class="str">        output_length.data = [[2], [1]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6114" href="#t6114">6114</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6115" href="#t6115">6115</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6116" href="#t6116">6116</a></span><span class="t"><span class="str">    Parameters:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6117" href="#t6117">6117</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6118" href="#t6118">6118</a></span><span class="t"><span class="str">        input(Variable): the probabilities of variable-length sequences. When in lod mode,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6119" href="#t6119">6119</a></span><span class="t"><span class="str">                         it is a 2-D LoDTensor with LoD information. It's shape is [Lp, num_classes + 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6120" href="#t6120">6120</a></span><span class="t"><span class="str">                         where Lp is the sum of all input sequences' length and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6121" href="#t6121">6121</a></span><span class="t"><span class="str">                         num_classes is the true number of classes. When in padding mode,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6122" href="#t6122">6122</a></span><span class="t"><span class="str">                         it is a 3-D Tensor with padding, It's shape is [batch_size, N, num_classes + 1].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6123" href="#t6123">6123</a></span><span class="t"><span class="str">                         (not including the blank label). The data type can be float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6124" href="#t6124">6124</a></span><span class="t"><span class="str">        blank(int): the blank label index of Connectionist Temporal</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6125" href="#t6125">6125</a></span><span class="t"><span class="str">                    Classification (CTC) loss, which is in the half-opened</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6126" href="#t6126">6126</a></span><span class="t"><span class="str">                    interval [0, num_classes + 1).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6127" href="#t6127">6127</a></span><span class="t"><span class="str">        input_length(Variable, optional): 2-D LoDTensor, shape is [batch_size, 1], data type is int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6128" href="#t6128">6128</a></span><span class="t"><span class="str">                                 It is used for padding mode. In lod mode, input_length is None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6129" href="#t6129">6129</a></span><span class="t"><span class="str">        padding_value(int): padding value.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6130" href="#t6130">6130</a></span><span class="t"><span class="str">        name(str, optional): The default value is None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6131" href="#t6131">6131</a></span><span class="t"><span class="str">                             Normally there is no need for user to set this property.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6132" href="#t6132">6132</a></span><span class="t"><span class="str">                             For more information, please refer to :ref:`api_guide_Name`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6133" href="#t6133">6133</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6134" href="#t6134">6134</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6135" href="#t6135">6135</a></span><span class="t"><span class="str">        For lod mode, returns the result of CTC greedy decoder, 2-D LoDTensor, shape is [Lp, 1], \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6136" href="#t6136">6136</a></span><span class="t"><span class="str">        data type is int64. 'Lp' is the sum of all output sequences' length. If all the sequences \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6137" href="#t6137">6137</a></span><span class="t"><span class="str">        in result were empty, the result LoDTensor will be [-1] with  empty \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6138" href="#t6138">6138</a></span><span class="t"><span class="str">        LoD [[]].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6139" href="#t6139">6139</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6140" href="#t6140">6140</a></span><span class="t"><span class="str">        For padding mode, returns a tuple of (output, output_length), which was described as below:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6141" href="#t6141">6141</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6142" href="#t6142">6142</a></span><span class="t"><span class="str">        output, 2-D Tensor, shape is [batch_size, N], data type is int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6143" href="#t6143">6143</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6144" href="#t6144">6144</a></span><span class="t"><span class="str">        output_length, 2-D Tensor, shape is [batch_size, 1], data type is int64. It is the length of \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6145" href="#t6145">6145</a></span><span class="t"><span class="str">                           each sequence of output for padding mode.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6146" href="#t6146">6146</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6147" href="#t6147">6147</a></span><span class="t"><span class="str">    Return type:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6148" href="#t6148">6148</a></span><span class="t"><span class="str">        For lod mode: Variable</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6149" href="#t6149">6149</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6150" href="#t6150">6150</a></span><span class="t"><span class="str">        For padding mode: tuple of two Variables (output, output_length).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6151" href="#t6151">6151</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6152" href="#t6152">6152</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6153" href="#t6153">6153</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6154" href="#t6154">6154</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6155" href="#t6155">6155</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6156" href="#t6156">6156</a></span><span class="t"><span class="str">            # for lod mode</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6157" href="#t6157">6157</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6158" href="#t6158">6158</a></span><span class="t"><span class="str">            x = fluid.data(name='x', shape=[None, 8], dtype='float32', lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6159" href="#t6159">6159</a></span><span class="t"><span class="str">            cost = fluid.layers.ctc_greedy_decoder(input=x, blank=0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6160" href="#t6160">6160</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6161" href="#t6161">6161</a></span><span class="t"><span class="str">            # for padding mode</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6162" href="#t6162">6162</a></span><span class="t"><span class="str">            x_pad = fluid.data(name='x_pad', shape=[10, 4, 8], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6163" href="#t6163">6163</a></span><span class="t"><span class="str">            x_pad_len = fluid.data(name='x_pad_len', shape=[10, 1], dtype='int64')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6164" href="#t6164">6164</a></span><span class="t"><span class="str">            out, out_len = fluid.layers.ctc_greedy_decoder(input=x_pad, blank=0,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6165" href="#t6165">6165</a></span><span class="t"><span class="str">                            input_length=x_pad_len)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6166" href="#t6166">6166</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6167" href="#t6167">6167</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6168" href="#t6168">6168</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6169" href="#t6169">6169</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'ctc_greedy_decoder'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6170" href="#t6170">6170</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6171" href="#t6171">6171</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6172" href="#t6172">6172</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"ctc_greedy_decoder"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6173" href="#t6173">6173</a></span><span class="t">    <span class="nam">_</span><span class="op">,</span> <span class="nam">topk_indices</span> <span class="op">=</span> <span class="nam">topk</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">k</span><span class="op">=</span><span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6174" href="#t6174">6174</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6175" href="#t6175">6175</a></span><span class="t">    <span class="com"># ctc align op</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6176" href="#t6176">6176</a></span><span class="t">    <span class="nam">ctc_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="str">"int64"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6177" href="#t6177">6177</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6178" href="#t6178">6178</a></span><span class="t">    <span class="key">if</span> <span class="nam">input_length</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6179" href="#t6179">6179</a></span><span class="t">        <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6180" href="#t6180">6180</a></span><span class="t">            <span class="nam">type</span><span class="op">=</span><span class="str">"ctc_align"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6181" href="#t6181">6181</a></span><span class="t">            <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Input"</span><span class="op">:</span> <span class="op">[</span><span class="nam">topk_indices</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6182" href="#t6182">6182</a></span><span class="t">            <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Output"</span><span class="op">:</span> <span class="op">[</span><span class="nam">ctc_out</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6183" href="#t6183">6183</a></span><span class="t">            <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">"merge_repeated"</span><span class="op">:</span> <span class="key">True</span><span class="op">,</span> <span class="str">"blank"</span><span class="op">:</span> <span class="nam">blank</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6184" href="#t6184">6184</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6185" href="#t6185">6185</a></span><span class="t">        <span class="key">return</span> <span class="nam">ctc_out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6186" href="#t6186">6186</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6187" href="#t6187">6187</a></span><span class="t">        <span class="nam">ctc_out_len</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="str">"int64"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6188" href="#t6188">6188</a></span><span class="t">        <span class="nam">ctc_input</span> <span class="op">=</span> <span class="nam">squeeze</span><span class="op">(</span><span class="nam">topk_indices</span><span class="op">,</span> <span class="op">[</span><span class="num">2</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6189" href="#t6189">6189</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6190" href="#t6190">6190</a></span><span class="t">        <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6191" href="#t6191">6191</a></span><span class="t">            <span class="nam">type</span><span class="op">=</span><span class="str">"ctc_align"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6192" href="#t6192">6192</a></span><span class="t">            <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Input"</span><span class="op">:</span> <span class="op">[</span><span class="nam">ctc_input</span><span class="op">]</span><span class="op">,</span> <span class="str">"InputLength"</span><span class="op">:</span> <span class="op">[</span><span class="nam">input_length</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6193" href="#t6193">6193</a></span><span class="t">            <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Output"</span><span class="op">:</span> <span class="op">[</span><span class="nam">ctc_out</span><span class="op">]</span><span class="op">,</span> <span class="str">"OutputLength"</span><span class="op">:</span> <span class="op">[</span><span class="nam">ctc_out_len</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6194" href="#t6194">6194</a></span><span class="t">            <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6195" href="#t6195">6195</a></span><span class="t">                <span class="str">"merge_repeated"</span><span class="op">:</span> <span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6196" href="#t6196">6196</a></span><span class="t">                <span class="str">"blank"</span><span class="op">:</span> <span class="nam">blank</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6197" href="#t6197">6197</a></span><span class="t">                <span class="str">"padding_value"</span><span class="op">:</span> <span class="nam">padding_value</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6198" href="#t6198">6198</a></span><span class="t">            <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6199" href="#t6199">6199</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6200" href="#t6200">6200</a></span><span class="t">        <span class="key">return</span> <span class="nam">ctc_out</span><span class="op">,</span> <span class="nam">ctc_out_len</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6201" href="#t6201">6201</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6202" href="#t6202">6202</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6203" href="#t6203">6203</a></span><span class="t"><span class="key">def</span> <span class="nam">transpose</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">perm</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6204" href="#t6204">6204</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6205" href="#t6205">6205</a></span><span class="t"><span class="str">    Permute the data dimensions of `input` according to `perm`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6206" href="#t6206">6206</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6207" href="#t6207">6207</a></span><span class="t"><span class="str">    The `i`-th dimension  of the returned tensor will correspond to the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6208" href="#t6208">6208</a></span><span class="t"><span class="str">    perm[i]-th dimension of `input`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6209" href="#t6209">6209</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6210" href="#t6210">6210</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6211" href="#t6211">6211</a></span><span class="t"><span class="str">        x (Tensor): The input Tensor. It is a N-D Tensor of data types bool, float32, float64, int32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6212" href="#t6212">6212</a></span><span class="t"><span class="str">        perm (list|tuple): Permute the input according to the data of perm.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6213" href="#t6213">6213</a></span><span class="t"><span class="str">        name (str): The name of this layer. It is optional.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6214" href="#t6214">6214</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6215" href="#t6215">6215</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6216" href="#t6216">6216</a></span><span class="t"><span class="str">        Tensor: A transposed n-D Tensor, with data type being bool, float32, float64, int32, int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6217" href="#t6217">6217</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6218" href="#t6218">6218</a></span><span class="t"><span class="str">    For Example:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6219" href="#t6219">6219</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6220" href="#t6220">6220</a></span><span class="t"><span class="str">        .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6221" href="#t6221">6221</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6222" href="#t6222">6222</a></span><span class="t"><span class="str">         x = [[[ 1  2  3  4] [ 5  6  7  8] [ 9 10 11 12]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6223" href="#t6223">6223</a></span><span class="t"><span class="str">             [[13 14 15 16] [17 18 19 20] [21 22 23 24]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6224" href="#t6224">6224</a></span><span class="t"><span class="str">         shape(x) =  [2,3,4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6225" href="#t6225">6225</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6226" href="#t6226">6226</a></span><span class="t"><span class="str">         # Example 1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6227" href="#t6227">6227</a></span><span class="t"><span class="str">         perm0 = [1,0,2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6228" href="#t6228">6228</a></span><span class="t"><span class="str">         y_perm0 = [[[ 1  2  3  4] [13 14 15 16]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6229" href="#t6229">6229</a></span><span class="t"><span class="str">                   [[ 5  6  7  8]  [17 18 19 20]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6230" href="#t6230">6230</a></span><span class="t"><span class="str">                   [[ 9 10 11 12]  [21 22 23 24]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6231" href="#t6231">6231</a></span><span class="t"><span class="str">         shape(y_perm0) = [3,2,4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6232" href="#t6232">6232</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6233" href="#t6233">6233</a></span><span class="t"><span class="str">         # Example 2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6234" href="#t6234">6234</a></span><span class="t"><span class="str">         perm1 = [2,1,0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6235" href="#t6235">6235</a></span><span class="t"><span class="str">         y_perm1 = [[[ 1 13] [ 5 17] [ 9 21]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6236" href="#t6236">6236</a></span><span class="t"><span class="str">                   [[ 2 14] [ 6 18] [10 22]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6237" href="#t6237">6237</a></span><span class="t"><span class="str">                   [[ 3 15]  [ 7 19]  [11 23]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6238" href="#t6238">6238</a></span><span class="t"><span class="str">                   [[ 4 16]  [ 8 20]  [12 24]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6239" href="#t6239">6239</a></span><span class="t"><span class="str">         shape(y_perm1) = [4,3,2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6240" href="#t6240">6240</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6241" href="#t6241">6241</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6242" href="#t6242">6242</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6243" href="#t6243">6243</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6244" href="#t6244">6244</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6245" href="#t6245">6245</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6246" href="#t6246">6246</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6247" href="#t6247">6247</a></span><span class="t"><span class="str">            x = paddle.randn([2, 3, 4])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6248" href="#t6248">6248</a></span><span class="t"><span class="str">            x_transposed = paddle.transpose(x, perm=[1, 0, 2])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6249" href="#t6249">6249</a></span><span class="t"><span class="str">            print(x_transposed.shape)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6250" href="#t6250">6250</a></span><span class="t"><span class="str">            # [3L, 2L, 4L]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6251" href="#t6251">6251</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6252" href="#t6252">6252</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t6253" href="#t6253">6253</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">6253&#x202F;&#x219B;&#x202F;6254</span><span class="annotate long">line 6253 didn't jump to line 6254, because the condition on line 6253 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6254" href="#t6254">6254</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">transpose</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">perm</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6255" href="#t6255">6255</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t6256" href="#t6256">6256</a></span><span class="t">        <span class="key">if</span> <span class="nam">_in_legacy_dygraph</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">6256&#x202F;&#x219B;&#x202F;6257</span><span class="annotate long">line 6256 didn't jump to line 6257, because the condition on line 6256 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6257" href="#t6257">6257</a></span><span class="t">            <span class="nam">out</span><span class="op">,</span> <span class="nam">_</span> <span class="op">=</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">transpose2</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'axis'</span><span class="op">,</span> <span class="nam">perm</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6258" href="#t6258">6258</a></span><span class="t">            <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6259" href="#t6259">6259</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6260" href="#t6260">6260</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6261" href="#t6261">6261</a></span><span class="t">        <span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6262" href="#t6262">6262</a></span><span class="t">        <span class="str">'x'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6263" href="#t6263">6263</a></span><span class="t">        <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6264" href="#t6264">6264</a></span><span class="t">            <span class="str">'bool'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6265" href="#t6265">6265</a></span><span class="t">            <span class="str">'float16'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6266" href="#t6266">6266</a></span><span class="t">            <span class="str">'float32'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6267" href="#t6267">6267</a></span><span class="t">            <span class="str">'float64'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6268" href="#t6268">6268</a></span><span class="t">            <span class="str">'int32'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6269" href="#t6269">6269</a></span><span class="t">            <span class="str">'int64'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6270" href="#t6270">6270</a></span><span class="t">            <span class="str">'complex64'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6271" href="#t6271">6271</a></span><span class="t">            <span class="str">'complex128'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6272" href="#t6272">6272</a></span><span class="t">        <span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6273" href="#t6273">6273</a></span><span class="t">        <span class="str">'transpose'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6274" href="#t6274">6274</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6275" href="#t6275">6275</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">perm</span><span class="op">,</span> <span class="str">'perm'</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">,</span> <span class="str">'transpose'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t6276" href="#t6276">6276</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">perm</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">6276&#x202F;&#x219B;&#x202F;6277</span><span class="annotate long">line 6276 didn't jump to line 6277, because the condition on line 6276 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6277" href="#t6277">6277</a></span><span class="t">        <span class="nam">perm</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="nam">perm</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6278" href="#t6278">6278</a></span><span class="t">    <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">perm</span><span class="op">)</span> <span class="op">!=</span> <span class="nam">len</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6279" href="#t6279">6279</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6280" href="#t6280">6280</a></span><span class="t">            <span class="str">"Input(perm) is the permutation of dimensions of Input(x), "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6281" href="#t6281">6281</a></span><span class="t">            <span class="str">"its length should be equal to dimensions of Input(x), "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6282" href="#t6282">6282</a></span><span class="t">            <span class="str">"but received dimension of Input(x) is %s, "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6283" href="#t6283">6283</a></span><span class="t">            <span class="str">"the length of Input(perm) is %s."</span> <span class="op">%</span> <span class="op">(</span><span class="nam">len</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span><span class="op">,</span> <span class="nam">len</span><span class="op">(</span><span class="nam">perm</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6284" href="#t6284">6284</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t6285" href="#t6285">6285</a></span><span class="t">    <span class="key">for</span> <span class="nam">idx</span><span class="op">,</span> <span class="nam">dim</span> <span class="key">in</span> <span class="nam">enumerate</span><span class="op">(</span><span class="nam">perm</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">6285&#x202F;&#x219B;&#x202F;6293</span><span class="annotate long">line 6285 didn't jump to line 6293, because the loop on line 6285 didn't complete</span></span></p>
    <p class="par run show_par"><span class="n"><a id="t6286" href="#t6286">6286</a></span><span class="t">        <span class="key">if</span> <span class="nam">dim</span> <span class="op">>=</span> <span class="nam">len</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">6286&#x202F;&#x219B;&#x202F;6285</span><span class="annotate long">line 6286 didn't jump to line 6285, because the condition on line 6286 was never false</span></span></p>
    <p class="run"><span class="n"><a id="t6287" href="#t6287">6287</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6288" href="#t6288">6288</a></span><span class="t">                <span class="str">"Each element in Input(perm) should be less than Input(x)'s dimension, "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6289" href="#t6289">6289</a></span><span class="t">                <span class="str">"but %d-th element in Input(perm) is %d which exceeds Input(x)'s "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6290" href="#t6290">6290</a></span><span class="t">                <span class="str">"dimension %d."</span> <span class="op">%</span> <span class="op">(</span><span class="nam">idx</span><span class="op">,</span> <span class="nam">perm</span><span class="op">[</span><span class="nam">idx</span><span class="op">]</span><span class="op">,</span> <span class="nam">len</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6291" href="#t6291">6291</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6292" href="#t6292">6292</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6293" href="#t6293">6293</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'transpose'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6294" href="#t6294">6294</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6295" href="#t6295">6295</a></span><span class="t">    <span class="nam">x_shape</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6296" href="#t6296">6296</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6297" href="#t6297">6297</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'transpose2'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6298" href="#t6298">6298</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="op">[</span><span class="nam">x</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6299" href="#t6299">6299</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="op">[</span><span class="nam">out</span><span class="op">]</span><span class="op">,</span> <span class="str">'XShape'</span><span class="op">:</span> <span class="op">[</span><span class="nam">x_shape</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6300" href="#t6300">6300</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'axis'</span><span class="op">:</span> <span class="nam">perm</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6301" href="#t6301">6301</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6302" href="#t6302">6302</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6303" href="#t6303">6303</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6304" href="#t6304">6304</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6305" href="#t6305">6305</a></span><span class="t"><span class="key">def</span> <span class="nam">im2sequence</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6306" href="#t6306">6306</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6307" href="#t6307">6307</a></span><span class="t">    <span class="nam">filter_size</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6308" href="#t6308">6308</a></span><span class="t">    <span class="nam">stride</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6309" href="#t6309">6309</a></span><span class="t">    <span class="nam">padding</span><span class="op">=</span><span class="num">0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6310" href="#t6310">6310</a></span><span class="t">    <span class="nam">input_image_size</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6311" href="#t6311">6311</a></span><span class="t">    <span class="nam">out_stride</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6312" href="#t6312">6312</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6313" href="#t6313">6313</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6314" href="#t6314">6314</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6315" href="#t6315">6315</a></span><span class="t"><span class="str">    :api_attr: Static Graph</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6316" href="#t6316">6316</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6317" href="#t6317">6317</a></span><span class="t"><span class="str">    Extracts image patches from the input tensor to form a tensor of shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6318" href="#t6318">6318</a></span><span class="t"><span class="str">    {input.batch_size * output_height * output_width, filter_size_height *</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6319" href="#t6319">6319</a></span><span class="t"><span class="str">    filter_size_width * input.channels}. This op use filter to scan images</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6320" href="#t6320">6320</a></span><span class="t"><span class="str">    and convert these images to sequences. After expanding, the number of time step are</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6321" href="#t6321">6321</a></span><span class="t"><span class="str">    output_height * output_width for an image, in which output_height and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6322" href="#t6322">6322</a></span><span class="t"><span class="str">    output_width are calculated by below equation:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6323" href="#t6323">6323</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6324" href="#t6324">6324</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6325" href="#t6325">6325</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6326" href="#t6326">6326</a></span><span class="t"><span class="str">        output\_height  = 1 + \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6327" href="#t6327">6327</a></span><span class="t"><span class="str">            (padding\_up + padding\_down + input\_height  - filter\_size\_height  + stride\_height - 1) / stride\_height \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6328" href="#t6328">6328</a></span><span class="t"><span class="str">        output\_width  = 1 + \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6329" href="#t6329">6329</a></span><span class="t"><span class="str">            (padding\_left + padding\_right + input\_width  - filter\_size\_width  + stride\_width - 1) / stride\_width</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6330" href="#t6330">6330</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6331" href="#t6331">6331</a></span><span class="t"><span class="str">    And the dimension of each time step is filter_size_height * filter_size_width * input.channels.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6332" href="#t6332">6332</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6333" href="#t6333">6333</a></span><span class="t"><span class="str">    Parameters:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6334" href="#t6334">6334</a></span><span class="t"><span class="str">        input (Variable): The input should be a 4-D Tensor in :math:`NCHW` format. The data type is float32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6335" href="#t6335">6335</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6336" href="#t6336">6336</a></span><span class="t"><span class="str">        filter_size(int32 | List[int32]): The filter size. If filter_size is a List,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6337" href="#t6337">6337</a></span><span class="t"><span class="str">            it must contain two integers, :math:`[filter\_size\_height, filter\_size\_width]` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6338" href="#t6338">6338</a></span><span class="t"><span class="str">            Otherwise, the filter size will be a square :math:`[filter\_size, filter\_size]` . Default is 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6339" href="#t6339">6339</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6340" href="#t6340">6340</a></span><span class="t"><span class="str">        stride(int32 | List[int32]): The stride size. If stride is a List, it must</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6341" href="#t6341">6341</a></span><span class="t"><span class="str">            contain two integers, :math:`[stride\_height, stride\_width]` . Otherwise, the stride size will be a square :math:`[stride\_size, stride\_size]` . Default is 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6342" href="#t6342">6342</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6343" href="#t6343">6343</a></span><span class="t"><span class="str">        padding(int32 | List[int32]): The padding size. If padding is a List, it can</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6344" href="#t6344">6344</a></span><span class="t"><span class="str">            contain four integers like :math:`[padding\_up, padding\_left, padding\_down, padding\_right]` to indicate</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6345" href="#t6345">6345</a></span><span class="t"><span class="str">            paddings of four direction.  Or it can contain two integers :math:`[padding\_height, padding\_width]` which means</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6346" href="#t6346">6346</a></span><span class="t"><span class="str">            padding_up = padding_down = padding_height and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6347" href="#t6347">6347</a></span><span class="t"><span class="str">            padding_left = padding_right = padding_width. Otherwise, a scalar padding means</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6348" href="#t6348">6348</a></span><span class="t"><span class="str">            padding_up = padding_down = padding_left = padding_right = padding.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6349" href="#t6349">6349</a></span><span class="t"><span class="str">            Default is 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6350" href="#t6350">6350</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6351" href="#t6351">6351</a></span><span class="t"><span class="str">        input_image_size(Variable, optional): the input contains image real size.It's dim</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6352" href="#t6352">6352</a></span><span class="t"><span class="str">            is :math:`[batchsize, 2]` . It is just for batch inference when not None. Default is None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6353" href="#t6353">6353</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6354" href="#t6354">6354</a></span><span class="t"><span class="str">        out_stride(int32 | List[int32]): The scaling of image through CNN. It is valid only when input_image_size is not None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6355" href="#t6355">6355</a></span><span class="t"><span class="str">            If out_stride is List,  it must contain two integers,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6356" href="#t6356">6356</a></span><span class="t"><span class="str">            :math:`[out\_stride\_height, out\_stride\_W]` . Otherwise,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6357" href="#t6357">6357</a></span><span class="t"><span class="str">            the out_stride_height = out_stride_width = out_stride. Default is 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6358" href="#t6358">6358</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6359" href="#t6359">6359</a></span><span class="t"><span class="str">        name (str, optional): The default value is None.  Normally there is no need for</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6360" href="#t6360">6360</a></span><span class="t"><span class="str">                    user to set this property.  For more information, please refer to :ref:`api_guide_Name` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6361" href="#t6361">6361</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6362" href="#t6362">6362</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6363" href="#t6363">6363</a></span><span class="t"><span class="str">            The output is a 2-D LoDTensor with shape {input.batch\_size * output\_height * output\_width, \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6364" href="#t6364">6364</a></span><span class="t"><span class="str">            filter\_size\_height * filter\_size\_width * input.channels}. The data type is float32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6365" href="#t6365">6365</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6366" href="#t6366">6366</a></span><span class="t"><span class="str">    Return Type: Variable</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6367" href="#t6367">6367</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6368" href="#t6368">6368</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6369" href="#t6369">6369</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6370" href="#t6370">6370</a></span><span class="t"><span class="str">        .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6371" href="#t6371">6371</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6372" href="#t6372">6372</a></span><span class="t"><span class="str">            Given:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6373" href="#t6373">6373</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6374" href="#t6374">6374</a></span><span class="t"><span class="str">            x = [[[[ 6.  2.  1.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6375" href="#t6375">6375</a></span><span class="t"><span class="str">                   [ 8.  3.  5.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6376" href="#t6376">6376</a></span><span class="t"><span class="str">                   [ 0.  2.  6.]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6377" href="#t6377">6377</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6378" href="#t6378">6378</a></span><span class="t"><span class="str">                  [[ 2.  4.  4.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6379" href="#t6379">6379</a></span><span class="t"><span class="str">                   [ 6.  3.  0.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6380" href="#t6380">6380</a></span><span class="t"><span class="str">                   [ 6.  4.  7.]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6381" href="#t6381">6381</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6382" href="#t6382">6382</a></span><span class="t"><span class="str">                 [[[ 6.  7.  1.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6383" href="#t6383">6383</a></span><span class="t"><span class="str">                   [ 5.  7.  9.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6384" href="#t6384">6384</a></span><span class="t"><span class="str">                   [ 2.  4.  8.]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6385" href="#t6385">6385</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6386" href="#t6386">6386</a></span><span class="t"><span class="str">                  [[ 1.  2.  1.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6387" href="#t6387">6387</a></span><span class="t"><span class="str">                   [ 1.  3.  5.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6388" href="#t6388">6388</a></span><span class="t"><span class="str">                   [ 9.  0.  8.]]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6389" href="#t6389">6389</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6390" href="#t6390">6390</a></span><span class="t"><span class="str">            x.dims = {2, 2, 3, 3}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6391" href="#t6391">6391</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6392" href="#t6392">6392</a></span><span class="t"><span class="str">            And:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6393" href="#t6393">6393</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6394" href="#t6394">6394</a></span><span class="t"><span class="str">            filter = [2, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6395" href="#t6395">6395</a></span><span class="t"><span class="str">            stride = [1, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6396" href="#t6396">6396</a></span><span class="t"><span class="str">            padding = [0, 0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6397" href="#t6397">6397</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6398" href="#t6398">6398</a></span><span class="t"><span class="str">            Then:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6399" href="#t6399">6399</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6400" href="#t6400">6400</a></span><span class="t"><span class="str">            output.data = [[ 6.  2.  8.  3.  2.  4.  6.  3.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6401" href="#t6401">6401</a></span><span class="t"><span class="str">                           [ 2.  1.  3.  5.  4.  4.  3.  0.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6402" href="#t6402">6402</a></span><span class="t"><span class="str">                           [ 8.  3.  0.  2.  6.  3.  6.  4.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6403" href="#t6403">6403</a></span><span class="t"><span class="str">                           [ 3.  5.  2.  6.  3.  0.  4.  7.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6404" href="#t6404">6404</a></span><span class="t"><span class="str">                           [ 6.  7.  5.  7.  1.  2.  1.  3.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6405" href="#t6405">6405</a></span><span class="t"><span class="str">                           [ 7.  1.  7.  9.  2.  1.  3.  5.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6406" href="#t6406">6406</a></span><span class="t"><span class="str">                           [ 5.  7.  2.  4.  1.  3.  9.  0.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6407" href="#t6407">6407</a></span><span class="t"><span class="str">                           [ 7.  9.  4.  8.  3.  5.  0.  8.]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6408" href="#t6408">6408</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6409" href="#t6409">6409</a></span><span class="t"><span class="str">            output.dims = {8, 8}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6410" href="#t6410">6410</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6411" href="#t6411">6411</a></span><span class="t"><span class="str">            output.lod = [[4, 4]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6412" href="#t6412">6412</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6413" href="#t6413">6413</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6414" href="#t6414">6414</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6415" href="#t6415">6415</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6416" href="#t6416">6416</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6417" href="#t6417">6417</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6418" href="#t6418">6418</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6419" href="#t6419">6419</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6420" href="#t6420">6420</a></span><span class="t"><span class="str">            data = fluid.data(name='data', shape=[None, 3, 32, 32],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6421" href="#t6421">6421</a></span><span class="t"><span class="str">                                     dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6422" href="#t6422">6422</a></span><span class="t"><span class="str">            output = fluid.layers.im2sequence(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6423" href="#t6423">6423</a></span><span class="t"><span class="str">                input=data, stride=[1, 1], filter_size=[2, 2])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6424" href="#t6424">6424</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6425" href="#t6425">6425</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6426" href="#t6426">6426</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6427" href="#t6427">6427</a></span><span class="t">    <span class="key">assert</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6428" href="#t6428">6428</a></span><span class="t">        <span class="key">not</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6429" href="#t6429">6429</a></span><span class="t">    <span class="op">)</span><span class="op">,</span> <span class="str">"sequence layer is not supported in dygraph mode yet."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6430" href="#t6430">6430</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6431" href="#t6431">6431</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">]</span><span class="op">,</span> <span class="str">'im2sequence'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6432" href="#t6432">6432</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6433" href="#t6433">6433</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">filter_size</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6434" href="#t6434">6434</a></span><span class="t">        <span class="nam">filter_size</span> <span class="op">=</span> <span class="op">[</span><span class="nam">filter_size</span><span class="op">,</span> <span class="nam">filter_size</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6435" href="#t6435">6435</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">stride</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6436" href="#t6436">6436</a></span><span class="t">        <span class="nam">stride</span> <span class="op">=</span> <span class="op">[</span><span class="nam">stride</span><span class="op">,</span> <span class="nam">stride</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6437" href="#t6437">6437</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6438" href="#t6438">6438</a></span><span class="t">        <span class="nam">padding</span> <span class="op">=</span> <span class="op">[</span><span class="nam">padding</span><span class="op">,</span> <span class="nam">padding</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6439" href="#t6439">6439</a></span><span class="t">    <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">padding</span><span class="op">)</span> <span class="op">==</span> <span class="num">2</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6440" href="#t6440">6440</a></span><span class="t">        <span class="nam">padding</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6441" href="#t6441">6441</a></span><span class="t">        <span class="nam">padding</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">padding</span><span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6442" href="#t6442">6442</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6443" href="#t6443">6443</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="str">"kernels"</span><span class="op">:</span> <span class="nam">filter_size</span><span class="op">,</span> <span class="str">"strides"</span><span class="op">:</span> <span class="nam">stride</span><span class="op">,</span> <span class="str">"paddings"</span><span class="op">:</span> <span class="nam">padding</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6444" href="#t6444">6444</a></span><span class="t">    <span class="key">if</span> <span class="nam">input_image_size</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6445" href="#t6445">6445</a></span><span class="t">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">out_stride</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6446" href="#t6446">6446</a></span><span class="t">            <span class="nam">out_stride</span> <span class="op">=</span> <span class="op">[</span><span class="nam">out_stride</span><span class="op">,</span> <span class="nam">out_stride</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6447" href="#t6447">6447</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">"Y"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">input_image_size</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6448" href="#t6448">6448</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">"out_stride"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">out_stride</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6449" href="#t6449">6449</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'im2sequence'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6450" href="#t6450">6450</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6451" href="#t6451">6451</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6452" href="#t6452">6452</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'im2sequence'</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span> <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6453" href="#t6453">6453</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6454" href="#t6454">6454</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6455" href="#t6455">6455</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6456" href="#t6456">6456</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6457" href="#t6457">6457</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6458" href="#t6458">6458</a></span><span class="t"><span class="key">def</span> <span class="nam">row_conv</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">future_context_size</span><span class="op">,</span> <span class="nam">param_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6459" href="#t6459">6459</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6460" href="#t6460">6460</a></span><span class="t"><span class="str">    :api_attr: Static Graph</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6461" href="#t6461">6461</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6462" href="#t6462">6462</a></span><span class="t"><span class="str">    ${comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6463" href="#t6463">6463</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6464" href="#t6464">6464</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6465" href="#t6465">6465</a></span><span class="t"><span class="str">        input (${x_type}): ${x_comment}.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6466" href="#t6466">6466</a></span><span class="t"><span class="str">        future_context_size (int): Future context size. Please note, the shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6467" href="#t6467">6467</a></span><span class="t"><span class="str">            of convolution kernel is [future_context_size + 1, D].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6468" href="#t6468">6468</a></span><span class="t"><span class="str">        param_attr (ParamAttr): Attributes of parameters, including</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6469" href="#t6469">6469</a></span><span class="t"><span class="str">            name, initializer etc.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6470" href="#t6470">6470</a></span><span class="t"><span class="str">        act (str): Non-linear activation to be applied to output variable.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6471" href="#t6471">6471</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6472" href="#t6472">6472</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6473" href="#t6473">6473</a></span><span class="t"><span class="str">        ${out_comment}.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6474" href="#t6474">6474</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6475" href="#t6475">6475</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6476" href="#t6476">6476</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6477" href="#t6477">6477</a></span><span class="t"><span class="str">      .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6478" href="#t6478">6478</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6479" href="#t6479">6479</a></span><span class="t"><span class="str">        # for LodTensor inputs</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6480" href="#t6480">6480</a></span><span class="t"><span class="str">        import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6481" href="#t6481">6481</a></span><span class="t"><span class="str">        paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6482" href="#t6482">6482</a></span><span class="t"><span class="str">        x = paddle.static.data(name='x', shape=[9, 16],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6483" href="#t6483">6483</a></span><span class="t"><span class="str">                               dtype='float32', lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6484" href="#t6484">6484</a></span><span class="t"><span class="str">        out = paddle.static.nn.row_conv(input=x, future_context_size=2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6485" href="#t6485">6485</a></span><span class="t"><span class="str">        # for Tensor inputs</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6486" href="#t6486">6486</a></span><span class="t"><span class="str">        x = paddle.static.data(name='x', shape=[9, 4, 16], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6487" href="#t6487">6487</a></span><span class="t"><span class="str">        out = paddle.static.nn.row_conv(input=x, future_context_size=2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6488" href="#t6488">6488</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6489" href="#t6489">6489</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'row_conv'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6490" href="#t6490">6490</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">]</span><span class="op">,</span> <span class="str">'row_conv'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6491" href="#t6491">6491</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6492" href="#t6492">6492</a></span><span class="t">    <span class="nam">filter_shape</span> <span class="op">=</span> <span class="op">[</span><span class="nam">future_context_size</span> <span class="op">+</span> <span class="num">1</span><span class="op">,</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6493" href="#t6493">6493</a></span><span class="t">    <span class="nam">filter_param</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6494" href="#t6494">6494</a></span><span class="t">        <span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">param_attr</span><span class="op">,</span> <span class="nam">shape</span><span class="op">=</span><span class="nam">filter_shape</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6495" href="#t6495">6495</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6496" href="#t6496">6496</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6497" href="#t6497">6497</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6498" href="#t6498">6498</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'row_conv'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6499" href="#t6499">6499</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="op">[</span><span class="nam">input</span><span class="op">]</span><span class="op">,</span> <span class="str">'Filter'</span><span class="op">:</span> <span class="op">[</span><span class="nam">filter_param</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6500" href="#t6500">6500</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="op">[</span><span class="nam">out</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6501" href="#t6501">6501</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6502" href="#t6502">6502</a></span><span class="t">    <span class="key">return</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_activation</span><span class="op">(</span><span class="nam">out</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6503" href="#t6503">6503</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6504" href="#t6504">6504</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6505" href="#t6505">6505</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6506" href="#t6506">6506</a></span><span class="t"><span class="key">def</span> <span class="nam">multiplex</span><span class="op">(</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">index</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6507" href="#t6507">6507</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6508" href="#t6508">6508</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6509" href="#t6509">6509</a></span><span class="t"><span class="str">    Based on the given index parameter, the OP selects a specific row from each input Tensor to construct the output Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6510" href="#t6510">6510</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6511" href="#t6511">6511</a></span><span class="t"><span class="str">    If the input of this OP contains :math:`m` Tensors, where :math:`I_{i}` means the i-th input Tensor, :math:`i` between :math:`[0,m)` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6512" href="#t6512">6512</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6513" href="#t6513">6513</a></span><span class="t"><span class="str">    And :math:`O` means the output, where :math:`O[i]` means the i-th row of the output, then the output satisfies that :math:`O[i] = I_{index[i]}[i]` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6514" href="#t6514">6514</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6515" href="#t6515">6515</a></span><span class="t"><span class="str">    For Example:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6516" href="#t6516">6516</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6517" href="#t6517">6517</a></span><span class="t"><span class="str">            .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6518" href="#t6518">6518</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6519" href="#t6519">6519</a></span><span class="t"><span class="str">                Given:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6520" href="#t6520">6520</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6521" href="#t6521">6521</a></span><span class="t"><span class="str">                inputs = [[[0,0,3,4], [0,1,3,4], [0,2,4,4], [0,3,3,4]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6522" href="#t6522">6522</a></span><span class="t"><span class="str">                          [[1,0,3,4], [1,1,7,8], [1,2,4,2], [1,3,3,4]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6523" href="#t6523">6523</a></span><span class="t"><span class="str">                          [[2,0,3,4], [2,1,7,8], [2,2,4,2], [2,3,3,4]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6524" href="#t6524">6524</a></span><span class="t"><span class="str">                          [[3,0,3,4], [3,1,7,8], [3,2,4,2], [3,3,3,4]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6525" href="#t6525">6525</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6526" href="#t6526">6526</a></span><span class="t"><span class="str">                index = [[3],[0],[1],[2]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6527" href="#t6527">6527</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6528" href="#t6528">6528</a></span><span class="t"><span class="str">                out = [[3,0,3,4],    # out[0] = inputs[index[0]][0] = inputs[3][0] = [3,0,3,4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6529" href="#t6529">6529</a></span><span class="t"><span class="str">                       [0,1,3,4],    # out[1] = inputs[index[1]][1] = inputs[0][1] = [0,1,3,4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6530" href="#t6530">6530</a></span><span class="t"><span class="str">                       [1,2,4,2],    # out[2] = inputs[index[2]][2] = inputs[1][2] = [1,2,4,2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6531" href="#t6531">6531</a></span><span class="t"><span class="str">                       [2,3,3,4]]    # out[3] = inputs[index[3]][3] = inputs[2][3] = [2,3,3,4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6532" href="#t6532">6532</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6533" href="#t6533">6533</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6534" href="#t6534">6534</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6535" href="#t6535">6535</a></span><span class="t"><span class="str">        inputs (list): The input Tensor list. The list elements are N-D Tensors of data types float32, float64, int32, int64. All input Tensor shapes should be the same and rank must be at least 2.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6536" href="#t6536">6536</a></span><span class="t"><span class="str">        index (Tensor): Used to select some rows in the input Tensor to construct an index of the output Tensor. It is a 2-D Tensor with data type int32 or int64 and shape [M, 1], where M is the number of input Tensors.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6537" href="#t6537">6537</a></span><span class="t"><span class="str">        name(str, optional): The default value is None. Normally there is no</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6538" href="#t6538">6538</a></span><span class="t"><span class="str">            need for user to set this property. For more information, please</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6539" href="#t6539">6539</a></span><span class="t"><span class="str">            refer to :ref:`api_guide_Name`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6540" href="#t6540">6540</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6541" href="#t6541">6541</a></span><span class="t"><span class="str">        Tensor: Output of multiplex OP, with data type being float32, float64, int32, int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6542" href="#t6542">6542</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6543" href="#t6543">6543</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6544" href="#t6544">6544</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6545" href="#t6545">6545</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6546" href="#t6546">6546</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6547" href="#t6547">6547</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6548" href="#t6548">6548</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6549" href="#t6549">6549</a></span><span class="t"><span class="str">            img1 = np.array([[1, 2], [3, 4]]).astype(np.float32)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6550" href="#t6550">6550</a></span><span class="t"><span class="str">            img2 = np.array([[5, 6], [7, 8]]).astype(np.float32)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6551" href="#t6551">6551</a></span><span class="t"><span class="str">            inputs = [paddle.to_tensor(img1), paddle.to_tensor(img2)]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6552" href="#t6552">6552</a></span><span class="t"><span class="str">            index = paddle.to_tensor(np.array([[1], [0]]).astype(np.int32))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6553" href="#t6553">6553</a></span><span class="t"><span class="str">            res = paddle.multiplex(inputs, index)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6554" href="#t6554">6554</a></span><span class="t"><span class="str">            print(res) # [array([[5., 6.], [3., 4.]], dtype=float32)]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6555" href="#t6555">6555</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6556" href="#t6556">6556</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6557" href="#t6557">6557</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6558" href="#t6558">6558</a></span><span class="t">    <span class="key">if</span> <span class="nam">_in_legacy_dygraph</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6559" href="#t6559">6559</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">multiplex</span><span class="op">(</span><span class="nam">index</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6560" href="#t6560">6560</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6561" href="#t6561">6561</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">multiplex</span><span class="op">(</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">index</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6562" href="#t6562">6562</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'multiplex'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6563" href="#t6563">6563</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6564" href="#t6564">6564</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">inputs</span><span class="op">,</span> <span class="str">'inputs'</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">)</span><span class="op">,</span> <span class="str">'multiplex'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6565" href="#t6565">6565</a></span><span class="t">    <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">inputs</span><span class="op">)</span> <span class="op">&lt;</span> <span class="num">2</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6566" href="#t6566">6566</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6567" href="#t6567">6567</a></span><span class="t">            <span class="str">"inputs should be a list object with at least 2 elements."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6568" href="#t6568">6568</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6569" href="#t6569">6569</a></span><span class="t">    <span class="key">for</span> <span class="nam">id</span><span class="op">,</span> <span class="nam">x</span> <span class="key">in</span> <span class="nam">enumerate</span><span class="op">(</span><span class="nam">inputs</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6570" href="#t6570">6570</a></span><span class="t">        <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6571" href="#t6571">6571</a></span><span class="t">            <span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6572" href="#t6572">6572</a></span><span class="t">            <span class="str">'input['</span> <span class="op">+</span> <span class="nam">str</span><span class="op">(</span><span class="nam">id</span><span class="op">)</span> <span class="op">+</span> <span class="str">']'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6573" href="#t6573">6573</a></span><span class="t">            <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6574" href="#t6574">6574</a></span><span class="t">            <span class="str">'multiplex'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6575" href="#t6575">6575</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6576" href="#t6576">6576</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">index</span><span class="op">,</span> <span class="str">"index"</span><span class="op">,</span> <span class="op">[</span><span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'multiplex'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6577" href="#t6577">6577</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6578" href="#t6578">6578</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">inputs</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6579" href="#t6579">6579</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6580" href="#t6580">6580</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'multiplex'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6581" href="#t6581">6581</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">inputs</span><span class="op">,</span> <span class="str">'Ids'</span><span class="op">:</span> <span class="nam">index</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6582" href="#t6582">6582</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="op">[</span><span class="nam">out</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6583" href="#t6583">6583</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6584" href="#t6584">6584</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6585" href="#t6585">6585</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6586" href="#t6586">6586</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6587" href="#t6587">6587</a></span><span class="t"><span class="key">def</span> <span class="nam">smooth_l1</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">inside_weight</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">outside_weight</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">sigma</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6588" href="#t6588">6588</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6589" href="#t6589">6589</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6590" href="#t6590">6590</a></span><span class="t"><span class="str">    This layer computes the smooth L1 loss for Variable :attr:`x` and :attr:`y`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6591" href="#t6591">6591</a></span><span class="t"><span class="str">    It takes the first dimension of :attr:`x` and :attr:`y` as batch size.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6592" href="#t6592">6592</a></span><span class="t"><span class="str">    For each instance, it computes the smooth L1 loss element by element first</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6593" href="#t6593">6593</a></span><span class="t"><span class="str">    and then sums all the losses. So the shape of output Variable is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6594" href="#t6594">6594</a></span><span class="t"><span class="str">    [batch_size, 1].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6595" href="#t6595">6595</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6596" href="#t6596">6596</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6597" href="#t6597">6597</a></span><span class="t"><span class="str">        x (Variable): A tensor with rank at least 2. The input value of smooth</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6598" href="#t6598">6598</a></span><span class="t"><span class="str">            L1 loss op with shape [batch_size, dim1, ..., dimN].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6599" href="#t6599">6599</a></span><span class="t"><span class="str">            A LoDTensor or Tensor with type float32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6600" href="#t6600">6600</a></span><span class="t"><span class="str">        y (Variable): A tensor with rank at least 2. The target value of smooth</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6601" href="#t6601">6601</a></span><span class="t"><span class="str">            L1 loss op with same shape as :attr:`x`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6602" href="#t6602">6602</a></span><span class="t"><span class="str">            A LoDTensor or Tensor with type float32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6603" href="#t6603">6603</a></span><span class="t"><span class="str">        inside_weight (Variable|None):  A tensor with rank at least 2. This</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6604" href="#t6604">6604</a></span><span class="t"><span class="str">            input is optional and should have same shape with :attr:`x`. If</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6605" href="#t6605">6605</a></span><span class="t"><span class="str">            provided, the result of (:attr:`x` - :attr:`y`) will be multiplied</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6606" href="#t6606">6606</a></span><span class="t"><span class="str">            by this tensor element by element.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6607" href="#t6607">6607</a></span><span class="t"><span class="str">            A Tensor with type float32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6608" href="#t6608">6608</a></span><span class="t"><span class="str">        outside_weight (Variable|None): A tensor with rank at least 2. This</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6609" href="#t6609">6609</a></span><span class="t"><span class="str">            input is optional and should have same shape with :attr:`x`. If</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6610" href="#t6610">6610</a></span><span class="t"><span class="str">            provided, the out smooth L1 loss will be multiplied by this tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6611" href="#t6611">6611</a></span><span class="t"><span class="str">            element by element.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6612" href="#t6612">6612</a></span><span class="t"><span class="str">            A Tensor with type float32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6613" href="#t6613">6613</a></span><span class="t"><span class="str">        sigma (float|None): Hyper parameter of smooth L1 loss layer. A float</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6614" href="#t6614">6614</a></span><span class="t"><span class="str">           scalar with default value 1.0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6615" href="#t6615">6615</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6616" href="#t6616">6616</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6617" href="#t6617">6617</a></span><span class="t"><span class="str">        Variable: The output smooth L1 loss with shape [batch_size, 1].  A Tensor with type float32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6618" href="#t6618">6618</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6619" href="#t6619">6619</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6620" href="#t6620">6620</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6621" href="#t6621">6621</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6622" href="#t6622">6622</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6623" href="#t6623">6623</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6624" href="#t6624">6624</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6625" href="#t6625">6625</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6626" href="#t6626">6626</a></span><span class="t"><span class="str">            data = fluid.data(name="x", shape=[-1, 3], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6627" href="#t6627">6627</a></span><span class="t"><span class="str">            label = fluid.data(name="y", shape=[-1, 3], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6628" href="#t6628">6628</a></span><span class="t"><span class="str">            result = fluid.layers.smooth_l1(data,label)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6629" href="#t6629">6629</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6630" href="#t6630">6630</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6631" href="#t6631">6631</a></span><span class="t"><span class="str">            exe.run(fluid.default_startup_program())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6632" href="#t6632">6632</a></span><span class="t"><span class="str">            x = np.random.rand(3,3).astype("float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6633" href="#t6633">6633</a></span><span class="t"><span class="str">            y = np.random.rand(3,3).astype("float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6634" href="#t6634">6634</a></span><span class="t"><span class="str">            output= exe.run(feed={"x":x, "y":y},</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6635" href="#t6635">6635</a></span><span class="t"><span class="str">                             fetch_list=[result])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6636" href="#t6636">6636</a></span><span class="t"><span class="str">            print(output)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6637" href="#t6637">6637</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6638" href="#t6638">6638</a></span><span class="t"><span class="str">            #[array([[0.08220536],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6639" href="#t6639">6639</a></span><span class="t"><span class="str">            #       [0.36652038],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6640" href="#t6640">6640</a></span><span class="t"><span class="str">            #      [0.20541131]], dtype=float32)]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6641" href="#t6641">6641</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6642" href="#t6642">6642</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6643" href="#t6643">6643</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'X'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'smooth_l1_loss'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6644" href="#t6644">6644</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">y</span><span class="op">,</span> <span class="str">'Y'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'smooth_l1_loss'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6645" href="#t6645">6645</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6646" href="#t6646">6646</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'smooth_l1_loss'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6647" href="#t6647">6647</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6648" href="#t6648">6648</a></span><span class="t">    <span class="nam">diff</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6649" href="#t6649">6649</a></span><span class="t">    <span class="nam">loss</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6650" href="#t6650">6650</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6651" href="#t6651">6651</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'smooth_l1_loss'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6652" href="#t6652">6652</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6653" href="#t6653">6653</a></span><span class="t">            <span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6654" href="#t6654">6654</a></span><span class="t">            <span class="str">'Y'</span><span class="op">:</span> <span class="nam">y</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6655" href="#t6655">6655</a></span><span class="t">            <span class="str">'InsideWeight'</span><span class="op">:</span> <span class="nam">inside_weight</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6656" href="#t6656">6656</a></span><span class="t">            <span class="str">'OutsideWeight'</span><span class="op">:</span> <span class="nam">outside_weight</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6657" href="#t6657">6657</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6658" href="#t6658">6658</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Diff'</span><span class="op">:</span> <span class="nam">diff</span><span class="op">,</span> <span class="str">'Out'</span><span class="op">:</span> <span class="nam">loss</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6659" href="#t6659">6659</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'sigma'</span><span class="op">:</span> <span class="nam">sigma</span> <span class="key">if</span> <span class="nam">sigma</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span> <span class="key">else</span> <span class="num">1.0</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6660" href="#t6660">6660</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6661" href="#t6661">6661</a></span><span class="t">    <span class="key">return</span> <span class="nam">loss</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6662" href="#t6662">6662</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6663" href="#t6663">6663</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6664" href="#t6664">6664</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">'2.0.0'</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">'paddle.nn.functional.one_hot'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6665" href="#t6665">6665</a></span><span class="t"><span class="key">def</span> <span class="nam">one_hot</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">depth</span><span class="op">,</span> <span class="nam">allow_out_of_range</span><span class="op">=</span><span class="key">False</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6666" href="#t6666">6666</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6667" href="#t6667">6667</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6668" href="#t6668">6668</a></span><span class="t"><span class="str">    **WARING:** This OP requires the last dimension of Tensor shape must be equal to 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6669" href="#t6669">6669</a></span><span class="t"><span class="str">    This OP will be deprecated in a future release. It is recommended to use fluid. :ref:`api_fluid_one_hot` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6670" href="#t6670">6670</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6671" href="#t6671">6671</a></span><span class="t"><span class="str">    The operator converts each id in the input to an one-hot vector with a</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6672" href="#t6672">6672</a></span><span class="t"><span class="str">    :attr:`depth` length. The value in the vector dimension corresponding to the id</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6673" href="#t6673">6673</a></span><span class="t"><span class="str">    is 1, and the value in the remaining dimension is 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6674" href="#t6674">6674</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6675" href="#t6675">6675</a></span><span class="t"><span class="str">    The shape of output Tensor or LoDTensor is generated by adding :attr:`depth` dimension</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6676" href="#t6676">6676</a></span><span class="t"><span class="str">    behind the last dimension of the input shape.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6677" href="#t6677">6677</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6678" href="#t6678">6678</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6679" href="#t6679">6679</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6680" href="#t6680">6680</a></span><span class="t"><span class="str">        Example 1 (allow_out_of_range=False):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6681" href="#t6681">6681</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6682" href="#t6682">6682</a></span><span class="t"><span class="str">        input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6683" href="#t6683">6683</a></span><span class="t"><span class="str">            X.shape = [4, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6684" href="#t6684">6684</a></span><span class="t"><span class="str">            X.data = [[1], [1], [3], [0]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6685" href="#t6685">6685</a></span><span class="t"><span class="str">            depth = 4</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6686" href="#t6686">6686</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6687" href="#t6687">6687</a></span><span class="t"><span class="str">        output:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6688" href="#t6688">6688</a></span><span class="t"><span class="str">            Out.shape = [4, 4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6689" href="#t6689">6689</a></span><span class="t"><span class="str">            Out.data = [[0., 1., 0., 0.],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6690" href="#t6690">6690</a></span><span class="t"><span class="str">                        [0., 1., 0., 0.],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6691" href="#t6691">6691</a></span><span class="t"><span class="str">                        [0., 0., 0., 1.],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6692" href="#t6692">6692</a></span><span class="t"><span class="str">                        [1., 0., 0., 0.]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6693" href="#t6693">6693</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6694" href="#t6694">6694</a></span><span class="t"><span class="str">        Example 2 (allow_out_of_range=True):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6695" href="#t6695">6695</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6696" href="#t6696">6696</a></span><span class="t"><span class="str">        input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6697" href="#t6697">6697</a></span><span class="t"><span class="str">            X.shape = [4, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6698" href="#t6698">6698</a></span><span class="t"><span class="str">            X.data = [[1], [1], [5], [0]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6699" href="#t6699">6699</a></span><span class="t"><span class="str">            depth = 4</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6700" href="#t6700">6700</a></span><span class="t"><span class="str">            allow_out_of_range = True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6701" href="#t6701">6701</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6702" href="#t6702">6702</a></span><span class="t"><span class="str">        output:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6703" href="#t6703">6703</a></span><span class="t"><span class="str">            Out.shape = [4, 4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6704" href="#t6704">6704</a></span><span class="t"><span class="str">            Out.data = [[0., 1., 0., 0.],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6705" href="#t6705">6705</a></span><span class="t"><span class="str">                        [0., 1., 0., 0.],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6706" href="#t6706">6706</a></span><span class="t"><span class="str">                        [0., 0., 0., 0.], # This id is 5, which goes beyond depth, so set it all-zeros data.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6707" href="#t6707">6707</a></span><span class="t"><span class="str">                        [1., 0., 0., 0.]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6708" href="#t6708">6708</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6709" href="#t6709">6709</a></span><span class="t"><span class="str">        Example 3 (allow_out_of_range=False):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6710" href="#t6710">6710</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6711" href="#t6711">6711</a></span><span class="t"><span class="str">        input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6712" href="#t6712">6712</a></span><span class="t"><span class="str">            X.shape = [4, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6713" href="#t6713">6713</a></span><span class="t"><span class="str">            X.data = [[1], [1], [5], [0]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6714" href="#t6714">6714</a></span><span class="t"><span class="str">            depth = 4</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6715" href="#t6715">6715</a></span><span class="t"><span class="str">            allow_out_of_range = False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6716" href="#t6716">6716</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6717" href="#t6717">6717</a></span><span class="t"><span class="str">        output: Throw an exception for Illegal value</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6718" href="#t6718">6718</a></span><span class="t"><span class="str">            The second dimension in X is 5, which is greater than depth.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6719" href="#t6719">6719</a></span><span class="t"><span class="str">            Allow_out_of_range =False means that does not allow the word id to exceed depth,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6720" href="#t6720">6720</a></span><span class="t"><span class="str">            so it throws an exception.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6721" href="#t6721">6721</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6722" href="#t6722">6722</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6723" href="#t6723">6723</a></span><span class="t"><span class="str">        input(Variable): Tensor or LoDTensor with shape :math:`[N_1, N_2, ..., N_k, 1]` ,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6724" href="#t6724">6724</a></span><span class="t"><span class="str">            which contains at least one dimension and the last dimension must be 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6725" href="#t6725">6725</a></span><span class="t"><span class="str">            The data type is int32 or int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6726" href="#t6726">6726</a></span><span class="t"><span class="str">        depth(scalar): An integer defining the :attr:`depth` of the one hot dimension. If input</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6727" href="#t6727">6727</a></span><span class="t"><span class="str">            is word id, depth is generally the dictionary size.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6728" href="#t6728">6728</a></span><span class="t"><span class="str">        allow_out_of_range(bool): A bool value indicating whether the input</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6729" href="#t6729">6729</a></span><span class="t"><span class="str">            indices could be out of range :math:`[0, depth)` . When input indices are</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6730" href="#t6730">6730</a></span><span class="t"><span class="str">            out of range, exceptions :code:`Illegal value` is raised if :attr:`allow_out_of_range`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6731" href="#t6731">6731</a></span><span class="t"><span class="str">            is False, or zero-filling representations is created if it is set True.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6732" href="#t6732">6732</a></span><span class="t"><span class="str">            Default: False.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6733" href="#t6733">6733</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6734" href="#t6734">6734</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6735" href="#t6735">6735</a></span><span class="t"><span class="str">        Variable: The one-hot representations of input. A Tensor or LoDTensor with type float32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6736" href="#t6736">6736</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6737" href="#t6737">6737</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6738" href="#t6738">6738</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6739" href="#t6739">6739</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6740" href="#t6740">6740</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6741" href="#t6741">6741</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6742" href="#t6742">6742</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6743" href="#t6743">6743</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6744" href="#t6744">6744</a></span><span class="t"><span class="str">            # Correspond to the first example above, where label.shape is [4, 1] and one_hot_label.shape is [4, 4].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6745" href="#t6745">6745</a></span><span class="t"><span class="str">            label = fluid.data(name="label", shape=[4, 1], dtype="int64")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6746" href="#t6746">6746</a></span><span class="t"><span class="str">            one_hot_label = fluid.layers.one_hot(input=label, depth=4)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6747" href="#t6747">6747</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6748" href="#t6748">6748</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6749" href="#t6749">6749</a></span><span class="t">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">depth</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6750" href="#t6750">6750</a></span><span class="t">            <span class="nam">depth</span> <span class="op">=</span> <span class="nam">depth</span><span class="op">.</span><span class="nam">numpy</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6751" href="#t6751">6751</a></span><span class="t">            <span class="key">assert</span> <span class="nam">depth</span><span class="op">.</span><span class="nam">shape</span> <span class="op">==</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6752" href="#t6752">6752</a></span><span class="t">                <span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6753" href="#t6753">6753</a></span><span class="t">            <span class="op">)</span><span class="op">,</span> <span class="str">"depth of type Variable should have shape [1]"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6754" href="#t6754">6754</a></span><span class="t">            <span class="nam">depth</span> <span class="op">=</span> <span class="nam">depth</span><span class="op">.</span><span class="nam">item</span><span class="op">(</span><span class="num">0</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6755" href="#t6755">6755</a></span><span class="t">        <span class="nam">out</span> <span class="op">=</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">one_hot</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6756" href="#t6756">6756</a></span><span class="t">            <span class="nam">input</span><span class="op">,</span> <span class="str">'depth'</span><span class="op">,</span> <span class="nam">depth</span><span class="op">,</span> <span class="str">'allow_out_of_range'</span><span class="op">,</span> <span class="nam">allow_out_of_range</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6757" href="#t6757">6757</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6758" href="#t6758">6758</a></span><span class="t">        <span class="nam">out</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6759" href="#t6759">6759</a></span><span class="t">        <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6760" href="#t6760">6760</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6761" href="#t6761">6761</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"one_hot"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6762" href="#t6762">6762</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'one_hot'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6763" href="#t6763">6763</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">depth</span><span class="op">,</span> <span class="str">'depth'</span><span class="op">,</span> <span class="op">(</span><span class="nam">six</span><span class="op">.</span><span class="nam">integer_types</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">,</span> <span class="str">'one_hot'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6764" href="#t6764">6764</a></span><span class="t">    <span class="nam">one_hot_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="str">'float32'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6765" href="#t6765">6765</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6766" href="#t6766">6766</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">depth</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6767" href="#t6767">6767</a></span><span class="t">        <span class="com"># user attribute</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6768" href="#t6768">6768</a></span><span class="t">        <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6769" href="#t6769">6769</a></span><span class="t">        <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'depth'</span><span class="op">:</span> <span class="nam">depth</span><span class="op">,</span> <span class="str">'allow_out_of_range'</span><span class="op">:</span> <span class="nam">allow_out_of_range</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6770" href="#t6770">6770</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6771" href="#t6771">6771</a></span><span class="t">        <span class="nam">depth</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6772" href="#t6772">6772</a></span><span class="t">        <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">input</span><span class="op">,</span> <span class="str">'depth_tensor'</span><span class="op">:</span> <span class="nam">depth</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6773" href="#t6773">6773</a></span><span class="t">        <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'allow_out_of_range'</span><span class="op">:</span> <span class="nam">allow_out_of_range</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6774" href="#t6774">6774</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6775" href="#t6775">6775</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"one_hot"</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">one_hot_out</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6776" href="#t6776">6776</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6777" href="#t6777">6777</a></span><span class="t">    <span class="nam">one_hot_out</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6778" href="#t6778">6778</a></span><span class="t">    <span class="key">return</span> <span class="nam">one_hot_out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6779" href="#t6779">6779</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6780" href="#t6780">6780</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6781" href="#t6781">6781</a></span><span class="t"><span class="key">def</span> <span class="nam">autoincreased_step_counter</span><span class="op">(</span><span class="nam">counter_name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">begin</span><span class="op">=</span><span class="num">1</span><span class="op">,</span> <span class="nam">step</span><span class="op">=</span><span class="num">1</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6782" href="#t6782">6782</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6783" href="#t6783">6783</a></span><span class="t"><span class="str">    :api_attr: Static Graph</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6784" href="#t6784">6784</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6785" href="#t6785">6785</a></span><span class="t"><span class="str">    Create an auto-increase variable. which will be automatically increased</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6786" href="#t6786">6786</a></span><span class="t"><span class="str">    by 1 in every iteration. By default, the first return of this counter is 1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6787" href="#t6787">6787</a></span><span class="t"><span class="str">    and the step size is 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6788" href="#t6788">6788</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6789" href="#t6789">6789</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6790" href="#t6790">6790</a></span><span class="t"><span class="str">        counter_name(str, optional): The counter name. Default '@STEP_COUNTER@'.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6791" href="#t6791">6791</a></span><span class="t"><span class="str">        begin(int, optional): The first return value of this counter. Default 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6792" href="#t6792">6792</a></span><span class="t"><span class="str">        step(int, optional): The step size. Default 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6793" href="#t6793">6793</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6794" href="#t6794">6794</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6795" href="#t6795">6795</a></span><span class="t"><span class="str">        Variable: The auto-increased Variable with data type int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6796" href="#t6796">6796</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6797" href="#t6797">6797</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6798" href="#t6798">6798</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6799" href="#t6799">6799</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6800" href="#t6800">6800</a></span><span class="t"><span class="str">           import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6801" href="#t6801">6801</a></span><span class="t"><span class="str">           import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6802" href="#t6802">6802</a></span><span class="t"><span class="str">           paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6803" href="#t6803">6803</a></span><span class="t"><span class="str">           global_step = fluid.layers.autoincreased_step_counter(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6804" href="#t6804">6804</a></span><span class="t"><span class="str">               counter_name='@LR_DECAY_COUNTER@', begin=0, step=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6805" href="#t6805">6805</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6806" href="#t6806">6806</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'global_step_counter'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t6807" href="#t6807">6807</a></span><span class="t">    <span class="key">if</span> <span class="nam">counter_name</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">6807&#x202F;&#x219B;&#x202F;6808</span><span class="annotate long">line 6807 didn't jump to line 6808, because the condition on line 6807 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6808" href="#t6808">6808</a></span><span class="t">        <span class="nam">counter_name</span> <span class="op">=</span> <span class="str">'@STEP_COUNTER@'</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6809" href="#t6809">6809</a></span><span class="t">    <span class="nam">counter</span><span class="op">,</span> <span class="nam">is_new_var</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_or_get_global_variable</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6810" href="#t6810">6810</a></span><span class="t">        <span class="nam">name</span><span class="op">=</span><span class="nam">counter_name</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6811" href="#t6811">6811</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="str">'int64'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6812" href="#t6812">6812</a></span><span class="t">        <span class="nam">shape</span><span class="op">=</span><span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6813" href="#t6813">6813</a></span><span class="t">        <span class="nam">persistable</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6814" href="#t6814">6814</a></span><span class="t">        <span class="nam">belong_to_optimizer</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6815" href="#t6815">6815</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6816" href="#t6816">6816</a></span><span class="t">    <span class="key">if</span> <span class="nam">is_new_var</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6817" href="#t6817">6817</a></span><span class="t">        <span class="nam">helper</span><span class="op">.</span><span class="nam">set_variable_initializer</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6818" href="#t6818">6818</a></span><span class="t">            <span class="nam">counter</span><span class="op">,</span> <span class="nam">initializer</span><span class="op">=</span><span class="nam">Constant</span><span class="op">(</span><span class="nam">value</span><span class="op">=</span><span class="nam">begin</span> <span class="op">-</span> <span class="num">1</span><span class="op">,</span> <span class="nam">force_cpu</span><span class="op">=</span><span class="key">True</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6819" href="#t6819">6819</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6820" href="#t6820">6820</a></span><span class="t">        <span class="nam">helper</span><span class="op">.</span><span class="nam">main_program</span><span class="op">.</span><span class="nam">global_block</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">_prepend_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6821" href="#t6821">6821</a></span><span class="t">            <span class="nam">type</span><span class="op">=</span><span class="str">'increment'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6822" href="#t6822">6822</a></span><span class="t">            <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="op">[</span><span class="nam">counter</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6823" href="#t6823">6823</a></span><span class="t">            <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="op">[</span><span class="nam">counter</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6824" href="#t6824">6824</a></span><span class="t">            <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'step'</span><span class="op">:</span> <span class="nam">float</span><span class="op">(</span><span class="nam">step</span><span class="op">)</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6825" href="#t6825">6825</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6826" href="#t6826">6826</a></span><span class="t">        <span class="nam">counter</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6827" href="#t6827">6827</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6828" href="#t6828">6828</a></span><span class="t">    <span class="key">return</span> <span class="nam">counter</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6829" href="#t6829">6829</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6830" href="#t6830">6830</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6831" href="#t6831">6831</a></span><span class="t"><span class="key">def</span> <span class="nam">reshape</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">shape</span><span class="op">,</span> <span class="nam">actual_shape</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">inplace</span><span class="op">=</span><span class="key">False</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6832" href="#t6832">6832</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6833" href="#t6833">6833</a></span><span class="t"><span class="str">    :alias_main: paddle.reshape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6834" href="#t6834">6834</a></span><span class="t"><span class="str">        :alias: paddle.reshape,paddle.tensor.reshape,paddle.tensor.manipulation.reshape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6835" href="#t6835">6835</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6836" href="#t6836">6836</a></span><span class="t"><span class="str">    This operator changes the shape of ``x`` without changing its data.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6837" href="#t6837">6837</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6838" href="#t6838">6838</a></span><span class="t"><span class="str">    The target shape can be given by ``shape`` or ``actual_shape``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6839" href="#t6839">6839</a></span><span class="t"><span class="str">    When ``shape`` and ``actual_shape`` are set at the same time,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6840" href="#t6840">6840</a></span><span class="t"><span class="str">    ``actual_shape`` has a higher priority than ``shape``</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6841" href="#t6841">6841</a></span><span class="t"><span class="str">    but at this time ``shape`` can only be an integer list or tuple, and ``shape`` still should be set correctly to</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6842" href="#t6842">6842</a></span><span class="t"><span class="str">    guarantee shape inference in compile-time.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6843" href="#t6843">6843</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6844" href="#t6844">6844</a></span><span class="t"><span class="str">    Some tricks exist when specifying the target shape.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6845" href="#t6845">6845</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6846" href="#t6846">6846</a></span><span class="t"><span class="str">    1. -1 means the value of this dimension is inferred from the total element</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6847" href="#t6847">6847</a></span><span class="t"><span class="str">    number of x and remaining dimensions. Thus one and only one dimension can</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6848" href="#t6848">6848</a></span><span class="t"><span class="str">    be set -1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6849" href="#t6849">6849</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6850" href="#t6850">6850</a></span><span class="t"><span class="str">    2. 0 means the actual dimension value is going to be copied from the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6851" href="#t6851">6851</a></span><span class="t"><span class="str">    corresponding dimension of x. The index of 0s in shape can not exceed</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6852" href="#t6852">6852</a></span><span class="t"><span class="str">    the dimension of x.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6853" href="#t6853">6853</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6854" href="#t6854">6854</a></span><span class="t"><span class="str">    Here are some examples to explain it.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6855" href="#t6855">6855</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6856" href="#t6856">6856</a></span><span class="t"><span class="str">    1. Given a 3-D tensor x with a shape [2, 4, 6], and the target shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6857" href="#t6857">6857</a></span><span class="t"><span class="str">    is [6, 8], the reshape operator will transform x into a 2-D tensor with</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6858" href="#t6858">6858</a></span><span class="t"><span class="str">    shape [6, 8] and leaving x's data unchanged.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6859" href="#t6859">6859</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6860" href="#t6860">6860</a></span><span class="t"><span class="str">    2. Given a 3-D tensor x with a shape [2, 4, 6], and the target shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6861" href="#t6861">6861</a></span><span class="t"><span class="str">    specified is [2, 3, -1, 2], the reshape operator will transform x into a</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6862" href="#t6862">6862</a></span><span class="t"><span class="str">    4-D tensor with shape [2, 3, 4, 2] and leaving x's data unchanged. In this</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6863" href="#t6863">6863</a></span><span class="t"><span class="str">    case, one dimension of the target shape is set to -1, the value of this</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6864" href="#t6864">6864</a></span><span class="t"><span class="str">    dimension is inferred from the total element number of x and remaining</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6865" href="#t6865">6865</a></span><span class="t"><span class="str">    dimensions.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6866" href="#t6866">6866</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6867" href="#t6867">6867</a></span><span class="t"><span class="str">    3. Given a 3-D tensor x with a shape [2, 4, 6], and the target shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6868" href="#t6868">6868</a></span><span class="t"><span class="str">    is [-1, 0, 3, 2], the reshape operator will transform x into a 4-D tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6869" href="#t6869">6869</a></span><span class="t"><span class="str">    with shape [2, 4, 3, 2] and leaving x's data unchanged. In this case,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6870" href="#t6870">6870</a></span><span class="t"><span class="str">    besides -1, 0 means the actual dimension value is going to be copied from</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6871" href="#t6871">6871</a></span><span class="t"><span class="str">    the corresponding dimension of x.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6872" href="#t6872">6872</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6873" href="#t6873">6873</a></span><span class="t"><span class="str">    **Note**:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6874" href="#t6874">6874</a></span><span class="t"><span class="str">        The parameter ``actual_shape`` will be deprecated in the future and only use ``shape`` instead to represent the target shape.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6875" href="#t6875">6875</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6876" href="#t6876">6876</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6877" href="#t6877">6877</a></span><span class="t"><span class="str">        x(Tensor): An N-D Tensor. The data type is ``float32``, ``float64``, ``int32`` or ``int64``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6878" href="#t6878">6878</a></span><span class="t"><span class="str">        shape(list|tuple|Tensor): Define the target shape. At most one dimension of the target shape can be -1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6879" href="#t6879">6879</a></span><span class="t"><span class="str">                        The data type is ``int32`` . If ``shape`` is a list or tuple, the elements of it should be integers or Tensors with shape [1].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6880" href="#t6880">6880</a></span><span class="t"><span class="str">                        If ``shape`` is an Tensor, it should be an 1-D Tensor .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6881" href="#t6881">6881</a></span><span class="t"><span class="str">        actual_shape(variable, optional): An 1-D ``Tensor`` or ``LoDTensor`` . The data type is ``int32`` . If provided, reshape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6882" href="#t6882">6882</a></span><span class="t"><span class="str">                                according to this given shape rather than ``shape`` specifying shape.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6883" href="#t6883">6883</a></span><span class="t"><span class="str">                                That is to say ``actual_shape`` has a higher priority</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6884" href="#t6884">6884</a></span><span class="t"><span class="str">                                than ``shape(list|tuple)`` but not ``shape(Tensor)``. \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6885" href="#t6885">6885</a></span><span class="t"><span class="str">                                This argument ``actual_shape`` will be removed in a future version. \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6886" href="#t6886">6886</a></span><span class="t"><span class="str">                                Instructions for updating: ``actual_shape`` will be removed in future versions and replaced by ``shape``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6887" href="#t6887">6887</a></span><span class="t"><span class="str">        act (str, optional): The non-linear activation to be applied to the reshaped input. Default None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6888" href="#t6888">6888</a></span><span class="t"><span class="str">        inplace(bool, optional): If ``inplace`` is True, the input and output of ``layers.reshape``</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6889" href="#t6889">6889</a></span><span class="t"><span class="str">                       are the same variable. Otherwise, the input and output of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6890" href="#t6890">6890</a></span><span class="t"><span class="str">                       ``layers.reshape`` are different variable. Default False. Note that if ``x``</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6891" href="#t6891">6891</a></span><span class="t"><span class="str">                       is more than one OPs' input, ``inplace`` must be False.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6892" href="#t6892">6892</a></span><span class="t"><span class="str">        name(str, optional): The default value is None. Normally there is no need for user to set this property.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6893" href="#t6893">6893</a></span><span class="t"><span class="str">                            For more information, please refer to :ref:`api_guide_Name` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6894" href="#t6894">6894</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6895" href="#t6895">6895</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6896" href="#t6896">6896</a></span><span class="t"><span class="str">        Tensor: A reshaped Tensor with the same data type as ``x``. It is a new tensor variable if ``inplace`` is ``False``, otherwise it is ``x``. If ``act`` is None, return the reshaped tensor variable, otherwise return the activated tensor variable.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6897" href="#t6897">6897</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6898" href="#t6898">6898</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6899" href="#t6899">6899</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6900" href="#t6900">6900</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6901" href="#t6901">6901</a></span><span class="t"><span class="str">            </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6902" href="#t6902">6902</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6903" href="#t6903">6903</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6904" href="#t6904">6904</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6905" href="#t6905">6905</a></span><span class="t"><span class="str">            </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6906" href="#t6906">6906</a></span><span class="t"><span class="str">            # example 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6907" href="#t6907">6907</a></span><span class="t"><span class="str">            # attr shape is a list which doesn't contain Tensors.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6908" href="#t6908">6908</a></span><span class="t"><span class="str">            data_1 = fluid.data(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6909" href="#t6909">6909</a></span><span class="t"><span class="str">              name='data_1', shape=[2, 4, 6], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6910" href="#t6910">6910</a></span><span class="t"><span class="str">            reshaped_1 = fluid.layers.reshape(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6911" href="#t6911">6911</a></span><span class="t"><span class="str">              x=data_1, shape=[-1, 0, 3, 2])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6912" href="#t6912">6912</a></span><span class="t"><span class="str">            # the shape of reshaped_1 is [2,4,3,2].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6913" href="#t6913">6913</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6914" href="#t6914">6914</a></span><span class="t"><span class="str">            # example 2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6915" href="#t6915">6915</a></span><span class="t"><span class="str">            # attr shape is a list which contains Tensors.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6916" href="#t6916">6916</a></span><span class="t"><span class="str">            data_2 = fluid.layers.fill_constant([2,25], "int32", 3)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6917" href="#t6917">6917</a></span><span class="t"><span class="str">            dim = fluid.layers.fill_constant([1], "int32", 5)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6918" href="#t6918">6918</a></span><span class="t"><span class="str">            reshaped_2 = fluid.layers.reshape(data_2, shape=[dim, 10])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6919" href="#t6919">6919</a></span><span class="t"><span class="str">            # the shape of reshaped_2 is [5,10].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6920" href="#t6920">6920</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6921" href="#t6921">6921</a></span><span class="t"><span class="str">            # example 3:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6922" href="#t6922">6922</a></span><span class="t"><span class="str">            data_3 = fluid.data(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6923" href="#t6923">6923</a></span><span class="t"><span class="str">              name="data_3", shape=[2,4,6], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6924" href="#t6924">6924</a></span><span class="t"><span class="str">            reshaped_3 = fluid.layers.reshape(x=data_3, shape=[6,8])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6925" href="#t6925">6925</a></span><span class="t"><span class="str">            # the shape of reshaped_3 is [6,8].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6926" href="#t6926">6926</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t6927" href="#t6927">6927</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">6927&#x202F;&#x219B;&#x202F;6928</span><span class="annotate long">line 6927 didn't jump to line 6928, because the condition on line 6927 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6928" href="#t6928">6928</a></span><span class="t">        <span class="nam">tmp_tensor_type</span> <span class="op">=</span> <span class="nam">core</span><span class="op">.</span><span class="nam">eager</span><span class="op">.</span><span class="nam">Tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6929" href="#t6929">6929</a></span><span class="t">        <span class="com"># TODO(zhiqiu): enable inplace in dygraph mode.</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6930" href="#t6930">6930</a></span><span class="t">        <span class="key">if</span> <span class="nam">inplace</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6931" href="#t6931">6931</a></span><span class="t">            <span class="nam">warnings</span><span class="op">.</span><span class="nam">warn</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6932" href="#t6932">6932</a></span><span class="t">                <span class="str">"Inplace on reshape is not allowed and will be discarded in dygraph mode currently."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6933" href="#t6933">6933</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6934" href="#t6934">6934</a></span><span class="t">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">shape</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6935" href="#t6935">6935</a></span><span class="t">            <span class="nam">shape</span> <span class="op">=</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6936" href="#t6936">6936</a></span><span class="t">                <span class="nam">item</span><span class="op">.</span><span class="nam">numpy</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">item</span><span class="op">(</span><span class="num">0</span><span class="op">)</span> <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">item</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span> <span class="key">else</span> <span class="nam">item</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6937" href="#t6937">6937</a></span><span class="t">                <span class="key">for</span> <span class="nam">item</span> <span class="key">in</span> <span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6938" href="#t6938">6938</a></span><span class="t">            <span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6939" href="#t6939">6939</a></span><span class="t">            <span class="nam">out</span> <span class="op">=</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">reshape</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6940" href="#t6940">6940</a></span><span class="t">        <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">shape</span><span class="op">,</span> <span class="nam">tmp_tensor_type</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6941" href="#t6941">6941</a></span><span class="t">            <span class="com"># TODO: Tensor shape in reshape has not been tested</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6942" href="#t6942">6942</a></span><span class="t">            <span class="nam">shape</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6943" href="#t6943">6943</a></span><span class="t">            <span class="nam">out</span> <span class="op">=</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">reshape</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6944" href="#t6944">6944</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6945" href="#t6945">6945</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6946" href="#t6946">6946</a></span><span class="t">                <span class="str">"shape must be an instance of `list`, `tuple` or `Variable`,"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6947" href="#t6947">6947</a></span><span class="t">                <span class="str">" got '{}.'"</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">type</span><span class="op">(</span><span class="nam">shape</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6948" href="#t6948">6948</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6949" href="#t6949">6949</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6950" href="#t6950">6950</a></span><span class="t">        <span class="key">return</span> <span class="nam">dygraph_utils</span><span class="op">.</span><span class="nam">_append_activation_in_dygraph</span><span class="op">(</span><span class="nam">out</span><span class="op">,</span> <span class="nam">act</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6951" href="#t6951">6951</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t6952" href="#t6952">6952</a></span><span class="t">        <span class="key">if</span> <span class="nam">_in_legacy_dygraph</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">6952&#x202F;&#x219B;&#x202F;6953</span><span class="annotate long">line 6952 didn't jump to line 6953, because the condition on line 6952 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6953" href="#t6953">6953</a></span><span class="t">            <span class="nam">tmp_tensor_type</span> <span class="op">=</span> <span class="nam">Variable</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6954" href="#t6954">6954</a></span><span class="t">            <span class="key">if</span> <span class="nam">inplace</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6955" href="#t6955">6955</a></span><span class="t">                <span class="nam">warnings</span><span class="op">.</span><span class="nam">warn</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6956" href="#t6956">6956</a></span><span class="t">                    <span class="str">"Inplace on reshape is not allowed and will be discarded in dygraph mode currently."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6957" href="#t6957">6957</a></span><span class="t">                <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6958" href="#t6958">6958</a></span><span class="t">            <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">shape</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6959" href="#t6959">6959</a></span><span class="t">                <span class="nam">shape</span> <span class="op">=</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6960" href="#t6960">6960</a></span><span class="t">                    <span class="nam">item</span><span class="op">.</span><span class="nam">numpy</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">item</span><span class="op">(</span><span class="num">0</span><span class="op">)</span> <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">item</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span> <span class="key">else</span> <span class="nam">item</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6961" href="#t6961">6961</a></span><span class="t">                    <span class="key">for</span> <span class="nam">item</span> <span class="key">in</span> <span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6962" href="#t6962">6962</a></span><span class="t">                <span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6963" href="#t6963">6963</a></span><span class="t">                <span class="nam">out</span><span class="op">,</span> <span class="nam">_</span> <span class="op">=</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">reshape2</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="key">None</span><span class="op">,</span> <span class="str">'shape'</span><span class="op">,</span> <span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6964" href="#t6964">6964</a></span><span class="t">            <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">shape</span><span class="op">,</span> <span class="nam">tmp_tensor_type</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6965" href="#t6965">6965</a></span><span class="t">                <span class="nam">shape</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6966" href="#t6966">6966</a></span><span class="t">                <span class="nam">out</span><span class="op">,</span> <span class="nam">_</span> <span class="op">=</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">reshape2</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6967" href="#t6967">6967</a></span><span class="t">            <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6968" href="#t6968">6968</a></span><span class="t">                <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6969" href="#t6969">6969</a></span><span class="t">                    <span class="str">"shape must be an instance of `list`, `tuple` or `Variable`,"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6970" href="#t6970">6970</a></span><span class="t">                    <span class="str">" got '{}.'"</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">type</span><span class="op">(</span><span class="nam">shape</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6971" href="#t6971">6971</a></span><span class="t">                <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6972" href="#t6972">6972</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t6973" href="#t6973">6973</a></span><span class="t">            <span class="key">return</span> <span class="nam">dygraph_utils</span><span class="op">.</span><span class="nam">_append_activation_in_dygraph</span><span class="op">(</span><span class="nam">out</span><span class="op">,</span> <span class="nam">act</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6974" href="#t6974">6974</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6975" href="#t6975">6975</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6976" href="#t6976">6976</a></span><span class="t">        <span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6977" href="#t6977">6977</a></span><span class="t">        <span class="str">'x'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6978" href="#t6978">6978</a></span><span class="t">        <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6979" href="#t6979">6979</a></span><span class="t">            <span class="str">'float16'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6980" href="#t6980">6980</a></span><span class="t">            <span class="str">'float32'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6981" href="#t6981">6981</a></span><span class="t">            <span class="str">'float64'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6982" href="#t6982">6982</a></span><span class="t">            <span class="str">'int16'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6983" href="#t6983">6983</a></span><span class="t">            <span class="str">'int32'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6984" href="#t6984">6984</a></span><span class="t">            <span class="str">'int64'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6985" href="#t6985">6985</a></span><span class="t">            <span class="str">'bool'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6986" href="#t6986">6986</a></span><span class="t">            <span class="str">'uint16'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6987" href="#t6987">6987</a></span><span class="t">        <span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6988" href="#t6988">6988</a></span><span class="t">        <span class="str">'reshape'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6989" href="#t6989">6989</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6990" href="#t6990">6990</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">shape</span><span class="op">,</span> <span class="str">'shape'</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">,</span> <span class="str">'reshape'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6991" href="#t6991">6991</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">actual_shape</span><span class="op">,</span> <span class="str">'actual_shape'</span><span class="op">,</span> <span class="op">(</span><span class="nam">Variable</span><span class="op">,</span> <span class="nam">type</span><span class="op">(</span><span class="key">None</span><span class="op">)</span><span class="op">)</span><span class="op">,</span> <span class="str">'reshape'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6992" href="#t6992">6992</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6993" href="#t6993">6993</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"reshape2"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t6994" href="#t6994">6994</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6995" href="#t6995">6995</a></span><span class="t">    <span class="key">def</span> <span class="nam">get_attr_shape</span><span class="op">(</span><span class="nam">list_shape</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6996" href="#t6996">6996</a></span><span class="t">        <span class="nam">unk_dim_idx</span> <span class="op">=</span> <span class="op">-</span><span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6997" href="#t6997">6997</a></span><span class="t">        <span class="nam">attrs_shape</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6998" href="#t6998">6998</a></span><span class="t">        <span class="key">for</span> <span class="nam">dim_idx</span><span class="op">,</span> <span class="nam">dim_size</span> <span class="key">in</span> <span class="nam">enumerate</span><span class="op">(</span><span class="nam">list_shape</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t6999" href="#t6999">6999</a></span><span class="t">            <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim_size</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">6999&#x202F;&#x219B;&#x202F;7000</span><span class="annotate long">line 6999 didn't jump to line 7000, because the condition on line 6999 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7000" href="#t7000">7000</a></span><span class="t">                <span class="nam">attrs_shape</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="op">-</span><span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7001" href="#t7001">7001</a></span><span class="t">            <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7002" href="#t7002">7002</a></span><span class="t">                <span class="nam">attrs_shape</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">dim_size</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t7003" href="#t7003">7003</a></span><span class="t">                <span class="key">if</span> <span class="nam">dim_size</span> <span class="op">==</span> <span class="op">-</span><span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">7003&#x202F;&#x219B;&#x202F;7004</span><span class="annotate long">line 7003 didn't jump to line 7004, because the condition on line 7003 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7004" href="#t7004">7004</a></span><span class="t">                    <span class="key">assert</span> <span class="nam">unk_dim_idx</span> <span class="op">==</span> <span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7005" href="#t7005">7005</a></span><span class="t">                        <span class="str">"Only one dimension value of 'shape' in reshape can "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7006" href="#t7006">7006</a></span><span class="t">                        <span class="str">"be -1. But received shape[%d] is also -1.\n"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7007" href="#t7007">7007</a></span><span class="t">                        <span class="str">"\n\t# N = x.shape()[2]\t\t# N is an int. "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7008" href="#t7008">7008</a></span><span class="t">                        <span class="str">"(NOT recommend under @to_static)\n\tN = paddle.shape(x)[2]\t\t"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7009" href="#t7009">7009</a></span><span class="t">                        <span class="str">"# N is a Tensor. (Recommend)\n\tz = paddle.reshape([N, -1, 4])"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7010" href="#t7010">7010</a></span><span class="t">                        <span class="str">"\t# z.shape is [-1, -1, 4]\n\n"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7011" href="#t7011">7011</a></span><span class="t">                        <span class="str">"    If your target shape in Reshape represents dynamic shape, "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7012" href="#t7012">7012</a></span><span class="t">                        <span class="str">"please turn it into a Tensor under @to_static. See above example for details."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7013" href="#t7013">7013</a></span><span class="t">                        <span class="op">%</span> <span class="nam">dim_idx</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7014" href="#t7014">7014</a></span><span class="t">                    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7015" href="#t7015">7015</a></span><span class="t">                    <span class="nam">unk_dim_idx</span> <span class="op">=</span> <span class="nam">dim_idx</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t7016" href="#t7016">7016</a></span><span class="t">                <span class="key">elif</span> <span class="nam">dim_size</span> <span class="op">==</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">7016&#x202F;&#x219B;&#x202F;7017</span><span class="annotate long">line 7016 didn't jump to line 7017, because the condition on line 7016 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7017" href="#t7017">7017</a></span><span class="t">                    <span class="key">assert</span> <span class="nam">dim_idx</span> <span class="op">&lt;</span> <span class="nam">len</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span><span class="op">,</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7018" href="#t7018">7018</a></span><span class="t">                        <span class="str">"The index of 0 in `shape` must be less than "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7019" href="#t7019">7019</a></span><span class="t">                        <span class="str">"the input tensor X's dimensions. "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7020" href="#t7020">7020</a></span><span class="t">                        <span class="str">"But received shape[%d] = 0, X's dimensions = %d."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7021" href="#t7021">7021</a></span><span class="t">                        <span class="op">%</span> <span class="op">(</span><span class="nam">dim_idx</span><span class="op">,</span> <span class="nam">len</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7022" href="#t7022">7022</a></span><span class="t">                    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7023" href="#t7023">7023</a></span><span class="t">                <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7024" href="#t7024">7024</a></span><span class="t">                    <span class="key">assert</span> <span class="nam">dim_size</span> <span class="op">></span> <span class="num">0</span><span class="op">,</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7025" href="#t7025">7025</a></span><span class="t">                        <span class="str">"Each dimension value of 'shape' in reshape must not "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7026" href="#t7026">7026</a></span><span class="t">                        <span class="str">"be negative except one unknown dimension. "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7027" href="#t7027">7027</a></span><span class="t">                        <span class="str">"But received shape[%d] = %s."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7028" href="#t7028">7028</a></span><span class="t">                        <span class="op">%</span> <span class="op">(</span><span class="nam">dim_idx</span><span class="op">,</span> <span class="nam">str</span><span class="op">(</span><span class="nam">dim_size</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7029" href="#t7029">7029</a></span><span class="t">                    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7030" href="#t7030">7030</a></span><span class="t">        <span class="key">return</span> <span class="nam">attrs_shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7031" href="#t7031">7031</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7032" href="#t7032">7032</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7033" href="#t7033">7033</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t7034" href="#t7034">7034</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">shape</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">7034&#x202F;&#x219B;&#x202F;7035</span><span class="annotate long">line 7034 didn't jump to line 7035, because the condition on line 7034 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7035" href="#t7035">7035</a></span><span class="t">        <span class="nam">shape</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7036" href="#t7036">7036</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">"Shape"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t7037" href="#t7037">7037</a></span><span class="t">    <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">shape</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">7037&#x202F;&#x219B;&#x202F;7049</span><span class="annotate long">line 7037 didn't jump to line 7049</span></span></p>
    <p class="run"><span class="n"><a id="t7038" href="#t7038">7038</a></span><span class="t">        <span class="key">assert</span> <span class="nam">len</span><span class="op">(</span><span class="nam">shape</span><span class="op">)</span> <span class="op">></span> <span class="num">0</span><span class="op">,</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7039" href="#t7039">7039</a></span><span class="t">            <span class="str">"The size of 'shape' in reshape can't be zero, "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7040" href="#t7040">7040</a></span><span class="t">            <span class="str">"but received %s."</span> <span class="op">%</span> <span class="nam">len</span><span class="op">(</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7041" href="#t7041">7041</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7042" href="#t7042">7042</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">"shape"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">get_attr_shape</span><span class="op">(</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t7043" href="#t7043">7043</a></span><span class="t">        <span class="key">if</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_contain_var</span><span class="op">(</span><span class="nam">shape</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">7043&#x202F;&#x219B;&#x202F;7044</span><span class="annotate long">line 7043 didn't jump to line 7044, because the condition on line 7043 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7044" href="#t7044">7044</a></span><span class="t">            <span class="nam">inputs</span><span class="op">[</span><span class="str">'ShapeTensor'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_convert_to_tensor_list</span><span class="op">(</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t7045" href="#t7045">7045</a></span><span class="t">        <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">actual_shape</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">7045&#x202F;&#x219B;&#x202F;7046</span><span class="annotate long">line 7045 didn't jump to line 7046, because the condition on line 7045 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7046" href="#t7046">7046</a></span><span class="t">            <span class="nam">actual_shape</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7047" href="#t7047">7047</a></span><span class="t">            <span class="nam">inputs</span><span class="op">[</span><span class="str">"Shape"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">actual_shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7048" href="#t7048">7048</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7049" href="#t7049">7049</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7050" href="#t7050">7050</a></span><span class="t">        <span class="nam">x</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7051" href="#t7051">7051</a></span><span class="t">        <span class="key">if</span> <span class="nam">inplace</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7052" href="#t7052">7052</a></span><span class="t">        <span class="key">else</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7053" href="#t7053">7053</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7054" href="#t7054">7054</a></span><span class="t">    <span class="nam">x_shape</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7055" href="#t7055">7055</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7056" href="#t7056">7056</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"reshape2"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7057" href="#t7057">7057</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7058" href="#t7058">7058</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7059" href="#t7059">7059</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">,</span> <span class="str">"XShape"</span><span class="op">:</span> <span class="nam">x_shape</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7060" href="#t7060">7060</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7061" href="#t7061">7061</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7062" href="#t7062">7062</a></span><span class="t">    <span class="key">return</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_activation</span><span class="op">(</span><span class="nam">out</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7063" href="#t7063">7063</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7064" href="#t7064">7064</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7065" href="#t7065">7065</a></span><span class="t"><span class="key">def</span> <span class="nam">squeeze</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">axes</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7066" href="#t7066">7066</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7067" href="#t7067">7067</a></span><span class="t"><span class="str">    This OP will squeeze single-dimensional entries of input tensor's shape. If axes is provided, will</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7068" href="#t7068">7068</a></span><span class="t"><span class="str">    remove the dims by axes, the dims selected by axes should be one. If not provide axes, all dims equal</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7069" href="#t7069">7069</a></span><span class="t"><span class="str">    to one will be deleted.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7070" href="#t7070">7070</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7071" href="#t7071">7071</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7072" href="#t7072">7072</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7073" href="#t7073">7073</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7074" href="#t7074">7074</a></span><span class="t"><span class="str">        Case1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7075" href="#t7075">7075</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7076" href="#t7076">7076</a></span><span class="t"><span class="str">          Input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7077" href="#t7077">7077</a></span><span class="t"><span class="str">            X.shape = (1, 3, 1, 5)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7078" href="#t7078">7078</a></span><span class="t"><span class="str">            axes = [0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7079" href="#t7079">7079</a></span><span class="t"><span class="str">          Output:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7080" href="#t7080">7080</a></span><span class="t"><span class="str">            Out.shape = (3, 1, 5)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7081" href="#t7081">7081</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7082" href="#t7082">7082</a></span><span class="t"><span class="str">        Case2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7083" href="#t7083">7083</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7084" href="#t7084">7084</a></span><span class="t"><span class="str">          Input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7085" href="#t7085">7085</a></span><span class="t"><span class="str">            X.shape = (1, 3, 1, 5)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7086" href="#t7086">7086</a></span><span class="t"><span class="str">            axes = []</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7087" href="#t7087">7087</a></span><span class="t"><span class="str">          Output:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7088" href="#t7088">7088</a></span><span class="t"><span class="str">            Out.shape = (3, 5)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7089" href="#t7089">7089</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7090" href="#t7090">7090</a></span><span class="t"><span class="str">        Case3:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7091" href="#t7091">7091</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7092" href="#t7092">7092</a></span><span class="t"><span class="str">          Input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7093" href="#t7093">7093</a></span><span class="t"><span class="str">            X.shape = [1,3,1,5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7094" href="#t7094">7094</a></span><span class="t"><span class="str">            axes = [-2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7095" href="#t7095">7095</a></span><span class="t"><span class="str">          Output:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7096" href="#t7096">7096</a></span><span class="t"><span class="str">            Out.shape = [1,3,5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7097" href="#t7097">7097</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7098" href="#t7098">7098</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7099" href="#t7099">7099</a></span><span class="t"><span class="str">        input (Variable): The input Tensor. Supported data type: float32, float64, bool, int8, int32, int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7100" href="#t7100">7100</a></span><span class="t"><span class="str">                          axes (list): One integer or List of integers, indicating the dimensions to be squeezed.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7101" href="#t7101">7101</a></span><span class="t"><span class="str">                          Axes range is :math:`[-rank(input), rank(input))`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7102" href="#t7102">7102</a></span><span class="t"><span class="str">                          If axes is negative, :math:`axes=axes+rank(input)`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7103" href="#t7103">7103</a></span><span class="t"><span class="str">        name (str, optional): Please refer to :ref:`api_guide_Name`, Default None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7104" href="#t7104">7104</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7105" href="#t7105">7105</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7106" href="#t7106">7106</a></span><span class="t"><span class="str">        Variable: Output squeezed Tensor. Data type is same as input Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7107" href="#t7107">7107</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7108" href="#t7108">7108</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7109" href="#t7109">7109</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7110" href="#t7110">7110</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7111" href="#t7111">7111</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7112" href="#t7112">7112</a></span><span class="t"><span class="str">            import paddle.fluid.layers as layers</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7113" href="#t7113">7113</a></span><span class="t"><span class="str">            # set batch size=None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7114" href="#t7114">7114</a></span><span class="t"><span class="str">            x = fluid.data(name='x', shape=[None, 5, 1, 10])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7115" href="#t7115">7115</a></span><span class="t"><span class="str">            y = layers.squeeze(input=x, axes=[2]) # y.shape=[None, 5, 10]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7116" href="#t7116">7116</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7117" href="#t7117">7117</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7118" href="#t7118">7118</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7119" href="#t7119">7119</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">squeeze</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">axes</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t7120" href="#t7120">7120</a></span><span class="t">    <span class="key">if</span> <span class="nam">_in_legacy_dygraph</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">7120&#x202F;&#x219B;&#x202F;7121</span><span class="annotate long">line 7120 didn't jump to line 7121, because the condition on line 7120 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7121" href="#t7121">7121</a></span><span class="t">        <span class="nam">out</span><span class="op">,</span> <span class="nam">_</span> <span class="op">=</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">squeeze2</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="str">'axes'</span><span class="op">,</span> <span class="nam">axes</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7122" href="#t7122">7122</a></span><span class="t">        <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7123" href="#t7123">7123</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7124" href="#t7124">7124</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"squeeze"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7125" href="#t7125">7125</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7126" href="#t7126">7126</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7127" href="#t7127">7127</a></span><span class="t">        <span class="str">'input'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7128" href="#t7128">7128</a></span><span class="t">        <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7129" href="#t7129">7129</a></span><span class="t">            <span class="str">'float16'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7130" href="#t7130">7130</a></span><span class="t">            <span class="str">'float32'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7131" href="#t7131">7131</a></span><span class="t">            <span class="str">'float64'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7132" href="#t7132">7132</a></span><span class="t">            <span class="str">'bool'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7133" href="#t7133">7133</a></span><span class="t">            <span class="str">'int8'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7134" href="#t7134">7134</a></span><span class="t">            <span class="str">'int32'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7135" href="#t7135">7135</a></span><span class="t">            <span class="str">'int64'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7136" href="#t7136">7136</a></span><span class="t">            <span class="str">'complex64'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7137" href="#t7137">7137</a></span><span class="t">            <span class="str">'complex128'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7138" href="#t7138">7138</a></span><span class="t">        <span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7139" href="#t7139">7139</a></span><span class="t">        <span class="str">'squeeze'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7140" href="#t7140">7140</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7141" href="#t7141">7141</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">axes</span><span class="op">,</span> <span class="str">'axis/axes'</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">,</span> <span class="str">'squeeze'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7142" href="#t7142">7142</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7143" href="#t7143">7143</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7144" href="#t7144">7144</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">axes</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7145" href="#t7145">7145</a></span><span class="t">        <span class="nam">axes</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7146" href="#t7146">7146</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">"axes"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">axes</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7147" href="#t7147">7147</a></span><span class="t">    <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">axes</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7148" href="#t7148">7148</a></span><span class="t">        <span class="key">if</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_contain_var</span><span class="op">(</span><span class="nam">axes</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7149" href="#t7149">7149</a></span><span class="t">            <span class="nam">attrs</span><span class="op">[</span><span class="str">"axes"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_convert_to_tensor_list</span><span class="op">(</span><span class="nam">axes</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7150" href="#t7150">7150</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7151" href="#t7151">7151</a></span><span class="t">            <span class="nam">attrs</span><span class="op">[</span><span class="str">"axes"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">axes</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7152" href="#t7152">7152</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">input</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7153" href="#t7153">7153</a></span><span class="t">    <span class="nam">x_shape</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">input</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7154" href="#t7154">7154</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7155" href="#t7155">7155</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"squeeze2"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7156" href="#t7156">7156</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7157" href="#t7157">7157</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7158" href="#t7158">7158</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">,</span> <span class="str">"XShape"</span><span class="op">:</span> <span class="nam">x_shape</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7159" href="#t7159">7159</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7160" href="#t7160">7160</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7161" href="#t7161">7161</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7162" href="#t7162">7162</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7163" href="#t7163">7163</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7164" href="#t7164">7164</a></span><span class="t"><span class="key">def</span> <span class="nam">unsqueeze</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">axes</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7165" href="#t7165">7165</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7166" href="#t7166">7166</a></span><span class="t"><span class="str">    Insert single-dimensional entries to the shape of a Tensor. Takes one</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7167" href="#t7167">7167</a></span><span class="t"><span class="str">    required argument axes, a list of dimensions that will be inserted.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7168" href="#t7168">7168</a></span><span class="t"><span class="str">    Dimension indices in axes are as seen in the output tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7169" href="#t7169">7169</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7170" href="#t7170">7170</a></span><span class="t"><span class="str">    For example:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7171" href="#t7171">7171</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7172" href="#t7172">7172</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7173" href="#t7173">7173</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7174" href="#t7174">7174</a></span><span class="t"><span class="str">      Given a tensor such that tensor with shape [3, 4, 5],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7175" href="#t7175">7175</a></span><span class="t"><span class="str">      then Unsqueezed tensor with axes=[0, 4] has shape [1, 3, 4, 5, 1].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7176" href="#t7176">7176</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7177" href="#t7177">7177</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7178" href="#t7178">7178</a></span><span class="t"><span class="str">        input (Variable): The input Tensor to be unsqueezed. Supported data type: float32, float64, bool, int8, int32, int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7179" href="#t7179">7179</a></span><span class="t"><span class="str">        axes (int|list|tuple|Variable): Indicates the dimensions to be inserted. The data type is ``int32`` . If ``axes`` is a list or tuple, the elements of it should be integers or Tensors with shape [1]. If ``axes`` is an Variable, it should be an 1-D Tensor .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7180" href="#t7180">7180</a></span><span class="t"><span class="str">        name (str|None): Name for this layer.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7181" href="#t7181">7181</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7182" href="#t7182">7182</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7183" href="#t7183">7183</a></span><span class="t"><span class="str">        Variable: Unsqueezed Tensor, with the same data type as input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7184" href="#t7184">7184</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7185" href="#t7185">7185</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7186" href="#t7186">7186</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7187" href="#t7187">7187</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7188" href="#t7188">7188</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7189" href="#t7189">7189</a></span><span class="t"><span class="str">            x = fluid.layers.data(name='x', shape=[5, 10])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7190" href="#t7190">7190</a></span><span class="t"><span class="str">            y = fluid.layers.unsqueeze(input=x, axes=[1])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7191" href="#t7191">7191</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7192" href="#t7192">7192</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t7193" href="#t7193">7193</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">7193&#x202F;&#x219B;&#x202F;7194</span><span class="annotate long">line 7193 didn't jump to line 7194, because the condition on line 7193 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7194" href="#t7194">7194</a></span><span class="t">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">axes</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7195" href="#t7195">7195</a></span><span class="t">            <span class="nam">axes</span> <span class="op">=</span> <span class="op">[</span><span class="nam">axes</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7196" href="#t7196">7196</a></span><span class="t">        <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">axes</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7197" href="#t7197">7197</a></span><span class="t">            <span class="nam">axes</span> <span class="op">=</span> <span class="nam">axes</span><span class="op">.</span><span class="nam">numpy</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">tolist</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7198" href="#t7198">7198</a></span><span class="t">        <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">axes</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7199" href="#t7199">7199</a></span><span class="t">            <span class="nam">axes</span> <span class="op">=</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7200" href="#t7200">7200</a></span><span class="t">                <span class="nam">item</span><span class="op">.</span><span class="nam">numpy</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">item</span><span class="op">(</span><span class="num">0</span><span class="op">)</span> <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">item</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span> <span class="key">else</span> <span class="nam">item</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7201" href="#t7201">7201</a></span><span class="t">                <span class="key">for</span> <span class="nam">item</span> <span class="key">in</span> <span class="nam">axes</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7202" href="#t7202">7202</a></span><span class="t">            <span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7203" href="#t7203">7203</a></span><span class="t">        <span class="key">if</span> <span class="nam">_in_legacy_dygraph</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7204" href="#t7204">7204</a></span><span class="t">            <span class="nam">out</span><span class="op">,</span> <span class="nam">_</span> <span class="op">=</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">unsqueeze2</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="str">'axes'</span><span class="op">,</span> <span class="nam">axes</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7205" href="#t7205">7205</a></span><span class="t">            <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7206" href="#t7206">7206</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">unsqueeze</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">axes</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7207" href="#t7207">7207</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7208" href="#t7208">7208</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">axes</span><span class="op">,</span> <span class="str">'axis/axes'</span><span class="op">,</span> <span class="op">(</span><span class="nam">int</span><span class="op">,</span> <span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">,</span> <span class="str">'unsqueeze'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7209" href="#t7209">7209</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7210" href="#t7210">7210</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7211" href="#t7211">7211</a></span><span class="t">        <span class="str">'input'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7212" href="#t7212">7212</a></span><span class="t">        <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7213" href="#t7213">7213</a></span><span class="t">            <span class="str">'float16'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7214" href="#t7214">7214</a></span><span class="t">            <span class="str">'float32'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7215" href="#t7215">7215</a></span><span class="t">            <span class="str">'float64'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7216" href="#t7216">7216</a></span><span class="t">            <span class="str">'bool'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7217" href="#t7217">7217</a></span><span class="t">            <span class="str">'int8'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7218" href="#t7218">7218</a></span><span class="t">            <span class="str">'int16'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7219" href="#t7219">7219</a></span><span class="t">            <span class="str">'int32'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7220" href="#t7220">7220</a></span><span class="t">            <span class="str">'int64'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7221" href="#t7221">7221</a></span><span class="t">            <span class="str">'complex64'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7222" href="#t7222">7222</a></span><span class="t">            <span class="str">'complex128'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7223" href="#t7223">7223</a></span><span class="t">        <span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7224" href="#t7224">7224</a></span><span class="t">        <span class="str">'unsqueeze'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7225" href="#t7225">7225</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7226" href="#t7226">7226</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"unsqueeze2"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7227" href="#t7227">7227</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7228" href="#t7228">7228</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7229" href="#t7229">7229</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t7230" href="#t7230">7230</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">axes</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">7230&#x202F;&#x219B;&#x202F;7231</span><span class="annotate long">line 7230 didn't jump to line 7231, because the condition on line 7230 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7231" href="#t7231">7231</a></span><span class="t">        <span class="nam">axes</span> <span class="op">=</span> <span class="op">[</span><span class="nam">axes</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t7232" href="#t7232">7232</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">axes</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">7232&#x202F;&#x219B;&#x202F;7233</span><span class="annotate long">line 7232 didn't jump to line 7233, because the condition on line 7232 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7233" href="#t7233">7233</a></span><span class="t">        <span class="nam">axes</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7234" href="#t7234">7234</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">"AxesTensor"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">axes</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t7235" href="#t7235">7235</a></span><span class="t">    <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">axes</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">7235&#x202F;&#x219B;&#x202F;7241</span><span class="annotate long">line 7235 didn't jump to line 7241, because the condition on line 7235 was never false</span></span></p>
    <p class="par run show_par"><span class="n"><a id="t7236" href="#t7236">7236</a></span><span class="t">        <span class="key">if</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_contain_var</span><span class="op">(</span><span class="nam">axes</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">7236&#x202F;&#x219B;&#x202F;7237</span><span class="annotate long">line 7236 didn't jump to line 7237, because the condition on line 7236 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7237" href="#t7237">7237</a></span><span class="t">            <span class="nam">inputs</span><span class="op">[</span><span class="str">"AxesTensorList"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_convert_to_tensor_list</span><span class="op">(</span><span class="nam">axes</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7238" href="#t7238">7238</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7239" href="#t7239">7239</a></span><span class="t">            <span class="nam">attrs</span><span class="op">[</span><span class="str">"axes"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">axes</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7240" href="#t7240">7240</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7241" href="#t7241">7241</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">input</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7242" href="#t7242">7242</a></span><span class="t">    <span class="nam">x_shape</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">input</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7243" href="#t7243">7243</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7244" href="#t7244">7244</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"unsqueeze2"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7245" href="#t7245">7245</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7246" href="#t7246">7246</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7247" href="#t7247">7247</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">,</span> <span class="str">"XShape"</span><span class="op">:</span> <span class="nam">x_shape</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7248" href="#t7248">7248</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7249" href="#t7249">7249</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7250" href="#t7250">7250</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7251" href="#t7251">7251</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7252" href="#t7252">7252</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7253" href="#t7253">7253</a></span><span class="t"><span class="key">def</span> <span class="nam">lod_reset</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">target_lod</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7254" href="#t7254">7254</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7255" href="#t7255">7255</a></span><span class="t"><span class="str">    Set LoD of :attr:`x` to a new one specified by :attr:`y` or</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7256" href="#t7256">7256</a></span><span class="t"><span class="str">    :attr:`target_lod`. When :attr:`y` provided, :attr:`y.lod` would be</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7257" href="#t7257">7257</a></span><span class="t"><span class="str">    considered as target LoD first, otherwise :attr:`y.data` would be</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7258" href="#t7258">7258</a></span><span class="t"><span class="str">    considered as target LoD. If :attr:`y` is not provided, target LoD should</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7259" href="#t7259">7259</a></span><span class="t"><span class="str">    be specified by :attr:`target_lod`. If target LoD is specified by</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7260" href="#t7260">7260</a></span><span class="t"><span class="str">    :attr:`y.data` or :attr:`target_lod`, only one level LoD is supported.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7261" href="#t7261">7261</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7262" href="#t7262">7262</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7263" href="#t7263">7263</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7264" href="#t7264">7264</a></span><span class="t"><span class="str">        * Example 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7265" href="#t7265">7265</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7266" href="#t7266">7266</a></span><span class="t"><span class="str">            Given a 1-level LoDTensor x:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7267" href="#t7267">7267</a></span><span class="t"><span class="str">                x.lod =  [[ 2,           3,                   1 ]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7268" href="#t7268">7268</a></span><span class="t"><span class="str">                x.data = [[1.0], [2.0], [3.0], [4.0], [5.0], [6.0]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7269" href="#t7269">7269</a></span><span class="t"><span class="str">                x.dims = [6, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7270" href="#t7270">7270</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7271" href="#t7271">7271</a></span><span class="t"><span class="str">            target_lod: [4, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7272" href="#t7272">7272</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7273" href="#t7273">7273</a></span><span class="t"><span class="str">            then we get a 1-level LoDTensor:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7274" href="#t7274">7274</a></span><span class="t"><span class="str">                out.lod =  [[4,                          2]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7275" href="#t7275">7275</a></span><span class="t"><span class="str">                out.data = [[1.0], [2.0], [3.0], [4.0], [5.0], [6.0]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7276" href="#t7276">7276</a></span><span class="t"><span class="str">                out.dims = [6, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7277" href="#t7277">7277</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7278" href="#t7278">7278</a></span><span class="t"><span class="str">        * Example 2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7279" href="#t7279">7279</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7280" href="#t7280">7280</a></span><span class="t"><span class="str">            Given a 1-level LoDTensor x:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7281" href="#t7281">7281</a></span><span class="t"><span class="str">                x.lod =  [[2,            3,                   1]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7282" href="#t7282">7282</a></span><span class="t"><span class="str">                x.data = [[1.0], [2.0], [3.0], [4.0], [5.0], [6.0]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7283" href="#t7283">7283</a></span><span class="t"><span class="str">                x.dims = [6, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7284" href="#t7284">7284</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7285" href="#t7285">7285</a></span><span class="t"><span class="str">            y is a Tensor:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7286" href="#t7286">7286</a></span><span class="t"><span class="str">                y.data = [[2, 4]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7287" href="#t7287">7287</a></span><span class="t"><span class="str">                y.dims = [1, 3]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7288" href="#t7288">7288</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7289" href="#t7289">7289</a></span><span class="t"><span class="str">            then we get a 1-level LoDTensor:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7290" href="#t7290">7290</a></span><span class="t"><span class="str">                out.lod =  [[2,            4]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7291" href="#t7291">7291</a></span><span class="t"><span class="str">                out.data = [[1.0], [2.0], [3.0], [4.0], [5.0], [6.0]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7292" href="#t7292">7292</a></span><span class="t"><span class="str">                out.dims = [6, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7293" href="#t7293">7293</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7294" href="#t7294">7294</a></span><span class="t"><span class="str">        * Example 3:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7295" href="#t7295">7295</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7296" href="#t7296">7296</a></span><span class="t"><span class="str">            Given a 1-level LoDTensor x:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7297" href="#t7297">7297</a></span><span class="t"><span class="str">                x.lod =  [[2,            3,                   1]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7298" href="#t7298">7298</a></span><span class="t"><span class="str">                x.data = [[1.0], [2.0], [3.0], [4.0], [5.0], [6.0]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7299" href="#t7299">7299</a></span><span class="t"><span class="str">                x.dims = [6, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7300" href="#t7300">7300</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7301" href="#t7301">7301</a></span><span class="t"><span class="str">            y is a 2-level LoDTensor:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7302" href="#t7302">7302</a></span><span class="t"><span class="str">                y.lod =  [[2, 2], [2, 2, 1, 1]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7303" href="#t7303">7303</a></span><span class="t"><span class="str">                y.data = [[1.1], [2.1], [3.1], [4.1], [5.1], [6.1]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7304" href="#t7304">7304</a></span><span class="t"><span class="str">                y.dims = [6, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7305" href="#t7305">7305</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7306" href="#t7306">7306</a></span><span class="t"><span class="str">            then we get a 2-level LoDTensor:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7307" href="#t7307">7307</a></span><span class="t"><span class="str">                out.lod =  [[2, 2], [2, 2, 1, 1]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7308" href="#t7308">7308</a></span><span class="t"><span class="str">                out.data = [[1.0], [2.0], [3.0], [4.0], [5.0], [6.0]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7309" href="#t7309">7309</a></span><span class="t"><span class="str">                out.dims = [6, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7310" href="#t7310">7310</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7311" href="#t7311">7311</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7312" href="#t7312">7312</a></span><span class="t"><span class="str">        x (Variable): Input variable which could be a Tensor or LoDTensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7313" href="#t7313">7313</a></span><span class="t"><span class="str">                      The data type should be int32, int64, float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7314" href="#t7314">7314</a></span><span class="t"><span class="str">        y (Variable, optional): If provided, output's LoD would be derived from :attr:`y`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7315" href="#t7315">7315</a></span><span class="t"><span class="str">                                If y's lod level>0, the data type can be any type.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7316" href="#t7316">7316</a></span><span class="t"><span class="str">                                If y's lod level=0, the data type should be int32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7317" href="#t7317">7317</a></span><span class="t"><span class="str">        target_lod (list|tuple, optional): One level LoD which should be considered</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7318" href="#t7318">7318</a></span><span class="t"><span class="str">                                      as target LoD when :attr:`y` not provided.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7319" href="#t7319">7319</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7320" href="#t7320">7320</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7321" href="#t7321">7321</a></span><span class="t"><span class="str">        Variable: Output variable with LoD specified by this layer.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7322" href="#t7322">7322</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7323" href="#t7323">7323</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7324" href="#t7324">7324</a></span><span class="t"><span class="str">        ValueError: If :attr:`y` and :attr:`target_lod` are both None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7325" href="#t7325">7325</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7326" href="#t7326">7326</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7327" href="#t7327">7327</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7328" href="#t7328">7328</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7329" href="#t7329">7329</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7330" href="#t7330">7330</a></span><span class="t"><span class="str">            x = fluid.layers.data(name='x', shape=[10])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7331" href="#t7331">7331</a></span><span class="t"><span class="str">            y = fluid.layers.data(name='y', shape=[10, 20], lod_level=2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7332" href="#t7332">7332</a></span><span class="t"><span class="str">            out = fluid.layers.lod_reset(x=x, y=y)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7333" href="#t7333">7333</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7334" href="#t7334">7334</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7335" href="#t7335">7335</a></span><span class="t">        <span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'lod_reset'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7336" href="#t7336">7336</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7337" href="#t7337">7337</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"lod_reset"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7338" href="#t7338">7338</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7339" href="#t7339">7339</a></span><span class="t">    <span class="key">if</span> <span class="nam">y</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7340" href="#t7340">7340</a></span><span class="t">        <span class="nam">check_type</span><span class="op">(</span><span class="nam">y</span><span class="op">,</span> <span class="str">'y'</span><span class="op">,</span> <span class="op">(</span><span class="nam">Variable</span><span class="op">)</span><span class="op">,</span> <span class="str">'lod_reset'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7341" href="#t7341">7341</a></span><span class="t">        <span class="com"># TODO: check y.lod_level = 0 dtype</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7342" href="#t7342">7342</a></span><span class="t">        <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7343" href="#t7343">7343</a></span><span class="t">            <span class="nam">type</span><span class="op">=</span><span class="str">"lod_reset"</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">,</span> <span class="str">'Y'</span><span class="op">:</span> <span class="nam">y</span><span class="op">}</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7344" href="#t7344">7344</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7345" href="#t7345">7345</a></span><span class="t">    <span class="key">elif</span> <span class="nam">target_lod</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7346" href="#t7346">7346</a></span><span class="t">        <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7347" href="#t7347">7347</a></span><span class="t">            <span class="nam">type</span><span class="op">=</span><span class="str">"lod_reset"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7348" href="#t7348">7348</a></span><span class="t">            <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7349" href="#t7349">7349</a></span><span class="t">            <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'target_lod'</span><span class="op">:</span> <span class="nam">target_lod</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7350" href="#t7350">7350</a></span><span class="t">            <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7351" href="#t7351">7351</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7352" href="#t7352">7352</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7353" href="#t7353">7353</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"y and target_lod should not be both none."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7354" href="#t7354">7354</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7355" href="#t7355">7355</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7356" href="#t7356">7356</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7357" href="#t7357">7357</a></span><span class="t"><span class="key">def</span> <span class="nam">lod_append</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">level</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7358" href="#t7358">7358</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7359" href="#t7359">7359</a></span><span class="t"><span class="str">    Append level to LoD of :attr:`x`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7360" href="#t7360">7360</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7361" href="#t7361">7361</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7362" href="#t7362">7362</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7363" href="#t7363">7363</a></span><span class="t"><span class="str">        * Example 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7364" href="#t7364">7364</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7365" href="#t7365">7365</a></span><span class="t"><span class="str">            given a 1-level LoDTensor x:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7366" href="#t7366">7366</a></span><span class="t"><span class="str">                x.lod =  [[ 2,           3,                   1 ]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7367" href="#t7367">7367</a></span><span class="t"><span class="str">                x.data = [[1.0], [2.0], [3.0], [4.0], [5.0], [6.0]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7368" href="#t7368">7368</a></span><span class="t"><span class="str">                x.dims = [6, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7369" href="#t7369">7369</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7370" href="#t7370">7370</a></span><span class="t"><span class="str">            level: [1, 1, 1, 1, 1, 1, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7371" href="#t7371">7371</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7372" href="#t7372">7372</a></span><span class="t"><span class="str">            then we get a 2-level LoDTensor:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7373" href="#t7373">7373</a></span><span class="t"><span class="str">                x.lod =  [[ 2, 3, 1 ], [1, 1, 1, 1, 1, 1]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7374" href="#t7374">7374</a></span><span class="t"><span class="str">                x.data = [[1.0], [2.0], [3.0], [4.0], [5.0], [6.0]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7375" href="#t7375">7375</a></span><span class="t"><span class="str">                x.dims = [6, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7376" href="#t7376">7376</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7377" href="#t7377">7377</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7378" href="#t7378">7378</a></span><span class="t"><span class="str">        x (Variable): Input variable which could be a tensor or LoDTensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7379" href="#t7379">7379</a></span><span class="t"><span class="str">                      The data type should be int32, int64, float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7380" href="#t7380">7380</a></span><span class="t"><span class="str">        level (list|tuple|Variable, optional): The LoD level to be appended into LoD of x.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7381" href="#t7381">7381</a></span><span class="t"><span class="str">                                               If level is variable and its lod level>0, the data type can be any type.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7382" href="#t7382">7382</a></span><span class="t"><span class="str">                                               If level is variable and its lod level=0, the data type should be int32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7383" href="#t7383">7383</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7384" href="#t7384">7384</a></span><span class="t"><span class="str">        Variable: Output variable with new LoD level.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7385" href="#t7385">7385</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7386" href="#t7386">7386</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7387" href="#t7387">7387</a></span><span class="t"><span class="str">        ValueError: If :attr:`y` is None or and :attr:`level` is not Iterator.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7388" href="#t7388">7388</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7389" href="#t7389">7389</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7390" href="#t7390">7390</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7391" href="#t7391">7391</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7392" href="#t7392">7392</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7393" href="#t7393">7393</a></span><span class="t"><span class="str">            x = fluid.layers.data(name='x', shape=[6, 10], lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7394" href="#t7394">7394</a></span><span class="t"><span class="str">            out = fluid.layers.lod_append(x, [1,1,1,1,1,1])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7395" href="#t7395">7395</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7396" href="#t7396">7396</a></span><span class="t">    <span class="key">try</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7397" href="#t7397">7397</a></span><span class="t">        <span class="key">from</span> <span class="nam">collections</span><span class="op">.</span><span class="nam">abc</span> <span class="key">import</span> <span class="nam">Iterable</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7398" href="#t7398">7398</a></span><span class="t">    <span class="key">except</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7399" href="#t7399">7399</a></span><span class="t">        <span class="key">from</span> <span class="nam">collections</span> <span class="key">import</span> <span class="nam">Iterable</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7400" href="#t7400">7400</a></span><span class="t">    <span class="key">if</span> <span class="nam">x</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7401" href="#t7401">7401</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"Input(x) can't be None."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7402" href="#t7402">7402</a></span><span class="t">    <span class="key">if</span> <span class="op">(</span><span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">level</span><span class="op">,</span> <span class="nam">Iterable</span><span class="op">)</span><span class="op">)</span> <span class="key">and</span> <span class="op">(</span><span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">level</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7403" href="#t7403">7403</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"Input(level) must be list, tuple or Variable."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7404" href="#t7404">7404</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7405" href="#t7405">7405</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7406" href="#t7406">7406</a></span><span class="t">        <span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'lod_append'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7407" href="#t7407">7407</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7408" href="#t7408">7408</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7409" href="#t7409">7409</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"lod_append"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7410" href="#t7410">7410</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7411" href="#t7411">7411</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7412" href="#t7412">7412</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7413" href="#t7413">7413</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'append'</span><span class="op">:</span> <span class="key">True</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7414" href="#t7414">7414</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7415" href="#t7415">7415</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">level</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7416" href="#t7416">7416</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">'Y'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">level</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7417" href="#t7417">7417</a></span><span class="t">        <span class="com"># TODO: check y.lod_level = 0 dtype</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7418" href="#t7418">7418</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7419" href="#t7419">7419</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">'target_lod'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">level</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7420" href="#t7420">7420</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7421" href="#t7421">7421</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"lod_reset"</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7422" href="#t7422">7422</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7423" href="#t7423">7423</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7424" href="#t7424">7424</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7425" href="#t7425">7425</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7426" href="#t7426">7426</a></span><span class="t"><span class="key">def</span> <span class="nam">lrn</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7427" href="#t7427">7427</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span> <span class="nam">n</span><span class="op">=</span><span class="num">5</span><span class="op">,</span> <span class="nam">k</span><span class="op">=</span><span class="num">1.0</span><span class="op">,</span> <span class="nam">alpha</span><span class="op">=</span><span class="num">1e-4</span><span class="op">,</span> <span class="nam">beta</span><span class="op">=</span><span class="num">0.75</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">data_format</span><span class="op">=</span><span class="str">'NCHW'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7428" href="#t7428">7428</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7429" href="#t7429">7429</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7430" href="#t7430">7430</a></span><span class="t"><span class="str">    :alias_main: paddle.nn.functional.lrn</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7431" href="#t7431">7431</a></span><span class="t"><span class="str">        :alias: paddle.nn.functional.lrn,paddle.nn.functional.norm.lrn</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7432" href="#t7432">7432</a></span><span class="t"><span class="str">        :old_api: paddle.fluid.layers.lrn</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7433" href="#t7433">7433</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7434" href="#t7434">7434</a></span><span class="t"><span class="str">    This operator implements the Local Response Normalization Layer.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7435" href="#t7435">7435</a></span><span class="t"><span class="str">    This layer performs a type of "lateral inhibition" by normalizing over local input regions.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7436" href="#t7436">7436</a></span><span class="t"><span class="str">    For more information, please refer to `ImageNet Classification with Deep Convolutional Neural Networks &lt;https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf>`_</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7437" href="#t7437">7437</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7438" href="#t7438">7438</a></span><span class="t"><span class="str">    The formula is as follows:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7439" href="#t7439">7439</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7440" href="#t7440">7440</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7441" href="#t7441">7441</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7442" href="#t7442">7442</a></span><span class="t"><span class="str">        Output(i, x, y) = Input(i, x, y) / \\left(k + \\alpha \\sum\\limits^{\\min(C-1, i + n/2)}_{j = \\max(0, i - n/2)}(Input(j, x, y))^2\\right)^{\\beta}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7443" href="#t7443">7443</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7444" href="#t7444">7444</a></span><span class="t"><span class="str">    In the above equation:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7445" href="#t7445">7445</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7446" href="#t7446">7446</a></span><span class="t"><span class="str">    - :math:`n` : The number of channels to sum over.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7447" href="#t7447">7447</a></span><span class="t"><span class="str">    - :math:`k` : The offset (avoid being divided by 0).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7448" href="#t7448">7448</a></span><span class="t"><span class="str">    - :math:`\\alpha` : The scaling parameter.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7449" href="#t7449">7449</a></span><span class="t"><span class="str">    - :math:`\\beta` : The exponent parameter.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7450" href="#t7450">7450</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7451" href="#t7451">7451</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7452" href="#t7452">7452</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7453" href="#t7453">7453</a></span><span class="t"><span class="str">        input (Variable): Input feature, 4D-Tensor with the shape of [N,C,H,W] or [N, H, W, C],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7454" href="#t7454">7454</a></span><span class="t"><span class="str">            where N is the batch size, C is the input channel, H is Height, W is weight. The data</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7455" href="#t7455">7455</a></span><span class="t"><span class="str">            type is float32. The rank of this tensor must be 4, otherwise it will raise ValueError.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7456" href="#t7456">7456</a></span><span class="t"><span class="str">        n (int, optional): The number of channels to sum over. Default: 5</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7457" href="#t7457">7457</a></span><span class="t"><span class="str">        k (float, optional): An offset, positive. Default: 1.0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7458" href="#t7458">7458</a></span><span class="t"><span class="str">        alpha (float, optional): The scaling parameter, positive. Default:1e-4</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7459" href="#t7459">7459</a></span><span class="t"><span class="str">        beta (float, optional): The exponent, positive. Default:0.75</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7460" href="#t7460">7460</a></span><span class="t"><span class="str">        name (str, optional): The default value is None. Normally there is no need for user to set</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7461" href="#t7461">7461</a></span><span class="t"><span class="str">            this property. For more information, please refer to :ref:`api_guide_Name`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7462" href="#t7462">7462</a></span><span class="t"><span class="str">        data_format (str, optional): Specify the data format of the input, and the data format of the output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7463" href="#t7463">7463</a></span><span class="t"><span class="str">            will be consistent with that of the input. An optional string from: `"NCHW"`, `"NHWC"`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7464" href="#t7464">7464</a></span><span class="t"><span class="str">            The default is `"NCHW"`. When it is `"NCHW"`, the data is stored in the order of:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7465" href="#t7465">7465</a></span><span class="t"><span class="str">            `[batch_size, input_channels, input_height, input_width]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7466" href="#t7466">7466</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7467" href="#t7467">7467</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7468" href="#t7468">7468</a></span><span class="t"><span class="str">        Variable: A tensor variable storing the transformation result with the same shape and data type as input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7469" href="#t7469">7469</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7470" href="#t7470">7470</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7471" href="#t7471">7471</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7472" href="#t7472">7472</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7473" href="#t7473">7473</a></span><span class="t"><span class="str">    .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7474" href="#t7474">7474</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7475" href="#t7475">7475</a></span><span class="t"><span class="str">        import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7476" href="#t7476">7476</a></span><span class="t"><span class="str">        data = fluid.data(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7477" href="#t7477">7477</a></span><span class="t"><span class="str">            name="data", shape=[None, 3, 112, 112], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7478" href="#t7478">7478</a></span><span class="t"><span class="str">        lrn = fluid.layers.lrn(input=data)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7479" href="#t7479">7479</a></span><span class="t"><span class="str">        print(lrn.shape)  # [-1, 3, 112, 112]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7480" href="#t7480">7480</a></span><span class="t"><span class="str">        print(lrn.dtype)  # float32</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7481" href="#t7481">7481</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7482" href="#t7482">7482</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'lrn'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7483" href="#t7483">7483</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">]</span><span class="op">,</span> <span class="str">'lrn'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7484" href="#t7484">7484</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7485" href="#t7485">7485</a></span><span class="t">    <span class="nam">input_shape</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7486" href="#t7486">7486</a></span><span class="t">    <span class="nam">dims</span> <span class="op">=</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input_shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7487" href="#t7487">7487</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7488" href="#t7488">7488</a></span><span class="t">    <span class="key">if</span> <span class="nam">dims</span> <span class="op">!=</span> <span class="num">4</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7489" href="#t7489">7489</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7490" href="#t7490">7490</a></span><span class="t">            <span class="str">"Input's dimension size of Op(lrn) must be 4, but received %d."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7491" href="#t7491">7491</a></span><span class="t">            <span class="op">%</span> <span class="op">(</span><span class="nam">dims</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7492" href="#t7492">7492</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7493" href="#t7493">7493</a></span><span class="t">    <span class="key">if</span> <span class="nam">data_format</span> <span class="key">not</span> <span class="key">in</span> <span class="op">[</span><span class="str">'NCHW'</span><span class="op">,</span> <span class="str">'NHWC'</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7494" href="#t7494">7494</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7495" href="#t7495">7495</a></span><span class="t">            <span class="str">"Attr(data_format) of Op(lrn) got wrong value: received "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7496" href="#t7496">7496</a></span><span class="t">            <span class="op">+</span> <span class="nam">data_format</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7497" href="#t7497">7497</a></span><span class="t">            <span class="op">+</span> <span class="str">" but only NCHW or NHWC supported."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7498" href="#t7498">7498</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7499" href="#t7499">7499</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7500" href="#t7500">7500</a></span><span class="t">    <span class="nam">mid_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7501" href="#t7501">7501</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7502" href="#t7502">7502</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7503" href="#t7503">7503</a></span><span class="t">    <span class="nam">lrn_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7504" href="#t7504">7504</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7505" href="#t7505">7505</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"lrn"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7506" href="#t7506">7506</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7507" href="#t7507">7507</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7508" href="#t7508">7508</a></span><span class="t">            <span class="str">"Out"</span><span class="op">:</span> <span class="nam">lrn_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7509" href="#t7509">7509</a></span><span class="t">            <span class="str">"MidOut"</span><span class="op">:</span> <span class="nam">mid_out</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7510" href="#t7510">7510</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7511" href="#t7511">7511</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7512" href="#t7512">7512</a></span><span class="t">            <span class="str">"n"</span><span class="op">:</span> <span class="nam">n</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7513" href="#t7513">7513</a></span><span class="t">            <span class="str">"k"</span><span class="op">:</span> <span class="nam">k</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7514" href="#t7514">7514</a></span><span class="t">            <span class="str">"alpha"</span><span class="op">:</span> <span class="nam">alpha</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7515" href="#t7515">7515</a></span><span class="t">            <span class="str">"beta"</span><span class="op">:</span> <span class="nam">beta</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7516" href="#t7516">7516</a></span><span class="t">            <span class="str">"data_format"</span><span class="op">:</span> <span class="nam">data_format</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7517" href="#t7517">7517</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7518" href="#t7518">7518</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7519" href="#t7519">7519</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7520" href="#t7520">7520</a></span><span class="t">    <span class="key">return</span> <span class="nam">lrn_out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7521" href="#t7521">7521</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7522" href="#t7522">7522</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7523" href="#t7523">7523</a></span><span class="t"><span class="key">def</span> <span class="nam">pad</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">paddings</span><span class="op">,</span> <span class="nam">pad_value</span><span class="op">=</span><span class="num">0.0</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7524" href="#t7524">7524</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7525" href="#t7525">7525</a></span><span class="t"><span class="str">    :alias_main: paddle.nn.functional.pad</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7526" href="#t7526">7526</a></span><span class="t"><span class="str">        :alias: paddle.nn.functional.pad,paddle.nn.functional.common.pad</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7527" href="#t7527">7527</a></span><span class="t"><span class="str">        :old_api: paddle.fluid.layers.pad</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7528" href="#t7528">7528</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7529" href="#t7529">7529</a></span><span class="t"><span class="str">    This op will pad a tensor with a constant value given by :attr:`pad_value`, and the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7530" href="#t7530">7530</a></span><span class="t"><span class="str">    padded shape is specified by :attr:`paddings`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7531" href="#t7531">7531</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7532" href="#t7532">7532</a></span><span class="t"><span class="str">    Specifically, the number of values padded before the elements of :attr:`x`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7533" href="#t7533">7533</a></span><span class="t"><span class="str">    in dimension :attr:`i` is indicated by :attr:`paddings[2*i]`, and the number</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7534" href="#t7534">7534</a></span><span class="t"><span class="str">    of values padded after the elements of :attr:`x` in dimension :attr:`i` is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7535" href="#t7535">7535</a></span><span class="t"><span class="str">    indicated by :attr:`paddings[2*i+1]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7536" href="#t7536">7536</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7537" href="#t7537">7537</a></span><span class="t"><span class="str">    See below for an example.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7538" href="#t7538">7538</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7539" href="#t7539">7539</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7540" href="#t7540">7540</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7541" href="#t7541">7541</a></span><span class="t"><span class="str">        Given:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7542" href="#t7542">7542</a></span><span class="t"><span class="str">            x = [[1, 2], [3, 4]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7543" href="#t7543">7543</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7544" href="#t7544">7544</a></span><span class="t"><span class="str">            paddings = [0, 1, 1, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7545" href="#t7545">7545</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7546" href="#t7546">7546</a></span><span class="t"><span class="str">            pad_value = 0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7547" href="#t7547">7547</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7548" href="#t7548">7548</a></span><span class="t"><span class="str">        Return:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7549" href="#t7549">7549</a></span><span class="t"><span class="str">            out = [[0, 1, 2, 0, 0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7550" href="#t7550">7550</a></span><span class="t"><span class="str">                   [0, 3, 4, 0, 0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7551" href="#t7551">7551</a></span><span class="t"><span class="str">                   [0, 0, 0, 0, 0]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7552" href="#t7552">7552</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7553" href="#t7553">7553</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7554" href="#t7554">7554</a></span><span class="t"><span class="str">        x (Variable): Tensor, data type is float32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7555" href="#t7555">7555</a></span><span class="t"><span class="str">        paddings (list): A list of integers. Its elements specify the padded</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7556" href="#t7556">7556</a></span><span class="t"><span class="str">                         width before and after each dimension in turn.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7557" href="#t7557">7557</a></span><span class="t"><span class="str">                         The length of :attr:`paddings` must be equal to</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7558" href="#t7558">7558</a></span><span class="t"><span class="str">                         :math:`rank(x) \\times 2`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7559" href="#t7559">7559</a></span><span class="t"><span class="str">        pad_value (float): The constant value used to pad.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7560" href="#t7560">7560</a></span><span class="t"><span class="str">        name(str, optional): The default value is None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7561" href="#t7561">7561</a></span><span class="t"><span class="str">                             Normally there is no need for user to set this property.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7562" href="#t7562">7562</a></span><span class="t"><span class="str">                             For more information, please refer to :ref:`api_guide_Name`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7563" href="#t7563">7563</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7564" href="#t7564">7564</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7565" href="#t7565">7565</a></span><span class="t"><span class="str">        The padded tensor, with the same data type and rank as :attr:`x`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7566" href="#t7566">7566</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7567" href="#t7567">7567</a></span><span class="t"><span class="str">    Return Type:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7568" href="#t7568">7568</a></span><span class="t"><span class="str">        Variable</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7569" href="#t7569">7569</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7570" href="#t7570">7570</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7571" href="#t7571">7571</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7572" href="#t7572">7572</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7573" href="#t7573">7573</a></span><span class="t"><span class="str">            # x is a rank 2 tensor variable</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7574" href="#t7574">7574</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7575" href="#t7575">7575</a></span><span class="t"><span class="str">            x = fluid.data(name='data', shape=[300, 300], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7576" href="#t7576">7576</a></span><span class="t"><span class="str">            out = fluid.layers.pad(x=x, paddings=[0, 1, 1, 2], pad_value=0.)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7577" href="#t7577">7577</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7578" href="#t7578">7578</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7579" href="#t7579">7579</a></span><span class="t">        <span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7580" href="#t7580">7580</a></span><span class="t">        <span class="str">'x'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7581" href="#t7581">7581</a></span><span class="t">        <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7582" href="#t7582">7582</a></span><span class="t">            <span class="str">'float16'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7583" href="#t7583">7583</a></span><span class="t">            <span class="str">'float32'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7584" href="#t7584">7584</a></span><span class="t">            <span class="str">'float64'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7585" href="#t7585">7585</a></span><span class="t">            <span class="str">'int32'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7586" href="#t7586">7586</a></span><span class="t">            <span class="str">'int64'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7587" href="#t7587">7587</a></span><span class="t">            <span class="str">'complex64'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7588" href="#t7588">7588</a></span><span class="t">            <span class="str">'complex128'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7589" href="#t7589">7589</a></span><span class="t">        <span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7590" href="#t7590">7590</a></span><span class="t">        <span class="str">"pad"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7591" href="#t7591">7591</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7592" href="#t7592">7592</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7593" href="#t7593">7593</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">pad_value</span><span class="op">,</span> <span class="str">'pad_value'</span><span class="op">,</span> <span class="op">(</span><span class="nam">float</span><span class="op">,</span> <span class="nam">int</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">,</span> <span class="str">'pad'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t7594" href="#t7594">7594</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">pad_value</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">7594&#x202F;&#x219B;&#x202F;7595</span><span class="annotate long">line 7594 didn't jump to line 7595, because the condition on line 7594 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7595" href="#t7595">7595</a></span><span class="t">        <span class="nam">pad_value</span> <span class="op">=</span> <span class="nam">float</span><span class="op">(</span><span class="nam">pad_value</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7596" href="#t7596">7596</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7597" href="#t7597">7597</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'pad'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7598" href="#t7598">7598</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="nam">input_param_name</span><span class="op">=</span><span class="str">'x'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7599" href="#t7599">7599</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7600" href="#t7600">7600</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7601" href="#t7601">7601</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'pad'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7602" href="#t7602">7602</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7603" href="#t7603">7603</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7604" href="#t7604">7604</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'paddings'</span><span class="op">:</span> <span class="nam">paddings</span><span class="op">,</span> <span class="str">'pad_value'</span><span class="op">:</span> <span class="nam">pad_value</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7605" href="#t7605">7605</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7606" href="#t7606">7606</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7607" href="#t7607">7607</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7608" href="#t7608">7608</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7609" href="#t7609">7609</a></span><span class="t"><span class="key">def</span> <span class="nam">pad_constant_like</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">pad_value</span><span class="op">=</span><span class="num">0.0</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7610" href="#t7610">7610</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7611" href="#t7611">7611</a></span><span class="t"><span class="str">    Pad :attr:`y` with :attr:`pad_value`, the number of values padded to</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7612" href="#t7612">7612</a></span><span class="t"><span class="str">    the edges of each axis is specified by the difference of the shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7613" href="#t7613">7613</a></span><span class="t"><span class="str">    of :attr:`x` and :attr:`y` . ((0, shape_x_0 - shape_y_0), ... (0, shape_x_n - shape_y_n))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7614" href="#t7614">7614</a></span><span class="t"><span class="str">    specify padding widths for each axis. The input should be a k-D tensor(k > 0 and k &lt; 7).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7615" href="#t7615">7615</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7616" href="#t7616">7616</a></span><span class="t"><span class="str">    See below for an example.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7617" href="#t7617">7617</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7618" href="#t7618">7618</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7619" href="#t7619">7619</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7620" href="#t7620">7620</a></span><span class="t"><span class="str">        Given:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7621" href="#t7621">7621</a></span><span class="t"><span class="str">            X = [[[[ 0,  1,  2],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7622" href="#t7622">7622</a></span><span class="t"><span class="str">                   [ 3,  4,  5]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7623" href="#t7623">7623</a></span><span class="t"><span class="str">                  [[ 6,  7,  8],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7624" href="#t7624">7624</a></span><span class="t"><span class="str">                   [ 9, 10, 11]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7625" href="#t7625">7625</a></span><span class="t"><span class="str">                  [[12, 13, 14],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7626" href="#t7626">7626</a></span><span class="t"><span class="str">                   [15, 16, 17]]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7627" href="#t7627">7627</a></span><span class="t"><span class="str">                 [[[18, 19, 20],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7628" href="#t7628">7628</a></span><span class="t"><span class="str">                   [21, 22, 23]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7629" href="#t7629">7629</a></span><span class="t"><span class="str">                  [[24, 25, 26],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7630" href="#t7630">7630</a></span><span class="t"><span class="str">                   [27, 28, 29]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7631" href="#t7631">7631</a></span><span class="t"><span class="str">                  [[30, 31, 32],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7632" href="#t7632">7632</a></span><span class="t"><span class="str">                   [33, 34, 35]]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7633" href="#t7633">7633</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7634" href="#t7634">7634</a></span><span class="t"><span class="str">            X.shape = (2, 3, 2, 3)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7635" href="#t7635">7635</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7636" href="#t7636">7636</a></span><span class="t"><span class="str">            Y = [[[[35, 36, 37]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7637" href="#t7637">7637</a></span><span class="t"><span class="str">                  [[38, 39, 40]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7638" href="#t7638">7638</a></span><span class="t"><span class="str">                  [[41, 42, 43]]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7639" href="#t7639">7639</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7640" href="#t7640">7640</a></span><span class="t"><span class="str">            Y.shape = (1, 3, 1, 3)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7641" href="#t7641">7641</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7642" href="#t7642">7642</a></span><span class="t"><span class="str">        And</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7643" href="#t7643">7643</a></span><span class="t"><span class="str">            pad_value = 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7644" href="#t7644">7644</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7645" href="#t7645">7645</a></span><span class="t"><span class="str">        Return:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7646" href="#t7646">7646</a></span><span class="t"><span class="str">            Out = [[[[35, 36, 37],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7647" href="#t7647">7647</a></span><span class="t"><span class="str">                     [ 0,  0,  0]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7648" href="#t7648">7648</a></span><span class="t"><span class="str">                    [[38, 39, 40],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7649" href="#t7649">7649</a></span><span class="t"><span class="str">                     [ 0,  0,  0]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7650" href="#t7650">7650</a></span><span class="t"><span class="str">                    [[41, 42, 43],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7651" href="#t7651">7651</a></span><span class="t"><span class="str">                     [ 0,  0,  0]]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7652" href="#t7652">7652</a></span><span class="t"><span class="str">                   [[[ 0,  0,  0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7653" href="#t7653">7653</a></span><span class="t"><span class="str">                     [ 0,  0,  0]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7654" href="#t7654">7654</a></span><span class="t"><span class="str">                    [[ 0,  0,  0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7655" href="#t7655">7655</a></span><span class="t"><span class="str">                     [ 0,  0,  0]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7656" href="#t7656">7656</a></span><span class="t"><span class="str">                    [[ 0,  0,  0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7657" href="#t7657">7657</a></span><span class="t"><span class="str">                     [ 0,  0,  0]]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7658" href="#t7658">7658</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7659" href="#t7659">7659</a></span><span class="t"><span class="str">            Out.shape = [2, 3, 2, 3]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7660" href="#t7660">7660</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7661" href="#t7661">7661</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7662" href="#t7662">7662</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7663" href="#t7663">7663</a></span><span class="t"><span class="str">        x (Variable): Tensor, its shape specifies the shape of output.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7664" href="#t7664">7664</a></span><span class="t"><span class="str">        y (Variable): Tensor, its rank is the same with :attr:`x`, and for each dimension :math:`i` ,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7665" href="#t7665">7665</a></span><span class="t"><span class="str">                      :math:`y\_shape[i] &lt;= x\_shape[i]` . The data type can be float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7666" href="#t7666">7666</a></span><span class="t"><span class="str">        pad_value (float): The constant value used to pad.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7667" href="#t7667">7667</a></span><span class="t"><span class="str">        name(str, optional): The default value is None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7668" href="#t7668">7668</a></span><span class="t"><span class="str">                             Normally there is no need for user to set this property.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7669" href="#t7669">7669</a></span><span class="t"><span class="str">                             For more information, please refer to :ref:`api_guide_Name`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7670" href="#t7670">7670</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7671" href="#t7671">7671</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7672" href="#t7672">7672</a></span><span class="t"><span class="str">        The padded tensor, with the same shape as :attr:`x` and the same data type as :attr:`y`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7673" href="#t7673">7673</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7674" href="#t7674">7674</a></span><span class="t"><span class="str">    Return Type:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7675" href="#t7675">7675</a></span><span class="t"><span class="str">        Variable</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7676" href="#t7676">7676</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7677" href="#t7677">7677</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7678" href="#t7678">7678</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7679" href="#t7679">7679</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7680" href="#t7680">7680</a></span><span class="t"><span class="str">            # x is a rank 4 tensor variable, x.shape = (2, 3, 2, 3)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7681" href="#t7681">7681</a></span><span class="t"><span class="str">            # y is a rank 4 tensor variable, y.shape = (1, 3, 1, 3)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7682" href="#t7682">7682</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7683" href="#t7683">7683</a></span><span class="t"><span class="str">            x = fluid.data(name='x', shape=[2,3,2,3], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7684" href="#t7684">7684</a></span><span class="t"><span class="str">            y = fluid.data(name='y', shape=[1,3,1,3], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7685" href="#t7685">7685</a></span><span class="t"><span class="str">            out = fluid.layers.pad_constant_like(x=x, y=y, pad_value=0.)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7686" href="#t7686">7686</a></span><span class="t"><span class="str">            # out is a rank 4 tensor variable, and out.shape = [2, 3 ,2 , 3]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7687" href="#t7687">7687</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7688" href="#t7688">7688</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">(</span><span class="nam">Variable</span><span class="op">)</span><span class="op">,</span> <span class="str">'pad_constant_like'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7689" href="#t7689">7689</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7690" href="#t7690">7690</a></span><span class="t">        <span class="nam">y</span><span class="op">,</span> <span class="str">'y'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span> <span class="str">"pad_constant_like"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7691" href="#t7691">7691</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7692" href="#t7692">7692</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7693" href="#t7693">7693</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'pad_constant_like'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7694" href="#t7694">7694</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="nam">input_param_name</span><span class="op">=</span><span class="str">'y'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7695" href="#t7695">7695</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7696" href="#t7696">7696</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7697" href="#t7697">7697</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'pad_constant_like'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7698" href="#t7698">7698</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">,</span> <span class="str">'Y'</span><span class="op">:</span> <span class="nam">y</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7699" href="#t7699">7699</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7700" href="#t7700">7700</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'pad_value'</span><span class="op">:</span> <span class="nam">float</span><span class="op">(</span><span class="nam">pad_value</span><span class="op">)</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7701" href="#t7701">7701</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7702" href="#t7702">7702</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7703" href="#t7703">7703</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7704" href="#t7704">7704</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7705" href="#t7705">7705</a></span><span class="t"><span class="key">def</span> <span class="nam">label_smooth</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7706" href="#t7706">7706</a></span><span class="t">    <span class="nam">label</span><span class="op">,</span> <span class="nam">prior_dist</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">epsilon</span><span class="op">=</span><span class="num">0.1</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="str">"float32"</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7707" href="#t7707">7707</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7708" href="#t7708">7708</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7709" href="#t7709">7709</a></span><span class="t"><span class="str">    :alias_main: paddle.nn.functional.label_smooth</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7710" href="#t7710">7710</a></span><span class="t"><span class="str">        :alias: paddle.nn.functional.label_smooth,paddle.nn.functional.common.label_smooth</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7711" href="#t7711">7711</a></span><span class="t"><span class="str">        :old_api: paddle.fluid.layers.label_smooth</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7712" href="#t7712">7712</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7713" href="#t7713">7713</a></span><span class="t"><span class="str">    Label smoothing is a mechanism to regularize the classifier layer and is called</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7714" href="#t7714">7714</a></span><span class="t"><span class="str">    label-smoothing regularization (LSR).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7715" href="#t7715">7715</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7716" href="#t7716">7716</a></span><span class="t"><span class="str">    Label smoothing is proposed to encourage the model to be less confident,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7717" href="#t7717">7717</a></span><span class="t"><span class="str">    since optimizing the log-likelihood of the correct label directly may</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7718" href="#t7718">7718</a></span><span class="t"><span class="str">    cause overfitting and reduce the ability of the model to adapt. Label</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7719" href="#t7719">7719</a></span><span class="t"><span class="str">    smoothing replaces the ground-truth label :math:`y` with the weighted sum</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7720" href="#t7720">7720</a></span><span class="t"><span class="str">    of itself and some fixed distribution :math:`\mu`. For class :math:`k`,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7721" href="#t7721">7721</a></span><span class="t"><span class="str">    i.e.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7722" href="#t7722">7722</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7723" href="#t7723">7723</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7724" href="#t7724">7724</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7725" href="#t7725">7725</a></span><span class="t"><span class="str">        \\tilde{y_k} = (1 - \epsilon) * y_k + \epsilon * \mu_k,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7726" href="#t7726">7726</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7727" href="#t7727">7727</a></span><span class="t"><span class="str">    where :math:`1 - \epsilon` and :math:`\epsilon` are the weights</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7728" href="#t7728">7728</a></span><span class="t"><span class="str">    respectively, and :math:`\\tilde{y}_k` is the smoothed label. Usually</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7729" href="#t7729">7729</a></span><span class="t"><span class="str">    uniform distribution is used for :math:`\mu`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7730" href="#t7730">7730</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7731" href="#t7731">7731</a></span><span class="t"><span class="str">    See more details about label smoothing in https://arxiv.org/abs/1512.00567.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7732" href="#t7732">7732</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7733" href="#t7733">7733</a></span><span class="t"><span class="str">    Parameters:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7734" href="#t7734">7734</a></span><span class="t"><span class="str">        label(Variable): The input variable containing the label data. The</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7735" href="#t7735">7735</a></span><span class="t"><span class="str">                        label data should use one-hot representation. It's</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7736" href="#t7736">7736</a></span><span class="t"><span class="str">                        a multidimensional tensor with a shape of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7737" href="#t7737">7737</a></span><span class="t"><span class="str">                        :math:`[N_1, ..., Depth]`, where Depth is class number. The dtype can be "float32" and "float64".</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7738" href="#t7738">7738</a></span><span class="t"><span class="str">        prior_dist(Variable, optional): The prior distribution to be used to smooth</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7739" href="#t7739">7739</a></span><span class="t"><span class="str">                        labels. If not provided, an uniform distribution</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7740" href="#t7740">7740</a></span><span class="t"><span class="str">                        is used. It's a multidimensional tensor with a shape of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7741" href="#t7741">7741</a></span><span class="t"><span class="str">                        :math:`[1, class\_num]` . The default value is None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7742" href="#t7742">7742</a></span><span class="t"><span class="str">        epsilon(float, optional): The weight used to mix up the original ground-truth</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7743" href="#t7743">7743</a></span><span class="t"><span class="str">                        distribution and the fixed distribution. The default value is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7744" href="#t7744">7744</a></span><span class="t"><span class="str">                        0.1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7745" href="#t7745">7745</a></span><span class="t"><span class="str">        dtype(np.dtype|core.VarDesc.VarType|str, optional): The data type can be set</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7746" href="#t7746">7746</a></span><span class="t"><span class="str">                        as 'float32', 'float64'. The default value is 'float32'.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7747" href="#t7747">7747</a></span><span class="t"><span class="str">        name(str, optional): The default value is None. Normally there is no need for user</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7748" href="#t7748">7748</a></span><span class="t"><span class="str">                        to set this property. For more information, please refer to</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7749" href="#t7749">7749</a></span><span class="t"><span class="str">                        :ref:`api_guide_Name`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7750" href="#t7750">7750</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7751" href="#t7751">7751</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7752" href="#t7752">7752</a></span><span class="t"><span class="str">        Variable: The tensor variable containing the smoothed labels.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7753" href="#t7753">7753</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7754" href="#t7754">7754</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7755" href="#t7755">7755</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7756" href="#t7756">7756</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7757" href="#t7757">7757</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7758" href="#t7758">7758</a></span><span class="t"><span class="str">            import paddle.fluid.layers as layers</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7759" href="#t7759">7759</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7760" href="#t7760">7760</a></span><span class="t"><span class="str">            label = layers.data(name="label", shape=[1], dtype="int32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7761" href="#t7761">7761</a></span><span class="t"><span class="str">            one_hot_label = layers.one_hot(input=label, depth=10)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7762" href="#t7762">7762</a></span><span class="t"><span class="str">            smooth_label = layers.label_smooth(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7763" href="#t7763">7763</a></span><span class="t"><span class="str">                label=one_hot_label, epsilon=0.1, dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7764" href="#t7764">7764</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7765" href="#t7765">7765</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7766" href="#t7766">7766</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">label_smooth</span><span class="op">(</span><span class="nam">label</span><span class="op">,</span> <span class="nam">prior_dist</span><span class="op">,</span> <span class="nam">float</span><span class="op">(</span><span class="nam">epsilon</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7767" href="#t7767">7767</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7768" href="#t7768">7768</a></span><span class="t">    <span class="key">if</span> <span class="nam">epsilon</span> <span class="op">></span> <span class="num">1.0</span> <span class="key">or</span> <span class="nam">epsilon</span> <span class="op">&lt;</span> <span class="num">0.0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7769" href="#t7769">7769</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"The value of epsilon must be between 0 and 1."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7770" href="#t7770">7770</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7771" href="#t7771">7771</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7772" href="#t7772">7772</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">label_smooth</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7773" href="#t7773">7773</a></span><span class="t">            <span class="nam">label</span><span class="op">,</span> <span class="nam">prior_dist</span><span class="op">,</span> <span class="str">'epsilon'</span><span class="op">,</span> <span class="nam">float</span><span class="op">(</span><span class="nam">epsilon</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7774" href="#t7774">7774</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7775" href="#t7775">7775</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7776" href="#t7776">7776</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7777" href="#t7777">7777</a></span><span class="t">        <span class="nam">label</span><span class="op">,</span> <span class="str">'label'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'label_smooth'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7778" href="#t7778">7778</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7779" href="#t7779">7779</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7780" href="#t7780">7780</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"label_smooth"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7781" href="#t7781">7781</a></span><span class="t">    <span class="nam">label</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7782" href="#t7782">7782</a></span><span class="t">    <span class="nam">smooth_label</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7783" href="#t7783">7783</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7784" href="#t7784">7784</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"label_smooth"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7785" href="#t7785">7785</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">label</span><span class="op">,</span> <span class="str">"PriorDist"</span><span class="op">:</span> <span class="nam">prior_dist</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7786" href="#t7786">7786</a></span><span class="t">        <span class="key">if</span> <span class="nam">prior_dist</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7787" href="#t7787">7787</a></span><span class="t">        <span class="key">else</span> <span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">label</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7788" href="#t7788">7788</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">smooth_label</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7789" href="#t7789">7789</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">"epsilon"</span><span class="op">:</span> <span class="nam">float</span><span class="op">(</span><span class="nam">epsilon</span><span class="op">)</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7790" href="#t7790">7790</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7791" href="#t7791">7791</a></span><span class="t">    <span class="key">return</span> <span class="nam">smooth_label</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7792" href="#t7792">7792</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7793" href="#t7793">7793</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7794" href="#t7794">7794</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7795" href="#t7795">7795</a></span><span class="t"><span class="key">def</span> <span class="nam">roi_pool</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7796" href="#t7796">7796</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7797" href="#t7797">7797</a></span><span class="t">    <span class="nam">rois</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7798" href="#t7798">7798</a></span><span class="t">    <span class="nam">pooled_height</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7799" href="#t7799">7799</a></span><span class="t">    <span class="nam">pooled_width</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7800" href="#t7800">7800</a></span><span class="t">    <span class="nam">spatial_scale</span><span class="op">=</span><span class="num">1.0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7801" href="#t7801">7801</a></span><span class="t">    <span class="nam">rois_num</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7802" href="#t7802">7802</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7803" href="#t7803">7803</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7804" href="#t7804">7804</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7805" href="#t7805">7805</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7806" href="#t7806">7806</a></span><span class="t"><span class="str">    This operator implements the roi_pooling layer.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7807" href="#t7807">7807</a></span><span class="t"><span class="str">    Region of interest pooling (also known as RoI pooling) is to perform max pooling on inputs of nonuniform sizes to obtain fixed-size feature maps (e.g. 7*7).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7808" href="#t7808">7808</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7809" href="#t7809">7809</a></span><span class="t"><span class="str">    The operator has three steps:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7810" href="#t7810">7810</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7811" href="#t7811">7811</a></span><span class="t"><span class="str">        1. Dividing each region proposal into equal-sized sections with the pooled_width and pooled_height;</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7812" href="#t7812">7812</a></span><span class="t"><span class="str">        2. Finding the largest value in each section;</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7813" href="#t7813">7813</a></span><span class="t"><span class="str">        3. Copying these max values to the output buffer.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7814" href="#t7814">7814</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7815" href="#t7815">7815</a></span><span class="t"><span class="str">    For more information, please refer to https://stackoverflow.com/questions/43430056/what-is-roi-layer-in-fast-rcnn</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7816" href="#t7816">7816</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7817" href="#t7817">7817</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7818" href="#t7818">7818</a></span><span class="t"><span class="str">        input (Variable): Input feature, 4D-Tensor with the shape of [N,C,H,W], where N is the batch size, C is the input channel, H is Height, W is weight. The data type is float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7819" href="#t7819">7819</a></span><span class="t"><span class="str">        rois (Variable): ROIs (Regions of Interest) to pool over. 2D-LoDTensor with the shape of [num_rois,4], the lod level is 1. Given as [[x1, y1, x2, y2], ...], (x1, y1) is the top left coordinates, and (x2, y2) is the bottom right coordinates.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7820" href="#t7820">7820</a></span><span class="t"><span class="str">        pooled_height (int, optional): The pooled output height, data type is int32. Default: 1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7821" href="#t7821">7821</a></span><span class="t"><span class="str">        pooled_width (int, optional): The pooled output height, data type is int32. Default: 1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7822" href="#t7822">7822</a></span><span class="t"><span class="str">        spatial_scale (float, optional): Multiplicative spatial scale factor to translate ROI coords from their input scale to the scale used when pooling. Default: 1.0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7823" href="#t7823">7823</a></span><span class="t"><span class="str">        rois_num (Tensor): The number of RoIs in each image. Default: None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7824" href="#t7824">7824</a></span><span class="t"><span class="str">        name(str, optional): For detailed information, please refer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7825" href="#t7825">7825</a></span><span class="t"><span class="str">            to :ref:`api_guide_Name`. Usually name is no need to set and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7826" href="#t7826">7826</a></span><span class="t"><span class="str">            None by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7827" href="#t7827">7827</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7828" href="#t7828">7828</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7829" href="#t7829">7829</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7830" href="#t7830">7830</a></span><span class="t"><span class="str">        Variable: The pooled feature, 4D-Tensor with the shape of [num_rois, C, pooled_height, pooled_width].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7831" href="#t7831">7831</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7832" href="#t7832">7832</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7833" href="#t7833">7833</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7834" href="#t7834">7834</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7835" href="#t7835">7835</a></span><span class="t"><span class="str">    ..  code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7836" href="#t7836">7836</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7837" href="#t7837">7837</a></span><span class="t"><span class="str">        import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7838" href="#t7838">7838</a></span><span class="t"><span class="str">        import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7839" href="#t7839">7839</a></span><span class="t"><span class="str">        import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7840" href="#t7840">7840</a></span><span class="t"><span class="str">        paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7841" href="#t7841">7841</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7842" href="#t7842">7842</a></span><span class="t"><span class="str">        DATATYPE='float32'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7843" href="#t7843">7843</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7844" href="#t7844">7844</a></span><span class="t"><span class="str">        place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7845" href="#t7845">7845</a></span><span class="t"><span class="str">        #place = fluid.CUDAPlace(0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7846" href="#t7846">7846</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7847" href="#t7847">7847</a></span><span class="t"><span class="str">        input_data = np.array([i for i in range(1,17)]).reshape(1,1,4,4).astype(DATATYPE)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7848" href="#t7848">7848</a></span><span class="t"><span class="str">        roi_data =fluid.create_lod_tensor(np.array([[1., 1., 2., 2.], [1.5, 1.5, 3., 3.]]).astype(DATATYPE),[[2]], place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7849" href="#t7849">7849</a></span><span class="t"><span class="str">        rois_num_data = np.array([2]).astype('int32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7850" href="#t7850">7850</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7851" href="#t7851">7851</a></span><span class="t"><span class="str">        x = fluid.data(name='input', shape=[None,1,4,4], dtype=DATATYPE)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7852" href="#t7852">7852</a></span><span class="t"><span class="str">        rois = fluid.data(name='roi', shape=[None,4], dtype=DATATYPE)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7853" href="#t7853">7853</a></span><span class="t"><span class="str">        rois_num = fluid.data(name='rois_num', shape=[None], dtype='int32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7854" href="#t7854">7854</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7855" href="#t7855">7855</a></span><span class="t"><span class="str">        pool_out = fluid.layers.roi_pool(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7856" href="#t7856">7856</a></span><span class="t"><span class="str">                input=x,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7857" href="#t7857">7857</a></span><span class="t"><span class="str">                rois=rois,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7858" href="#t7858">7858</a></span><span class="t"><span class="str">                pooled_height=1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7859" href="#t7859">7859</a></span><span class="t"><span class="str">                pooled_width=1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7860" href="#t7860">7860</a></span><span class="t"><span class="str">                spatial_scale=1.0,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7861" href="#t7861">7861</a></span><span class="t"><span class="str">                rois_num=rois_num)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7862" href="#t7862">7862</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7863" href="#t7863">7863</a></span><span class="t"><span class="str">        exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7864" href="#t7864">7864</a></span><span class="t"><span class="str">        out, = exe.run(feed={'input':input_data ,'roi':roi_data, 'rois_num': rois_num_data}, fetch_list=[pool_out.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7865" href="#t7865">7865</a></span><span class="t"><span class="str">        print(out)   #array([[[[11.]]], [[[16.]]]], dtype=float32)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7866" href="#t7866">7866</a></span><span class="t"><span class="str">        print(np.array(out).shape)  # (2, 1, 1, 1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7867" href="#t7867">7867</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7868" href="#t7868">7868</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7869" href="#t7869">7869</a></span><span class="t">        <span class="key">assert</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7870" href="#t7870">7870</a></span><span class="t">            <span class="nam">rois_num</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7871" href="#t7871">7871</a></span><span class="t">        <span class="op">)</span><span class="op">,</span> <span class="str">"rois_num should not be None in dygraph mode."</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7872" href="#t7872">7872</a></span><span class="t">        <span class="nam">pool_out</span><span class="op">,</span> <span class="nam">argmaxes</span> <span class="op">=</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">roi_pool</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7873" href="#t7873">7873</a></span><span class="t">            <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7874" href="#t7874">7874</a></span><span class="t">            <span class="nam">rois</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7875" href="#t7875">7875</a></span><span class="t">            <span class="nam">rois_num</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7876" href="#t7876">7876</a></span><span class="t">            <span class="str">"pooled_height"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7877" href="#t7877">7877</a></span><span class="t">            <span class="nam">pooled_height</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7878" href="#t7878">7878</a></span><span class="t">            <span class="str">"pooled_width"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7879" href="#t7879">7879</a></span><span class="t">            <span class="nam">pooled_width</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7880" href="#t7880">7880</a></span><span class="t">            <span class="str">"spatial_scale"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7881" href="#t7881">7881</a></span><span class="t">            <span class="nam">spatial_scale</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7882" href="#t7882">7882</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7883" href="#t7883">7883</a></span><span class="t">        <span class="key">return</span> <span class="nam">pool_out</span><span class="op">,</span> <span class="nam">argmaxes</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7884" href="#t7884">7884</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7885" href="#t7885">7885</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">]</span><span class="op">,</span> <span class="str">'roi_pool'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7886" href="#t7886">7886</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">rois</span><span class="op">,</span> <span class="str">'rois'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">]</span><span class="op">,</span> <span class="str">'roi_pool'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7887" href="#t7887">7887</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'roi_pool'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7888" href="#t7888">7888</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7889" href="#t7889">7889</a></span><span class="t">    <span class="nam">pool_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7890" href="#t7890">7890</a></span><span class="t">    <span class="nam">argmaxes</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="str">'int32'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7891" href="#t7891">7891</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7892" href="#t7892">7892</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7893" href="#t7893">7893</a></span><span class="t">        <span class="str">"X"</span><span class="op">:</span> <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7894" href="#t7894">7894</a></span><span class="t">        <span class="str">"ROIs"</span><span class="op">:</span> <span class="nam">rois</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7895" href="#t7895">7895</a></span><span class="t">    <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7896" href="#t7896">7896</a></span><span class="t">    <span class="key">if</span> <span class="nam">rois_num</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7897" href="#t7897">7897</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">'RoisNum'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">rois_num</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7898" href="#t7898">7898</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7899" href="#t7899">7899</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"roi_pool"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7900" href="#t7900">7900</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7901" href="#t7901">7901</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">pool_out</span><span class="op">,</span> <span class="str">"Argmax"</span><span class="op">:</span> <span class="nam">argmaxes</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7902" href="#t7902">7902</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7903" href="#t7903">7903</a></span><span class="t">            <span class="str">"pooled_height"</span><span class="op">:</span> <span class="nam">pooled_height</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7904" href="#t7904">7904</a></span><span class="t">            <span class="str">"pooled_width"</span><span class="op">:</span> <span class="nam">pooled_width</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7905" href="#t7905">7905</a></span><span class="t">            <span class="str">"spatial_scale"</span><span class="op">:</span> <span class="nam">spatial_scale</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7906" href="#t7906">7906</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7907" href="#t7907">7907</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7908" href="#t7908">7908</a></span><span class="t">    <span class="key">return</span> <span class="nam">pool_out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7909" href="#t7909">7909</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7910" href="#t7910">7910</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7911" href="#t7911">7911</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t7912" href="#t7912">7912</a></span><span class="t"><span class="key">def</span> <span class="nam">roi_align</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7913" href="#t7913">7913</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7914" href="#t7914">7914</a></span><span class="t">    <span class="nam">rois</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7915" href="#t7915">7915</a></span><span class="t">    <span class="nam">pooled_height</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7916" href="#t7916">7916</a></span><span class="t">    <span class="nam">pooled_width</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7917" href="#t7917">7917</a></span><span class="t">    <span class="nam">spatial_scale</span><span class="op">=</span><span class="num">1.0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7918" href="#t7918">7918</a></span><span class="t">    <span class="nam">sampling_ratio</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7919" href="#t7919">7919</a></span><span class="t">    <span class="nam">rois_num</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7920" href="#t7920">7920</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7921" href="#t7921">7921</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7922" href="#t7922">7922</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7923" href="#t7923">7923</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7924" href="#t7924">7924</a></span><span class="t"><span class="str">    ${comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7925" href="#t7925">7925</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7926" href="#t7926">7926</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7927" href="#t7927">7927</a></span><span class="t"><span class="str">        input (Variable): ${x_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7928" href="#t7928">7928</a></span><span class="t"><span class="str">        rois (Variable): ROIs (Regions of Interest) to pool over.It should be</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7929" href="#t7929">7929</a></span><span class="t"><span class="str">            a 2-D LoDTensor of shape (num_rois, 4), the lod level is 1. The</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7930" href="#t7930">7930</a></span><span class="t"><span class="str">            data type is float32 or float64. Given as [[x1, y1, x2, y2], ...],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7931" href="#t7931">7931</a></span><span class="t"><span class="str">            (x1, y1) is the top left coordinates, and (x2, y2) is the bottom</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7932" href="#t7932">7932</a></span><span class="t"><span class="str">            right coordinates.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7933" href="#t7933">7933</a></span><span class="t"><span class="str">        pooled_height (int32, optional): ${pooled_height_comment} Default: 1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7934" href="#t7934">7934</a></span><span class="t"><span class="str">        pooled_width (int32, optional): ${pooled_width_comment} Default: 1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7935" href="#t7935">7935</a></span><span class="t"><span class="str">        spatial_scale (float32, optional): ${spatial_scale_comment} Default: 1.0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7936" href="#t7936">7936</a></span><span class="t"><span class="str">        sampling_ratio(int32, optional): ${sampling_ratio_comment} Default: -1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7937" href="#t7937">7937</a></span><span class="t"><span class="str">        rois_num (Tensor): The number of RoIs in each image. Default: None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7938" href="#t7938">7938</a></span><span class="t"><span class="str">        name(str, optional): For detailed information, please refer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7939" href="#t7939">7939</a></span><span class="t"><span class="str">            to :ref:`api_guide_Name`. Usually name is no need to set and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7940" href="#t7940">7940</a></span><span class="t"><span class="str">            None by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7941" href="#t7941">7941</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7942" href="#t7942">7942</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7943" href="#t7943">7943</a></span><span class="t"><span class="str">        Variable:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7944" href="#t7944">7944</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7945" href="#t7945">7945</a></span><span class="t"><span class="str">        Output: ${out_comment}.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7946" href="#t7946">7946</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7947" href="#t7947">7947</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7948" href="#t7948">7948</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7949" href="#t7949">7949</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7950" href="#t7950">7950</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7951" href="#t7951">7951</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7952" href="#t7952">7952</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7953" href="#t7953">7953</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7954" href="#t7954">7954</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7955" href="#t7955">7955</a></span><span class="t"><span class="str">            x = fluid.data(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7956" href="#t7956">7956</a></span><span class="t"><span class="str">                name='data', shape=[None, 256, 32, 32], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7957" href="#t7957">7957</a></span><span class="t"><span class="str">            rois = fluid.data(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7958" href="#t7958">7958</a></span><span class="t"><span class="str">                name='rois', shape=[None, 4], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7959" href="#t7959">7959</a></span><span class="t"><span class="str">            rois_num = fluid.data(name='rois_num', shape=[None], dtype='int32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7960" href="#t7960">7960</a></span><span class="t"><span class="str">            align_out = fluid.layers.roi_align(input=x,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7961" href="#t7961">7961</a></span><span class="t"><span class="str">                                               rois=rois,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7962" href="#t7962">7962</a></span><span class="t"><span class="str">                                               pooled_height=7,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7963" href="#t7963">7963</a></span><span class="t"><span class="str">                                               pooled_width=7,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7964" href="#t7964">7964</a></span><span class="t"><span class="str">                                               spatial_scale=0.5,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7965" href="#t7965">7965</a></span><span class="t"><span class="str">                                               sampling_ratio=-1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7966" href="#t7966">7966</a></span><span class="t"><span class="str">                                               rois_num=rois_num)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7967" href="#t7967">7967</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7968" href="#t7968">7968</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7969" href="#t7969">7969</a></span><span class="t">        <span class="key">assert</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7970" href="#t7970">7970</a></span><span class="t">            <span class="nam">rois_num</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7971" href="#t7971">7971</a></span><span class="t">        <span class="op">)</span><span class="op">,</span> <span class="str">"rois_num should not be None in dygraph mode."</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7972" href="#t7972">7972</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">roi_align</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7973" href="#t7973">7973</a></span><span class="t">            <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7974" href="#t7974">7974</a></span><span class="t">            <span class="nam">rois</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7975" href="#t7975">7975</a></span><span class="t">            <span class="nam">rois_num</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7976" href="#t7976">7976</a></span><span class="t">            <span class="nam">pooled_height</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7977" href="#t7977">7977</a></span><span class="t">            <span class="nam">pooled_width</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7978" href="#t7978">7978</a></span><span class="t">            <span class="nam">spatial_scale</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7979" href="#t7979">7979</a></span><span class="t">            <span class="nam">sampling_ratio</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7980" href="#t7980">7980</a></span><span class="t">            <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7981" href="#t7981">7981</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7982" href="#t7982">7982</a></span><span class="t">    <span class="key">if</span> <span class="nam">_in_legacy_dygraph</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7983" href="#t7983">7983</a></span><span class="t">        <span class="key">assert</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7984" href="#t7984">7984</a></span><span class="t">            <span class="nam">rois_num</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7985" href="#t7985">7985</a></span><span class="t">        <span class="op">)</span><span class="op">,</span> <span class="str">"rois_num should not be None in dygraph mode."</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7986" href="#t7986">7986</a></span><span class="t">        <span class="nam">align_out</span> <span class="op">=</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">roi_align</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7987" href="#t7987">7987</a></span><span class="t">            <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7988" href="#t7988">7988</a></span><span class="t">            <span class="nam">rois</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7989" href="#t7989">7989</a></span><span class="t">            <span class="nam">rois_num</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7990" href="#t7990">7990</a></span><span class="t">            <span class="str">"pooled_height"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7991" href="#t7991">7991</a></span><span class="t">            <span class="nam">pooled_height</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7992" href="#t7992">7992</a></span><span class="t">            <span class="str">"pooled_width"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7993" href="#t7993">7993</a></span><span class="t">            <span class="nam">pooled_width</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7994" href="#t7994">7994</a></span><span class="t">            <span class="str">"spatial_scale"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7995" href="#t7995">7995</a></span><span class="t">            <span class="nam">spatial_scale</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7996" href="#t7996">7996</a></span><span class="t">            <span class="str">"sampling_ratio"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7997" href="#t7997">7997</a></span><span class="t">            <span class="nam">sampling_ratio</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7998" href="#t7998">7998</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t7999" href="#t7999">7999</a></span><span class="t">        <span class="key">return</span> <span class="nam">align_out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8000" href="#t8000">8000</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8001" href="#t8001">8001</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8002" href="#t8002">8002</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'roi_align'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8003" href="#t8003">8003</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8004" href="#t8004">8004</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">rois</span><span class="op">,</span> <span class="str">'rois'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'roi_align'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8005" href="#t8005">8005</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'roi_align'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8006" href="#t8006">8006</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8007" href="#t8007">8007</a></span><span class="t">    <span class="nam">align_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8008" href="#t8008">8008</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8009" href="#t8009">8009</a></span><span class="t">        <span class="str">"X"</span><span class="op">:</span> <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8010" href="#t8010">8010</a></span><span class="t">        <span class="str">"ROIs"</span><span class="op">:</span> <span class="nam">rois</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8011" href="#t8011">8011</a></span><span class="t">    <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8012" href="#t8012">8012</a></span><span class="t">    <span class="key">if</span> <span class="nam">rois_num</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8013" href="#t8013">8013</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">'RoisNum'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">rois_num</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8014" href="#t8014">8014</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8015" href="#t8015">8015</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"roi_align"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8016" href="#t8016">8016</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8017" href="#t8017">8017</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">align_out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8018" href="#t8018">8018</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8019" href="#t8019">8019</a></span><span class="t">            <span class="str">"pooled_height"</span><span class="op">:</span> <span class="nam">pooled_height</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8020" href="#t8020">8020</a></span><span class="t">            <span class="str">"pooled_width"</span><span class="op">:</span> <span class="nam">pooled_width</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8021" href="#t8021">8021</a></span><span class="t">            <span class="str">"spatial_scale"</span><span class="op">:</span> <span class="nam">spatial_scale</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8022" href="#t8022">8022</a></span><span class="t">            <span class="str">"sampling_ratio"</span><span class="op">:</span> <span class="nam">sampling_ratio</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8023" href="#t8023">8023</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8024" href="#t8024">8024</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8025" href="#t8025">8025</a></span><span class="t">    <span class="key">return</span> <span class="nam">align_out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8026" href="#t8026">8026</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8027" href="#t8027">8027</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t8028" href="#t8028">8028</a></span><span class="t"><span class="key">def</span> <span class="nam">dice_loss</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">label</span><span class="op">,</span> <span class="nam">epsilon</span><span class="op">=</span><span class="num">0.00001</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8029" href="#t8029">8029</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8030" href="#t8030">8030</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8031" href="#t8031">8031</a></span><span class="t"><span class="str">    Dice loss for comparing the similarity between the input predictions and the label.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8032" href="#t8032">8032</a></span><span class="t"><span class="str">    This implementation is for binary classification, where the input is sigmoid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8033" href="#t8033">8033</a></span><span class="t"><span class="str">    predictions of each pixel, usually used for segmentation task. The dice loss can</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8034" href="#t8034">8034</a></span><span class="t"><span class="str">    be defined as the following equation:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8035" href="#t8035">8035</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8036" href="#t8036">8036</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8037" href="#t8037">8037</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8038" href="#t8038">8038</a></span><span class="t"><span class="str">        dice\_loss &amp;= 1 - \frac{2 * intersection\_area}{total\_area} \\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8039" href="#t8039">8039</a></span><span class="t"><span class="str">                  &amp;= \frac{(total\_area - intersection\_area) - intersection\_area}{total\_area} \\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8040" href="#t8040">8040</a></span><span class="t"><span class="str">                  &amp;= \frac{(union\_area - intersection\_area)}{total\_area}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8041" href="#t8041">8041</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8042" href="#t8042">8042</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8043" href="#t8043">8043</a></span><span class="t"><span class="str">    Parameters:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8044" href="#t8044">8044</a></span><span class="t"><span class="str">        input (Tensor): Tensor, rank>=2, shape is :math:`[N_1, N_2, ..., N_k, D]`, where :math:`N_1` is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8045" href="#t8045">8045</a></span><span class="t"><span class="str">                          the batch_size, :math:`D` is the number of categories. It is usually the output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8046" href="#t8046">8046</a></span><span class="t"><span class="str">                          predictions of sigmoid activation. The data type can be float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8047" href="#t8047">8047</a></span><span class="t"><span class="str">        label (Tensor): Tensor, the groud truth with the same rank as input, shape is :math:`[N_1, N_2, ..., N_k, 1]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8048" href="#t8048">8048</a></span><span class="t"><span class="str">                          where :math:`N_1` is the batch_size. The data type can be int32 or int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8049" href="#t8049">8049</a></span><span class="t"><span class="str">        epsilon (float): The epsilon will be added to the numerator and denominator.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8050" href="#t8050">8050</a></span><span class="t"><span class="str">                         If both input and label are empty, it makes sure dice is 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8051" href="#t8051">8051</a></span><span class="t"><span class="str">                         Default: 0.00001</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8052" href="#t8052">8052</a></span><span class="t"><span class="str">        name(str, optional): The default value is None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8053" href="#t8053">8053</a></span><span class="t"><span class="str">                             Normally there is no need for user to set this property.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8054" href="#t8054">8054</a></span><span class="t"><span class="str">                             For more information, please refer to :ref:`api_guide_Name`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8055" href="#t8055">8055</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8056" href="#t8056">8056</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8057" href="#t8057">8057</a></span><span class="t"><span class="str">        Tensor, which shape is [1], data type is the same as `input` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8058" href="#t8058">8058</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8059" href="#t8059">8059</a></span><span class="t"><span class="str">    Example:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8060" href="#t8060">8060</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8061" href="#t8061">8061</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8062" href="#t8062">8062</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8063" href="#t8063">8063</a></span><span class="t"><span class="str">            import paddle.nn.functional as F</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8064" href="#t8064">8064</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8065" href="#t8065">8065</a></span><span class="t"><span class="str">            x = paddle.randn((3,224,224,2))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8066" href="#t8066">8066</a></span><span class="t"><span class="str">            label = paddle.randint(high=2, shape=(3,224,224,1))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8067" href="#t8067">8067</a></span><span class="t"><span class="str">            predictions = F.softmax(x)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8068" href="#t8068">8068</a></span><span class="t"><span class="str">            loss = F.dice_loss(input=predictions, label=label)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8069" href="#t8069">8069</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8070" href="#t8070">8070</a></span><span class="t">    <span class="key">return</span> <span class="nam">paddle</span><span class="op">.</span><span class="nam">nn</span><span class="op">.</span><span class="nam">functional</span><span class="op">.</span><span class="nam">dice_loss</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8071" href="#t8071">8071</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span> <span class="nam">label</span><span class="op">,</span> <span class="nam">epsilon</span><span class="op">=</span><span class="nam">epsilon</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="nam">name</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8072" href="#t8072">8072</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8073" href="#t8073">8073</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8074" href="#t8074">8074</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t8075" href="#t8075">8075</a></span><span class="t"><span class="key">def</span> <span class="nam">image_resize</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8076" href="#t8076">8076</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8077" href="#t8077">8077</a></span><span class="t">    <span class="nam">out_shape</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8078" href="#t8078">8078</a></span><span class="t">    <span class="nam">scale</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8079" href="#t8079">8079</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8080" href="#t8080">8080</a></span><span class="t">    <span class="nam">resample</span><span class="op">=</span><span class="str">'BILINEAR'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8081" href="#t8081">8081</a></span><span class="t">    <span class="nam">actual_shape</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8082" href="#t8082">8082</a></span><span class="t">    <span class="nam">align_corners</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8083" href="#t8083">8083</a></span><span class="t">    <span class="nam">align_mode</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8084" href="#t8084">8084</a></span><span class="t">    <span class="nam">data_format</span><span class="op">=</span><span class="str">'NCHW'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8085" href="#t8085">8085</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8086" href="#t8086">8086</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8087" href="#t8087">8087</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8088" href="#t8088">8088</a></span><span class="t"><span class="str">    This op resizes a batch of images.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8089" href="#t8089">8089</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8090" href="#t8090">8090</a></span><span class="t"><span class="str">    The input must be a 3-D Tensor of the shape (num_batches, channels, in_w)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8091" href="#t8091">8091</a></span><span class="t"><span class="str">    or a 4-D Tensor of the shape (num_batches, channels, in_h, in_w)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8092" href="#t8092">8092</a></span><span class="t"><span class="str">    or (num_batches, in_h, in_w, channels), or a 5-D Tensor of the shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8093" href="#t8093">8093</a></span><span class="t"><span class="str">    (num_batches, channels, in_d, in_h, in_w) or (num_batches, in_d, in_h, in_w, channels),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8094" href="#t8094">8094</a></span><span class="t"><span class="str">    and the resizing only applies on the three dimensions(depth, height and width).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8095" href="#t8095">8095</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8096" href="#t8096">8096</a></span><span class="t"><span class="str">    **Warning:** the parameter :attr:`actual_shape` will be deprecated in the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8097" href="#t8097">8097</a></span><span class="t"><span class="str">    future and only use :attr:`out_shape` instead.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8098" href="#t8098">8098</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8099" href="#t8099">8099</a></span><span class="t"><span class="str">    Supporting resample methods:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8100" href="#t8100">8100</a></span><span class="t"><span class="str">        'LINEAR' : Linear interpolation</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8101" href="#t8101">8101</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8102" href="#t8102">8102</a></span><span class="t"><span class="str">        'BILINEAR' : Bilinear interpolation</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8103" href="#t8103">8103</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8104" href="#t8104">8104</a></span><span class="t"><span class="str">        'TRILINEAR' : Trilinear interpolation</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8105" href="#t8105">8105</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8106" href="#t8106">8106</a></span><span class="t"><span class="str">        'NEAREST' : Nearest neighbor interpolation</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8107" href="#t8107">8107</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8108" href="#t8108">8108</a></span><span class="t"><span class="str">        'BICUBIC' : Bicubic interpolation</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8109" href="#t8109">8109</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8110" href="#t8110">8110</a></span><span class="t"><span class="str">    Linear interpolation is the method of using a line connecting two known quantities</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8111" href="#t8111">8111</a></span><span class="t"><span class="str">    to determine the value of an unknown quantity between the two known quantities.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8112" href="#t8112">8112</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8113" href="#t8113">8113</a></span><span class="t"><span class="str">    Nearest neighbor interpolation is to perform nearest neighbor interpolation</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8114" href="#t8114">8114</a></span><span class="t"><span class="str">    in both the 3rd dimension(in height direction) and the 4th dimension(in width</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8115" href="#t8115">8115</a></span><span class="t"><span class="str">    direction) on input tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8116" href="#t8116">8116</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8117" href="#t8117">8117</a></span><span class="t"><span class="str">    Bilinear interpolation is an extension of linear interpolation for</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8118" href="#t8118">8118</a></span><span class="t"><span class="str">    interpolating functions of two variables (e.g. H-direction and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8119" href="#t8119">8119</a></span><span class="t"><span class="str">    W-direction in this op) on a rectilinear 2D grid. The key idea is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8120" href="#t8120">8120</a></span><span class="t"><span class="str">    to perform linear interpolation first in one direction, and then</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8121" href="#t8121">8121</a></span><span class="t"><span class="str">    again in the other direction.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8122" href="#t8122">8122</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8123" href="#t8123">8123</a></span><span class="t"><span class="str">    Trilinear interpolation is an extension of linear interpolation for</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8124" href="#t8124">8124</a></span><span class="t"><span class="str">    interpolating functions of three variables (e.g. D-direction,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8125" href="#t8125">8125</a></span><span class="t"><span class="str">    H-direction and W-direction in this op) on a rectilinear 3D grid.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8126" href="#t8126">8126</a></span><span class="t"><span class="str">    The linear interpolation is performed on three directions.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8127" href="#t8127">8127</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8128" href="#t8128">8128</a></span><span class="t"><span class="str">    Bicubic interpolation is an extension of cubic interpolation for interpolating</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8129" href="#t8129">8129</a></span><span class="t"><span class="str">    data points on a two-dimensional regular grid. The interpolated surface is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8130" href="#t8130">8130</a></span><span class="t"><span class="str">    smoother than corresponding surfaces obtained by bilinear interpolation or</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8131" href="#t8131">8131</a></span><span class="t"><span class="str">    nearest-neighbor interpolation.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8132" href="#t8132">8132</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8133" href="#t8133">8133</a></span><span class="t"><span class="str">    Align_corners and align_mode are optional parameters,the calculation method</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8134" href="#t8134">8134</a></span><span class="t"><span class="str">    of interpolation can be selected by them.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8135" href="#t8135">8135</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8136" href="#t8136">8136</a></span><span class="t"><span class="str">    Example:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8137" href="#t8137">8137</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8138" href="#t8138">8138</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8139" href="#t8139">8139</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8140" href="#t8140">8140</a></span><span class="t"><span class="str">        For scale:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8141" href="#t8141">8141</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8142" href="#t8142">8142</a></span><span class="t"><span class="str">            if align_corners = True &amp;&amp; out_size > 1 :</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8143" href="#t8143">8143</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8144" href="#t8144">8144</a></span><span class="t"><span class="str">              scale_factor = (in_size-1.0)/(out_size-1.0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8145" href="#t8145">8145</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8146" href="#t8146">8146</a></span><span class="t"><span class="str">            else:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8147" href="#t8147">8147</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8148" href="#t8148">8148</a></span><span class="t"><span class="str">              scale_factor = float(in_size/out_size)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8149" href="#t8149">8149</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8150" href="#t8150">8150</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8151" href="#t8151">8151</a></span><span class="t"><span class="str">        Nearest neighbor interpolation:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8152" href="#t8152">8152</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8153" href="#t8153">8153</a></span><span class="t"><span class="str">          if:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8154" href="#t8154">8154</a></span><span class="t"><span class="str">              align_corners = False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8155" href="#t8155">8155</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8156" href="#t8156">8156</a></span><span class="t"><span class="str">              input : (N,C,H_in,W_in)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8157" href="#t8157">8157</a></span><span class="t"><span class="str">              output: (N,C,H_out,W_out) where:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8158" href="#t8158">8158</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8159" href="#t8159">8159</a></span><span class="t"><span class="str">              H_out = floor (H_{in} * scale_{factor})</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8160" href="#t8160">8160</a></span><span class="t"><span class="str">              W_out = floor (W_{in} * scale_{factor})</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8161" href="#t8161">8161</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8162" href="#t8162">8162</a></span><span class="t"><span class="str">          else:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8163" href="#t8163">8163</a></span><span class="t"><span class="str">              align_corners = True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8164" href="#t8164">8164</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8165" href="#t8165">8165</a></span><span class="t"><span class="str">              input : (N,C,H_in,W_in)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8166" href="#t8166">8166</a></span><span class="t"><span class="str">              output: (N,C,H_out,W_out) where:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8167" href="#t8167">8167</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8168" href="#t8168">8168</a></span><span class="t"><span class="str">              H_out = round(H_{in} * scale_{factor})</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8169" href="#t8169">8169</a></span><span class="t"><span class="str">              W_out = round(W_{in} * scale_{factor})</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8170" href="#t8170">8170</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8171" href="#t8171">8171</a></span><span class="t"><span class="str">        linear interpolation:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8172" href="#t8172">8172</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8173" href="#t8173">8173</a></span><span class="t"><span class="str">          if:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8174" href="#t8174">8174</a></span><span class="t"><span class="str">              align_corners = False , align_mode = 0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8175" href="#t8175">8175</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8176" href="#t8176">8176</a></span><span class="t"><span class="str">              input : (N,C,W_in)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8177" href="#t8177">8177</a></span><span class="t"><span class="str">              output: (N,C,W_out) where:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8178" href="#t8178">8178</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8179" href="#t8179">8179</a></span><span class="t"><span class="str">              W_out = (W_{in}+0.5) * scale_{factor} - 0.5</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8180" href="#t8180">8180</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8181" href="#t8181">8181</a></span><span class="t"><span class="str">          else:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8182" href="#t8182">8182</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8183" href="#t8183">8183</a></span><span class="t"><span class="str">              input : (N,C,W_in)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8184" href="#t8184">8184</a></span><span class="t"><span class="str">              output: (N,C,H_out,W_out) where:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8185" href="#t8185">8185</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8186" href="#t8186">8186</a></span><span class="t"><span class="str">              W_out = W_{in} * scale_{factor}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8187" href="#t8187">8187</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8188" href="#t8188">8188</a></span><span class="t"><span class="str">        Bilinear interpolation:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8189" href="#t8189">8189</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8190" href="#t8190">8190</a></span><span class="t"><span class="str">          if:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8191" href="#t8191">8191</a></span><span class="t"><span class="str">              align_corners = False , align_mode = 0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8192" href="#t8192">8192</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8193" href="#t8193">8193</a></span><span class="t"><span class="str">              input : (N,C,H_in,W_in)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8194" href="#t8194">8194</a></span><span class="t"><span class="str">              output: (N,C,H_out,W_out) where:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8195" href="#t8195">8195</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8196" href="#t8196">8196</a></span><span class="t"><span class="str">              H_out = (H_{in}+0.5) * scale_{factor} - 0.5</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8197" href="#t8197">8197</a></span><span class="t"><span class="str">              W_out = (W_{in}+0.5) * scale_{factor} - 0.5</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8198" href="#t8198">8198</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8199" href="#t8199">8199</a></span><span class="t"><span class="str">          else:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8200" href="#t8200">8200</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8201" href="#t8201">8201</a></span><span class="t"><span class="str">              input : (N,C,H_in,W_in)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8202" href="#t8202">8202</a></span><span class="t"><span class="str">              output: (N,C,H_out,W_out) where:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8203" href="#t8203">8203</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8204" href="#t8204">8204</a></span><span class="t"><span class="str">              H_out = H_{in} * scale_{factor}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8205" href="#t8205">8205</a></span><span class="t"><span class="str">              W_out = W_{in} * scale_{factor}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8206" href="#t8206">8206</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8207" href="#t8207">8207</a></span><span class="t"><span class="str">        Trilinear interpolation:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8208" href="#t8208">8208</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8209" href="#t8209">8209</a></span><span class="t"><span class="str">          if:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8210" href="#t8210">8210</a></span><span class="t"><span class="str">              align_corners = False , align_mode = 0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8211" href="#t8211">8211</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8212" href="#t8212">8212</a></span><span class="t"><span class="str">              input : (N,C,D_in,H_in,W_in)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8213" href="#t8213">8213</a></span><span class="t"><span class="str">              output: (N,C,D_out,H_out,W_out) where:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8214" href="#t8214">8214</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8215" href="#t8215">8215</a></span><span class="t"><span class="str">              D_out = (D_{in}+0.5) * scale_{factor} - 0.5</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8216" href="#t8216">8216</a></span><span class="t"><span class="str">              H_out = (H_{in}+0.5) * scale_{factor} - 0.5</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8217" href="#t8217">8217</a></span><span class="t"><span class="str">              W_out = (W_{in}+0.5) * scale_{factor} - 0.5</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8218" href="#t8218">8218</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8219" href="#t8219">8219</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8220" href="#t8220">8220</a></span><span class="t"><span class="str">          else:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8221" href="#t8221">8221</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8222" href="#t8222">8222</a></span><span class="t"><span class="str">              input : (N,C,D_in,H_in,W_in)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8223" href="#t8223">8223</a></span><span class="t"><span class="str">              output: (N,C,D_out,H_out,W_out) where:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8224" href="#t8224">8224</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8225" href="#t8225">8225</a></span><span class="t"><span class="str">              D_out = D_{in} * scale_{factor}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8226" href="#t8226">8226</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8227" href="#t8227">8227</a></span><span class="t"><span class="str">        Trilinear interpolation:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8228" href="#t8228">8228</a></span><span class="t"><span class="str">          if:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8229" href="#t8229">8229</a></span><span class="t"><span class="str">              align_corners = False , align_mode = 0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8230" href="#t8230">8230</a></span><span class="t"><span class="str">              input : (N,C,D_in,H_in,W_in)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8231" href="#t8231">8231</a></span><span class="t"><span class="str">              output: (N,C,D_out,H_out,W_out) where:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8232" href="#t8232">8232</a></span><span class="t"><span class="str">              D_out = (D_{in}+0.5) * scale_{factor} - 0.5</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8233" href="#t8233">8233</a></span><span class="t"><span class="str">              H_out = (H_{in}+0.5) * scale_{factor} - 0.5</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8234" href="#t8234">8234</a></span><span class="t"><span class="str">              W_out = (W_{in}+0.5) * scale_{factor} - 0.5</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8235" href="#t8235">8235</a></span><span class="t"><span class="str">          else:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8236" href="#t8236">8236</a></span><span class="t"><span class="str">              input : (N,C,D_in,H_in,W_in)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8237" href="#t8237">8237</a></span><span class="t"><span class="str">              output: (N,C,D_out,H_out,W_out) where:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8238" href="#t8238">8238</a></span><span class="t"><span class="str">              D_out = D_{in} * scale_{factor}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8239" href="#t8239">8239</a></span><span class="t"><span class="str">              H_out = H_{in} * scale_{factor}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8240" href="#t8240">8240</a></span><span class="t"><span class="str">              W_out = W_{in} * scale_{factor}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8241" href="#t8241">8241</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8242" href="#t8242">8242</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8243" href="#t8243">8243</a></span><span class="t"><span class="str">    For details of linear interpolation, please refer to Wikipedia:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8244" href="#t8244">8244</a></span><span class="t"><span class="str">    https://en.wikipedia.org/wiki/Linear_interpolation.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8245" href="#t8245">8245</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8246" href="#t8246">8246</a></span><span class="t"><span class="str">    For details of nearest neighbor interpolation, please refer to Wikipedia:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8247" href="#t8247">8247</a></span><span class="t"><span class="str">    https://en.wikipedia.org/wiki/Nearest-neighbor_interpolation.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8248" href="#t8248">8248</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8249" href="#t8249">8249</a></span><span class="t"><span class="str">    For details of bilinear interpolation, please refer to Wikipedia:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8250" href="#t8250">8250</a></span><span class="t"><span class="str">    https://en.wikipedia.org/wiki/Bilinear_interpolation.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8251" href="#t8251">8251</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8252" href="#t8252">8252</a></span><span class="t"><span class="str">    For details of trilinear interpolation, please refer to Wikipedia:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8253" href="#t8253">8253</a></span><span class="t"><span class="str">    https://en.wikipedia.org/wiki/Trilinear_interpolation.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8254" href="#t8254">8254</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8255" href="#t8255">8255</a></span><span class="t"><span class="str">    For details of bicubic interpolation, please refer to Wikipedia:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8256" href="#t8256">8256</a></span><span class="t"><span class="str">    https://en.wikipedia.org/wiki/Bicubic_interpolation</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8257" href="#t8257">8257</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8258" href="#t8258">8258</a></span><span class="t"><span class="str">    Parameters:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8259" href="#t8259">8259</a></span><span class="t"><span class="str">        input (Variable): 3-D, 4-D or 5-D Tensor, its data type is float32, float64, or uint8,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8260" href="#t8260">8260</a></span><span class="t"><span class="str">                          its data format is specified by :attr:`data_format`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8261" href="#t8261">8261</a></span><span class="t"><span class="str">        out_shape (list|tuple|Variable|None): Output shape of image resize</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8262" href="#t8262">8262</a></span><span class="t"><span class="str">             layer, the shape is (out_w, ) when input is a 3-D Tensor, the shape is (out_h, out_w)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8263" href="#t8263">8263</a></span><span class="t"><span class="str">             when input is a 4-D Tensor and is (out_d, out_h, out_w) when input is a 5-D Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8264" href="#t8264">8264</a></span><span class="t"><span class="str">             Default: None. If a list, each element can be an integer or a Tensor Variable of shape: [1].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8265" href="#t8265">8265</a></span><span class="t"><span class="str">             If a Tensor Variable, its dimensions size should be a 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8266" href="#t8266">8266</a></span><span class="t"><span class="str">        scale(float|Variable|None): The multiplier for the input height or width. At</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8267" href="#t8267">8267</a></span><span class="t"><span class="str">             least one of :attr:`out_shape` or :attr:`scale` must be set.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8268" href="#t8268">8268</a></span><span class="t"><span class="str">             And :attr:`out_shape` has a higher priority than :attr:`scale`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8269" href="#t8269">8269</a></span><span class="t"><span class="str">             Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8270" href="#t8270">8270</a></span><span class="t"><span class="str">        name(str|None): A name for this layer(optional). If set None, the layer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8271" href="#t8271">8271</a></span><span class="t"><span class="str">                        will be named automatically.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8272" href="#t8272">8272</a></span><span class="t"><span class="str">        resample(str): The resample method. It supports 'LINEAR', 'BICUBIC', 'BILINEAR', 'TRILINEAR'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8273" href="#t8273">8273</a></span><span class="t"><span class="str">                       and 'NEAREST' currently. Default: 'BILINEAR'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8274" href="#t8274">8274</a></span><span class="t"><span class="str">        actual_shape(Variable): An optional input to specify output shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8275" href="#t8275">8275</a></span><span class="t"><span class="str">                                dynamically. If provided, image resize</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8276" href="#t8276">8276</a></span><span class="t"><span class="str">                                according to this given shape rather than</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8277" href="#t8277">8277</a></span><span class="t"><span class="str">                                :attr:`out_shape` and :attr:`scale` specifying</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8278" href="#t8278">8278</a></span><span class="t"><span class="str">                                shape. That is to say actual_shape has the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8279" href="#t8279">8279</a></span><span class="t"><span class="str">                                highest priority. It is recommended to use</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8280" href="#t8280">8280</a></span><span class="t"><span class="str">                                :attr:`out_shape` if you want to specify output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8281" href="#t8281">8281</a></span><span class="t"><span class="str">                                shape dynamically, because :attr:`actual_shape`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8282" href="#t8282">8282</a></span><span class="t"><span class="str">                                will be deprecated. When using actual_shape to</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8283" href="#t8283">8283</a></span><span class="t"><span class="str">                                specify output shape, one of :attr:`out_shape`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8284" href="#t8284">8284</a></span><span class="t"><span class="str">                                and :attr:`scale` should also be set, otherwise</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8285" href="#t8285">8285</a></span><span class="t"><span class="str">                                errors would be occurred in graph constructing stage.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8286" href="#t8286">8286</a></span><span class="t"><span class="str">                                Default: None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8287" href="#t8287">8287</a></span><span class="t"><span class="str">        align_corners(bool) :  An optional bool, If True, the centers of the 4 corner pixels of the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8288" href="#t8288">8288</a></span><span class="t"><span class="str">                               input and output tensors are aligned, preserving the values at the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8289" href="#t8289">8289</a></span><span class="t"><span class="str">                               corner pixels.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8290" href="#t8290">8290</a></span><span class="t"><span class="str">                               Default: True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8291" href="#t8291">8291</a></span><span class="t"><span class="str">        align_mode(int)  :  An optional for linear/bilinear/trilinear interpolation. Refer to the fomula in the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8292" href="#t8292">8292</a></span><span class="t"><span class="str">                            the example code above, it can be \'0\' for src_idx = scale*(dst_indx+0.5)-0.5 ,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8293" href="#t8293">8293</a></span><span class="t"><span class="str">                            can be \'1\' for src_idx = scale*dst_index.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8294" href="#t8294">8294</a></span><span class="t"><span class="str">        data_format (str, optional): Specify the data format of the input, and the data format of the output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8295" href="#t8295">8295</a></span><span class="t"><span class="str">            will be consistent with that of the input. An optional string from:`NCW`, `NWC`, `"NCHW"`, `"NHWC"`, `"NCDHW"`,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8296" href="#t8296">8296</a></span><span class="t"><span class="str">            `"NDHWC"`. The default is `"NCHW"`. When it is `"NCHW"`, the data is stored in the order of:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8297" href="#t8297">8297</a></span><span class="t"><span class="str">            `[batch_size, input_channels, input_height, input_width]`. When it is `"NCHW"`, the data is stored</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8298" href="#t8298">8298</a></span><span class="t"><span class="str">            in the order of: `[batch_size, input_channels, input_depth, input_height, input_width]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8299" href="#t8299">8299</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8300" href="#t8300">8300</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8301" href="#t8301">8301</a></span><span class="t"><span class="str">        A 3-D Tensor of the shape (num_batches, channels, out_w) or (num_batches, out_w, channels),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8302" href="#t8302">8302</a></span><span class="t"><span class="str">        A 4-D Tensor of the shape (num_batches, channels, out_h, out_w) or (num_batches, out_h, out_w, channels),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8303" href="#t8303">8303</a></span><span class="t"><span class="str">        or 5-D Tensor of the shape (num_batches, channels, out_d, out_h, out_w) or (num_batches, out_d, out_h, out_w, channels).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8304" href="#t8304">8304</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8305" href="#t8305">8305</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8306" href="#t8306">8306</a></span><span class="t"><span class="str">        TypeError: out_shape should be a list or tuple or Variable.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8307" href="#t8307">8307</a></span><span class="t"><span class="str">        TypeError: actual_shape should either be Variable or None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8308" href="#t8308">8308</a></span><span class="t"><span class="str">        ValueError: The 'resample' of image_resize can only be 'LINEAR', 'BILINEAR',</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8309" href="#t8309">8309</a></span><span class="t"><span class="str">                    'TRILINEAR', 'BICUBIC' or 'NEAREST' currently.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8310" href="#t8310">8310</a></span><span class="t"><span class="str">        ValueError: 'LINEAR' only support 3-D tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8311" href="#t8311">8311</a></span><span class="t"><span class="str">        ValueError: 'BICUBIC', 'BILINEAR' and 'NEAREST' only support 4-D tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8312" href="#t8312">8312</a></span><span class="t"><span class="str">        ValueError: 'TRILINEAR' only support 5-D tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8313" href="#t8313">8313</a></span><span class="t"><span class="str">        ValueError: One of out_shape and scale must not be None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8314" href="#t8314">8314</a></span><span class="t"><span class="str">        ValueError: out_shape length should be 1 for input 3-D tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8315" href="#t8315">8315</a></span><span class="t"><span class="str">        ValueError: out_shape length should be 2 for input 4-D tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8316" href="#t8316">8316</a></span><span class="t"><span class="str">        ValueError: out_shape length should be 3 for input 5-D tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8317" href="#t8317">8317</a></span><span class="t"><span class="str">        ValueError: scale should be greater than zero.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8318" href="#t8318">8318</a></span><span class="t"><span class="str">        TypeError: align_corners should be a bool value</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8319" href="#t8319">8319</a></span><span class="t"><span class="str">        ValueError: align_mode can only be '0' or '1'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8320" href="#t8320">8320</a></span><span class="t"><span class="str">        ValueError: data_format can only be 'NCW', 'NWC', 'NCHW', 'NHWC', 'NCDHW' or 'NDHWC'.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8321" href="#t8321">8321</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8322" href="#t8322">8322</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8323" href="#t8323">8323</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8324" href="#t8324">8324</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8325" href="#t8325">8325</a></span><span class="t"><span class="str">            #declarative mode</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8326" href="#t8326">8326</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8327" href="#t8327">8327</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8328" href="#t8328">8328</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8329" href="#t8329">8329</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8330" href="#t8330">8330</a></span><span class="t"><span class="str">            input = fluid.data(name="input", shape=[None,3,6,10])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8331" href="#t8331">8331</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8332" href="#t8332">8332</a></span><span class="t"><span class="str">            #1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8333" href="#t8333">8333</a></span><span class="t"><span class="str">            output = fluid.layers.image_resize(input=input,out_shape=[12,12])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8334" href="#t8334">8334</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8335" href="#t8335">8335</a></span><span class="t"><span class="str">            #2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8336" href="#t8336">8336</a></span><span class="t"><span class="str">            #x = np.array([2]).astype("int32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8337" href="#t8337">8337</a></span><span class="t"><span class="str">            #dim1 = fluid.data(name="dim1", shape=[1], dtype="int32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8338" href="#t8338">8338</a></span><span class="t"><span class="str">            #fluid.layers.assign(input=x, output=dim1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8339" href="#t8339">8339</a></span><span class="t"><span class="str">            #output = fluid.layers.image_resize(input=input,out_shape=[12,dim1])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8340" href="#t8340">8340</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8341" href="#t8341">8341</a></span><span class="t"><span class="str">            #3</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8342" href="#t8342">8342</a></span><span class="t"><span class="str">            #x = np.array([3,12]).astype("int32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8343" href="#t8343">8343</a></span><span class="t"><span class="str">            #shape_tensor = fluid.data(name="shape_tensor", shape=[2], dtype="int32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8344" href="#t8344">8344</a></span><span class="t"><span class="str">            #fluid.layers.assign(input=x, output=shape_tensor)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8345" href="#t8345">8345</a></span><span class="t"><span class="str">            #output = fluid.layers.image_resize(input=input,out_shape=shape_tensor)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8346" href="#t8346">8346</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8347" href="#t8347">8347</a></span><span class="t"><span class="str">            #4</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8348" href="#t8348">8348</a></span><span class="t"><span class="str">            #x = np.array([0.5]).astype("float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8349" href="#t8349">8349</a></span><span class="t"><span class="str">            #scale_tensor = fluid.data(name="scale", shape=[1], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8350" href="#t8350">8350</a></span><span class="t"><span class="str">            #fluid.layers.assign(x,scale_tensor)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8351" href="#t8351">8351</a></span><span class="t"><span class="str">            #output = fluid.layers.image_resize(input=input,scale=scale_tensor)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8352" href="#t8352">8352</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8353" href="#t8353">8353</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8354" href="#t8354">8354</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8355" href="#t8355">8355</a></span><span class="t"><span class="str">            exe.run(fluid.default_startup_program())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8356" href="#t8356">8356</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8357" href="#t8357">8357</a></span><span class="t"><span class="str">            input_data = np.random.rand(2,3,6,10).astype("float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8358" href="#t8358">8358</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8359" href="#t8359">8359</a></span><span class="t"><span class="str">            output_data = exe.run(fluid.default_main_program(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8360" href="#t8360">8360</a></span><span class="t"><span class="str">                feed={"input":input_data},</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8361" href="#t8361">8361</a></span><span class="t"><span class="str">                fetch_list=[output],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8362" href="#t8362">8362</a></span><span class="t"><span class="str">                return_numpy=True)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8363" href="#t8363">8363</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8364" href="#t8364">8364</a></span><span class="t"><span class="str">            print(output_data[0].shape)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8365" href="#t8365">8365</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8366" href="#t8366">8366</a></span><span class="t"><span class="str">            #1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8367" href="#t8367">8367</a></span><span class="t"><span class="str">            # (2, 3, 12, 12)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8368" href="#t8368">8368</a></span><span class="t"><span class="str">            #2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8369" href="#t8369">8369</a></span><span class="t"><span class="str">            # (2, 3, 12, 2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8370" href="#t8370">8370</a></span><span class="t"><span class="str">            #3</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8371" href="#t8371">8371</a></span><span class="t"><span class="str">            # (2, 3, 3, 12)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8372" href="#t8372">8372</a></span><span class="t"><span class="str">            #4</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8373" href="#t8373">8373</a></span><span class="t"><span class="str">            # (2, 3, 3, 5)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8374" href="#t8374">8374</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8375" href="#t8375">8375</a></span><span class="t"><span class="str">            #imperative mode</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8376" href="#t8376">8376</a></span><span class="t"><span class="str">            import paddle.fluid.dygraph as dg</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8377" href="#t8377">8377</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8378" href="#t8378">8378</a></span><span class="t"><span class="str">            with dg.guard(place) as g:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8379" href="#t8379">8379</a></span><span class="t"><span class="str">                input = dg.to_variable(input_data)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8380" href="#t8380">8380</a></span><span class="t"><span class="str">                output = fluid.layers.image_resize(input=input, out_shape=[12,12])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8381" href="#t8381">8381</a></span><span class="t"><span class="str">                print(output.shape)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8382" href="#t8382">8382</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8383" href="#t8383">8383</a></span><span class="t"><span class="str">                # [2L, 3L, 12L, 12L]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8384" href="#t8384">8384</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8385" href="#t8385">8385</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8386" href="#t8386">8386</a></span><span class="t">    <span class="nam">resample_methods</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8387" href="#t8387">8387</a></span><span class="t">        <span class="str">'LINEAR'</span><span class="op">:</span> <span class="str">'linear'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8388" href="#t8388">8388</a></span><span class="t">        <span class="str">'BILINEAR'</span><span class="op">:</span> <span class="str">'bilinear'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8389" href="#t8389">8389</a></span><span class="t">        <span class="str">'TRILINEAR'</span><span class="op">:</span> <span class="str">'trilinear'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8390" href="#t8390">8390</a></span><span class="t">        <span class="str">'NEAREST'</span><span class="op">:</span> <span class="str">'nearest'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8391" href="#t8391">8391</a></span><span class="t">        <span class="str">'LINEAR'</span><span class="op">:</span> <span class="str">'linear'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8392" href="#t8392">8392</a></span><span class="t">    <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8393" href="#t8393">8393</a></span><span class="t">    <span class="nam">resample</span> <span class="op">=</span> <span class="nam">resample</span><span class="op">.</span><span class="nam">upper</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8394" href="#t8394">8394</a></span><span class="t">    <span class="key">if</span> <span class="nam">resample</span> <span class="key">not</span> <span class="key">in</span> <span class="nam">resample_methods</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8395" href="#t8395">8395</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8396" href="#t8396">8396</a></span><span class="t">            <span class="str">"The 'resample' of image_resize can only be 'LINEAR', 'BILINEAR', 'TRILINEAR' "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8397" href="#t8397">8397</a></span><span class="t">            <span class="str">"or 'NEAREST' currently."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8398" href="#t8398">8398</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8399" href="#t8399">8399</a></span><span class="t">    <span class="nam">resample_type</span> <span class="op">=</span> <span class="nam">resample_methods</span><span class="op">[</span><span class="nam">resample</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8400" href="#t8400">8400</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8401" href="#t8401">8401</a></span><span class="t">    <span class="key">if</span> <span class="nam">resample</span> <span class="op">==</span> <span class="str">'LINEAR'</span> <span class="key">and</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">!=</span> <span class="num">3</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8402" href="#t8402">8402</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"'LINER only support 3-D tensor."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8403" href="#t8403">8403</a></span><span class="t">    <span class="key">elif</span> <span class="nam">resample</span> <span class="key">in</span> <span class="op">[</span><span class="str">'BILINEAR'</span><span class="op">,</span> <span class="str">'NEAREST'</span><span class="op">]</span> <span class="key">and</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">!=</span> <span class="num">4</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8404" href="#t8404">8404</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"'BILINEAR' and 'NEAREST' only support 4-D tensor."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8405" href="#t8405">8405</a></span><span class="t">    <span class="key">elif</span> <span class="nam">resample</span> <span class="op">==</span> <span class="str">'TRILINEAR'</span> <span class="key">and</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">!=</span> <span class="num">5</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8406" href="#t8406">8406</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"'TRILINEAR'only support 5-D tensor."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8407" href="#t8407">8407</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8408" href="#t8408">8408</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">align_corners</span><span class="op">,</span> <span class="nam">bool</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8409" href="#t8409">8409</a></span><span class="t">        <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span><span class="str">"Attr align_corners should be a bool value"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8410" href="#t8410">8410</a></span><span class="t">    <span class="key">if</span> <span class="nam">align_mode</span> <span class="op">!=</span> <span class="num">0</span> <span class="key">and</span> <span class="nam">align_mode</span> <span class="op">!=</span> <span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8411" href="#t8411">8411</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"align_mode can only be 0 or 1"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8412" href="#t8412">8412</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8413" href="#t8413">8413</a></span><span class="t">    <span class="key">if</span> <span class="nam">out_shape</span> <span class="key">is</span> <span class="key">None</span> <span class="key">and</span> <span class="nam">scale</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8414" href="#t8414">8414</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"One of out_shape and scale must not be None."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8415" href="#t8415">8415</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'{}_interp'</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">resample_type</span><span class="op">)</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8416" href="#t8416">8416</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8417" href="#t8417">8417</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8418" href="#t8418">8418</a></span><span class="t">    <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">==</span> <span class="num">3</span> <span class="key">and</span> <span class="nam">data_format</span> <span class="key">not</span> <span class="key">in</span> <span class="op">[</span><span class="str">'NCW'</span><span class="op">,</span> <span class="str">'NWC'</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8419" href="#t8419">8419</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8420" href="#t8420">8420</a></span><span class="t">            <span class="str">"Got wrong value for param `data_format`: "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8421" href="#t8421">8421</a></span><span class="t">            <span class="op">+</span> <span class="nam">data_format</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8422" href="#t8422">8422</a></span><span class="t">            <span class="op">+</span> <span class="str">" received but only `NCW` or `NWC` supported for 3-D input."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8423" href="#t8423">8423</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8424" href="#t8424">8424</a></span><span class="t">    <span class="key">elif</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">==</span> <span class="num">4</span> <span class="key">and</span> <span class="nam">data_format</span> <span class="key">not</span> <span class="key">in</span> <span class="op">[</span><span class="str">'NCHW'</span><span class="op">,</span> <span class="str">'NHWC'</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8425" href="#t8425">8425</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8426" href="#t8426">8426</a></span><span class="t">            <span class="str">"Got wrong value for param `data_format`: "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8427" href="#t8427">8427</a></span><span class="t">            <span class="op">+</span> <span class="nam">data_format</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8428" href="#t8428">8428</a></span><span class="t">            <span class="op">+</span> <span class="str">" received but only `NCHW` or `NHWC` supported for 4-D input."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8429" href="#t8429">8429</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8430" href="#t8430">8430</a></span><span class="t">    <span class="key">elif</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">==</span> <span class="num">5</span> <span class="key">and</span> <span class="nam">data_format</span> <span class="key">not</span> <span class="key">in</span> <span class="op">[</span><span class="str">'NCDHW'</span><span class="op">,</span> <span class="str">'NDHWC'</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8431" href="#t8431">8431</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8432" href="#t8432">8432</a></span><span class="t">            <span class="str">"Got wrong value for param `data_format`: "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8433" href="#t8433">8433</a></span><span class="t">            <span class="op">+</span> <span class="nam">data_format</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8434" href="#t8434">8434</a></span><span class="t">            <span class="op">+</span> <span class="str">" received but only `NCDHW` or `NDHWC` supported for 5-D input."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8435" href="#t8435">8435</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8436" href="#t8436">8436</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8437" href="#t8437">8437</a></span><span class="t">    <span class="key">def</span> <span class="nam">_is_list_or_turple_</span><span class="op">(</span><span class="nam">data</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8438" href="#t8438">8438</a></span><span class="t">        <span class="key">return</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">data</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span> <span class="key">or</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">data</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8439" href="#t8439">8439</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8440" href="#t8440">8440</a></span><span class="t">    <span class="key">if</span> <span class="nam">data_format</span> <span class="op">==</span> <span class="str">'NCHW'</span> <span class="key">or</span> <span class="nam">data_format</span> <span class="op">==</span> <span class="str">'NCDHW'</span> <span class="key">or</span> <span class="nam">data_format</span> <span class="op">==</span> <span class="str">'NCW'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8441" href="#t8441">8441</a></span><span class="t">        <span class="nam">data_layout</span> <span class="op">=</span> <span class="str">'NCHW'</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8442" href="#t8442">8442</a></span><span class="t">    <span class="key">if</span> <span class="nam">data_format</span> <span class="op">==</span> <span class="str">'NHWC'</span> <span class="key">or</span> <span class="nam">data_format</span> <span class="op">==</span> <span class="str">'NDHWC'</span> <span class="key">or</span> <span class="nam">data_format</span> <span class="op">==</span> <span class="str">'NWC'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8443" href="#t8443">8443</a></span><span class="t">        <span class="nam">data_layout</span> <span class="op">=</span> <span class="str">'NHWC'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8444" href="#t8444">8444</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8445" href="#t8445">8445</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8446" href="#t8446">8446</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8447" href="#t8447">8447</a></span><span class="t">        <span class="str">"out_d"</span><span class="op">:</span> <span class="op">-</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8448" href="#t8448">8448</a></span><span class="t">        <span class="str">"out_h"</span><span class="op">:</span> <span class="op">-</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8449" href="#t8449">8449</a></span><span class="t">        <span class="str">"out_w"</span><span class="op">:</span> <span class="op">-</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8450" href="#t8450">8450</a></span><span class="t">        <span class="str">"interp_method"</span><span class="op">:</span> <span class="nam">resample_type</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8451" href="#t8451">8451</a></span><span class="t">        <span class="str">"align_corners"</span><span class="op">:</span> <span class="nam">align_corners</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8452" href="#t8452">8452</a></span><span class="t">        <span class="str">"align_mode"</span><span class="op">:</span> <span class="nam">align_mode</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8453" href="#t8453">8453</a></span><span class="t">        <span class="str">"data_layout"</span><span class="op">:</span> <span class="nam">data_layout</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8454" href="#t8454">8454</a></span><span class="t">    <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8455" href="#t8455">8455</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8456" href="#t8456">8456</a></span><span class="t">    <span class="key">if</span> <span class="nam">out_shape</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8457" href="#t8457">8457</a></span><span class="t">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">out_shape</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span> <span class="key">and</span> <span class="key">not</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8458" href="#t8458">8458</a></span><span class="t">            <span class="nam">out_shape</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8459" href="#t8459">8459</a></span><span class="t">            <span class="nam">inputs</span><span class="op">[</span><span class="str">'OutSize'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">out_shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8460" href="#t8460">8460</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8461" href="#t8461">8461</a></span><span class="t">            <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8462" href="#t8462">8462</a></span><span class="t">                <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">out_shape</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8463" href="#t8463">8463</a></span><span class="t">                    <span class="nam">out_shape</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="nam">out_shape</span><span class="op">.</span><span class="nam">numpy</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8464" href="#t8464">8464</a></span><span class="t">                <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8465" href="#t8465">8465</a></span><span class="t">                    <span class="nam">out_shape</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="nam">out_shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8466" href="#t8466">8466</a></span><span class="t">                <span class="key">for</span> <span class="nam">i</span><span class="op">,</span> <span class="nam">dim</span> <span class="key">in</span> <span class="nam">enumerate</span><span class="op">(</span><span class="nam">out_shape</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8467" href="#t8467">8467</a></span><span class="t">                    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8468" href="#t8468">8468</a></span><span class="t">                        <span class="nam">out_shape</span><span class="op">[</span><span class="nam">i</span><span class="op">]</span> <span class="op">=</span> <span class="nam">dim</span><span class="op">.</span><span class="nam">numpy</span><span class="op">(</span><span class="op">)</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8469" href="#t8469">8469</a></span><span class="t">            <span class="key">if</span> <span class="key">not</span> <span class="op">(</span><span class="nam">_is_list_or_turple_</span><span class="op">(</span><span class="nam">out_shape</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8470" href="#t8470">8470</a></span><span class="t">                <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8471" href="#t8471">8471</a></span><span class="t">                    <span class="str">"out_shape should be a list or tuple or Variable."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8472" href="#t8472">8472</a></span><span class="t">                <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8473" href="#t8473">8473</a></span><span class="t">            <span class="com"># Validate the shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8474" href="#t8474">8474</a></span><span class="t">            <span class="nam">contain_var</span> <span class="op">=</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8475" href="#t8475">8475</a></span><span class="t">            <span class="key">for</span> <span class="nam">dim_idx</span><span class="op">,</span> <span class="nam">dim_size</span> <span class="key">in</span> <span class="nam">enumerate</span><span class="op">(</span><span class="nam">out_shape</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8476" href="#t8476">8476</a></span><span class="t">                <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim_size</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8477" href="#t8477">8477</a></span><span class="t">                    <span class="nam">contain_var</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8478" href="#t8478">8478</a></span><span class="t">                    <span class="key">continue</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8479" href="#t8479">8479</a></span><span class="t">                <span class="key">assert</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8480" href="#t8480">8480</a></span><span class="t">                    <span class="nam">dim_size</span> <span class="op">></span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8481" href="#t8481">8481</a></span><span class="t">                <span class="op">)</span><span class="op">,</span> <span class="str">"Each dimension size given in out_shape must be greater than 0."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8482" href="#t8482">8482</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8483" href="#t8483">8483</a></span><span class="t">            <span class="key">if</span> <span class="nam">contain_var</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8484" href="#t8484">8484</a></span><span class="t">                <span class="nam">new_size_tensor</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8485" href="#t8485">8485</a></span><span class="t">                <span class="nam">size_list</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8486" href="#t8486">8486</a></span><span class="t">                <span class="key">for</span> <span class="nam">dim</span> <span class="key">in</span> <span class="nam">out_shape</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8487" href="#t8487">8487</a></span><span class="t">                    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8488" href="#t8488">8488</a></span><span class="t">                        <span class="nam">dim</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8489" href="#t8489">8489</a></span><span class="t">                        <span class="nam">new_size_tensor</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">dim</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8490" href="#t8490">8490</a></span><span class="t">                        <span class="nam">size_list</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="op">-</span><span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8491" href="#t8491">8491</a></span><span class="t">                    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8492" href="#t8492">8492</a></span><span class="t">                        <span class="key">assert</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8493" href="#t8493">8493</a></span><span class="t">                        <span class="nam">temp_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8494" href="#t8494">8494</a></span><span class="t">                            <span class="str">'int32'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8495" href="#t8495">8495</a></span><span class="t">                        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8496" href="#t8496">8496</a></span><span class="t">                        <span class="nam">fill_constant</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8497" href="#t8497">8497</a></span><span class="t">                            <span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="nam">dim</span><span class="op">,</span> <span class="nam">force_cpu</span><span class="op">=</span><span class="key">True</span><span class="op">,</span> <span class="nam">out</span><span class="op">=</span><span class="nam">temp_out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8498" href="#t8498">8498</a></span><span class="t">                        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8499" href="#t8499">8499</a></span><span class="t">                        <span class="nam">new_size_tensor</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">temp_out</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8500" href="#t8500">8500</a></span><span class="t">                        <span class="nam">size_list</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">dim</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8501" href="#t8501">8501</a></span><span class="t">                <span class="nam">inputs</span><span class="op">[</span><span class="str">'SizeTensor'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">new_size_tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8502" href="#t8502">8502</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8503" href="#t8503">8503</a></span><span class="t">            <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">==</span> <span class="num">3</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8504" href="#t8504">8504</a></span><span class="t">                <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">out_shape</span><span class="op">)</span> <span class="op">!=</span> <span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8505" href="#t8505">8505</a></span><span class="t">                    <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8506" href="#t8506">8506</a></span><span class="t">                        <span class="str">"out_shape length should be 1 for "</span> <span class="str">"input 3-D tensor."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8507" href="#t8507">8507</a></span><span class="t">                    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8508" href="#t8508">8508</a></span><span class="t">                <span class="key">if</span> <span class="nam">contain_var</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8509" href="#t8509">8509</a></span><span class="t">                    <span class="nam">attrs</span><span class="op">[</span><span class="str">'out_w'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">size_list</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8510" href="#t8510">8510</a></span><span class="t">                <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8511" href="#t8511">8511</a></span><span class="t">                    <span class="nam">out_shape</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="nam">map</span><span class="op">(</span><span class="nam">int</span><span class="op">,</span> <span class="nam">out_shape</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8512" href="#t8512">8512</a></span><span class="t">                    <span class="nam">attrs</span><span class="op">[</span><span class="str">'out_w'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">out_shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8513" href="#t8513">8513</a></span><span class="t">            <span class="key">elif</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">==</span> <span class="num">4</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8514" href="#t8514">8514</a></span><span class="t">                <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">out_shape</span><span class="op">)</span> <span class="op">!=</span> <span class="num">2</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8515" href="#t8515">8515</a></span><span class="t">                    <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8516" href="#t8516">8516</a></span><span class="t">                        <span class="str">"out_shape length should be 2 for "</span> <span class="str">"input 4-D tensor."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8517" href="#t8517">8517</a></span><span class="t">                    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8518" href="#t8518">8518</a></span><span class="t">                <span class="key">if</span> <span class="nam">contain_var</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8519" href="#t8519">8519</a></span><span class="t">                    <span class="nam">attrs</span><span class="op">[</span><span class="str">'out_h'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">size_list</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8520" href="#t8520">8520</a></span><span class="t">                    <span class="nam">attrs</span><span class="op">[</span><span class="str">'out_w'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">size_list</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8521" href="#t8521">8521</a></span><span class="t">                <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8522" href="#t8522">8522</a></span><span class="t">                    <span class="nam">out_shape</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="nam">map</span><span class="op">(</span><span class="nam">int</span><span class="op">,</span> <span class="nam">out_shape</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8523" href="#t8523">8523</a></span><span class="t">                    <span class="nam">attrs</span><span class="op">[</span><span class="str">'out_h'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">out_shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8524" href="#t8524">8524</a></span><span class="t">                    <span class="nam">attrs</span><span class="op">[</span><span class="str">'out_w'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">out_shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8525" href="#t8525">8525</a></span><span class="t">            <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">==</span> <span class="num">5</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8526" href="#t8526">8526</a></span><span class="t">                <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">out_shape</span><span class="op">)</span> <span class="op">!=</span> <span class="num">3</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8527" href="#t8527">8527</a></span><span class="t">                    <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8528" href="#t8528">8528</a></span><span class="t">                        <span class="str">"out_shape length should be 3 for "</span> <span class="str">"input 5-D tensor."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8529" href="#t8529">8529</a></span><span class="t">                    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8530" href="#t8530">8530</a></span><span class="t">                <span class="key">if</span> <span class="nam">contain_var</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8531" href="#t8531">8531</a></span><span class="t">                    <span class="nam">attrs</span><span class="op">[</span><span class="str">'out_d'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">size_list</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8532" href="#t8532">8532</a></span><span class="t">                    <span class="nam">attrs</span><span class="op">[</span><span class="str">'out_h'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">size_list</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8533" href="#t8533">8533</a></span><span class="t">                    <span class="nam">attrs</span><span class="op">[</span><span class="str">'out_w'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">size_list</span><span class="op">[</span><span class="num">2</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8534" href="#t8534">8534</a></span><span class="t">                <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8535" href="#t8535">8535</a></span><span class="t">                    <span class="nam">out_shape</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="nam">map</span><span class="op">(</span><span class="nam">int</span><span class="op">,</span> <span class="nam">out_shape</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8536" href="#t8536">8536</a></span><span class="t">                    <span class="nam">attrs</span><span class="op">[</span><span class="str">'out_d'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">out_shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8537" href="#t8537">8537</a></span><span class="t">                    <span class="nam">attrs</span><span class="op">[</span><span class="str">'out_h'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">out_shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8538" href="#t8538">8538</a></span><span class="t">                    <span class="nam">attrs</span><span class="op">[</span><span class="str">'out_w'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">out_shape</span><span class="op">[</span><span class="num">2</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8539" href="#t8539">8539</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8540" href="#t8540">8540</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8541" href="#t8541">8541</a></span><span class="t">        <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span> <span class="key">and</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">scale</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8542" href="#t8542">8542</a></span><span class="t">            <span class="nam">scale</span> <span class="op">=</span> <span class="nam">scale</span><span class="op">.</span><span class="nam">numpy</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8543" href="#t8543">8543</a></span><span class="t">        <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">scale</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8544" href="#t8544">8544</a></span><span class="t">            <span class="nam">scale</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8545" href="#t8545">8545</a></span><span class="t">            <span class="nam">inputs</span><span class="op">[</span><span class="str">"Scale"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">scale</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8546" href="#t8546">8546</a></span><span class="t">        <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">scale</span><span class="op">,</span> <span class="nam">float</span><span class="op">)</span> <span class="key">or</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">scale</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8547" href="#t8547">8547</a></span><span class="t">            <span class="key">if</span> <span class="nam">scale</span> <span class="op">&lt;=</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8548" href="#t8548">8548</a></span><span class="t">                <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"Attr(scale) should be greater than zero."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8549" href="#t8549">8549</a></span><span class="t">            <span class="nam">attrs</span><span class="op">[</span><span class="str">'scale'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">float</span><span class="op">(</span><span class="nam">scale</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8550" href="#t8550">8550</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8551" href="#t8551">8551</a></span><span class="t">            <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8552" href="#t8552">8552</a></span><span class="t">                <span class="str">"Attr(scale)'s type should be float, int or Variable."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8553" href="#t8553">8553</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8554" href="#t8554">8554</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8555" href="#t8555">8555</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">actual_shape</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8556" href="#t8556">8556</a></span><span class="t">        <span class="nam">warnings</span><span class="op">.</span><span class="nam">warn</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8557" href="#t8557">8557</a></span><span class="t">            <span class="str">"actual_shape will be deprecated, it is recommended to use "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8558" href="#t8558">8558</a></span><span class="t">            <span class="str">"out_shape instead of actual_shape to specify output shape dynamically."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8559" href="#t8559">8559</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8560" href="#t8560">8560</a></span><span class="t">        <span class="nam">actual_shape</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8561" href="#t8561">8561</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">"OutSize"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">actual_shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8562" href="#t8562">8562</a></span><span class="t">    <span class="key">elif</span> <span class="nam">actual_shape</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8563" href="#t8563">8563</a></span><span class="t">        <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span><span class="str">"actual_shape should either be Variable or None."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8564" href="#t8564">8564</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8565" href="#t8565">8565</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8566" href="#t8566">8566</a></span><span class="t">        <span class="nam">attr_list</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8567" href="#t8567">8567</a></span><span class="t">        <span class="key">for</span> <span class="nam">k</span><span class="op">,</span> <span class="nam">v</span> <span class="key">in</span> <span class="nam">attrs</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8568" href="#t8568">8568</a></span><span class="t">            <span class="nam">attr_list</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">k</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8569" href="#t8569">8569</a></span><span class="t">            <span class="nam">attr_list</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">v</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8570" href="#t8570">8570</a></span><span class="t">        <span class="nam">dy_attr</span> <span class="op">=</span> <span class="nam">tuple</span><span class="op">(</span><span class="nam">attr_list</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8571" href="#t8571">8571</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8572" href="#t8572">8572</a></span><span class="t">        <span class="key">if</span> <span class="nam">resample_type</span> <span class="op">==</span> <span class="str">"linear"</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8573" href="#t8573">8573</a></span><span class="t">            <span class="nam">out</span> <span class="op">=</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">linear_interp</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">actual_shape</span><span class="op">,</span> <span class="op">*</span><span class="nam">dy_attr</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8574" href="#t8574">8574</a></span><span class="t">        <span class="key">elif</span> <span class="nam">resample_type</span> <span class="op">==</span> <span class="str">"bilinear"</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8575" href="#t8575">8575</a></span><span class="t">            <span class="nam">out</span> <span class="op">=</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">bilinear_interp</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">actual_shape</span><span class="op">,</span> <span class="op">*</span><span class="nam">dy_attr</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8576" href="#t8576">8576</a></span><span class="t">        <span class="key">elif</span> <span class="nam">resample_type</span> <span class="op">==</span> <span class="str">"trilinear"</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8577" href="#t8577">8577</a></span><span class="t">            <span class="nam">out</span> <span class="op">=</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">trilinear_interp</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">actual_shape</span><span class="op">,</span> <span class="op">*</span><span class="nam">dy_attr</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8578" href="#t8578">8578</a></span><span class="t">        <span class="key">elif</span> <span class="nam">resample_type</span> <span class="op">==</span> <span class="str">"nearest"</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8579" href="#t8579">8579</a></span><span class="t">            <span class="nam">out</span> <span class="op">=</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">nearest_interp</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">actual_shape</span><span class="op">,</span> <span class="op">*</span><span class="nam">dy_attr</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8580" href="#t8580">8580</a></span><span class="t">        <span class="key">elif</span> <span class="nam">resample_type</span> <span class="op">==</span> <span class="str">"bicubic"</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8581" href="#t8581">8581</a></span><span class="t">            <span class="nam">out</span> <span class="op">=</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">bicubic_interp</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">actual_shape</span><span class="op">,</span> <span class="op">*</span><span class="nam">dy_attr</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8582" href="#t8582">8582</a></span><span class="t">        <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8583" href="#t8583">8583</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8584" href="#t8584">8584</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8585" href="#t8585">8585</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8586" href="#t8586">8586</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'{}_interp'</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">resample_type</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8587" href="#t8587">8587</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8588" href="#t8588">8588</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8589" href="#t8589">8589</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8590" href="#t8590">8590</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8591" href="#t8591">8591</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8592" href="#t8592">8592</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8593" href="#t8593">8593</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t8594" href="#t8594">8594</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="nam">op_type</span><span class="op">=</span><span class="str">"linear_interp"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t8595" href="#t8595">8595</a></span><span class="t"><span class="key">def</span> <span class="nam">resize_linear</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8596" href="#t8596">8596</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8597" href="#t8597">8597</a></span><span class="t">    <span class="nam">out_shape</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8598" href="#t8598">8598</a></span><span class="t">    <span class="nam">scale</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8599" href="#t8599">8599</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8600" href="#t8600">8600</a></span><span class="t">    <span class="nam">actual_shape</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8601" href="#t8601">8601</a></span><span class="t">    <span class="nam">align_corners</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8602" href="#t8602">8602</a></span><span class="t">    <span class="nam">align_mode</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8603" href="#t8603">8603</a></span><span class="t">    <span class="nam">data_format</span><span class="op">=</span><span class="str">'NCW'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8604" href="#t8604">8604</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8605" href="#t8605">8605</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8606" href="#t8606">8606</a></span><span class="t"><span class="str">    This op resizes the input by performing linear interpolation based on given</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8607" href="#t8607">8607</a></span><span class="t"><span class="str">    output shape which specified by actual_shape, out_shape and scale</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8608" href="#t8608">8608</a></span><span class="t"><span class="str">    in priority order.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8609" href="#t8609">8609</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8610" href="#t8610">8610</a></span><span class="t"><span class="str">    **Warning:** the parameter :attr:`actual_shape` will be deprecated in</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8611" href="#t8611">8611</a></span><span class="t"><span class="str">    the future and only use :attr:`out_shape` instead.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8612" href="#t8612">8612</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8613" href="#t8613">8613</a></span><span class="t"><span class="str">    Align_corners and align_mode are optional parameters,the calculation</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8614" href="#t8614">8614</a></span><span class="t"><span class="str">    method of interpolation can be selected by them.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8615" href="#t8615">8615</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8616" href="#t8616">8616</a></span><span class="t"><span class="str">    Example:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8617" href="#t8617">8617</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8618" href="#t8618">8618</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8619" href="#t8619">8619</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8620" href="#t8620">8620</a></span><span class="t"><span class="str">        For scale:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8621" href="#t8621">8621</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8622" href="#t8622">8622</a></span><span class="t"><span class="str">            if align_corners = True &amp;&amp; out_size > 1 :</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8623" href="#t8623">8623</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8624" href="#t8624">8624</a></span><span class="t"><span class="str">              scale_factor = (in_size-1.0)/(out_size-1.0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8625" href="#t8625">8625</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8626" href="#t8626">8626</a></span><span class="t"><span class="str">            else:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8627" href="#t8627">8627</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8628" href="#t8628">8628</a></span><span class="t"><span class="str">              scale_factor = float(in_size/out_size)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8629" href="#t8629">8629</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8630" href="#t8630">8630</a></span><span class="t"><span class="str">        Linear interpolation:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8631" href="#t8631">8631</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8632" href="#t8632">8632</a></span><span class="t"><span class="str">          if:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8633" href="#t8633">8633</a></span><span class="t"><span class="str">              align_corners = False , align_mode = 0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8634" href="#t8634">8634</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8635" href="#t8635">8635</a></span><span class="t"><span class="str">              input : (N,C,W_in)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8636" href="#t8636">8636</a></span><span class="t"><span class="str">              output: (N,C,W_out) where:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8637" href="#t8637">8637</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8638" href="#t8638">8638</a></span><span class="t"><span class="str">              W_out = (W_{in}+0.5) * scale_{factor} - 0.5</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8639" href="#t8639">8639</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8640" href="#t8640">8640</a></span><span class="t"><span class="str">          else:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8641" href="#t8641">8641</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8642" href="#t8642">8642</a></span><span class="t"><span class="str">              input : (N,C,W_in)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8643" href="#t8643">8643</a></span><span class="t"><span class="str">              output: (N,C,W_out) where:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8644" href="#t8644">8644</a></span><span class="t"><span class="str">              W_out = W_{in} * scale_{factor}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8645" href="#t8645">8645</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8646" href="#t8646">8646</a></span><span class="t"><span class="str">    Parameters:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8647" href="#t8647">8647</a></span><span class="t"><span class="str">        input(Variable): 3-D Tensor(NCW), its data type is float32, float64, or uint8,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8648" href="#t8648">8648</a></span><span class="t"><span class="str">                          its data format is specified by :attr:`data_format`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8649" href="#t8649">8649</a></span><span class="t"><span class="str">        out_shape(list|tuple|Variable|None): Output shape of resize linear</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8650" href="#t8650">8650</a></span><span class="t"><span class="str">            layer, the shape is (out_w,). Default: None. If a list, each</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8651" href="#t8651">8651</a></span><span class="t"><span class="str">            element can be an integer or a Tensor Variable with shape: [1]. If a</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8652" href="#t8652">8652</a></span><span class="t"><span class="str">            Tensor Variable, its dimension size should be 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8653" href="#t8653">8653</a></span><span class="t"><span class="str">        scale(float|Variable|None): The multiplier for the input height or width. At</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8654" href="#t8654">8654</a></span><span class="t"><span class="str">             least one of :attr:`out_shape` or :attr:`scale` must be set.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8655" href="#t8655">8655</a></span><span class="t"><span class="str">             And :attr:`out_shape` has a higher priority than :attr:`scale`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8656" href="#t8656">8656</a></span><span class="t"><span class="str">             Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8657" href="#t8657">8657</a></span><span class="t"><span class="str">        actual_shape(Variable): An optional input to specify output shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8658" href="#t8658">8658</a></span><span class="t"><span class="str">                                dynamically. If provided, image resize</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8659" href="#t8659">8659</a></span><span class="t"><span class="str">                                according to this given shape rather than</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8660" href="#t8660">8660</a></span><span class="t"><span class="str">                                :attr:`out_shape` and :attr:`scale` specifying</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8661" href="#t8661">8661</a></span><span class="t"><span class="str">                                shape. That is to say actual_shape has the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8662" href="#t8662">8662</a></span><span class="t"><span class="str">                                highest priority. It is recommended to use</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8663" href="#t8663">8663</a></span><span class="t"><span class="str">                                :attr:`out_shape` if you want to specify output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8664" href="#t8664">8664</a></span><span class="t"><span class="str">                                shape dynamically, because :attr:`actual_shape`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8665" href="#t8665">8665</a></span><span class="t"><span class="str">                                will be deprecated. When using actual_shape to</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8666" href="#t8666">8666</a></span><span class="t"><span class="str">                                specify output shape, one of :attr:`out_shape`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8667" href="#t8667">8667</a></span><span class="t"><span class="str">                                and :attr:`scale` should also be set, otherwise</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8668" href="#t8668">8668</a></span><span class="t"><span class="str">                                errors would be occurred in graph constructing stage.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8669" href="#t8669">8669</a></span><span class="t"><span class="str">                                Default: None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8670" href="#t8670">8670</a></span><span class="t"><span class="str">        align_corners(bool): ${align_corners_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8671" href="#t8671">8671</a></span><span class="t"><span class="str">        align_mode(bool): ${align_mode_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8672" href="#t8672">8672</a></span><span class="t"><span class="str">        data_format (str, optional): Specify the data format of the input, and the data format of the output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8673" href="#t8673">8673</a></span><span class="t"><span class="str">            will be consistent with that of the input. An optional string from: `"NCW"`, `"NWC"`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8674" href="#t8674">8674</a></span><span class="t"><span class="str">            The default is `"NCW"`. When it is `"NCW"`, the data is stored in the order of:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8675" href="#t8675">8675</a></span><span class="t"><span class="str">            `[batch_size, input_channels, input_width]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8676" href="#t8676">8676</a></span><span class="t"><span class="str">        name(str, optional): The default value is None.  Normally there is no need for user to set this property.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8677" href="#t8677">8677</a></span><span class="t"><span class="str">            For more information, please refer to :ref:`api_guide_Name`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8678" href="#t8678">8678</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8679" href="#t8679">8679</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8680" href="#t8680">8680</a></span><span class="t"><span class="str">        Variable: 3-D tensor(NCW or NWC).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8681" href="#t8681">8681</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8682" href="#t8682">8682</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8683" href="#t8683">8683</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8684" href="#t8684">8684</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8685" href="#t8685">8685</a></span><span class="t"><span class="str">            #declarative mode</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8686" href="#t8686">8686</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8687" href="#t8687">8687</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8688" href="#t8688">8688</a></span><span class="t"><span class="str">            input = fluid.data(name="input", shape=[None,3,100])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8689" href="#t8689">8689</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8690" href="#t8690">8690</a></span><span class="t"><span class="str">            output = fluid.layers.resize_linear(input=input,out_shape=[50,])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8691" href="#t8691">8691</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8692" href="#t8692">8692</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8693" href="#t8693">8693</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8694" href="#t8694">8694</a></span><span class="t"><span class="str">            exe.run(fluid.default_startup_program())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8695" href="#t8695">8695</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8696" href="#t8696">8696</a></span><span class="t"><span class="str">            input_data = np.random.rand(1,3,100).astype("float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8697" href="#t8697">8697</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8698" href="#t8698">8698</a></span><span class="t"><span class="str">            output_data = exe.run(fluid.default_main_program(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8699" href="#t8699">8699</a></span><span class="t"><span class="str">                feed={"input":input_data},</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8700" href="#t8700">8700</a></span><span class="t"><span class="str">                fetch_list=[output],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8701" href="#t8701">8701</a></span><span class="t"><span class="str">                return_numpy=True)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8702" href="#t8702">8702</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8703" href="#t8703">8703</a></span><span class="t"><span class="str">            print(output_data[0].shape)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8704" href="#t8704">8704</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8705" href="#t8705">8705</a></span><span class="t"><span class="str">            # (1, 3, 50)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8706" href="#t8706">8706</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8707" href="#t8707">8707</a></span><span class="t"><span class="str">            #imperative mode</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8708" href="#t8708">8708</a></span><span class="t"><span class="str">            import paddle.fluid.dygraph as dg</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8709" href="#t8709">8709</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8710" href="#t8710">8710</a></span><span class="t"><span class="str">            with dg.guard(place) as g:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8711" href="#t8711">8711</a></span><span class="t"><span class="str">                input = dg.to_variable(input_data)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8712" href="#t8712">8712</a></span><span class="t"><span class="str">                output = fluid.layers.resize_linear(input=input, out_shape=[50,])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8713" href="#t8713">8713</a></span><span class="t"><span class="str">                print(output.shape)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8714" href="#t8714">8714</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8715" href="#t8715">8715</a></span><span class="t"><span class="str">                # [1L, 3L, 50L]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8716" href="#t8716">8716</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8717" href="#t8717">8717</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8718" href="#t8718">8718</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8719" href="#t8719">8719</a></span><span class="t">    <span class="key">return</span> <span class="nam">image_resize</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8720" href="#t8720">8720</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8721" href="#t8721">8721</a></span><span class="t">        <span class="nam">out_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8722" href="#t8722">8722</a></span><span class="t">        <span class="nam">scale</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8723" href="#t8723">8723</a></span><span class="t">        <span class="nam">name</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8724" href="#t8724">8724</a></span><span class="t">        <span class="str">'LINEAR'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8725" href="#t8725">8725</a></span><span class="t">        <span class="nam">actual_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8726" href="#t8726">8726</a></span><span class="t">        <span class="nam">align_corners</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8727" href="#t8727">8727</a></span><span class="t">        <span class="nam">align_mode</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8728" href="#t8728">8728</a></span><span class="t">        <span class="nam">data_format</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8729" href="#t8729">8729</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8730" href="#t8730">8730</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8731" href="#t8731">8731</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t8732" href="#t8732">8732</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="nam">op_type</span><span class="op">=</span><span class="str">"bilinear_interp"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t8733" href="#t8733">8733</a></span><span class="t"><span class="key">def</span> <span class="nam">resize_bilinear</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8734" href="#t8734">8734</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8735" href="#t8735">8735</a></span><span class="t">    <span class="nam">out_shape</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8736" href="#t8736">8736</a></span><span class="t">    <span class="nam">scale</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8737" href="#t8737">8737</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8738" href="#t8738">8738</a></span><span class="t">    <span class="nam">actual_shape</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8739" href="#t8739">8739</a></span><span class="t">    <span class="nam">align_corners</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8740" href="#t8740">8740</a></span><span class="t">    <span class="nam">align_mode</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8741" href="#t8741">8741</a></span><span class="t">    <span class="nam">data_format</span><span class="op">=</span><span class="str">'NCHW'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8742" href="#t8742">8742</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8743" href="#t8743">8743</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8744" href="#t8744">8744</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8745" href="#t8745">8745</a></span><span class="t"><span class="str">    This op resizes the input by performing bilinear interpolation based on given</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8746" href="#t8746">8746</a></span><span class="t"><span class="str">    output shape which specified by actual_shape, out_shape and scale</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8747" href="#t8747">8747</a></span><span class="t"><span class="str">    in priority order.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8748" href="#t8748">8748</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8749" href="#t8749">8749</a></span><span class="t"><span class="str">    **Warning:** the parameter :attr:`actual_shape` will be deprecated in</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8750" href="#t8750">8750</a></span><span class="t"><span class="str">    the future and only use :attr:`out_shape` instead.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8751" href="#t8751">8751</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8752" href="#t8752">8752</a></span><span class="t"><span class="str">    Bilinear interpolation is an extension of linear interpolation for</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8753" href="#t8753">8753</a></span><span class="t"><span class="str">    interpolating functions of two variables (e.g. H-direction and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8754" href="#t8754">8754</a></span><span class="t"><span class="str">    W-direction in this op) on a rectilinear 2D grid. The key idea is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8755" href="#t8755">8755</a></span><span class="t"><span class="str">    to perform linear interpolation first in one direction, and then</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8756" href="#t8756">8756</a></span><span class="t"><span class="str">    again in the other direction.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8757" href="#t8757">8757</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8758" href="#t8758">8758</a></span><span class="t"><span class="str">    For details of bilinear interpolation, please refer to Wikipedia:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8759" href="#t8759">8759</a></span><span class="t"><span class="str">    https://en.wikipedia.org/wiki/Bilinear_interpolation</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8760" href="#t8760">8760</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8761" href="#t8761">8761</a></span><span class="t"><span class="str">    Align_corners and align_mode are optional parameters,the calculation</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8762" href="#t8762">8762</a></span><span class="t"><span class="str">    method of interpolation can be selected by them.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8763" href="#t8763">8763</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8764" href="#t8764">8764</a></span><span class="t"><span class="str">    Example:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8765" href="#t8765">8765</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8766" href="#t8766">8766</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8767" href="#t8767">8767</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8768" href="#t8768">8768</a></span><span class="t"><span class="str">        For scale:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8769" href="#t8769">8769</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8770" href="#t8770">8770</a></span><span class="t"><span class="str">            if align_corners = True &amp;&amp; out_size > 1 :</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8771" href="#t8771">8771</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8772" href="#t8772">8772</a></span><span class="t"><span class="str">              scale_factor = (in_size-1.0)/(out_size-1.0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8773" href="#t8773">8773</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8774" href="#t8774">8774</a></span><span class="t"><span class="str">            else:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8775" href="#t8775">8775</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8776" href="#t8776">8776</a></span><span class="t"><span class="str">              scale_factor = float(in_size/out_size)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8777" href="#t8777">8777</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8778" href="#t8778">8778</a></span><span class="t"><span class="str">        Bilinear interpolation:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8779" href="#t8779">8779</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8780" href="#t8780">8780</a></span><span class="t"><span class="str">          if:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8781" href="#t8781">8781</a></span><span class="t"><span class="str">              align_corners = False , align_mode = 0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8782" href="#t8782">8782</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8783" href="#t8783">8783</a></span><span class="t"><span class="str">              input : (N,C,H_in,W_in)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8784" href="#t8784">8784</a></span><span class="t"><span class="str">              output: (N,C,H_out,W_out) where:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8785" href="#t8785">8785</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8786" href="#t8786">8786</a></span><span class="t"><span class="str">              H_out = (H_{in}+0.5) * scale_{factor} - 0.5</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8787" href="#t8787">8787</a></span><span class="t"><span class="str">              W_out = (W_{in}+0.5) * scale_{factor} - 0.5</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8788" href="#t8788">8788</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8789" href="#t8789">8789</a></span><span class="t"><span class="str">          else:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8790" href="#t8790">8790</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8791" href="#t8791">8791</a></span><span class="t"><span class="str">              input : (N,C,H_in,W_in)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8792" href="#t8792">8792</a></span><span class="t"><span class="str">              output: (N,C,H_out,W_out) where:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8793" href="#t8793">8793</a></span><span class="t"><span class="str">              H_out = H_{in} * scale_{factor}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8794" href="#t8794">8794</a></span><span class="t"><span class="str">              W_out = W_{in} * scale_{factor}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8795" href="#t8795">8795</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8796" href="#t8796">8796</a></span><span class="t"><span class="str">    Parameters:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8797" href="#t8797">8797</a></span><span class="t"><span class="str">        input(Variable): 4-D Tensor(NCHW), its data type is float32, float64, or uint8,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8798" href="#t8798">8798</a></span><span class="t"><span class="str">                          its data format is specified by :attr:`data_format`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8799" href="#t8799">8799</a></span><span class="t"><span class="str">        out_shape(list|tuple|Variable|None): Output shape of resize bilinear</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8800" href="#t8800">8800</a></span><span class="t"><span class="str">            layer, the shape is (out_h, out_w).Default: None. If a list, each</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8801" href="#t8801">8801</a></span><span class="t"><span class="str">            element can be an integer or a Tensor Variable with shape: [1]. If a</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8802" href="#t8802">8802</a></span><span class="t"><span class="str">            Tensor Variable, its dimension size should be 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8803" href="#t8803">8803</a></span><span class="t"><span class="str">        scale(float|Variable|None): The multiplier for the input height or width. At</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8804" href="#t8804">8804</a></span><span class="t"><span class="str">             least one of :attr:`out_shape` or :attr:`scale` must be set.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8805" href="#t8805">8805</a></span><span class="t"><span class="str">             And :attr:`out_shape` has a higher priority than :attr:`scale`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8806" href="#t8806">8806</a></span><span class="t"><span class="str">             Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8807" href="#t8807">8807</a></span><span class="t"><span class="str">        actual_shape(Variable): An optional input to specify output shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8808" href="#t8808">8808</a></span><span class="t"><span class="str">                                dynamically. If provided, image resize</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8809" href="#t8809">8809</a></span><span class="t"><span class="str">                                according to this given shape rather than</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8810" href="#t8810">8810</a></span><span class="t"><span class="str">                                :attr:`out_shape` and :attr:`scale` specifying</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8811" href="#t8811">8811</a></span><span class="t"><span class="str">                                shape. That is to say actual_shape has the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8812" href="#t8812">8812</a></span><span class="t"><span class="str">                                highest priority. It is recommended to use</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8813" href="#t8813">8813</a></span><span class="t"><span class="str">                                :attr:`out_shape` if you want to specify output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8814" href="#t8814">8814</a></span><span class="t"><span class="str">                                shape dynamically, because :attr:`actual_shape`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8815" href="#t8815">8815</a></span><span class="t"><span class="str">                                will be deprecated. When using actual_shape to</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8816" href="#t8816">8816</a></span><span class="t"><span class="str">                                specify output shape, one of :attr:`out_shape`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8817" href="#t8817">8817</a></span><span class="t"><span class="str">                                and :attr:`scale` should also be set, otherwise</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8818" href="#t8818">8818</a></span><span class="t"><span class="str">                                errors would be occurred in graph constructing stage.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8819" href="#t8819">8819</a></span><span class="t"><span class="str">                                Default: None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8820" href="#t8820">8820</a></span><span class="t"><span class="str">        align_corners(bool): ${align_corners_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8821" href="#t8821">8821</a></span><span class="t"><span class="str">        align_mode(bool): ${align_mode_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8822" href="#t8822">8822</a></span><span class="t"><span class="str">        data_format (str, optional): Specify the data format of the input, and the data format of the output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8823" href="#t8823">8823</a></span><span class="t"><span class="str">            will be consistent with that of the input. An optional string from: `"NCHW"`, `"NHWC"`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8824" href="#t8824">8824</a></span><span class="t"><span class="str">            The default is `"NCHW"`. When it is `"NCHW"`, the data is stored in the order of:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8825" href="#t8825">8825</a></span><span class="t"><span class="str">            `[batch_size, input_channels, input_height, input_width]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8826" href="#t8826">8826</a></span><span class="t"><span class="str">        name(str, optional): The default value is None.  Normally there is no need for user to set this property.  For more information, please refer to :ref:`api_guide_Name`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8827" href="#t8827">8827</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8828" href="#t8828">8828</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8829" href="#t8829">8829</a></span><span class="t"><span class="str">        Variable: 4-D tensor(NCHW or NHWC).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8830" href="#t8830">8830</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8831" href="#t8831">8831</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8832" href="#t8832">8832</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8833" href="#t8833">8833</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8834" href="#t8834">8834</a></span><span class="t"><span class="str">            #declarative mode</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8835" href="#t8835">8835</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8836" href="#t8836">8836</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8837" href="#t8837">8837</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8838" href="#t8838">8838</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8839" href="#t8839">8839</a></span><span class="t"><span class="str">            input = fluid.data(name="input", shape=[None,3,6,10])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8840" href="#t8840">8840</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8841" href="#t8841">8841</a></span><span class="t"><span class="str">            #1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8842" href="#t8842">8842</a></span><span class="t"><span class="str">            output = fluid.layers.resize_bilinear(input=input,out_shape=[12,12])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8843" href="#t8843">8843</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8844" href="#t8844">8844</a></span><span class="t"><span class="str">            #2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8845" href="#t8845">8845</a></span><span class="t"><span class="str">            #x = np.array([2]).astype("int32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8846" href="#t8846">8846</a></span><span class="t"><span class="str">            #dim1 = fluid.data(name="dim1", shape=[1], dtype="int32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8847" href="#t8847">8847</a></span><span class="t"><span class="str">            #fluid.layers.assign(input=x, output=dim1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8848" href="#t8848">8848</a></span><span class="t"><span class="str">            #output = fluid.layers.resize_bilinear(input=input,out_shape=[12,dim1])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8849" href="#t8849">8849</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8850" href="#t8850">8850</a></span><span class="t"><span class="str">            #3</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8851" href="#t8851">8851</a></span><span class="t"><span class="str">            #x = np.array([3,12]).astype("int32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8852" href="#t8852">8852</a></span><span class="t"><span class="str">            #shape_tensor = fluid.data(name="shape_tensor", shape=[2], dtype="int32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8853" href="#t8853">8853</a></span><span class="t"><span class="str">            #fluid.layers.assign(input=x, output=shape_tensor)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8854" href="#t8854">8854</a></span><span class="t"><span class="str">            #output = fluid.layers.resize_bilinear(input=input,out_shape=shape_tensor)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8855" href="#t8855">8855</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8856" href="#t8856">8856</a></span><span class="t"><span class="str">            #4</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8857" href="#t8857">8857</a></span><span class="t"><span class="str">            #x = np.array([0.5]).astype("float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8858" href="#t8858">8858</a></span><span class="t"><span class="str">            #scale_tensor = fluid.data(name="scale", shape=[1], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8859" href="#t8859">8859</a></span><span class="t"><span class="str">            #fluid.layers.assign(x,scale_tensor)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8860" href="#t8860">8860</a></span><span class="t"><span class="str">            #output = fluid.layers.resize_bilinear(input=input,scale=scale_tensor)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8861" href="#t8861">8861</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8862" href="#t8862">8862</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8863" href="#t8863">8863</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8864" href="#t8864">8864</a></span><span class="t"><span class="str">            exe.run(fluid.default_startup_program())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8865" href="#t8865">8865</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8866" href="#t8866">8866</a></span><span class="t"><span class="str">            input_data = np.random.rand(2,3,6,10).astype("float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8867" href="#t8867">8867</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8868" href="#t8868">8868</a></span><span class="t"><span class="str">            output_data = exe.run(fluid.default_main_program(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8869" href="#t8869">8869</a></span><span class="t"><span class="str">                feed={"input":input_data},</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8870" href="#t8870">8870</a></span><span class="t"><span class="str">                fetch_list=[output],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8871" href="#t8871">8871</a></span><span class="t"><span class="str">                return_numpy=True)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8872" href="#t8872">8872</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8873" href="#t8873">8873</a></span><span class="t"><span class="str">            print(output_data[0].shape)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8874" href="#t8874">8874</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8875" href="#t8875">8875</a></span><span class="t"><span class="str">            #1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8876" href="#t8876">8876</a></span><span class="t"><span class="str">            # (2, 3, 12, 12)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8877" href="#t8877">8877</a></span><span class="t"><span class="str">            #2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8878" href="#t8878">8878</a></span><span class="t"><span class="str">            # (2, 3, 12, 2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8879" href="#t8879">8879</a></span><span class="t"><span class="str">            #3</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8880" href="#t8880">8880</a></span><span class="t"><span class="str">            # (2, 3, 3, 12)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8881" href="#t8881">8881</a></span><span class="t"><span class="str">            #4</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8882" href="#t8882">8882</a></span><span class="t"><span class="str">            # (2, 3, 3, 5)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8883" href="#t8883">8883</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8884" href="#t8884">8884</a></span><span class="t"><span class="str">            #imperative mode</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8885" href="#t8885">8885</a></span><span class="t"><span class="str">            import paddle.fluid.dygraph as dg</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8886" href="#t8886">8886</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8887" href="#t8887">8887</a></span><span class="t"><span class="str">            with dg.guard(place) as g:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8888" href="#t8888">8888</a></span><span class="t"><span class="str">                input = dg.to_variable(input_data)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8889" href="#t8889">8889</a></span><span class="t"><span class="str">                output = fluid.layers.resize_bilinear(input=input, out_shape=[12,12])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8890" href="#t8890">8890</a></span><span class="t"><span class="str">                print(output.shape)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8891" href="#t8891">8891</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8892" href="#t8892">8892</a></span><span class="t"><span class="str">                # [2L, 3L, 12L, 12L]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8893" href="#t8893">8893</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8894" href="#t8894">8894</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8895" href="#t8895">8895</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t8896" href="#t8896">8896</a></span><span class="t">    <span class="key">return</span> <span class="nam">image_resize</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8897" href="#t8897">8897</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8898" href="#t8898">8898</a></span><span class="t">        <span class="nam">out_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8899" href="#t8899">8899</a></span><span class="t">        <span class="nam">scale</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8900" href="#t8900">8900</a></span><span class="t">        <span class="nam">name</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8901" href="#t8901">8901</a></span><span class="t">        <span class="str">'BILINEAR'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8902" href="#t8902">8902</a></span><span class="t">        <span class="nam">actual_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8903" href="#t8903">8903</a></span><span class="t">        <span class="nam">align_corners</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8904" href="#t8904">8904</a></span><span class="t">        <span class="nam">align_mode</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8905" href="#t8905">8905</a></span><span class="t">        <span class="nam">data_format</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8906" href="#t8906">8906</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8907" href="#t8907">8907</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8908" href="#t8908">8908</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t8909" href="#t8909">8909</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="nam">op_type</span><span class="op">=</span><span class="str">"trilinear_interp"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t8910" href="#t8910">8910</a></span><span class="t"><span class="key">def</span> <span class="nam">resize_trilinear</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8911" href="#t8911">8911</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8912" href="#t8912">8912</a></span><span class="t">    <span class="nam">out_shape</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8913" href="#t8913">8913</a></span><span class="t">    <span class="nam">scale</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8914" href="#t8914">8914</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8915" href="#t8915">8915</a></span><span class="t">    <span class="nam">actual_shape</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8916" href="#t8916">8916</a></span><span class="t">    <span class="nam">align_corners</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8917" href="#t8917">8917</a></span><span class="t">    <span class="nam">align_mode</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8918" href="#t8918">8918</a></span><span class="t">    <span class="nam">data_format</span><span class="op">=</span><span class="str">'NCDHW'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8919" href="#t8919">8919</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8920" href="#t8920">8920</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8921" href="#t8921">8921</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8922" href="#t8922">8922</a></span><span class="t"><span class="str">    This op resizes the input by performing trilinear interpolation based on given</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8923" href="#t8923">8923</a></span><span class="t"><span class="str">    output shape which specified by actual_shape, out_shape and scale</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8924" href="#t8924">8924</a></span><span class="t"><span class="str">    in priority order.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8925" href="#t8925">8925</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8926" href="#t8926">8926</a></span><span class="t"><span class="str">    **Warning:** the parameter :attr:`actual_shape` will be deprecated</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8927" href="#t8927">8927</a></span><span class="t"><span class="str">    in the future and only use :attr:`out_shape` instead.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8928" href="#t8928">8928</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8929" href="#t8929">8929</a></span><span class="t"><span class="str">    Trilinear interpolation is an extension of linear interpolation for</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8930" href="#t8930">8930</a></span><span class="t"><span class="str">    interpolating functions of three variables (e.g. D-direction,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8931" href="#t8931">8931</a></span><span class="t"><span class="str">    H-direction and W-direction in this op) on a rectilinear 3D grid.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8932" href="#t8932">8932</a></span><span class="t"><span class="str">    The linear interpolation is performed on three directions.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8933" href="#t8933">8933</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8934" href="#t8934">8934</a></span><span class="t"><span class="str">    For details of trilinear interpolation, please refer to Wikipedia:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8935" href="#t8935">8935</a></span><span class="t"><span class="str">    https://en.wikipedia.org/wiki/Trilinear_interpolation</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8936" href="#t8936">8936</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8937" href="#t8937">8937</a></span><span class="t"><span class="str">    Align_corners and align_mode are optional parameters,the calculation</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8938" href="#t8938">8938</a></span><span class="t"><span class="str">    method of interpolation can be selected by them.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8939" href="#t8939">8939</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8940" href="#t8940">8940</a></span><span class="t"><span class="str">    Example:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8941" href="#t8941">8941</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8942" href="#t8942">8942</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8943" href="#t8943">8943</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8944" href="#t8944">8944</a></span><span class="t"><span class="str">        For scale:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8945" href="#t8945">8945</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8946" href="#t8946">8946</a></span><span class="t"><span class="str">            if align_corners = True &amp;&amp; out_size > 1 :</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8947" href="#t8947">8947</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8948" href="#t8948">8948</a></span><span class="t"><span class="str">              scale_factor = (in_size-1.0)/(out_size-1.0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8949" href="#t8949">8949</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8950" href="#t8950">8950</a></span><span class="t"><span class="str">            else:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8951" href="#t8951">8951</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8952" href="#t8952">8952</a></span><span class="t"><span class="str">              scale_factor = float(in_size/out_size)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8953" href="#t8953">8953</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8954" href="#t8954">8954</a></span><span class="t"><span class="str">        Bilinear interpolation:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8955" href="#t8955">8955</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8956" href="#t8956">8956</a></span><span class="t"><span class="str">          if:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8957" href="#t8957">8957</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8958" href="#t8958">8958</a></span><span class="t"><span class="str">              align_corners = False , align_mode = 0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8959" href="#t8959">8959</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8960" href="#t8960">8960</a></span><span class="t"><span class="str">              input : (N,C,D_in,H_in,W_in)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8961" href="#t8961">8961</a></span><span class="t"><span class="str">              output: (N,C,D_out,H_out,W_out) where:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8962" href="#t8962">8962</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8963" href="#t8963">8963</a></span><span class="t"><span class="str">              D_out = (D_{in}+0.5) * scale_{factor} - 0.5</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8964" href="#t8964">8964</a></span><span class="t"><span class="str">              H_out = (H_{in}+0.5) * scale_{factor} - 0.5</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8965" href="#t8965">8965</a></span><span class="t"><span class="str">              W_out = (W_{in}+0.5) * scale_{factor} - 0.5</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8966" href="#t8966">8966</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8967" href="#t8967">8967</a></span><span class="t"><span class="str">          else:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8968" href="#t8968">8968</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8969" href="#t8969">8969</a></span><span class="t"><span class="str">              input : (N,C,D_in,H_in,W_in)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8970" href="#t8970">8970</a></span><span class="t"><span class="str">              output: (N,C,D_out,H_out,W_out) where:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8971" href="#t8971">8971</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8972" href="#t8972">8972</a></span><span class="t"><span class="str">              D_out = D_{in} * scale_{factor}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8973" href="#t8973">8973</a></span><span class="t"><span class="str">              H_out = H_{in} * scale_{factor}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8974" href="#t8974">8974</a></span><span class="t"><span class="str">              W_out = W_{in} * scale_{factor}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8975" href="#t8975">8975</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8976" href="#t8976">8976</a></span><span class="t"><span class="str">    Parameters:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8977" href="#t8977">8977</a></span><span class="t"><span class="str">        input(${x_type}): 5-D Tensor, its data type is float32, float64, or uint8,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8978" href="#t8978">8978</a></span><span class="t"><span class="str">                          its data format is specified by :attr:`data_format`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8979" href="#t8979">8979</a></span><span class="t"><span class="str">        out_shape(list|tuple|Variable|None): The output shape of resized tensor, the shape is (out_d, out_h, out_w). Default: None. Every element should be an integer or a Tensor Variable with shape: [1] if it is a list. If it is a Tensor Variable, its dimension size should be 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8980" href="#t8980">8980</a></span><span class="t"><span class="str">        scale(float|Variable|None): The multiplier for the input depth, height or width.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8981" href="#t8981">8981</a></span><span class="t"><span class="str">             At least one of :attr:`out_shape` or :attr:`scale` must be set.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8982" href="#t8982">8982</a></span><span class="t"><span class="str">             And :attr:`out_shape` has a higher priority than :attr:`scale`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8983" href="#t8983">8983</a></span><span class="t"><span class="str">             Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8984" href="#t8984">8984</a></span><span class="t"><span class="str">        name(str, optional): The default value is None.  Normally there is no need for user to set this property.  For more information, please refer to :ref:`api_guide_Name`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8985" href="#t8985">8985</a></span><span class="t"><span class="str">        actual_shape(Variable): An optional input to specify output shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8986" href="#t8986">8986</a></span><span class="t"><span class="str">                                dynamically. If provided, image resize</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8987" href="#t8987">8987</a></span><span class="t"><span class="str">                                according to this given shape rather than</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8988" href="#t8988">8988</a></span><span class="t"><span class="str">                                :attr:`out_shape` and :attr:`scale` specifying</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8989" href="#t8989">8989</a></span><span class="t"><span class="str">                                shape. That is to say actual_shape has the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8990" href="#t8990">8990</a></span><span class="t"><span class="str">                                highest priority. It is recommended to use</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8991" href="#t8991">8991</a></span><span class="t"><span class="str">                                :attr:`out_shape` if you want to specify output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8992" href="#t8992">8992</a></span><span class="t"><span class="str">                                shape dynamically, because :attr:`actual_shape`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8993" href="#t8993">8993</a></span><span class="t"><span class="str">                                will be deprecated. When using actual_shape to</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8994" href="#t8994">8994</a></span><span class="t"><span class="str">                                specify output shape, one of :attr:`out_shape`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8995" href="#t8995">8995</a></span><span class="t"><span class="str">                                and :attr:`scale` should also be set, otherwise</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8996" href="#t8996">8996</a></span><span class="t"><span class="str">                                errors would be occurred in graph constructing stage.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8997" href="#t8997">8997</a></span><span class="t"><span class="str">                                Default: None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8998" href="#t8998">8998</a></span><span class="t"><span class="str">        align_corners(bool): ${align_corners_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t8999" href="#t8999">8999</a></span><span class="t"><span class="str">        align_mode(bool): ${align_mode_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9000" href="#t9000">9000</a></span><span class="t"><span class="str">        data_format (str, optional): Specify the data format of the input, and the data format of the output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9001" href="#t9001">9001</a></span><span class="t"><span class="str">            will be consistent with that of the input. An optional string from: `"NCDHW"`, `"NDHWC"`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9002" href="#t9002">9002</a></span><span class="t"><span class="str">            The default is `"NCDHW"`. When it is `"NCDHW"`, the data is stored in the order of:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9003" href="#t9003">9003</a></span><span class="t"><span class="str">            `[batch_size, input_channels, input_depth, input_height, input_width]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9004" href="#t9004">9004</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9005" href="#t9005">9005</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9006" href="#t9006">9006</a></span><span class="t"><span class="str">        Variable: A 5-D Tensor(NCDHW or NDHWC)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9007" href="#t9007">9007</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9008" href="#t9008">9008</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9009" href="#t9009">9009</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9010" href="#t9010">9010</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9011" href="#t9011">9011</a></span><span class="t"><span class="str">            #declarative mode</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9012" href="#t9012">9012</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9013" href="#t9013">9013</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9014" href="#t9014">9014</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9015" href="#t9015">9015</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9016" href="#t9016">9016</a></span><span class="t"><span class="str">            input = fluid.data(name="input", shape=[None,3,6,8,10])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9017" href="#t9017">9017</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9018" href="#t9018">9018</a></span><span class="t"><span class="str">            #1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9019" href="#t9019">9019</a></span><span class="t"><span class="str">            output = fluid.layers.resize_trilinear(input=input,out_shape=[12,12,12])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9020" href="#t9020">9020</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9021" href="#t9021">9021</a></span><span class="t"><span class="str">            #2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9022" href="#t9022">9022</a></span><span class="t"><span class="str">            #x = np.array([2]).astype("int32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9023" href="#t9023">9023</a></span><span class="t"><span class="str">            #dim1 = fluid.data(name="dim1", shape=[1], dtype="int32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9024" href="#t9024">9024</a></span><span class="t"><span class="str">            #fluid.layers.assign(input=x, output=dim1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9025" href="#t9025">9025</a></span><span class="t"><span class="str">            #output = fluid.layers.resize_trilinear(input=input,out_shape=[12,dim1,4])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9026" href="#t9026">9026</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9027" href="#t9027">9027</a></span><span class="t"><span class="str">            #3</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9028" href="#t9028">9028</a></span><span class="t"><span class="str">            #x = np.array([3,12,12]).astype("int32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9029" href="#t9029">9029</a></span><span class="t"><span class="str">            #shape_tensor = fluid.data(name="shape_tensor", shape=[3], dtype="int32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9030" href="#t9030">9030</a></span><span class="t"><span class="str">            #fluid.layers.assign(input=x, output=shape_tensor)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9031" href="#t9031">9031</a></span><span class="t"><span class="str">            #output = fluid.layers.resize_trilinear(input=input,out_shape=shape_tensor)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9032" href="#t9032">9032</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9033" href="#t9033">9033</a></span><span class="t"><span class="str">            #4</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9034" href="#t9034">9034</a></span><span class="t"><span class="str">            #x = np.array([0.5]).astype("float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9035" href="#t9035">9035</a></span><span class="t"><span class="str">            #scale_tensor = fluid.data(name="scale", shape=[1], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9036" href="#t9036">9036</a></span><span class="t"><span class="str">            #fluid.layers.assign(x,scale_tensor)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9037" href="#t9037">9037</a></span><span class="t"><span class="str">            #output = fluid.layers.resize_trilinear(input=input,scale=scale_tensor)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9038" href="#t9038">9038</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9039" href="#t9039">9039</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9040" href="#t9040">9040</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9041" href="#t9041">9041</a></span><span class="t"><span class="str">            exe.run(fluid.default_startup_program())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9042" href="#t9042">9042</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9043" href="#t9043">9043</a></span><span class="t"><span class="str">            input_data = np.random.rand(2,3,6,8,10).astype("float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9044" href="#t9044">9044</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9045" href="#t9045">9045</a></span><span class="t"><span class="str">            output_data = exe.run(fluid.default_main_program(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9046" href="#t9046">9046</a></span><span class="t"><span class="str">                feed={"input":input_data},</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9047" href="#t9047">9047</a></span><span class="t"><span class="str">                fetch_list=[output],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9048" href="#t9048">9048</a></span><span class="t"><span class="str">                return_numpy=True)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9049" href="#t9049">9049</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9050" href="#t9050">9050</a></span><span class="t"><span class="str">            print(output_data[0].shape)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9051" href="#t9051">9051</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9052" href="#t9052">9052</a></span><span class="t"><span class="str">            #1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9053" href="#t9053">9053</a></span><span class="t"><span class="str">            # (2, 3, 12, 12, 12)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9054" href="#t9054">9054</a></span><span class="t"><span class="str">            #2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9055" href="#t9055">9055</a></span><span class="t"><span class="str">            # (2, 3, 12, 2, 4)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9056" href="#t9056">9056</a></span><span class="t"><span class="str">            #3</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9057" href="#t9057">9057</a></span><span class="t"><span class="str">            # (2, 3, 3, 12, 12)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9058" href="#t9058">9058</a></span><span class="t"><span class="str">            #4</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9059" href="#t9059">9059</a></span><span class="t"><span class="str">            # (2, 3, 3, 4, 5)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9060" href="#t9060">9060</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9061" href="#t9061">9061</a></span><span class="t"><span class="str">            #imperative mode</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9062" href="#t9062">9062</a></span><span class="t"><span class="str">            import paddle.fluid.dygraph as dg</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9063" href="#t9063">9063</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9064" href="#t9064">9064</a></span><span class="t"><span class="str">            with dg.guard(place) as g:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9065" href="#t9065">9065</a></span><span class="t"><span class="str">                input = dg.to_variable(input_data)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9066" href="#t9066">9066</a></span><span class="t"><span class="str">                output = fluid.layers.resize_trilinear(input=input, out_shape=[12,12,12])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9067" href="#t9067">9067</a></span><span class="t"><span class="str">                print(output.shape)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9068" href="#t9068">9068</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9069" href="#t9069">9069</a></span><span class="t"><span class="str">                # [2L, 3L, 12L, 12L, 12L]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9070" href="#t9070">9070</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9071" href="#t9071">9071</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9072" href="#t9072">9072</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9073" href="#t9073">9073</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9074" href="#t9074">9074</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9075" href="#t9075">9075</a></span><span class="t">    <span class="key">return</span> <span class="nam">image_resize</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9076" href="#t9076">9076</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9077" href="#t9077">9077</a></span><span class="t">        <span class="nam">out_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9078" href="#t9078">9078</a></span><span class="t">        <span class="nam">scale</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9079" href="#t9079">9079</a></span><span class="t">        <span class="nam">name</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9080" href="#t9080">9080</a></span><span class="t">        <span class="str">'TRILINEAR'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9081" href="#t9081">9081</a></span><span class="t">        <span class="nam">actual_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9082" href="#t9082">9082</a></span><span class="t">        <span class="nam">align_corners</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9083" href="#t9083">9083</a></span><span class="t">        <span class="nam">align_mode</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9084" href="#t9084">9084</a></span><span class="t">        <span class="nam">data_format</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9085" href="#t9085">9085</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9086" href="#t9086">9086</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9087" href="#t9087">9087</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9088" href="#t9088">9088</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="nam">op_type</span><span class="op">=</span><span class="str">"nearest_interp"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9089" href="#t9089">9089</a></span><span class="t"><span class="key">def</span> <span class="nam">resize_nearest</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9090" href="#t9090">9090</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9091" href="#t9091">9091</a></span><span class="t">    <span class="nam">out_shape</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9092" href="#t9092">9092</a></span><span class="t">    <span class="nam">scale</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9093" href="#t9093">9093</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9094" href="#t9094">9094</a></span><span class="t">    <span class="nam">actual_shape</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9095" href="#t9095">9095</a></span><span class="t">    <span class="nam">align_corners</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9096" href="#t9096">9096</a></span><span class="t">    <span class="nam">data_format</span><span class="op">=</span><span class="str">'NCHW'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9097" href="#t9097">9097</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9098" href="#t9098">9098</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9099" href="#t9099">9099</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9100" href="#t9100">9100</a></span><span class="t"><span class="str">    This op resizes the input by performing nearest neighbor interpolation in both the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9101" href="#t9101">9101</a></span><span class="t"><span class="str">    height direction and the width direction based on given output shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9102" href="#t9102">9102</a></span><span class="t"><span class="str">    which is specified by actual_shape, out_shape and scale in priority order.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9103" href="#t9103">9103</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9104" href="#t9104">9104</a></span><span class="t"><span class="str">    **Warning:** the parameter :attr:`actual_shape` will be deprecated in the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9105" href="#t9105">9105</a></span><span class="t"><span class="str">    future and only use :attr:`out_shape` instead.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9106" href="#t9106">9106</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9107" href="#t9107">9107</a></span><span class="t"><span class="str">    Example:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9108" href="#t9108">9108</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9109" href="#t9109">9109</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9110" href="#t9110">9110</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9111" href="#t9111">9111</a></span><span class="t"><span class="str">        For scale:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9112" href="#t9112">9112</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9113" href="#t9113">9113</a></span><span class="t"><span class="str">            if align_corners = True &amp;&amp; out_size > 1 :</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9114" href="#t9114">9114</a></span><span class="t"><span class="str">              scale_factor = (in_size-1.0)/(out_size-1.0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9115" href="#t9115">9115</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9116" href="#t9116">9116</a></span><span class="t"><span class="str">            else:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9117" href="#t9117">9117</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9118" href="#t9118">9118</a></span><span class="t"><span class="str">              scale_factor = float(in_size/out_size)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9119" href="#t9119">9119</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9120" href="#t9120">9120</a></span><span class="t"><span class="str">        Nearest neighbor interpolation:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9121" href="#t9121">9121</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9122" href="#t9122">9122</a></span><span class="t"><span class="str">          if:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9123" href="#t9123">9123</a></span><span class="t"><span class="str">              align_corners = False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9124" href="#t9124">9124</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9125" href="#t9125">9125</a></span><span class="t"><span class="str">              input : (N,C,H_in,W_in)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9126" href="#t9126">9126</a></span><span class="t"><span class="str">              output: (N,C,H_out,W_out) where:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9127" href="#t9127">9127</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9128" href="#t9128">9128</a></span><span class="t"><span class="str">              H_out = floor(H_{in} * scale_{factor})</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9129" href="#t9129">9129</a></span><span class="t"><span class="str">              W_out = floor(W_{in} * scale_{factor})</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9130" href="#t9130">9130</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9131" href="#t9131">9131</a></span><span class="t"><span class="str">          else:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9132" href="#t9132">9132</a></span><span class="t"><span class="str">              align_corners = True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9133" href="#t9133">9133</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9134" href="#t9134">9134</a></span><span class="t"><span class="str">              input : (N,C,H_in,W_in)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9135" href="#t9135">9135</a></span><span class="t"><span class="str">              output: (N,C,H_out,W_out) where:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9136" href="#t9136">9136</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9137" href="#t9137">9137</a></span><span class="t"><span class="str">              H_out = round(H_{in} * scale_{factor})</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9138" href="#t9138">9138</a></span><span class="t"><span class="str">              W_out = round(W_{in} * scale_{factor})</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9139" href="#t9139">9139</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9140" href="#t9140">9140</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9141" href="#t9141">9141</a></span><span class="t"><span class="str">    For details of nearest neighbor interpolation, please refer to Wikipedia:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9142" href="#t9142">9142</a></span><span class="t"><span class="str">    https://en.wikipedia.org/wiki/Nearest-neighbor_interpolation</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9143" href="#t9143">9143</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9144" href="#t9144">9144</a></span><span class="t"><span class="str">    Parameters:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9145" href="#t9145">9145</a></span><span class="t"><span class="str">        input(${x_type}): 4-D Tensor, its data type is float32, float64, or uint8,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9146" href="#t9146">9146</a></span><span class="t"><span class="str">                          its data format is specified by :attr:`data_format`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9147" href="#t9147">9147</a></span><span class="t"><span class="str">        out_shape(list|tuple|Variable|None): The output shape of resized tensor, the shape is (out_h, out_w). Default: None. Every element should be an integer or a tensor Variable with shape: [1] if it is a list. If it is a tensor Variable, its dimension size should be 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9148" href="#t9148">9148</a></span><span class="t"><span class="str">        scale(float|Variable|None): The multiplier for the input height or width. At</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9149" href="#t9149">9149</a></span><span class="t"><span class="str">             least one of :attr:`out_shape` or :attr:`scale` must be set.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9150" href="#t9150">9150</a></span><span class="t"><span class="str">             And :attr:`out_shape` has a higher priority than :attr:`scale`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9151" href="#t9151">9151</a></span><span class="t"><span class="str">             Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9152" href="#t9152">9152</a></span><span class="t"><span class="str">        name(str, optional): The default value is None.  Normally there is no need for user to set this property.  For more information, please refer to :ref:`api_guide_Name`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9153" href="#t9153">9153</a></span><span class="t"><span class="str">        actual_shape(Variable): An optional input to specify output shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9154" href="#t9154">9154</a></span><span class="t"><span class="str">                                dynamically. If provided, image resize</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9155" href="#t9155">9155</a></span><span class="t"><span class="str">                                according to this given shape rather than</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9156" href="#t9156">9156</a></span><span class="t"><span class="str">                                :attr:`out_shape` and :attr:`scale` specifying</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9157" href="#t9157">9157</a></span><span class="t"><span class="str">                                shape. That is to say actual_shape has the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9158" href="#t9158">9158</a></span><span class="t"><span class="str">                                highest priority. It is recommended to use</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9159" href="#t9159">9159</a></span><span class="t"><span class="str">                                :attr:`out_shape` if you want to specify output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9160" href="#t9160">9160</a></span><span class="t"><span class="str">                                shape dynamically, because :attr:`actual_shape`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9161" href="#t9161">9161</a></span><span class="t"><span class="str">                                will be deprecated. When using actual_shape to</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9162" href="#t9162">9162</a></span><span class="t"><span class="str">                                specify output shape, one of :attr:`out_shape`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9163" href="#t9163">9163</a></span><span class="t"><span class="str">                                and :attr:`scale` should also be set, otherwise</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9164" href="#t9164">9164</a></span><span class="t"><span class="str">                                errors would be occurred in graph constructing stage.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9165" href="#t9165">9165</a></span><span class="t"><span class="str">                                Default: None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9166" href="#t9166">9166</a></span><span class="t"><span class="str">        align_corners(bool): ${align_corners_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9167" href="#t9167">9167</a></span><span class="t"><span class="str">        data_format (str, optional): Specify the data format of the input, and the data format of the output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9168" href="#t9168">9168</a></span><span class="t"><span class="str">            will be consistent with that of the input. An optional string from: `"NCHW"`, `"NHWC"`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9169" href="#t9169">9169</a></span><span class="t"><span class="str">            The default is `"NCHW"`. When it is `"NCHW"`, the data is stored in the order of:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9170" href="#t9170">9170</a></span><span class="t"><span class="str">            `[batch_size, input_channels, input_height, input_width]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9171" href="#t9171">9171</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9172" href="#t9172">9172</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9173" href="#t9173">9173</a></span><span class="t"><span class="str">        Variable: 4-D tensor(NCHW or NHWC).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9174" href="#t9174">9174</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9175" href="#t9175">9175</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9176" href="#t9176">9176</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9177" href="#t9177">9177</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9178" href="#t9178">9178</a></span><span class="t"><span class="str">            #declarative mode</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9179" href="#t9179">9179</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9180" href="#t9180">9180</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9181" href="#t9181">9181</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9182" href="#t9182">9182</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9183" href="#t9183">9183</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9184" href="#t9184">9184</a></span><span class="t"><span class="str">            input = fluid.data(name="input", shape=[None,3,6,10])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9185" href="#t9185">9185</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9186" href="#t9186">9186</a></span><span class="t"><span class="str">            #1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9187" href="#t9187">9187</a></span><span class="t"><span class="str">            output = fluid.layers.resize_nearest(input=input,out_shape=[12,12])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9188" href="#t9188">9188</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9189" href="#t9189">9189</a></span><span class="t"><span class="str">            #2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9190" href="#t9190">9190</a></span><span class="t"><span class="str">            #x = np.array([2]).astype("int32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9191" href="#t9191">9191</a></span><span class="t"><span class="str">            #dim1 = fluid.data(name="dim1", shape=[1], dtype="int32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9192" href="#t9192">9192</a></span><span class="t"><span class="str">            #fluid.layers.assign(input=x, output=dim1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9193" href="#t9193">9193</a></span><span class="t"><span class="str">            #output = fluid.layers.resize_nearest(input=input,out_shape=[12,dim1])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9194" href="#t9194">9194</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9195" href="#t9195">9195</a></span><span class="t"><span class="str">            #3</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9196" href="#t9196">9196</a></span><span class="t"><span class="str">            #x = np.array([3,12]).astype("int32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9197" href="#t9197">9197</a></span><span class="t"><span class="str">            #shape_tensor = fluid.data(name="shape_tensor", shape=[2], dtype="int32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9198" href="#t9198">9198</a></span><span class="t"><span class="str">            #fluid.layers.assign(input=x, output=shape_tensor)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9199" href="#t9199">9199</a></span><span class="t"><span class="str">            #output = fluid.layers.resize_nearest(input=input,out_shape=shape_tensor)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9200" href="#t9200">9200</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9201" href="#t9201">9201</a></span><span class="t"><span class="str">            #4</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9202" href="#t9202">9202</a></span><span class="t"><span class="str">            #x = np.array([0.5]).astype("float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9203" href="#t9203">9203</a></span><span class="t"><span class="str">            #scale_tensor = fluid.data(name="scale", shape=[1], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9204" href="#t9204">9204</a></span><span class="t"><span class="str">            #fluid.layers.assign(x,scale_tensor)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9205" href="#t9205">9205</a></span><span class="t"><span class="str">            #output = fluid.layers.resize_nearest(input=input,scale=scale_tensor)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9206" href="#t9206">9206</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9207" href="#t9207">9207</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9208" href="#t9208">9208</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9209" href="#t9209">9209</a></span><span class="t"><span class="str">            exe.run(fluid.default_startup_program())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9210" href="#t9210">9210</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9211" href="#t9211">9211</a></span><span class="t"><span class="str">            input_data = np.random.rand(2,3,6,10).astype("float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9212" href="#t9212">9212</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9213" href="#t9213">9213</a></span><span class="t"><span class="str">            output_data = exe.run(fluid.default_main_program(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9214" href="#t9214">9214</a></span><span class="t"><span class="str">                feed={"input":input_data},</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9215" href="#t9215">9215</a></span><span class="t"><span class="str">                fetch_list=[output],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9216" href="#t9216">9216</a></span><span class="t"><span class="str">                return_numpy=True)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9217" href="#t9217">9217</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9218" href="#t9218">9218</a></span><span class="t"><span class="str">            print(output_data[0].shape)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9219" href="#t9219">9219</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9220" href="#t9220">9220</a></span><span class="t"><span class="str">            #1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9221" href="#t9221">9221</a></span><span class="t"><span class="str">            # (2, 3, 12, 12)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9222" href="#t9222">9222</a></span><span class="t"><span class="str">            #2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9223" href="#t9223">9223</a></span><span class="t"><span class="str">            # (2, 3, 12, 2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9224" href="#t9224">9224</a></span><span class="t"><span class="str">            #3</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9225" href="#t9225">9225</a></span><span class="t"><span class="str">            # (2, 3, 3, 12)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9226" href="#t9226">9226</a></span><span class="t"><span class="str">            #4</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9227" href="#t9227">9227</a></span><span class="t"><span class="str">            # (2, 3, 3, 5)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9228" href="#t9228">9228</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9229" href="#t9229">9229</a></span><span class="t"><span class="str">            #imperative mode</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9230" href="#t9230">9230</a></span><span class="t"><span class="str">            import paddle.fluid.dygraph as dg</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9231" href="#t9231">9231</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9232" href="#t9232">9232</a></span><span class="t"><span class="str">            with dg.guard(place) as g:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9233" href="#t9233">9233</a></span><span class="t"><span class="str">                input = dg.to_variable(input_data)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9234" href="#t9234">9234</a></span><span class="t"><span class="str">                output = fluid.layers.resize_nearest(input=input, out_shape=[12,12])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9235" href="#t9235">9235</a></span><span class="t"><span class="str">                print(output.shape)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9236" href="#t9236">9236</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9237" href="#t9237">9237</a></span><span class="t"><span class="str">                # [2L, 3L, 12L, 12L]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9238" href="#t9238">9238</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9239" href="#t9239">9239</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9240" href="#t9240">9240</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9241" href="#t9241">9241</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9242" href="#t9242">9242</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9243" href="#t9243">9243</a></span><span class="t">    <span class="key">return</span> <span class="nam">image_resize</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9244" href="#t9244">9244</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9245" href="#t9245">9245</a></span><span class="t">        <span class="nam">out_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9246" href="#t9246">9246</a></span><span class="t">        <span class="nam">scale</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9247" href="#t9247">9247</a></span><span class="t">        <span class="nam">name</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9248" href="#t9248">9248</a></span><span class="t">        <span class="str">'NEAREST'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9249" href="#t9249">9249</a></span><span class="t">        <span class="nam">actual_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9250" href="#t9250">9250</a></span><span class="t">        <span class="nam">align_corners</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9251" href="#t9251">9251</a></span><span class="t">        <span class="nam">align_mode</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9252" href="#t9252">9252</a></span><span class="t">        <span class="nam">data_format</span><span class="op">=</span><span class="nam">data_format</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9253" href="#t9253">9253</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9254" href="#t9254">9254</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9255" href="#t9255">9255</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9256" href="#t9256">9256</a></span><span class="t"><span class="key">def</span> <span class="nam">image_resize_short</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">out_short_len</span><span class="op">,</span> <span class="nam">resample</span><span class="op">=</span><span class="str">'BILINEAR'</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9257" href="#t9257">9257</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9258" href="#t9258">9258</a></span><span class="t"><span class="str">    This op resizes a batch of images. The short edge of input images will be</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9259" href="#t9259">9259</a></span><span class="t"><span class="str">    resized to the given 'out_short_len'. The long edge of input images</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9260" href="#t9260">9260</a></span><span class="t"><span class="str">    will be resized proportionately to make images' length-width ratio</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9261" href="#t9261">9261</a></span><span class="t"><span class="str">    constant.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9262" href="#t9262">9262</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9263" href="#t9263">9263</a></span><span class="t"><span class="str">    Parameters:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9264" href="#t9264">9264</a></span><span class="t"><span class="str">        input (Variable): 4-D tensor(NCHW), The input tensor of image resize layer.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9265" href="#t9265">9265</a></span><span class="t"><span class="str">        out_short_len(int): The length of output images' short edge.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9266" href="#t9266">9266</a></span><span class="t"><span class="str">        resample (str): resample method, default: BILINEAR.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9267" href="#t9267">9267</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9268" href="#t9268">9268</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9269" href="#t9269">9269</a></span><span class="t"><span class="str">        Variable: 4-D tensor(NCHW).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9270" href="#t9270">9270</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9271" href="#t9271">9271</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9272" href="#t9272">9272</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9273" href="#t9273">9273</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9274" href="#t9274">9274</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9275" href="#t9275">9275</a></span><span class="t"><span class="str">            input = fluid.data(name="input", shape=[None,3,6,9], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9276" href="#t9276">9276</a></span><span class="t"><span class="str">            out = fluid.layers.image_resize_short(input, out_short_len=3)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9277" href="#t9277">9277</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9278" href="#t9278">9278</a></span><span class="t">    <span class="nam">in_shape</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9279" href="#t9279">9279</a></span><span class="t">    <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">in_shape</span><span class="op">)</span> <span class="op">!=</span> <span class="num">4</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9280" href="#t9280">9280</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9281" href="#t9281">9281</a></span><span class="t">            <span class="str">"The rank of input must be 4 (num_batches, channels, in_h, in_w)."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9282" href="#t9282">9282</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9283" href="#t9283">9283</a></span><span class="t">    <span class="nam">hw</span> <span class="op">=</span> <span class="nam">in_shape</span><span class="op">[</span><span class="num">2</span><span class="op">:</span><span class="num">4</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9284" href="#t9284">9284</a></span><span class="t">    <span class="nam">short_idx</span> <span class="op">=</span> <span class="nam">hw</span><span class="op">.</span><span class="nam">index</span><span class="op">(</span><span class="nam">min</span><span class="op">(</span><span class="nam">hw</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9285" href="#t9285">9285</a></span><span class="t">    <span class="nam">long_idx</span> <span class="op">=</span> <span class="num">1</span> <span class="op">-</span> <span class="nam">short_idx</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9286" href="#t9286">9286</a></span><span class="t">    <span class="nam">out_shape</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="nam">hw</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9287" href="#t9287">9287</a></span><span class="t">    <span class="nam">out_shape</span><span class="op">[</span><span class="nam">short_idx</span><span class="op">]</span> <span class="op">=</span> <span class="nam">out_short_len</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9288" href="#t9288">9288</a></span><span class="t">    <span class="nam">out_shape</span><span class="op">[</span><span class="nam">long_idx</span><span class="op">]</span> <span class="op">=</span> <span class="nam">int</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9289" href="#t9289">9289</a></span><span class="t">        <span class="nam">float</span><span class="op">(</span><span class="nam">out_shape</span><span class="op">[</span><span class="nam">long_idx</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9290" href="#t9290">9290</a></span><span class="t">        <span class="op">*</span> <span class="op">(</span><span class="nam">float</span><span class="op">(</span><span class="nam">out_short_len</span><span class="op">)</span> <span class="op">/</span> <span class="nam">float</span><span class="op">(</span><span class="nam">hw</span><span class="op">[</span><span class="nam">short_idx</span><span class="op">]</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9291" href="#t9291">9291</a></span><span class="t">        <span class="op">+</span> <span class="num">0.5</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9292" href="#t9292">9292</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9293" href="#t9293">9293</a></span><span class="t">    <span class="key">return</span> <span class="nam">image_resize</span><span class="op">(</span><span class="nam">input</span><span class="op">=</span><span class="nam">input</span><span class="op">,</span> <span class="nam">out_shape</span><span class="op">=</span><span class="nam">out_shape</span><span class="op">,</span> <span class="nam">resample</span><span class="op">=</span><span class="nam">resample</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9294" href="#t9294">9294</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9295" href="#t9295">9295</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9296" href="#t9296">9296</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.gather"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9297" href="#t9297">9297</a></span><span class="t"><span class="key">def</span> <span class="nam">gather</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">index</span><span class="op">,</span> <span class="nam">overwrite</span><span class="op">=</span><span class="key">True</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9298" href="#t9298">9298</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9299" href="#t9299">9299</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9300" href="#t9300">9300</a></span><span class="t"><span class="str">    Output is obtained by gathering entries of the outer-most dimension</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9301" href="#t9301">9301</a></span><span class="t"><span class="str">    of X indexed by `index` and concatenate them together.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9302" href="#t9302">9302</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9303" href="#t9303">9303</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9304" href="#t9304">9304</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9305" href="#t9305">9305</a></span><span class="t"><span class="str">        Out = X[Index]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9306" href="#t9306">9306</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9307" href="#t9307">9307</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9308" href="#t9308">9308</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9309" href="#t9309">9309</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9310" href="#t9310">9310</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9311" href="#t9311">9311</a></span><span class="t"><span class="str">                Given:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9312" href="#t9312">9312</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9313" href="#t9313">9313</a></span><span class="t"><span class="str">                X = [[1, 2],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9314" href="#t9314">9314</a></span><span class="t"><span class="str">                     [3, 4],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9315" href="#t9315">9315</a></span><span class="t"><span class="str">                     [5, 6]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9316" href="#t9316">9316</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9317" href="#t9317">9317</a></span><span class="t"><span class="str">                Index = [1, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9318" href="#t9318">9318</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9319" href="#t9319">9319</a></span><span class="t"><span class="str">                Then:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9320" href="#t9320">9320</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9321" href="#t9321">9321</a></span><span class="t"><span class="str">                Out = [[3, 4],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9322" href="#t9322">9322</a></span><span class="t"><span class="str">                       [5, 6]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9323" href="#t9323">9323</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9324" href="#t9324">9324</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9325" href="#t9325">9325</a></span><span class="t"><span class="str">        input (Tensor): The source input tensor with rank>=1. Supported data type is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9326" href="#t9326">9326</a></span><span class="t"><span class="str">            int32, int64, float32, float64 and uint8 (only for CPU),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9327" href="#t9327">9327</a></span><span class="t"><span class="str">            float16 (only for GPU).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9328" href="#t9328">9328</a></span><span class="t"><span class="str">        index (Tensor): The index input tensor with rank=1. Data type is int32 or int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9329" href="#t9329">9329</a></span><span class="t"><span class="str">        overwrite (bool, optional): The mode that updating the grad when has same index.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9330" href="#t9330">9330</a></span><span class="t"><span class="str">            If True, use the overwrite mode to update the grad of the same index,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9331" href="#t9331">9331</a></span><span class="t"><span class="str">            if False, use the accumulate mode to update the grad of the same index.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9332" href="#t9332">9332</a></span><span class="t"><span class="str">            Default value is True.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9333" href="#t9333">9333</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9334" href="#t9334">9334</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9335" href="#t9335">9335</a></span><span class="t"><span class="str">        output (Tensor): The output is a tensor with the same rank as input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9336" href="#t9336">9336</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9337" href="#t9337">9337</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9338" href="#t9338">9338</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9339" href="#t9339">9339</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9340" href="#t9340">9340</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9341" href="#t9341">9341</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9342" href="#t9342">9342</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9343" href="#t9343">9343</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9344" href="#t9344">9344</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9345" href="#t9345">9345</a></span><span class="t"><span class="str">            x = fluid.data(name='x', shape=[-1, 5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9346" href="#t9346">9346</a></span><span class="t"><span class="str">            index = fluid.data(name='index', shape=[-1, 1], dtype='int32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9347" href="#t9347">9347</a></span><span class="t"><span class="str">            output = fluid.layers.gather(x, index)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9348" href="#t9348">9348</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t9349" href="#t9349">9349</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">9349&#x202F;&#x219B;&#x202F;9352</span><span class="annotate long">line 9349 didn't jump to line 9352, because the condition on line 9349 was never false</span></span></p>
    <p class="run"><span class="n"><a id="t9350" href="#t9350">9350</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">gather</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">index</span><span class="op">,</span> <span class="key">None</span><span class="op">,</span> <span class="str">'overwrite'</span><span class="op">,</span> <span class="nam">overwrite</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9351" href="#t9351">9351</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9352" href="#t9352">9352</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9353" href="#t9353">9353</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9354" href="#t9354">9354</a></span><span class="t">        <span class="str">'x'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9355" href="#t9355">9355</a></span><span class="t">        <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">,</span> <span class="str">'uint8'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9356" href="#t9356">9356</a></span><span class="t">        <span class="str">'gather'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9357" href="#t9357">9357</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9358" href="#t9358">9358</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">index</span><span class="op">,</span> <span class="str">'index'</span><span class="op">,</span> <span class="op">[</span><span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'gather'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9359" href="#t9359">9359</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'gather'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9360" href="#t9360">9360</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9361" href="#t9361">9361</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9362" href="#t9362">9362</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9363" href="#t9363">9363</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"gather"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9364" href="#t9364">9364</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">input</span><span class="op">,</span> <span class="str">"Index"</span><span class="op">:</span> <span class="nam">index</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9365" href="#t9365">9365</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9366" href="#t9366">9366</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'overwrite'</span><span class="op">:</span> <span class="nam">overwrite</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9367" href="#t9367">9367</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9368" href="#t9368">9368</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9369" href="#t9369">9369</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9370" href="#t9370">9370</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9371" href="#t9371">9371</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.gather_nd"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9372" href="#t9372">9372</a></span><span class="t"><span class="key">def</span> <span class="nam">gather_nd</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">index</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9373" href="#t9373">9373</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9374" href="#t9374">9374</a></span><span class="t"><span class="str">    **Gather Nd Layer**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9375" href="#t9375">9375</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9376" href="#t9376">9376</a></span><span class="t"><span class="str">    This function is actually a high-dimensional extension of :code:`gather`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9377" href="#t9377">9377</a></span><span class="t"><span class="str">    and supports for simultaneous indexing by multiple axes. :attr:`index` is a</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9378" href="#t9378">9378</a></span><span class="t"><span class="str">    K-dimensional integer tensor, which is regarded as a (K-1)-dimensional</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9379" href="#t9379">9379</a></span><span class="t"><span class="str">    tensor of :attr:`index` into :attr:`input`, where each element defines</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9380" href="#t9380">9380</a></span><span class="t"><span class="str">    a slice of params:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9381" href="#t9381">9381</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9382" href="#t9382">9382</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9383" href="#t9383">9383</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9384" href="#t9384">9384</a></span><span class="t"><span class="str">        output[(i_0, ..., i_{K-2})] = input[index[(i_0, ..., i_{K-2})]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9385" href="#t9385">9385</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9386" href="#t9386">9386</a></span><span class="t"><span class="str">    Obviously, :code:`index.shape[-1] &lt;= input.rank` . And, the output tensor has</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9387" href="#t9387">9387</a></span><span class="t"><span class="str">    shape :code:`index.shape[:-1] + input.shape[index.shape[-1]:]` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9388" href="#t9388">9388</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9389" href="#t9389">9389</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9390" href="#t9390">9390</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9391" href="#t9391">9391</a></span><span class="t"><span class="str">            Given:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9392" href="#t9392">9392</a></span><span class="t"><span class="str">                input = [[[ 0,  1,  2,  3],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9393" href="#t9393">9393</a></span><span class="t"><span class="str">                          [ 4,  5,  6,  7],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9394" href="#t9394">9394</a></span><span class="t"><span class="str">                          [ 8,  9, 10, 11]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9395" href="#t9395">9395</a></span><span class="t"><span class="str">                         [[12, 13, 14, 15],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9396" href="#t9396">9396</a></span><span class="t"><span class="str">                          [16, 17, 18, 19],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9397" href="#t9397">9397</a></span><span class="t"><span class="str">                          [20, 21, 22, 23]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9398" href="#t9398">9398</a></span><span class="t"><span class="str">                input.shape = (2, 3, 4)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9399" href="#t9399">9399</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9400" href="#t9400">9400</a></span><span class="t"><span class="str">            * Case 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9401" href="#t9401">9401</a></span><span class="t"><span class="str">                index = [[1]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9402" href="#t9402">9402</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9403" href="#t9403">9403</a></span><span class="t"><span class="str">                gather_nd(input, index)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9404" href="#t9404">9404</a></span><span class="t"><span class="str">                         = [input[1, :, :]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9405" href="#t9405">9405</a></span><span class="t"><span class="str">                         = [[12, 13, 14, 15],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9406" href="#t9406">9406</a></span><span class="t"><span class="str">                            [16, 17, 18, 19],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9407" href="#t9407">9407</a></span><span class="t"><span class="str">                            [20, 21, 22, 23]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9408" href="#t9408">9408</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9409" href="#t9409">9409</a></span><span class="t"><span class="str">            * Case 2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9410" href="#t9410">9410</a></span><span class="t"><span class="str">                index = [[0,2]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9411" href="#t9411">9411</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9412" href="#t9412">9412</a></span><span class="t"><span class="str">                gather_nd(input, index)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9413" href="#t9413">9413</a></span><span class="t"><span class="str">                         = [input[0, 2, :]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9414" href="#t9414">9414</a></span><span class="t"><span class="str">                         = [8, 9, 10, 11]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9415" href="#t9415">9415</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9416" href="#t9416">9416</a></span><span class="t"><span class="str">            * Case 3:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9417" href="#t9417">9417</a></span><span class="t"><span class="str">                index = [[1, 2, 3]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9418" href="#t9418">9418</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9419" href="#t9419">9419</a></span><span class="t"><span class="str">                gather_nd(input, index)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9420" href="#t9420">9420</a></span><span class="t"><span class="str">                         = [input[1, 2, 3]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9421" href="#t9421">9421</a></span><span class="t"><span class="str">                         = [23]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9422" href="#t9422">9422</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9423" href="#t9423">9423</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9424" href="#t9424">9424</a></span><span class="t"><span class="str">        input (Tensor): The input Tensor which it's data type should be bool, float32, float64, int32, int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9425" href="#t9425">9425</a></span><span class="t"><span class="str">        index (Tensor): The index input with rank > 1, index.shape[-1] &lt;= input.rank.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9426" href="#t9426">9426</a></span><span class="t"><span class="str">                        Its dtype should be int32, int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9427" href="#t9427">9427</a></span><span class="t"><span class="str">        name(str, optional): The default value is None.  Normally there is no need for user to set this property.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9428" href="#t9428">9428</a></span><span class="t"><span class="str">                        For more information, please refer to :ref:`api_guide_Name` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9429" href="#t9429">9429</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9430" href="#t9430">9430</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9431" href="#t9431">9431</a></span><span class="t"><span class="str">        output (Tensor): A tensor with the shape index.shape[:-1] + input.shape[index.shape[-1]:]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9432" href="#t9432">9432</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9433" href="#t9433">9433</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9434" href="#t9434">9434</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9435" href="#t9435">9435</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9436" href="#t9436">9436</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9437" href="#t9437">9437</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9438" href="#t9438">9438</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9439" href="#t9439">9439</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9440" href="#t9440">9440</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9441" href="#t9441">9441</a></span><span class="t"><span class="str">            x = fluid.data(name='x', shape=[3, 4, 5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9442" href="#t9442">9442</a></span><span class="t"><span class="str">            index = fluid.data(name='index', shape=[2, 2], dtype='int32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9443" href="#t9443">9443</a></span><span class="t"><span class="str">            output = fluid.layers.gather_nd(x, index)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9444" href="#t9444">9444</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9445" href="#t9445">9445</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t9446" href="#t9446">9446</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">9446&#x202F;&#x219B;&#x202F;9449</span><span class="annotate long">line 9446 didn't jump to line 9449, because the condition on line 9446 was never false</span></span></p>
    <p class="run"><span class="n"><a id="t9447" href="#t9447">9447</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">gather_nd</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">index</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9448" href="#t9448">9448</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9449" href="#t9449">9449</a></span><span class="t">        <span class="key">if</span> <span class="nam">_in_legacy_dygraph</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9450" href="#t9450">9450</a></span><span class="t">            <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">gather_nd</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">index</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9451" href="#t9451">9451</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9452" href="#t9452">9452</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9453" href="#t9453">9453</a></span><span class="t">        <span class="str">'input'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9454" href="#t9454">9454</a></span><span class="t">        <span class="op">[</span><span class="str">'bool'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int16'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9455" href="#t9455">9455</a></span><span class="t">        <span class="str">'gather_np'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9456" href="#t9456">9456</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9457" href="#t9457">9457</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">index</span><span class="op">,</span> <span class="str">'index'</span><span class="op">,</span> <span class="op">[</span><span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'gather_np'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9458" href="#t9458">9458</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'gather_nd'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9459" href="#t9459">9459</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9460" href="#t9460">9460</a></span><span class="t">    <span class="nam">output</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9461" href="#t9461">9461</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9462" href="#t9462">9462</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"gather_nd"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9463" href="#t9463">9463</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">input</span><span class="op">,</span> <span class="str">"Index"</span><span class="op">:</span> <span class="nam">index</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9464" href="#t9464">9464</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">output</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9465" href="#t9465">9465</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9466" href="#t9466">9466</a></span><span class="t">    <span class="key">return</span> <span class="nam">output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9467" href="#t9467">9467</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9468" href="#t9468">9468</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9469" href="#t9469">9469</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.scatter"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9470" href="#t9470">9470</a></span><span class="t"><span class="key">def</span> <span class="nam">scatter</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">index</span><span class="op">,</span> <span class="nam">updates</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">overwrite</span><span class="op">=</span><span class="key">True</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9471" href="#t9471">9471</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9472" href="#t9472">9472</a></span><span class="t"><span class="str">    :alias_main: paddle.scatter</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9473" href="#t9473">9473</a></span><span class="t"><span class="str">        :alias: paddle.scatter,paddle.tensor.scatter,paddle.tensor.manipulation.scatter</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9474" href="#t9474">9474</a></span><span class="t"><span class="str">        :old_api: paddle.fluid.layers.scatter</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9475" href="#t9475">9475</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9476" href="#t9476">9476</a></span><span class="t"><span class="str">    **Scatter Layer**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9477" href="#t9477">9477</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9478" href="#t9478">9478</a></span><span class="t"><span class="str">    Output is obtained by updating the input on selected indices based on updates.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9479" href="#t9479">9479</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9480" href="#t9480">9480</a></span><span class="t"><span class="str">    .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9481" href="#t9481">9481</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9482" href="#t9482">9482</a></span><span class="t"><span class="str">        import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9483" href="#t9483">9483</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9484" href="#t9484">9484</a></span><span class="t"><span class="str">        #input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9485" href="#t9485">9485</a></span><span class="t"><span class="str">        input = np.array([[1, 1], [2, 2], [3, 3]])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9486" href="#t9486">9486</a></span><span class="t"><span class="str">        index = np.array([2, 1, 0, 1])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9487" href="#t9487">9487</a></span><span class="t"><span class="str">        # shape of updates should be the same as input</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9488" href="#t9488">9488</a></span><span class="t"><span class="str">        # shape of updates with dim > 1 should be the same as input</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9489" href="#t9489">9489</a></span><span class="t"><span class="str">        updates = np.array([[1, 1], [2, 2], [3, 3], [4, 4]])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9490" href="#t9490">9490</a></span><span class="t"><span class="str">        overwrite = False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9491" href="#t9491">9491</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9492" href="#t9492">9492</a></span><span class="t"><span class="str">        # calculation:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9493" href="#t9493">9493</a></span><span class="t"><span class="str">        if not overwrite:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9494" href="#t9494">9494</a></span><span class="t"><span class="str">            for i in range(len(index)):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9495" href="#t9495">9495</a></span><span class="t"><span class="str">                input[index[i]] = np.zeros((2))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9496" href="#t9496">9496</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9497" href="#t9497">9497</a></span><span class="t"><span class="str">        for i in range(len(index)):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9498" href="#t9498">9498</a></span><span class="t"><span class="str">            if (overwrite):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9499" href="#t9499">9499</a></span><span class="t"><span class="str">                input[index[i]] = updates[i]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9500" href="#t9500">9500</a></span><span class="t"><span class="str">            else:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9501" href="#t9501">9501</a></span><span class="t"><span class="str">                input[index[i]] += updates[i]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9502" href="#t9502">9502</a></span><span class="t"><span class="str">        # output:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9503" href="#t9503">9503</a></span><span class="t"><span class="str">        out = np.array([[3, 3], [6, 6], [1, 1]])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9504" href="#t9504">9504</a></span><span class="t"><span class="str">        out.shape # [3, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9505" href="#t9505">9505</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9506" href="#t9506">9506</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9507" href="#t9507">9507</a></span><span class="t"><span class="str">        input (Variable): The input N-D Tensor with rank>=1. Data type can be float32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9508" href="#t9508">9508</a></span><span class="t"><span class="str">        index (Variable): The index 1-D Tensor. Data type can be int32, int64. The length of index cannot exceed updates's length, and the value in index cannot exceed input's length.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9509" href="#t9509">9509</a></span><span class="t"><span class="str">        updates (Variable): update input with updates parameter based on index. shape should be the same as input, and dim value with dim > 1 should be the same as input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9510" href="#t9510">9510</a></span><span class="t"><span class="str">        name(str, optional): The default value is None.  Normally there is no need for user to set this property.  For more information, please refer to :ref:`api_guide_Name` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9511" href="#t9511">9511</a></span><span class="t"><span class="str">        overwrite (bool): The mode that updating the output when there are same indices.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9512" href="#t9512">9512</a></span><span class="t"><span class="str">            If True, use the overwrite mode to update the output of the same index,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9513" href="#t9513">9513</a></span><span class="t"><span class="str">            if False, use the accumulate mode to update the output of the same index.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9514" href="#t9514">9514</a></span><span class="t"><span class="str">            Default value is True.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9515" href="#t9515">9515</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9516" href="#t9516">9516</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9517" href="#t9517">9517</a></span><span class="t"><span class="str">        Variable(Tensor|LoDTensor): The output is a Tensor with the same shape as input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9518" href="#t9518">9518</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9519" href="#t9519">9519</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9520" href="#t9520">9520</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9521" href="#t9521">9521</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9522" href="#t9522">9522</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9523" href="#t9523">9523</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9524" href="#t9524">9524</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9525" href="#t9525">9525</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9526" href="#t9526">9526</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9527" href="#t9527">9527</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9528" href="#t9528">9528</a></span><span class="t"><span class="str">            input = fluid.layers.data(name='data', shape=[3, 2], dtype='float32', append_batch_size=False)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9529" href="#t9529">9529</a></span><span class="t"><span class="str">            index = fluid.layers.data(name='index', shape=[4], dtype='int64', append_batch_size=False)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9530" href="#t9530">9530</a></span><span class="t"><span class="str">            updates = fluid.layers.data(name='update', shape=[4, 2], dtype='float32', append_batch_size=False)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9531" href="#t9531">9531</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9532" href="#t9532">9532</a></span><span class="t"><span class="str">            output = fluid.layers.scatter(input, index, updates, overwrite=False)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9533" href="#t9533">9533</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9534" href="#t9534">9534</a></span><span class="t"><span class="str">            exe = fluid.Executor(fluid.CPUPlace())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9535" href="#t9535">9535</a></span><span class="t"><span class="str">            exe.run(fluid.default_startup_program())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9536" href="#t9536">9536</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9537" href="#t9537">9537</a></span><span class="t"><span class="str">            in_data = np.array([[1, 1], [2, 2], [3, 3]]).astype(np.float32)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9538" href="#t9538">9538</a></span><span class="t"><span class="str">            index_data = np.array([2, 1, 0, 1]).astype(np.int64)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9539" href="#t9539">9539</a></span><span class="t"><span class="str">            update_data = np.array([[1, 1], [2, 2], [3, 3], [4, 4]]).astype(np.float32)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9540" href="#t9540">9540</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9541" href="#t9541">9541</a></span><span class="t"><span class="str">            res = exe.run(fluid.default_main_program(), feed={'data':in_data, "index":index_data, "update":update_data}, fetch_list=[output])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9542" href="#t9542">9542</a></span><span class="t"><span class="str">            print(res)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9543" href="#t9543">9543</a></span><span class="t"><span class="str">            # [array([[3., 3.],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9544" href="#t9544">9544</a></span><span class="t"><span class="str">            #   [6., 6.],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9545" href="#t9545">9545</a></span><span class="t"><span class="str">            #   [1., 1.]], dtype=float32)]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9546" href="#t9546">9546</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9547" href="#t9547">9547</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'scatter'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9548" href="#t9548">9548</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9549" href="#t9549">9549</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9550" href="#t9550">9550</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9551" href="#t9551">9551</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"scatter"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9552" href="#t9552">9552</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">input</span><span class="op">,</span> <span class="str">"Ids"</span><span class="op">:</span> <span class="nam">index</span><span class="op">,</span> <span class="str">"Updates"</span><span class="op">:</span> <span class="nam">updates</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9553" href="#t9553">9553</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'overwrite'</span><span class="op">:</span> <span class="nam">overwrite</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9554" href="#t9554">9554</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9555" href="#t9555">9555</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9556" href="#t9556">9556</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9557" href="#t9557">9557</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9558" href="#t9558">9558</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9559" href="#t9559">9559</a></span><span class="t"><span class="key">def</span> <span class="nam">scatter_nd_add</span><span class="op">(</span><span class="nam">ref</span><span class="op">,</span> <span class="nam">index</span><span class="op">,</span> <span class="nam">updates</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9560" href="#t9560">9560</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9561" href="#t9561">9561</a></span><span class="t"><span class="str">    **Scatter_nd_add Layer**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9562" href="#t9562">9562</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9563" href="#t9563">9563</a></span><span class="t"><span class="str">    Output is obtained by applying sparse addition to a single value</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9564" href="#t9564">9564</a></span><span class="t"><span class="str">    or slice in a Variable.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9565" href="#t9565">9565</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9566" href="#t9566">9566</a></span><span class="t"><span class="str">    :attr:`ref` is a Tensor with rank :math:`R`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9567" href="#t9567">9567</a></span><span class="t"><span class="str">    and :attr:`index` is a Tensor with rank :math:`K` . Thus, :attr:`index`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9568" href="#t9568">9568</a></span><span class="t"><span class="str">    has shape :math:`[i_0, i_1, ..., i_{K-2}, Q]` where :math:`Q \leq R` . :attr:`updates`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9569" href="#t9569">9569</a></span><span class="t"><span class="str">    is a Tensor with rank :math:`K - 1 + R - Q` and its</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9570" href="#t9570">9570</a></span><span class="t"><span class="str">    shape is :math:`index.shape[:-1] + ref.shape[index.shape[-1]:]` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9571" href="#t9571">9571</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9572" href="#t9572">9572</a></span><span class="t"><span class="str">    According to the :math:`[i_0, i_1, ..., i_{K-2}]` of :attr:`index` ,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9573" href="#t9573">9573</a></span><span class="t"><span class="str">    add the corresponding :attr:`updates` slice to the :attr:`ref` slice</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9574" href="#t9574">9574</a></span><span class="t"><span class="str">    which is obtained by the last one dimension of :attr:`index` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9575" href="#t9575">9575</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9576" href="#t9576">9576</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9577" href="#t9577">9577</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9578" href="#t9578">9578</a></span><span class="t"><span class="str">        Given:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9579" href="#t9579">9579</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9580" href="#t9580">9580</a></span><span class="t"><span class="str">        * Case 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9581" href="#t9581">9581</a></span><span class="t"><span class="str">            ref = [0, 1, 2, 3, 4, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9582" href="#t9582">9582</a></span><span class="t"><span class="str">            index = [[1], [2], [3], [1]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9583" href="#t9583">9583</a></span><span class="t"><span class="str">            updates = [9, 10, 11, 12]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9584" href="#t9584">9584</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9585" href="#t9585">9585</a></span><span class="t"><span class="str">          we get:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9586" href="#t9586">9586</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9587" href="#t9587">9587</a></span><span class="t"><span class="str">            output = [0, 22, 12, 14, 4, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9588" href="#t9588">9588</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9589" href="#t9589">9589</a></span><span class="t"><span class="str">        * Case 2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9590" href="#t9590">9590</a></span><span class="t"><span class="str">            ref = [[65, 17], [-14, -25]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9591" href="#t9591">9591</a></span><span class="t"><span class="str">            index = [[], []]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9592" href="#t9592">9592</a></span><span class="t"><span class="str">            updates = [[[-1, -2], [1, 2]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9593" href="#t9593">9593</a></span><span class="t"><span class="str">                       [[3, 4], [-3, -4]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9594" href="#t9594">9594</a></span><span class="t"><span class="str">            ref.shape = (2, 2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9595" href="#t9595">9595</a></span><span class="t"><span class="str">            index.shape = (2, 0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9596" href="#t9596">9596</a></span><span class="t"><span class="str">            updates.shape = (2, 2, 2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9597" href="#t9597">9597</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9598" href="#t9598">9598</a></span><span class="t"><span class="str">          we get:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9599" href="#t9599">9599</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9600" href="#t9600">9600</a></span><span class="t"><span class="str">            output = [[67, 19], [-16, -27]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9601" href="#t9601">9601</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9602" href="#t9602">9602</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9603" href="#t9603">9603</a></span><span class="t"><span class="str">        ref (Variable): The ref input. Its dtype should be int32, int64, float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9604" href="#t9604">9604</a></span><span class="t"><span class="str">        index (Variable): The index input with rank > 1 and index.shape[-1] &lt;= ref.rank.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9605" href="#t9605">9605</a></span><span class="t"><span class="str">                          Its dtype should be int32 or int64 as it is used as indexes.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9606" href="#t9606">9606</a></span><span class="t"><span class="str">        updates (Variable): The updated value of scatter_nd_add op, and it must have the same dtype</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9607" href="#t9607">9607</a></span><span class="t"><span class="str">                            as ref. It must have the shape index.shape[:-1] + ref.shape[index.shape[-1]:].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9608" href="#t9608">9608</a></span><span class="t"><span class="str">        name (str|None): The output variable name. If set None, the layer will be named automatically.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9609" href="#t9609">9609</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9610" href="#t9610">9610</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9611" href="#t9611">9611</a></span><span class="t"><span class="str">        output (Variable): The output is a tensor with the same shape and dtype as ref.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9612" href="#t9612">9612</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9613" href="#t9613">9613</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9614" href="#t9614">9614</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9615" href="#t9615">9615</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9616" href="#t9616">9616</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9617" href="#t9617">9617</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9618" href="#t9618">9618</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9619" href="#t9619">9619</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9620" href="#t9620">9620</a></span><span class="t"><span class="str">            ref = fluid.data(name='ref', shape=[3, 5, 9, 10], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9621" href="#t9621">9621</a></span><span class="t"><span class="str">            index = fluid.data(name='index', shape=[3, 2], dtype='int32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9622" href="#t9622">9622</a></span><span class="t"><span class="str">            updates = fluid.data(name='update', shape=[3, 9, 10], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9623" href="#t9623">9623</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9624" href="#t9624">9624</a></span><span class="t"><span class="str">            output = fluid.layers.scatter_nd_add(ref, index, updates)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9625" href="#t9625">9625</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9626" href="#t9626">9626</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9627" href="#t9627">9627</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9628" href="#t9628">9628</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">scatter_nd_add</span><span class="op">(</span><span class="nam">ref</span><span class="op">,</span> <span class="nam">index</span><span class="op">,</span> <span class="nam">updates</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9629" href="#t9629">9629</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9630" href="#t9630">9630</a></span><span class="t">        <span class="key">if</span> <span class="nam">_in_legacy_dygraph</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9631" href="#t9631">9631</a></span><span class="t">            <span class="nam">op</span> <span class="op">=</span> <span class="nam">getattr</span><span class="op">(</span><span class="nam">_legacy_C_ops</span><span class="op">,</span> <span class="str">'scatter_nd_add'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9632" href="#t9632">9632</a></span><span class="t">            <span class="key">return</span> <span class="nam">op</span><span class="op">(</span><span class="nam">ref</span><span class="op">,</span> <span class="nam">index</span><span class="op">,</span> <span class="nam">updates</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9633" href="#t9633">9633</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9634" href="#t9634">9634</a></span><span class="t">            <span class="key">if</span> <span class="nam">ref</span><span class="op">.</span><span class="nam">dtype</span> <span class="op">!=</span> <span class="nam">updates</span><span class="op">.</span><span class="nam">dtype</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9635" href="#t9635">9635</a></span><span class="t">                <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"ref and updates must have same data type."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9636" href="#t9636">9636</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9637" href="#t9637">9637</a></span><span class="t">            <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'scatter_nd_add'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9638" href="#t9638">9638</a></span><span class="t">            <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="nam">input_param_name</span><span class="op">=</span><span class="str">'ref'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9639" href="#t9639">9639</a></span><span class="t">            <span class="nam">output</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9640" href="#t9640">9640</a></span><span class="t">            <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9641" href="#t9641">9641</a></span><span class="t">                <span class="nam">type</span><span class="op">=</span><span class="str">"scatter_nd_add"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9642" href="#t9642">9642</a></span><span class="t">                <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">ref</span><span class="op">,</span> <span class="str">"Index"</span><span class="op">:</span> <span class="nam">index</span><span class="op">,</span> <span class="str">"Updates"</span><span class="op">:</span> <span class="nam">updates</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9643" href="#t9643">9643</a></span><span class="t">                <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">output</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9644" href="#t9644">9644</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9645" href="#t9645">9645</a></span><span class="t">            <span class="key">return</span> <span class="nam">output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9646" href="#t9646">9646</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9647" href="#t9647">9647</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9648" href="#t9648">9648</a></span><span class="t"><span class="key">def</span> <span class="nam">scatter_nd</span><span class="op">(</span><span class="nam">index</span><span class="op">,</span> <span class="nam">updates</span><span class="op">,</span> <span class="nam">shape</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9649" href="#t9649">9649</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9650" href="#t9650">9650</a></span><span class="t"><span class="str">    **Scatter_nd Layer**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9651" href="#t9651">9651</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9652" href="#t9652">9652</a></span><span class="t"><span class="str">    Output is obtained by scattering the :attr:`updates` in a new tensor according</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9653" href="#t9653">9653</a></span><span class="t"><span class="str">    to :attr:`index` . This op is similar to :code:`scatter_nd_add`, except the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9654" href="#t9654">9654</a></span><span class="t"><span class="str">    tensor of :attr:`shape` is zero-initialized. Correspondingly, :code:`scatter_nd(index, updates, shape)`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9655" href="#t9655">9655</a></span><span class="t"><span class="str">    is equal to :code:`scatter_nd_add(paddle.zeros(shape, updates.dtype), index, updates)` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9656" href="#t9656">9656</a></span><span class="t"><span class="str">    If :attr:`index` has repeated elements, then the corresponding updates are accumulated.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9657" href="#t9657">9657</a></span><span class="t"><span class="str">    Because of the numerical approximation issues, the different order of repeated elements</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9658" href="#t9658">9658</a></span><span class="t"><span class="str">    in :attr:`index` may cause different results. The specific calculation method can be</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9659" href="#t9659">9659</a></span><span class="t"><span class="str">    seen :code:`scatter_nd_add` . This op is the inverse of the :code:`gather_nd` op.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9660" href="#t9660">9660</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9661" href="#t9661">9661</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9662" href="#t9662">9662</a></span><span class="t"><span class="str">        index (Tensor): The index input with ndim > 1 and index.shape[-1] &lt;= len(shape).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9663" href="#t9663">9663</a></span><span class="t"><span class="str">                          Its dtype should be int32 or int64 as it is used as indexes.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9664" href="#t9664">9664</a></span><span class="t"><span class="str">        updates (Tensor): The updated value of scatter_nd op. Its dtype should be float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9665" href="#t9665">9665</a></span><span class="t"><span class="str">                            It must have the shape index.shape[:-1] + shape[index.shape[-1]:]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9666" href="#t9666">9666</a></span><span class="t"><span class="str">        shape(tuple|list): Shape of output tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9667" href="#t9667">9667</a></span><span class="t"><span class="str">        name (str|None): The output Tensor name. If set None, the layer will be named automatically.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9668" href="#t9668">9668</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9669" href="#t9669">9669</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9670" href="#t9670">9670</a></span><span class="t"><span class="str">        output (Tensor): The output is a tensor with the same type as :attr:`updates` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9671" href="#t9671">9671</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9672" href="#t9672">9672</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9673" href="#t9673">9673</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9674" href="#t9674">9674</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9675" href="#t9675">9675</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9676" href="#t9676">9676</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9677" href="#t9677">9677</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9678" href="#t9678">9678</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9679" href="#t9679">9679</a></span><span class="t"><span class="str">            index_data = np.array([[1, 1],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9680" href="#t9680">9680</a></span><span class="t"><span class="str">                                   [0, 1],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9681" href="#t9681">9681</a></span><span class="t"><span class="str">                                   [1, 3]]).astype(np.int64)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9682" href="#t9682">9682</a></span><span class="t"><span class="str">            index = paddle.to_tensor(index_data)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9683" href="#t9683">9683</a></span><span class="t"><span class="str">            updates = paddle.rand(shape=[3, 9, 10], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9684" href="#t9684">9684</a></span><span class="t"><span class="str">            shape = [3, 5, 9, 10]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9685" href="#t9685">9685</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9686" href="#t9686">9686</a></span><span class="t"><span class="str">            output = paddle.scatter_nd(index, updates, shape)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9687" href="#t9687">9687</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9688" href="#t9688">9688</a></span><span class="t">    <span class="key">return</span> <span class="nam">scatter_nd_add</span><span class="op">(</span><span class="nam">zeros</span><span class="op">(</span><span class="nam">shape</span><span class="op">,</span> <span class="nam">updates</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span><span class="op">,</span> <span class="nam">index</span><span class="op">,</span> <span class="nam">updates</span><span class="op">,</span> <span class="nam">name</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9689" href="#t9689">9689</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9690" href="#t9690">9690</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9691" href="#t9691">9691</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9692" href="#t9692">9692</a></span><span class="t"><span class="key">def</span> <span class="nam">random_crop</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">shape</span><span class="op">,</span> <span class="nam">seed</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9693" href="#t9693">9693</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9694" href="#t9694">9694</a></span><span class="t"><span class="str">    ${comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9695" href="#t9695">9695</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9696" href="#t9696">9696</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9697" href="#t9697">9697</a></span><span class="t"><span class="str">        x(${x_type}): ${x_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9698" href="#t9698">9698</a></span><span class="t"><span class="str">        shape(${shape_type}): ${shape_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9699" href="#t9699">9699</a></span><span class="t"><span class="str">        seed(int|${seed_type}|None): ${seed_comment} By default, the seed will</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9700" href="#t9700">9700</a></span><span class="t"><span class="str">            get from `random.randint(-65536, 65535)`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9701" href="#t9701">9701</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9702" href="#t9702">9702</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9703" href="#t9703">9703</a></span><span class="t"><span class="str">        ${out_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9704" href="#t9704">9704</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9705" href="#t9705">9705</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9706" href="#t9706">9706</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9707" href="#t9707">9707</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9708" href="#t9708">9708</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9709" href="#t9709">9709</a></span><span class="t"><span class="str">            img = fluid.data("img", [None, 3, 256, 256])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9710" href="#t9710">9710</a></span><span class="t"><span class="str">            # cropped_img is [-1, 3, 224, 224]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9711" href="#t9711">9711</a></span><span class="t"><span class="str">            cropped_img = fluid.layers.random_crop(img, shape=[3, 224, 224])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9712" href="#t9712">9712</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9713" href="#t9713">9713</a></span><span class="t"><span class="str">            # cropped_img2 shape: [-1, 2, 224, 224]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9714" href="#t9714">9714</a></span><span class="t"><span class="str">            # cropped_img2 = fluid.layers.random_crop(img, shape=[2, 224, 224])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9715" href="#t9715">9715</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9716" href="#t9716">9716</a></span><span class="t"><span class="str">            # cropped_img3 shape: [-1, 3, 128, 224]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9717" href="#t9717">9717</a></span><span class="t"><span class="str">            # cropped_img3 = fluid.layers.random_crop(img, shape=[128, 224])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9718" href="#t9718">9718</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9719" href="#t9719">9719</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9720" href="#t9720">9720</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"random_crop"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9721" href="#t9721">9721</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9722" href="#t9722">9722</a></span><span class="t">        <span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'uint8'</span><span class="op">,</span> <span class="str">'int16'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">]</span><span class="op">,</span> <span class="str">'random_crop'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9723" href="#t9723">9723</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9724" href="#t9724">9724</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">shape</span><span class="op">,</span> <span class="str">'shape'</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">,</span> <span class="str">'random_crop'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9725" href="#t9725">9725</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9726" href="#t9726">9726</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9727" href="#t9727">9727</a></span><span class="t">    <span class="key">if</span> <span class="nam">seed</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9728" href="#t9728">9728</a></span><span class="t">        <span class="nam">seed</span> <span class="op">=</span> <span class="nam">np</span><span class="op">.</span><span class="nam">random</span><span class="op">.</span><span class="nam">randint</span><span class="op">(</span><span class="op">-</span><span class="num">65536</span><span class="op">,</span> <span class="num">65536</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9729" href="#t9729">9729</a></span><span class="t">    <span class="nam">op_attrs</span> <span class="op">=</span> <span class="op">{</span><span class="str">"shape"</span><span class="op">:</span> <span class="nam">shape</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9730" href="#t9730">9730</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">seed</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9731" href="#t9731">9731</a></span><span class="t">        <span class="nam">op_attrs</span><span class="op">[</span><span class="str">"startup_seed"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">seed</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9732" href="#t9732">9732</a></span><span class="t">        <span class="nam">seed</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9733" href="#t9733">9733</a></span><span class="t">            <span class="nam">name</span><span class="op">=</span><span class="nam">unique_name</span><span class="op">.</span><span class="nam">generate</span><span class="op">(</span><span class="str">"random_crop_seed"</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9734" href="#t9734">9734</a></span><span class="t">            <span class="nam">dtype</span><span class="op">=</span><span class="str">"int64"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9735" href="#t9735">9735</a></span><span class="t">            <span class="nam">persistable</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9736" href="#t9736">9736</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9737" href="#t9737">9737</a></span><span class="t">    <span class="key">elif</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">seed</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9738" href="#t9738">9738</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"'seed' must be a Variable or an int."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9739" href="#t9739">9739</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9740" href="#t9740">9740</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"random_crop"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9741" href="#t9741">9741</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">x</span><span class="op">,</span> <span class="str">"Seed"</span><span class="op">:</span> <span class="nam">seed</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9742" href="#t9742">9742</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">,</span> <span class="str">"SeedOut"</span><span class="op">:</span> <span class="nam">seed</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9743" href="#t9743">9743</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="nam">op_attrs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9744" href="#t9744">9744</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9745" href="#t9745">9745</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9746" href="#t9746">9746</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9747" href="#t9747">9747</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9748" href="#t9748">9748</a></span><span class="t"><span class="key">def</span> <span class="nam">log</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9749" href="#t9749">9749</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9750" href="#t9750">9750</a></span><span class="t"><span class="str">    Calculates the natural log of the given input tensor, element-wise.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9751" href="#t9751">9751</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9752" href="#t9752">9752</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9753" href="#t9753">9753</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9754" href="#t9754">9754</a></span><span class="t"><span class="str">        Out = \\ln(x)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9755" href="#t9755">9755</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9756" href="#t9756">9756</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9757" href="#t9757">9757</a></span><span class="t"><span class="str">        x (Tensor): Input Tensor. Must be one of the following types: float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9758" href="#t9758">9758</a></span><span class="t"><span class="str">        name (str|None): The default value is None. Normally there is no need for user to set this property. For more information, please refer to :ref:`api_guide_Name`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9759" href="#t9759">9759</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9760" href="#t9760">9760</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9761" href="#t9761">9761</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9762" href="#t9762">9762</a></span><span class="t"><span class="str">        Tensor: The natural log of the input Tensor computed element-wise.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9763" href="#t9763">9763</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9764" href="#t9764">9764</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9765" href="#t9765">9765</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9766" href="#t9766">9766</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9767" href="#t9767">9767</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9768" href="#t9768">9768</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9769" href="#t9769">9769</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9770" href="#t9770">9770</a></span><span class="t"><span class="str">            x = [[2,3,4], [7,8,9]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9771" href="#t9771">9771</a></span><span class="t"><span class="str">            x = paddle.to_tensor(x, dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9772" href="#t9772">9772</a></span><span class="t"><span class="str">            res = paddle.log(x)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9773" href="#t9773">9773</a></span><span class="t"><span class="str">            # [[0.693147, 1.09861, 1.38629], [1.94591, 2.07944, 2.19722]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9774" href="#t9774">9774</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t9775" href="#t9775">9775</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">9775&#x202F;&#x219B;&#x202F;9777</span><span class="annotate long">line 9775 didn't jump to line 9777, because the condition on line 9775 was never false</span></span></p>
    <p class="run"><span class="n"><a id="t9776" href="#t9776">9776</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">log</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9777" href="#t9777">9777</a></span><span class="t">    <span class="key">if</span> <span class="nam">_in_legacy_dygraph</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9778" href="#t9778">9778</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">log</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9779" href="#t9779">9779</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9780" href="#t9780">9780</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">"log"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9781" href="#t9781">9781</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="op">[</span><span class="nam">x</span><span class="op">]</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9782" href="#t9782">9782</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'log'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9783" href="#t9783">9783</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="nam">input_param_name</span><span class="op">=</span><span class="str">'x'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9784" href="#t9784">9784</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9785" href="#t9785">9785</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">"log"</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9786" href="#t9786">9786</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9787" href="#t9787">9787</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9788" href="#t9788">9788</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9789" href="#t9789">9789</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.nn.functional.relu"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9790" href="#t9790">9790</a></span><span class="t"><span class="key">def</span> <span class="nam">relu</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9791" href="#t9791">9791</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9792" href="#t9792">9792</a></span><span class="t"><span class="str">    ${comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9793" href="#t9793">9793</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9794" href="#t9794">9794</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9795" href="#t9795">9795</a></span><span class="t"><span class="str">        x(Variable): ${x_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9796" href="#t9796">9796</a></span><span class="t"><span class="str">        name(str, optional): The default value is None. Normally there is no</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9797" href="#t9797">9797</a></span><span class="t"><span class="str">            need for user to set this property. For more information, please</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9798" href="#t9798">9798</a></span><span class="t"><span class="str">            refer to :ref:`api_guide_Name`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9799" href="#t9799">9799</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9800" href="#t9800">9800</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9801" href="#t9801">9801</a></span><span class="t"><span class="str">        Variable: ${out_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9802" href="#t9802">9802</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9803" href="#t9803">9803</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9804" href="#t9804">9804</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9805" href="#t9805">9805</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9806" href="#t9806">9806</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9807" href="#t9807">9807</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9808" href="#t9808">9808</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9809" href="#t9809">9809</a></span><span class="t"><span class="str">            in1 = np.array([[-1,0],[1,2.6]])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9810" href="#t9810">9810</a></span><span class="t"><span class="str">            with fluid.dygraph.guard():</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9811" href="#t9811">9811</a></span><span class="t"><span class="str">                x1 = fluid.dygraph.to_variable(in1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9812" href="#t9812">9812</a></span><span class="t"><span class="str">                out1 = fluid.layers.relu(x1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9813" href="#t9813">9813</a></span><span class="t"><span class="str">                print(out1.numpy())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9814" href="#t9814">9814</a></span><span class="t"><span class="str">                # [[0.  0. ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9815" href="#t9815">9815</a></span><span class="t"><span class="str">                #  [1.  2.6]]"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9816" href="#t9816">9816</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9817" href="#t9817">9817</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9818" href="#t9818">9818</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">relu</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9819" href="#t9819">9819</a></span><span class="t">    <span class="key">if</span> <span class="nam">_in_legacy_dygraph</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9820" href="#t9820">9820</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">relu</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9821" href="#t9821">9821</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9822" href="#t9822">9822</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'relu'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9823" href="#t9823">9823</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9824" href="#t9824">9824</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="op">[</span><span class="nam">x</span><span class="op">]</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9825" href="#t9825">9825</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'relu'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9826" href="#t9826">9826</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="nam">input_param_name</span><span class="op">=</span><span class="str">'x'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9827" href="#t9827">9827</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9828" href="#t9828">9828</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9829" href="#t9829">9829</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"relu"</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input</span><span class="op">(</span><span class="str">'x'</span><span class="op">)</span><span class="op">}</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9830" href="#t9830">9830</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9831" href="#t9831">9831</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9832" href="#t9832">9832</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9833" href="#t9833">9833</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9834" href="#t9834">9834</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.nn.functional.selu"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9835" href="#t9835">9835</a></span><span class="t"><span class="key">def</span> <span class="nam">selu</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">scale</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">alpha</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9836" href="#t9836">9836</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9837" href="#t9837">9837</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9838" href="#t9838">9838</a></span><span class="t"><span class="str">    Selu Operator.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9839" href="#t9839">9839</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9840" href="#t9840">9840</a></span><span class="t"><span class="str">    The equation is:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9841" href="#t9841">9841</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9842" href="#t9842">9842</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9843" href="#t9843">9843</a></span><span class="t"><span class="str">        selu= \\lambda*</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9844" href="#t9844">9844</a></span><span class="t"><span class="str">        \\begin{cases}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9845" href="#t9845">9845</a></span><span class="t"><span class="str">            x                      &amp;\\quad \\text{ if } x>0 \n</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9846" href="#t9846">9846</a></span><span class="t"><span class="str">            \\alpha * e^x - \\alpha  &amp;\\quad \\text{ if } x&lt;=0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9847" href="#t9847">9847</a></span><span class="t"><span class="str">        \\end{cases}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9848" href="#t9848">9848</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9849" href="#t9849">9849</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9850" href="#t9850">9850</a></span><span class="t"><span class="str">    The input `X` can carry the LoD (Level of Details) information,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9851" href="#t9851">9851</a></span><span class="t"><span class="str">    or not. And the output shares the LoD information with input `X`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9852" href="#t9852">9852</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9853" href="#t9853">9853</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9854" href="#t9854">9854</a></span><span class="t"><span class="str">        x (Variable): The input N-D Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9855" href="#t9855">9855</a></span><span class="t"><span class="str">        scale(float, optional): lambda in selu activation function,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9856" href="#t9856">9856</a></span><span class="t"><span class="str">            the default value is 1.0507009873554804934193349852946.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9857" href="#t9857">9857</a></span><span class="t"><span class="str">            For more information about this value, please refer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9858" href="#t9858">9858</a></span><span class="t"><span class="str">            to: https://arxiv.org/abs/1706.02515.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9859" href="#t9859">9859</a></span><span class="t"><span class="str">        alpha(float, optional): alpha in selu activation function,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9860" href="#t9860">9860</a></span><span class="t"><span class="str">            the default value is 1.6732632423543772848170429916717.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9861" href="#t9861">9861</a></span><span class="t"><span class="str">            For more information about this value, please refer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9862" href="#t9862">9862</a></span><span class="t"><span class="str">            to: https://arxiv.org/abs/1706.02515.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9863" href="#t9863">9863</a></span><span class="t"><span class="str">        name(str, optional): The default value is None.  Normally there is no need for user to set this property.  For more information, please refer to :ref:`api_guide_Name` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9864" href="#t9864">9864</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9865" href="#t9865">9865</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9866" href="#t9866">9866</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9867" href="#t9867">9867</a></span><span class="t"><span class="str">        Variable(Tensor|LoDTensor): The output Tensor or LoDTensor with the same shape and LoD information as input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9868" href="#t9868">9868</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9869" href="#t9869">9869</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9870" href="#t9870">9870</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9871" href="#t9871">9871</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9872" href="#t9872">9872</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9873" href="#t9873">9873</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9874" href="#t9874">9874</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9875" href="#t9875">9875</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9876" href="#t9876">9876</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9877" href="#t9877">9877</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9878" href="#t9878">9878</a></span><span class="t"><span class="str">            inputs = fluid.layers.data(name="x", shape=[2, 2], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9879" href="#t9879">9879</a></span><span class="t"><span class="str">            output = fluid.layers.selu(inputs)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9880" href="#t9880">9880</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9881" href="#t9881">9881</a></span><span class="t"><span class="str">            exe = fluid.Executor(fluid.CPUPlace())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9882" href="#t9882">9882</a></span><span class="t"><span class="str">            exe.run(fluid.default_startup_program())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9883" href="#t9883">9883</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9884" href="#t9884">9884</a></span><span class="t"><span class="str">            img = np.array([[0, 1],[2, 3]]).astype(np.float32)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9885" href="#t9885">9885</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9886" href="#t9886">9886</a></span><span class="t"><span class="str">            res = exe.run(fluid.default_main_program(), feed={'x':img}, fetch_list=[output])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9887" href="#t9887">9887</a></span><span class="t"><span class="str">            print(res) # [array([[0.      , 1.050701],[2.101402, 3.152103]], dtype=float32)]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9888" href="#t9888">9888</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9889" href="#t9889">9889</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'selu'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9890" href="#t9890">9890</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9891" href="#t9891">9891</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'selu'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9892" href="#t9892">9892</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="nam">input_param_name</span><span class="op">=</span><span class="str">'x'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9893" href="#t9893">9893</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9894" href="#t9894">9894</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9895" href="#t9895">9895</a></span><span class="t">    <span class="key">if</span> <span class="nam">scale</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9896" href="#t9896">9896</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">"scale"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">scale</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9897" href="#t9897">9897</a></span><span class="t">    <span class="key">if</span> <span class="nam">alpha</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9898" href="#t9898">9898</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">"alpha"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">alpha</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9899" href="#t9899">9899</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9900" href="#t9900">9900</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9901" href="#t9901">9901</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"selu"</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span> <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9902" href="#t9902">9902</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9903" href="#t9903">9903</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9904" href="#t9904">9904</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9905" href="#t9905">9905</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9906" href="#t9906">9906</a></span><span class="t"><span class="key">def</span> <span class="nam">mean_iou</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">label</span><span class="op">,</span> <span class="nam">num_classes</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9907" href="#t9907">9907</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9908" href="#t9908">9908</a></span><span class="t"><span class="str">    Mean Intersection-Over-Union is a common evaluation metric for</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9909" href="#t9909">9909</a></span><span class="t"><span class="str">    semantic image segmentation, which first computes the IOU for each</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9910" href="#t9910">9910</a></span><span class="t"><span class="str">    semantic class and then computes the average over classes.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9911" href="#t9911">9911</a></span><span class="t"><span class="str">    IOU is defined as follows:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9912" href="#t9912">9912</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9913" href="#t9913">9913</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9914" href="#t9914">9914</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9915" href="#t9915">9915</a></span><span class="t"><span class="str">        IOU = \\frac{true\_positive}{(true\_positive + false\_positive + false\_negative)}.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9916" href="#t9916">9916</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9917" href="#t9917">9917</a></span><span class="t"><span class="str">    The predictions are accumulated in a confusion matrix and mean-IOU</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9918" href="#t9918">9918</a></span><span class="t"><span class="str">    is then calculated from it.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9919" href="#t9919">9919</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9920" href="#t9920">9920</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9921" href="#t9921">9921</a></span><span class="t"><span class="str">    Parameters:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9922" href="#t9922">9922</a></span><span class="t"><span class="str">        input (Tensor): A n-D Tensor of prediction results for semantic labels with type int32 or int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9923" href="#t9923">9923</a></span><span class="t"><span class="str">        label (Tensor): A Tensor of ground truth labels with type int32 or int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9924" href="#t9924">9924</a></span><span class="t"><span class="str">                           Its shape should be the same as input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9925" href="#t9925">9925</a></span><span class="t"><span class="str">        num_classes (int32): The possible number of labels.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9926" href="#t9926">9926</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9927" href="#t9927">9927</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9928" href="#t9928">9928</a></span><span class="t"><span class="str">        Three Tensors.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9929" href="#t9929">9929</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9930" href="#t9930">9930</a></span><span class="t"><span class="str">        - mean_iou(Tensor) : A 1-D Tensor representing the mean intersection-over-union with shape [1]. \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9931" href="#t9931">9931</a></span><span class="t"><span class="str">                            Data type is float32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9932" href="#t9932">9932</a></span><span class="t"><span class="str">        - out_wrong(Tensor) : A 1-D Tensor with shape [num_classes]. Data type is int32. \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9933" href="#t9933">9933</a></span><span class="t"><span class="str">                             The wrong numbers of each class.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9934" href="#t9934">9934</a></span><span class="t"><span class="str">        - out_correct(Tensor): A 1-D  Tensor with shape [num_classes]. Data type is int32. The correct numbers of each class.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9935" href="#t9935">9935</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9936" href="#t9936">9936</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9937" href="#t9937">9937</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9938" href="#t9938">9938</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9939" href="#t9939">9939</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9940" href="#t9940">9940</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9941" href="#t9941">9941</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9942" href="#t9942">9942</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9943" href="#t9943">9943</a></span><span class="t"><span class="str">            iou_shape = [64, 32, 32]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9944" href="#t9944">9944</a></span><span class="t"><span class="str">            num_classes = 5</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9945" href="#t9945">9945</a></span><span class="t"><span class="str">            predict = paddle.randint(low=0, high=255, shape=iou_shape, dtype='int64')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9946" href="#t9946">9946</a></span><span class="t"><span class="str">            label = paddle.randint(low=0, high=255, shape=iou_shape, dtype='int64')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9947" href="#t9947">9947</a></span><span class="t"><span class="str">            mean_iou, out_wrong, out_correct = paddle.metric.mean_iou(predict, label, num_classes)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9948" href="#t9948">9948</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t9949" href="#t9949">9949</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">9949&#x202F;&#x219B;&#x202F;9950</span><span class="annotate long">line 9949 didn't jump to line 9950, because the condition on line 9949 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9950" href="#t9950">9950</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">mean_iou</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">label</span><span class="op">,</span> <span class="str">'num_classes'</span><span class="op">,</span> <span class="nam">num_classes</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9951" href="#t9951">9951</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9952" href="#t9952">9952</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'mean_iou'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9953" href="#t9953">9953</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9954" href="#t9954">9954</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span> <span class="str">'Predictions'</span><span class="op">,</span> <span class="op">[</span><span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'mean_iou'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9955" href="#t9955">9955</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9956" href="#t9956">9956</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">label</span><span class="op">,</span> <span class="str">'Labels'</span><span class="op">,</span> <span class="op">[</span><span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'mean_iou'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9957" href="#t9957">9957</a></span><span class="t">    <span class="nam">out_mean_iou</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="str">'float32'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9958" href="#t9958">9958</a></span><span class="t">    <span class="nam">out_wrong</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="str">'int32'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9959" href="#t9959">9959</a></span><span class="t">    <span class="nam">out_correct</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="str">'int32'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9960" href="#t9960">9960</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9961" href="#t9961">9961</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"mean_iou"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9962" href="#t9962">9962</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Predictions"</span><span class="op">:</span> <span class="nam">input</span><span class="op">,</span> <span class="str">"Labels"</span><span class="op">:</span> <span class="nam">label</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9963" href="#t9963">9963</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9964" href="#t9964">9964</a></span><span class="t">            <span class="str">"OutMeanIou"</span><span class="op">:</span> <span class="nam">out_mean_iou</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9965" href="#t9965">9965</a></span><span class="t">            <span class="str">"OutWrong"</span><span class="op">:</span> <span class="nam">out_wrong</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9966" href="#t9966">9966</a></span><span class="t">            <span class="str">"OutCorrect"</span><span class="op">:</span> <span class="nam">out_correct</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9967" href="#t9967">9967</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9968" href="#t9968">9968</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">"num_classes"</span><span class="op">:</span> <span class="nam">num_classes</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9969" href="#t9969">9969</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t9970" href="#t9970">9970</a></span><span class="t">    <span class="key">return</span> <span class="nam">out_mean_iou</span><span class="op">,</span> <span class="nam">out_wrong</span><span class="op">,</span> <span class="nam">out_correct</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9971" href="#t9971">9971</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9972" href="#t9972">9972</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9973" href="#t9973">9973</a></span><span class="t"><span class="key">def</span> <span class="nam">crop</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">shape</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">offsets</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9974" href="#t9974">9974</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9975" href="#t9975">9975</a></span><span class="t"><span class="str">    Crop input into output, as specified by offsets and shape.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9976" href="#t9976">9976</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9977" href="#t9977">9977</a></span><span class="t"><span class="str">    **Warning:** THIS OP IS DEPRECATED. It will be removed in the future version.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9978" href="#t9978">9978</a></span><span class="t"><span class="str">    Instructions for updating: Use :ref:`api_fluid_layers_crop_tensor` instead.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9979" href="#t9979">9979</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9980" href="#t9980">9980</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9981" href="#t9981">9981</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9982" href="#t9982">9982</a></span><span class="t"><span class="str">        * Case 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9983" href="#t9983">9983</a></span><span class="t"><span class="str">            Given</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9984" href="#t9984">9984</a></span><span class="t"><span class="str">                X = [[0, 1, 2, 0, 0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9985" href="#t9985">9985</a></span><span class="t"><span class="str">                     [0, 3, 4, 0, 0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9986" href="#t9986">9986</a></span><span class="t"><span class="str">                     [0, 0, 0, 0, 0]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9987" href="#t9987">9987</a></span><span class="t"><span class="str">            and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9988" href="#t9988">9988</a></span><span class="t"><span class="str">                shape = [2, 2],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9989" href="#t9989">9989</a></span><span class="t"><span class="str">                offsets = [0, 1],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9990" href="#t9990">9990</a></span><span class="t"><span class="str">            output is:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9991" href="#t9991">9991</a></span><span class="t"><span class="str">                Out = [[1, 2],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9992" href="#t9992">9992</a></span><span class="t"><span class="str">                       [3, 4]].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9993" href="#t9993">9993</a></span><span class="t"><span class="str">        * Case 2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9994" href="#t9994">9994</a></span><span class="t"><span class="str">            Given</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9995" href="#t9995">9995</a></span><span class="t"><span class="str">                X = [[0, 1, 2, 5, 0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9996" href="#t9996">9996</a></span><span class="t"><span class="str">                     [0, 3, 4, 6, 0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9997" href="#t9997">9997</a></span><span class="t"><span class="str">                     [0, 0, 0, 0, 0]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9998" href="#t9998">9998</a></span><span class="t"><span class="str">            and shape is tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t9999" href="#t9999">9999</a></span><span class="t"><span class="str">                shape = [[0, 0, 0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10000" href="#t10000">10000</a></span><span class="t"><span class="str">                         [0, 0, 0]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10001" href="#t10001">10001</a></span><span class="t"><span class="str">            and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10002" href="#t10002">10002</a></span><span class="t"><span class="str">                offsets = [0, 1],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10003" href="#t10003">10003</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10004" href="#t10004">10004</a></span><span class="t"><span class="str">            output is:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10005" href="#t10005">10005</a></span><span class="t"><span class="str">                Out = [[1, 2, 5],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10006" href="#t10006">10006</a></span><span class="t"><span class="str">                       [3, 4, 6]].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10007" href="#t10007">10007</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10008" href="#t10008">10008</a></span><span class="t"><span class="str">    Parameters:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10009" href="#t10009">10009</a></span><span class="t"><span class="str">        x (Variable): Tensor, data type can be float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10010" href="#t10010">10010</a></span><span class="t"><span class="str">        shape (Variable|list/tuple of integers, optional): The output shape is specified</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10011" href="#t10011">10011</a></span><span class="t"><span class="str">            by `shape`, which can be a Tensor or a list/tuple of integers.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10012" href="#t10012">10012</a></span><span class="t"><span class="str">            If it is a Tensor, it's rank must be the same as `x` , only</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10013" href="#t10013">10013</a></span><span class="t"><span class="str">            it's shape will be used, and the value of it will be ignored. This way</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10014" href="#t10014">10014</a></span><span class="t"><span class="str">            is suitable for the case that the output shape may be changed each</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10015" href="#t10015">10015</a></span><span class="t"><span class="str">            iteration. If it is a list/tuple of integers, it's length must be the same</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10016" href="#t10016">10016</a></span><span class="t"><span class="str">            as the rank of `x`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10017" href="#t10017">10017</a></span><span class="t"><span class="str">        offsets (Variable|list/tuple of integers|None, optional): Specifies the cropping</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10018" href="#t10018">10018</a></span><span class="t"><span class="str">            offsets at each dimension. It can be a Tensor or a list/tuple</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10019" href="#t10019">10019</a></span><span class="t"><span class="str">            of integers. If it is a Tensor, it's rank must be the same as `x`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10020" href="#t10020">10020</a></span><span class="t"><span class="str">            This way is suitable for the case that the offsets may be changed</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10021" href="#t10021">10021</a></span><span class="t"><span class="str">            each iteration. If it is a list/tuple of integers, it's length must be the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10022" href="#t10022">10022</a></span><span class="t"><span class="str">            same as the rank of `x`. If None, the offsets are 0 at each dimension.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10023" href="#t10023">10023</a></span><span class="t"><span class="str">        name(str, optional): For detailed information, please refer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10024" href="#t10024">10024</a></span><span class="t"><span class="str">            to :ref:`api_guide_Name` . Usually name is no need to set and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10025" href="#t10025">10025</a></span><span class="t"><span class="str">            None by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10026" href="#t10026">10026</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10027" href="#t10027">10027</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10028" href="#t10028">10028</a></span><span class="t"><span class="str">        Tensor, The cropped Tensor, which has the same rank and data type with `x`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10029" href="#t10029">10029</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10030" href="#t10030">10030</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10031" href="#t10031">10031</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10032" href="#t10032">10032</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10033" href="#t10033">10033</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10034" href="#t10034">10034</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10035" href="#t10035">10035</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10036" href="#t10036">10036</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10037" href="#t10037">10037</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10038" href="#t10038">10038</a></span><span class="t"><span class="str">            x = fluid.data(name="x", shape=[3, 3, 5], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10039" href="#t10039">10039</a></span><span class="t"><span class="str">            y = fluid.data(name="y", shape=[2, 2, 3], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10040" href="#t10040">10040</a></span><span class="t"><span class="str">            crop = fluid.layers.crop(x, shape=y)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10041" href="#t10041">10041</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10042" href="#t10042">10042</a></span><span class="t"><span class="str">            # or</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10043" href="#t10043">10043</a></span><span class="t"><span class="str">            z = fluid.data(name="z", shape=[3, 3, 5], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10044" href="#t10044">10044</a></span><span class="t"><span class="str">            crop = fluid.layers.crop(z, shape=[2, 2, 3])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10045" href="#t10045">10045</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10046" href="#t10046">10046</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10047" href="#t10047">10047</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">]</span><span class="op">,</span> <span class="str">'crop'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10048" href="#t10048">10048</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">shape</span><span class="op">,</span> <span class="str">'shape'</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">,</span> <span class="str">'crop'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10049" href="#t10049">10049</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'crop'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10050" href="#t10050">10050</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10051" href="#t10051">10051</a></span><span class="t">    <span class="key">if</span> <span class="nam">offsets</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10052" href="#t10052">10052</a></span><span class="t">        <span class="nam">offsets</span> <span class="op">=</span> <span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">*</span> <span class="nam">len</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10053" href="#t10053">10053</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10054" href="#t10054">10054</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10055" href="#t10055">10055</a></span><span class="t">    <span class="nam">ipts</span> <span class="op">=</span> <span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10056" href="#t10056">10056</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10057" href="#t10057">10057</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">shape</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10058" href="#t10058">10058</a></span><span class="t">        <span class="nam">ipts</span><span class="op">[</span><span class="str">'Y'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10059" href="#t10059">10059</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10060" href="#t10060">10060</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">'shape'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10061" href="#t10061">10061</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">offsets</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10062" href="#t10062">10062</a></span><span class="t">        <span class="nam">ipts</span><span class="op">[</span><span class="str">'Offsets'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">offsets</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10063" href="#t10063">10063</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10064" href="#t10064">10064</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">'offsets'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">offsets</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10065" href="#t10065">10065</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10066" href="#t10066">10066</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10067" href="#t10067">10067</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'crop'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10068" href="#t10068">10068</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="nam">ipts</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10069" href="#t10069">10069</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10070" href="#t10070">10070</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="key">None</span> <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">attrs</span><span class="op">)</span> <span class="op">==</span> <span class="num">0</span> <span class="key">else</span> <span class="nam">attrs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10071" href="#t10071">10071</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10072" href="#t10072">10072</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10073" href="#t10073">10073</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10074" href="#t10074">10074</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t10075" href="#t10075">10075</a></span><span class="t"><span class="key">def</span> <span class="nam">crop_tensor</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">shape</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">offsets</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10076" href="#t10076">10076</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10077" href="#t10077">10077</a></span><span class="t"><span class="str">    Crop input into output, as specified by offsets and shape.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10078" href="#t10078">10078</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10079" href="#t10079">10079</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10080" href="#t10080">10080</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10081" href="#t10081">10081</a></span><span class="t"><span class="str">        * Case 1 (input is a 2-D Tensor):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10082" href="#t10082">10082</a></span><span class="t"><span class="str">            Input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10083" href="#t10083">10083</a></span><span class="t"><span class="str">                X.shape = [3, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10084" href="#t10084">10084</a></span><span class="t"><span class="str">                X.data = [[0, 1, 2, 0, 0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10085" href="#t10085">10085</a></span><span class="t"><span class="str">                          [0, 3, 4, 0, 0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10086" href="#t10086">10086</a></span><span class="t"><span class="str">                          [0, 0, 0, 0, 0]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10087" href="#t10087">10087</a></span><span class="t"><span class="str">            Parameters:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10088" href="#t10088">10088</a></span><span class="t"><span class="str">                shape = [2, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10089" href="#t10089">10089</a></span><span class="t"><span class="str">                offsets = [0, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10090" href="#t10090">10090</a></span><span class="t"><span class="str">            Output:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10091" href="#t10091">10091</a></span><span class="t"><span class="str">                Out.shape = [2, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10092" href="#t10092">10092</a></span><span class="t"><span class="str">                Out.data = [[1, 2],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10093" href="#t10093">10093</a></span><span class="t"><span class="str">                            [3, 4]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10094" href="#t10094">10094</a></span><span class="t"><span class="str">        * Case 2 (input is a 3-D Tensor):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10095" href="#t10095">10095</a></span><span class="t"><span class="str">            Input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10096" href="#t10096">10096</a></span><span class="t"><span class="str">                X.shape = [2, 3, 4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10097" href="#t10097">10097</a></span><span class="t"><span class="str">                X.data =  [[[0, 1, 2, 3],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10098" href="#t10098">10098</a></span><span class="t"><span class="str">                            [0, 5, 6, 7],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10099" href="#t10099">10099</a></span><span class="t"><span class="str">                            [0, 0, 0, 0]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10100" href="#t10100">10100</a></span><span class="t"><span class="str">                           [[0, 3, 4, 5],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10101" href="#t10101">10101</a></span><span class="t"><span class="str">                            [0, 6, 7, 8],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10102" href="#t10102">10102</a></span><span class="t"><span class="str">                            [0, 0, 0, 0]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10103" href="#t10103">10103</a></span><span class="t"><span class="str">            Parameters:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10104" href="#t10104">10104</a></span><span class="t"><span class="str">                shape = [2, 2, -1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10105" href="#t10105">10105</a></span><span class="t"><span class="str">                offsets = [0, 0, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10106" href="#t10106">10106</a></span><span class="t"><span class="str">            Output:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10107" href="#t10107">10107</a></span><span class="t"><span class="str">                Out.shape = [2, 2, 3]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10108" href="#t10108">10108</a></span><span class="t"><span class="str">                Out.data  = [[[1, 2, 3],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10109" href="#t10109">10109</a></span><span class="t"><span class="str">                              [5, 6, 7]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10110" href="#t10110">10110</a></span><span class="t"><span class="str">                             [[3, 4, 5],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10111" href="#t10111">10111</a></span><span class="t"><span class="str">                              [6, 7, 8]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10112" href="#t10112">10112</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10113" href="#t10113">10113</a></span><span class="t"><span class="str">    Parameters:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10114" href="#t10114">10114</a></span><span class="t"><span class="str">        x (Tensor): 1-D to 6-D Tensor, the data type is float32, float64, int32 or int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10115" href="#t10115">10115</a></span><span class="t"><span class="str">        shape (list|tuple|Tensor): The output shape is specified</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10116" href="#t10116">10116</a></span><span class="t"><span class="str">            by `shape`. Its data type is int32. If a list/tuple, it's length must be</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10117" href="#t10117">10117</a></span><span class="t"><span class="str">            the same as the dimension size of `x`. If a Tensor, it should be a 1-D Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10118" href="#t10118">10118</a></span><span class="t"><span class="str">            When it is a list, each element can be an integer or a Tensor of shape: [1].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10119" href="#t10119">10119</a></span><span class="t"><span class="str">            If Variable contained, it is suitable for the case that the shape may</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10120" href="#t10120">10120</a></span><span class="t"><span class="str">            be changed each iteration.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10121" href="#t10121">10121</a></span><span class="t"><span class="str">        offsets (list|tuple|Variable, optional): Specifies the cropping</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10122" href="#t10122">10122</a></span><span class="t"><span class="str">            offsets at each dimension. Its data type is int32. If a list/tuple, it's length</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10123" href="#t10123">10123</a></span><span class="t"><span class="str">            must be the same as the dimension size of `x`. If a Tensor, it should be a 1-D</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10124" href="#t10124">10124</a></span><span class="t"><span class="str">            Tensor. When it is a list, each element can be an integer or a Tensor of shape: [1].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10125" href="#t10125">10125</a></span><span class="t"><span class="str">            If Variable contained, it is suitable for the case that the offsets may be changed</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10126" href="#t10126">10126</a></span><span class="t"><span class="str">            each iteration. Default: None, the offsets are 0 at each dimension.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10127" href="#t10127">10127</a></span><span class="t"><span class="str">        name(str, optional): The default value is None. Normally there is no need for user to set</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10128" href="#t10128">10128</a></span><span class="t"><span class="str">            this property. For more information, please refer to :ref:`api_guide_Name` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10129" href="#t10129">10129</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10130" href="#t10130">10130</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10131" href="#t10131">10131</a></span><span class="t"><span class="str">        Tensor: The cropped Tensor has same data type with `x`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10132" href="#t10132">10132</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10133" href="#t10133">10133</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10134" href="#t10134">10134</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10135" href="#t10135">10135</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10136" href="#t10136">10136</a></span><span class="t"><span class="str">          :name: code-example1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10137" href="#t10137">10137</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10138" href="#t10138">10138</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10139" href="#t10139">10139</a></span><span class="t"><span class="str">            x = paddle.to_tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10140" href="#t10140">10140</a></span><span class="t"><span class="str">            # x.shape = [3, 3]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10141" href="#t10141">10141</a></span><span class="t"><span class="str">            # x = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10142" href="#t10142">10142</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10143" href="#t10143">10143</a></span><span class="t"><span class="str">            # shape can be a 1-D Tensor or list or tuple.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10144" href="#t10144">10144</a></span><span class="t"><span class="str">            shape = paddle.to_tensor([2, 2], dtype='int32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10145" href="#t10145">10145</a></span><span class="t"><span class="str">            # shape = [2, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10146" href="#t10146">10146</a></span><span class="t"><span class="str">            # shape = (2, 2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10147" href="#t10147">10147</a></span><span class="t"><span class="str">            out = paddle.crop(x, shape)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10148" href="#t10148">10148</a></span><span class="t"><span class="str">            # out.shape = [2, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10149" href="#t10149">10149</a></span><span class="t"><span class="str">            # out = [[1,2], [4,5]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10150" href="#t10150">10150</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10151" href="#t10151">10151</a></span><span class="t"><span class="str">            # offsets can be a 1-D Tensor or list or tuple.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10152" href="#t10152">10152</a></span><span class="t"><span class="str">            offsets = paddle.to_tensor([0, 1], dtype='int32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10153" href="#t10153">10153</a></span><span class="t"><span class="str">            # offsets = [1, 0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10154" href="#t10154">10154</a></span><span class="t"><span class="str">            # offsets = (1, 1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10155" href="#t10155">10155</a></span><span class="t"><span class="str">            out = paddle.crop(x, shape, offsets)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10156" href="#t10156">10156</a></span><span class="t"><span class="str">            # out.shape = [2, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10157" href="#t10157">10157</a></span><span class="t"><span class="str">            # if offsets = [0, 0], out = [[1,2], [4,5]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10158" href="#t10158">10158</a></span><span class="t"><span class="str">            # if offsets = [0, 1], out = [[2,3], [5,6]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10159" href="#t10159">10159</a></span><span class="t"><span class="str">            # if offsets = [1, 0], out = [[4,5], [7,8]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10160" href="#t10160">10160</a></span><span class="t"><span class="str">            # if offsets = [1, 1], out = [[5,6], [8,9]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10161" href="#t10161">10161</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10162" href="#t10162">10162</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10163" href="#t10163">10163</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'crop_tensor'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10164" href="#t10164">10164</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10165" href="#t10165">10165</a></span><span class="t">        <span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'crop_tensor'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10166" href="#t10166">10166</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10167" href="#t10167">10167</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">shape</span><span class="op">,</span> <span class="str">'shape'</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">,</span> <span class="str">'crop_tensor'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10168" href="#t10168">10168</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10169" href="#t10169">10169</a></span><span class="t">        <span class="nam">offsets</span><span class="op">,</span> <span class="str">'offsets'</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">,</span> <span class="nam">type</span><span class="op">(</span><span class="key">None</span><span class="op">)</span><span class="op">)</span><span class="op">,</span> <span class="str">'crop_tensor'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10170" href="#t10170">10170</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10171" href="#t10171">10171</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10172" href="#t10172">10172</a></span><span class="t">    <span class="key">if</span> <span class="nam">offsets</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10173" href="#t10173">10173</a></span><span class="t">        <span class="nam">offsets</span> <span class="op">=</span> <span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">*</span> <span class="nam">len</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10174" href="#t10174">10174</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10175" href="#t10175">10175</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10176" href="#t10176">10176</a></span><span class="t">    <span class="nam">ipts</span> <span class="op">=</span> <span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10177" href="#t10177">10177</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10178" href="#t10178">10178</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10179" href="#t10179">10179</a></span><span class="t">    <span class="key">def</span> <span class="nam">_attr_shape_check</span><span class="op">(</span><span class="nam">shape_val</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10180" href="#t10180">10180</a></span><span class="t">        <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">shape_val</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10181" href="#t10181">10181</a></span><span class="t">            <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10182" href="#t10182">10182</a></span><span class="t">                <span class="str">"Attr(shape)'s dtype of Op(crop_tensor) should be int32, but received: %s."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10183" href="#t10183">10183</a></span><span class="t">                <span class="op">%</span> <span class="nam">type</span><span class="op">(</span><span class="nam">shape_val</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10184" href="#t10184">10184</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10185" href="#t10185">10185</a></span><span class="t">        <span class="key">if</span> <span class="nam">shape_val</span> <span class="op">==</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10186" href="#t10186">10186</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10187" href="#t10187">10187</a></span><span class="t">                <span class="str">"Attr(shape) of Op(crop_tensor) should not be zero, but received: %s."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10188" href="#t10188">10188</a></span><span class="t">                <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">shape_val</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10189" href="#t10189">10189</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10190" href="#t10190">10190</a></span><span class="t">        <span class="key">if</span> <span class="nam">shape_val</span> <span class="op">&lt;</span> <span class="op">-</span><span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10191" href="#t10191">10191</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10192" href="#t10192">10192</a></span><span class="t">                <span class="str">"When the element in Attr(shape) of Op(crop_tensor) is negative, only -1 is supported, but received: %s."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10193" href="#t10193">10193</a></span><span class="t">                <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">shape_val</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10194" href="#t10194">10194</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10195" href="#t10195">10195</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10196" href="#t10196">10196</a></span><span class="t">    <span class="key">def</span> <span class="nam">_attr_offsets_check</span><span class="op">(</span><span class="nam">offset_val</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10197" href="#t10197">10197</a></span><span class="t">        <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">offset_val</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10198" href="#t10198">10198</a></span><span class="t">            <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10199" href="#t10199">10199</a></span><span class="t">                <span class="str">"Attr(offsets)'s dtype of Op(crop_tensor) should be int32, but received: %s."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10200" href="#t10200">10200</a></span><span class="t">                <span class="op">%</span> <span class="nam">type</span><span class="op">(</span><span class="nam">offset_val</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10201" href="#t10201">10201</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10202" href="#t10202">10202</a></span><span class="t">        <span class="key">if</span> <span class="nam">offset_val</span> <span class="op">&lt;</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10203" href="#t10203">10203</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10204" href="#t10204">10204</a></span><span class="t">                <span class="str">"Attr(offsets) of Op(crop_tensor) should be greater or equal to zero, but received: %s."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10205" href="#t10205">10205</a></span><span class="t">                <span class="op">%</span> <span class="nam">str</span><span class="op">(</span><span class="nam">offset_val</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10206" href="#t10206">10206</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10207" href="#t10207">10207</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10208" href="#t10208">10208</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">offsets</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10209" href="#t10209">10209</a></span><span class="t">        <span class="nam">offsets</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10210" href="#t10210">10210</a></span><span class="t">        <span class="nam">ipts</span><span class="op">[</span><span class="str">'Offsets'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">offsets</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10211" href="#t10211">10211</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">'offsets'</span><span class="op">]</span> <span class="op">=</span> <span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span> <span class="op">*</span> <span class="nam">len</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10212" href="#t10212">10212</a></span><span class="t">    <span class="key">elif</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_contain_var</span><span class="op">(</span><span class="nam">offsets</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10213" href="#t10213">10213</a></span><span class="t">        <span class="nam">new_offsets_tensor</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10214" href="#t10214">10214</a></span><span class="t">        <span class="nam">offsets_attr</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10215" href="#t10215">10215</a></span><span class="t">        <span class="key">for</span> <span class="nam">dim</span> <span class="key">in</span> <span class="nam">offsets</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10216" href="#t10216">10216</a></span><span class="t">            <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10217" href="#t10217">10217</a></span><span class="t">                <span class="nam">dim</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10218" href="#t10218">10218</a></span><span class="t">                <span class="nam">new_offsets_tensor</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">dim</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10219" href="#t10219">10219</a></span><span class="t">                <span class="nam">offsets_attr</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="op">-</span><span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10220" href="#t10220">10220</a></span><span class="t">            <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10221" href="#t10221">10221</a></span><span class="t">                <span class="nam">_attr_offsets_check</span><span class="op">(</span><span class="nam">dim</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10222" href="#t10222">10222</a></span><span class="t">                <span class="nam">temp_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="str">'int32'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10223" href="#t10223">10223</a></span><span class="t">                <span class="nam">fill_constant</span><span class="op">(</span><span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="nam">dim</span><span class="op">,</span> <span class="nam">force_cpu</span><span class="op">=</span><span class="key">True</span><span class="op">,</span> <span class="nam">out</span><span class="op">=</span><span class="nam">temp_out</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10224" href="#t10224">10224</a></span><span class="t">                <span class="nam">new_offsets_tensor</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">temp_out</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10225" href="#t10225">10225</a></span><span class="t">                <span class="nam">offsets_attr</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">dim</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10226" href="#t10226">10226</a></span><span class="t">        <span class="nam">ipts</span><span class="op">[</span><span class="str">'OffsetsTensor'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">new_offsets_tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10227" href="#t10227">10227</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">'offsets'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">offsets_attr</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10228" href="#t10228">10228</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10229" href="#t10229">10229</a></span><span class="t">        <span class="key">for</span> <span class="nam">offset</span> <span class="key">in</span> <span class="nam">offsets</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10230" href="#t10230">10230</a></span><span class="t">            <span class="nam">_attr_offsets_check</span><span class="op">(</span><span class="nam">offset</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10231" href="#t10231">10231</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">'offsets'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">offsets</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10232" href="#t10232">10232</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10233" href="#t10233">10233</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">shape</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10234" href="#t10234">10234</a></span><span class="t">        <span class="nam">shape</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10235" href="#t10235">10235</a></span><span class="t">        <span class="nam">ipts</span><span class="op">[</span><span class="str">'Shape'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10236" href="#t10236">10236</a></span><span class="t">    <span class="key">elif</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_contain_var</span><span class="op">(</span><span class="nam">shape</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10237" href="#t10237">10237</a></span><span class="t">        <span class="nam">new_shape_tensor</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10238" href="#t10238">10238</a></span><span class="t">        <span class="nam">shape_attr</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10239" href="#t10239">10239</a></span><span class="t">        <span class="key">for</span> <span class="nam">dim_size</span> <span class="key">in</span> <span class="nam">shape</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10240" href="#t10240">10240</a></span><span class="t">            <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim_size</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10241" href="#t10241">10241</a></span><span class="t">                <span class="nam">dim_size</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10242" href="#t10242">10242</a></span><span class="t">                <span class="nam">new_shape_tensor</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">dim_size</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10243" href="#t10243">10243</a></span><span class="t">                <span class="nam">shape_attr</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="num">0</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10244" href="#t10244">10244</a></span><span class="t">            <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10245" href="#t10245">10245</a></span><span class="t">                <span class="nam">_attr_shape_check</span><span class="op">(</span><span class="nam">dim_size</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10246" href="#t10246">10246</a></span><span class="t">                <span class="nam">temp_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="str">'int32'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10247" href="#t10247">10247</a></span><span class="t">                <span class="nam">fill_constant</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10248" href="#t10248">10248</a></span><span class="t">                    <span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="nam">dim_size</span><span class="op">,</span> <span class="nam">force_cpu</span><span class="op">=</span><span class="key">True</span><span class="op">,</span> <span class="nam">out</span><span class="op">=</span><span class="nam">temp_out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10249" href="#t10249">10249</a></span><span class="t">                <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10250" href="#t10250">10250</a></span><span class="t">                <span class="nam">new_shape_tensor</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">temp_out</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10251" href="#t10251">10251</a></span><span class="t">                <span class="nam">shape_attr</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">dim_size</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10252" href="#t10252">10252</a></span><span class="t">        <span class="nam">ipts</span><span class="op">[</span><span class="str">'ShapeTensor'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">new_shape_tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10253" href="#t10253">10253</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">'shape'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">shape_attr</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10254" href="#t10254">10254</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10255" href="#t10255">10255</a></span><span class="t">        <span class="key">for</span> <span class="nam">dim_size</span> <span class="key">in</span> <span class="nam">shape</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10256" href="#t10256">10256</a></span><span class="t">            <span class="nam">_attr_shape_check</span><span class="op">(</span><span class="nam">dim_size</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10257" href="#t10257">10257</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">'shape'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10258" href="#t10258">10258</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10259" href="#t10259">10259</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10260" href="#t10260">10260</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'crop_tensor'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10261" href="#t10261">10261</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="nam">ipts</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10262" href="#t10262">10262</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10263" href="#t10263">10263</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="key">None</span> <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">attrs</span><span class="op">)</span> <span class="op">==</span> <span class="num">0</span> <span class="key">else</span> <span class="nam">attrs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10264" href="#t10264">10264</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10265" href="#t10265">10265</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10266" href="#t10266">10266</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10267" href="#t10267">10267</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t10268" href="#t10268">10268</a></span><span class="t"><span class="key">def</span> <span class="nam">affine_grid</span><span class="op">(</span><span class="nam">theta</span><span class="op">,</span> <span class="nam">out_shape</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10269" href="#t10269">10269</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10270" href="#t10270">10270</a></span><span class="t"><span class="str">    :alias_main: paddle.nn.functional.affine_grid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10271" href="#t10271">10271</a></span><span class="t"><span class="str">        :alias: paddle.nn.functional.affine_grid,paddle.nn.functional.vision.affine_grid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10272" href="#t10272">10272</a></span><span class="t"><span class="str">        :old_api: paddle.fluid.layers.affine_grid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10273" href="#t10273">10273</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10274" href="#t10274">10274</a></span><span class="t"><span class="str">    It generates a grid of (x,y) coordinates using the parameters of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10275" href="#t10275">10275</a></span><span class="t"><span class="str">    the affine transformation that correspond to a set of points where</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10276" href="#t10276">10276</a></span><span class="t"><span class="str">    the input feature map should be sampled to produce the transformed</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10277" href="#t10277">10277</a></span><span class="t"><span class="str">    output feature map.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10278" href="#t10278">10278</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10279" href="#t10279">10279</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10280" href="#t10280">10280</a></span><span class="t"><span class="str">        theta (Variable) - A Tensor with shape [N, 2, 3]. It contains a batch of affine transform parameters.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10281" href="#t10281">10281</a></span><span class="t"><span class="str">                           The data type can be float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10282" href="#t10282">10282</a></span><span class="t"><span class="str">        out_shape (Variable | list | tuple): The shape of target output with format [batch_size, channel, height, width].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10283" href="#t10283">10283</a></span><span class="t"><span class="str">                                             ``out_shape`` can be a Tensor or a list or tuple. The data</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10284" href="#t10284">10284</a></span><span class="t"><span class="str">                                             type must be int32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10285" href="#t10285">10285</a></span><span class="t"><span class="str">        name(str|None): The default value is None.  Normally there is no need for user to set this property.  For more information, please refer to :ref:`api_guide_Name`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10286" href="#t10286">10286</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10287" href="#t10287">10287</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10288" href="#t10288">10288</a></span><span class="t"><span class="str">        Variable: A Tensor with shape [batch_size, H, W, 2] while 'H' and 'W' are the height and width of feature map in affine transformation. The data type is the same as `theta`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10289" href="#t10289">10289</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10290" href="#t10290">10290</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10291" href="#t10291">10291</a></span><span class="t"><span class="str">        ValueError: If the type of arguments is not supported.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10292" href="#t10292">10292</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10293" href="#t10293">10293</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10294" href="#t10294">10294</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10295" href="#t10295">10295</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10296" href="#t10296">10296</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10297" href="#t10297">10297</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10298" href="#t10298">10298</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10299" href="#t10299">10299</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10300" href="#t10300">10300</a></span><span class="t"><span class="str">            theta = fluid.data(name="x", shape=[None, 2, 3], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10301" href="#t10301">10301</a></span><span class="t"><span class="str">            out_shape = fluid.data(name="y", shape=[4], dtype="int32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10302" href="#t10302">10302</a></span><span class="t"><span class="str">            grid_0 = fluid.layers.affine_grid(theta, out_shape)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10303" href="#t10303">10303</a></span><span class="t"><span class="str">            grid_1 = fluid.layers.affine_grid(theta, [5, 3, 28, 28])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10304" href="#t10304">10304</a></span><span class="t"><span class="str">            batch_size=2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10305" href="#t10305">10305</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10306" href="#t10306">10306</a></span><span class="t"><span class="str">            exe.run(fluid.default_startup_program())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10307" href="#t10307">10307</a></span><span class="t"><span class="str">            output= exe.run(feed={"x": np.random.rand(batch_size,2,3).astype("float32"),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10308" href="#t10308">10308</a></span><span class="t"><span class="str">                                  "y": np.array([5, 3, 28, 28]).astype("int32")},</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10309" href="#t10309">10309</a></span><span class="t"><span class="str">                                  fetch_list=[grid_0.name, grid_1.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10310" href="#t10310">10310</a></span><span class="t"><span class="str">            print(output[0])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10311" href="#t10311">10311</a></span><span class="t"><span class="str">            print(output[1])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10312" href="#t10312">10312</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10313" href="#t10313">10313</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'affine_grid'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10314" href="#t10314">10314</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10315" href="#t10315">10315</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10316" href="#t10316">10316</a></span><span class="t">        <span class="nam">theta</span><span class="op">,</span> <span class="str">'theta'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'affine_grid'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10317" href="#t10317">10317</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10318" href="#t10318">10318</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10319" href="#t10319">10319</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10320" href="#t10320">10320</a></span><span class="t">        <span class="nam">isinstance</span><span class="op">(</span><span class="nam">out_shape</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10321" href="#t10321">10321</a></span><span class="t">        <span class="key">or</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">out_shape</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10322" href="#t10322">10322</a></span><span class="t">        <span class="key">or</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">out_shape</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10323" href="#t10323">10323</a></span><span class="t">    <span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10324" href="#t10324">10324</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"The out_shape should be a list, tuple or Variable."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10325" href="#t10325">10325</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10326" href="#t10326">10326</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">theta</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10327" href="#t10327">10327</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"The theta should be a Variable."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10328" href="#t10328">10328</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10329" href="#t10329">10329</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">theta</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10330" href="#t10330">10330</a></span><span class="t">    <span class="nam">ipts</span> <span class="op">=</span> <span class="op">{</span><span class="str">'Theta'</span><span class="op">:</span> <span class="nam">theta</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10331" href="#t10331">10331</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10332" href="#t10332">10332</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">out_shape</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10333" href="#t10333">10333</a></span><span class="t">        <span class="nam">ipts</span><span class="op">[</span><span class="str">'OutputShape'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">out_shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10334" href="#t10334">10334</a></span><span class="t">        <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10335" href="#t10335">10335</a></span><span class="t">            <span class="nam">out_shape</span><span class="op">,</span> <span class="str">'out_shape'</span><span class="op">,</span> <span class="op">[</span><span class="str">'int32'</span><span class="op">]</span><span class="op">,</span> <span class="str">'affine_grid'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10336" href="#t10336">10336</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10337" href="#t10337">10337</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10338" href="#t10338">10338</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">'output_shape'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">out_shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10339" href="#t10339">10339</a></span><span class="t">    <span class="key">if</span> <span class="nam">core</span><span class="op">.</span><span class="nam">is_compiled_with_rocm</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10340" href="#t10340">10340</a></span><span class="t">        <span class="com"># ROCM platform do not have MIOPEN kernel for affine_grid</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10341" href="#t10341">10341</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">'use_cudnn'</span><span class="op">]</span> <span class="op">=</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10342" href="#t10342">10342</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10343" href="#t10343">10343</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10344" href="#t10344">10344</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'affine_grid'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10345" href="#t10345">10345</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="nam">ipts</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10346" href="#t10346">10346</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Output'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10347" href="#t10347">10347</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="key">None</span> <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">attrs</span><span class="op">)</span> <span class="op">==</span> <span class="num">0</span> <span class="key">else</span> <span class="nam">attrs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10348" href="#t10348">10348</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10349" href="#t10349">10349</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10350" href="#t10350">10350</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10351" href="#t10351">10351</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t10352" href="#t10352">10352</a></span><span class="t"><span class="key">def</span> <span class="nam">pad2d</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10353" href="#t10353">10353</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10354" href="#t10354">10354</a></span><span class="t">    <span class="nam">paddings</span><span class="op">=</span><span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10355" href="#t10355">10355</a></span><span class="t">    <span class="nam">mode</span><span class="op">=</span><span class="str">'constant'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10356" href="#t10356">10356</a></span><span class="t">    <span class="nam">pad_value</span><span class="op">=</span><span class="num">0.0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10357" href="#t10357">10357</a></span><span class="t">    <span class="nam">data_format</span><span class="op">=</span><span class="str">"NCHW"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10358" href="#t10358">10358</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10359" href="#t10359">10359</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10360" href="#t10360">10360</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10361" href="#t10361">10361</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10362" href="#t10362">10362</a></span><span class="t"><span class="str">    Pad 2-d images according to 'paddings' and 'mode'.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10363" href="#t10363">10363</a></span><span class="t"><span class="str">    If mode is 'reflect', paddings[0] and paddings[1] must be no greater</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10364" href="#t10364">10364</a></span><span class="t"><span class="str">    than height-1. And the width dimension has the same condition.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10365" href="#t10365">10365</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10366" href="#t10366">10366</a></span><span class="t"><span class="str">    Parameters:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10367" href="#t10367">10367</a></span><span class="t"><span class="str">        input (Tensor): The input image with [N, C, H, W] format or [N, H, W, C] format, which is a 4-D Tensor with data type float32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10368" href="#t10368">10368</a></span><span class="t"><span class="str">        paddings (Tensor | List[int32]): The padding size. If padding is a List, it must</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10369" href="#t10369">10369</a></span><span class="t"><span class="str">            contain four integers, (padding_top, padding_bottom, padding_left, padding_right).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10370" href="#t10370">10370</a></span><span class="t"><span class="str">            Otherwise, it is a 1-D Tensor with shape [4]. Data type is int32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10371" href="#t10371">10371</a></span><span class="t"><span class="str">            Default is [0, 0, 0, 0].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10372" href="#t10372">10372</a></span><span class="t"><span class="str">        mode (str): Three modes: 'constant' (default), 'reflect', 'edge' .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10373" href="#t10373">10373</a></span><span class="t"><span class="str">                When in 'constant' mode, this op uses a constant value to pad the input tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10374" href="#t10374">10374</a></span><span class="t"><span class="str">                When in 'reflect' mode, uses reflection of the input boundaries to pad the input tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10375" href="#t10375">10375</a></span><span class="t"><span class="str">                When in 'edge' mode, uses input boundaries to pad the input tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10376" href="#t10376">10376</a></span><span class="t"><span class="str">                Default is 'constant'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10377" href="#t10377">10377</a></span><span class="t"><span class="str">        pad_value (float32): The value to fill the padded areas in 'constant' mode . Default is 0.0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10378" href="#t10378">10378</a></span><span class="t"><span class="str">        data_format (str): An string from: "NHWC", "NCHW". Specify the data format of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10379" href="#t10379">10379</a></span><span class="t"><span class="str">                           the input data.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10380" href="#t10380">10380</a></span><span class="t"><span class="str">                           Default is  "NCHW"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10381" href="#t10381">10381</a></span><span class="t"><span class="str">        name (str, optional) : The default value is None.  Normally there is no need for</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10382" href="#t10382">10382</a></span><span class="t"><span class="str">                    user to set this property.  For more information, please refer to :ref:`api_guide_Name` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10383" href="#t10383">10383</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10384" href="#t10384">10384</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10385" href="#t10385">10385</a></span><span class="t"><span class="str">        Tensor, a 4-D Tensor padded according to paddings and mode and data type is same as input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10386" href="#t10386">10386</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10387" href="#t10387">10387</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10388" href="#t10388">10388</a></span><span class="t"><span class="str">        .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10389" href="#t10389">10389</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10390" href="#t10390">10390</a></span><span class="t"><span class="str">            Input = [[[[1., 2., 3.],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10391" href="#t10391">10391</a></span><span class="t"><span class="str">                       [4., 5., 6.]]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10392" href="#t10392">10392</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10393" href="#t10393">10393</a></span><span class="t"><span class="str">            Case 0:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10394" href="#t10394">10394</a></span><span class="t"><span class="str">                paddings = [0, 1, 2, 3],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10395" href="#t10395">10395</a></span><span class="t"><span class="str">                mode = 'constant'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10396" href="#t10396">10396</a></span><span class="t"><span class="str">                pad_value = 0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10397" href="#t10397">10397</a></span><span class="t"><span class="str">                Out = [[[[0., 0., 1., 2., 3., 0., 0., 0.],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10398" href="#t10398">10398</a></span><span class="t"><span class="str">                         [0., 0., 4., 5., 6., 0., 0., 0.],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10399" href="#t10399">10399</a></span><span class="t"><span class="str">                         [0., 0., 0., 0., 0., 0., 0., 0.]]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10400" href="#t10400">10400</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10401" href="#t10401">10401</a></span><span class="t"><span class="str">            Case 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10402" href="#t10402">10402</a></span><span class="t"><span class="str">                paddings = [0, 1, 2, 1],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10403" href="#t10403">10403</a></span><span class="t"><span class="str">                mode = 'reflect'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10404" href="#t10404">10404</a></span><span class="t"><span class="str">                Out = [[[[3., 2., 1., 2., 3., 2.],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10405" href="#t10405">10405</a></span><span class="t"><span class="str">                         [6., 5., 4., 5., 6., 5.],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10406" href="#t10406">10406</a></span><span class="t"><span class="str">                         [3., 2., 1., 2., 3., 2.]]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10407" href="#t10407">10407</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10408" href="#t10408">10408</a></span><span class="t"><span class="str">            Case 2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10409" href="#t10409">10409</a></span><span class="t"><span class="str">                paddings = [0, 1, 2, 1],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10410" href="#t10410">10410</a></span><span class="t"><span class="str">                mode = 'edge'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10411" href="#t10411">10411</a></span><span class="t"><span class="str">                Out = [[[[1., 1., 1., 2., 3., 3.],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10412" href="#t10412">10412</a></span><span class="t"><span class="str">                         [4., 4., 4., 5., 6., 6.],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10413" href="#t10413">10413</a></span><span class="t"><span class="str">                         [4., 4., 4., 5., 6., 6.]]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10414" href="#t10414">10414</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10415" href="#t10415">10415</a></span><span class="t"><span class="str">    Code Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10416" href="#t10416">10416</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10417" href="#t10417">10417</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10418" href="#t10418">10418</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10419" href="#t10419">10419</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10420" href="#t10420">10420</a></span><span class="t"><span class="str">            import paddle.nn.functional as F</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10421" href="#t10421">10421</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10422" href="#t10422">10422</a></span><span class="t"><span class="str">            # example 1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10423" href="#t10423">10423</a></span><span class="t"><span class="str">            x_shape = (1, 1, 3, 4)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10424" href="#t10424">10424</a></span><span class="t"><span class="str">            x = np.arange(np.prod(x_shape), dtype=np.float32).reshape(x_shape) + 1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10425" href="#t10425">10425</a></span><span class="t"><span class="str">            tensor_x = paddle.to_tensor(x)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10426" href="#t10426">10426</a></span><span class="t"><span class="str">            y = paddle.fluid.layers.pad2d(tensor_x, paddings=[1, 2, 2, 1], pad_value=1, mode='constant')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10427" href="#t10427">10427</a></span><span class="t"><span class="str">            print(y.numpy())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10428" href="#t10428">10428</a></span><span class="t"><span class="str">            # [[[[ 1.  1.  1.  1.  1.  1.  1.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10429" href="#t10429">10429</a></span><span class="t"><span class="str">            #    [ 1.  1.  1.  2.  3.  4.  1.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10430" href="#t10430">10430</a></span><span class="t"><span class="str">            #    [ 1.  1.  5.  6.  7.  8.  1.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10431" href="#t10431">10431</a></span><span class="t"><span class="str">            #    [ 1.  1.  9. 10. 11. 12.  1.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10432" href="#t10432">10432</a></span><span class="t"><span class="str">            #    [ 1.  1.  1.  1.  1.  1.  1.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10433" href="#t10433">10433</a></span><span class="t"><span class="str">            #    [ 1.  1.  1.  1.  1.  1.  1.]]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10434" href="#t10434">10434</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10435" href="#t10435">10435</a></span><span class="t"><span class="str">            # example 2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10436" href="#t10436">10436</a></span><span class="t"><span class="str">            x_shape = (1, 1, 2, 3)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10437" href="#t10437">10437</a></span><span class="t"><span class="str">            x = np.arange(np.prod(x_shape), dtype=np.float32).reshape(x_shape) + 1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10438" href="#t10438">10438</a></span><span class="t"><span class="str">            tensor_x = paddle.to_tensor(x)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10439" href="#t10439">10439</a></span><span class="t"><span class="str">            y = paddle.fluid.layers.pad2d(tensor_x, paddings=[1, 1, 1, 1], mode='reflect')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10440" href="#t10440">10440</a></span><span class="t"><span class="str">            print(y.numpy())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10441" href="#t10441">10441</a></span><span class="t"><span class="str">            # [[[[5. 4. 5. 6. 5.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10442" href="#t10442">10442</a></span><span class="t"><span class="str">            #    [2. 1. 2. 3. 2.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10443" href="#t10443">10443</a></span><span class="t"><span class="str">            #    [5. 4. 5. 6. 5.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10444" href="#t10444">10444</a></span><span class="t"><span class="str">            #    [2. 1. 2. 3. 2.]]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10445" href="#t10445">10445</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10446" href="#t10446">10446</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10447" href="#t10447">10447</a></span><span class="t">        <span class="nam">_paddings</span> <span class="op">=</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10448" href="#t10448">10448</a></span><span class="t">            <span class="nam">paddings</span><span class="op">.</span><span class="nam">numpy</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">tolist</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10449" href="#t10449">10449</a></span><span class="t">            <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">paddings</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10450" href="#t10450">10450</a></span><span class="t">            <span class="key">else</span> <span class="nam">paddings</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10451" href="#t10451">10451</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10452" href="#t10452">10452</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">pad2d</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10453" href="#t10453">10453</a></span><span class="t">            <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10454" href="#t10454">10454</a></span><span class="t">            <span class="str">'mode'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10455" href="#t10455">10455</a></span><span class="t">            <span class="nam">mode</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10456" href="#t10456">10456</a></span><span class="t">            <span class="str">'pad_value'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10457" href="#t10457">10457</a></span><span class="t">            <span class="nam">pad_value</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10458" href="#t10458">10458</a></span><span class="t">            <span class="str">'data_format'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10459" href="#t10459">10459</a></span><span class="t">            <span class="nam">data_format</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10460" href="#t10460">10460</a></span><span class="t">            <span class="str">'paddings'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10461" href="#t10461">10461</a></span><span class="t">            <span class="nam">_paddings</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10462" href="#t10462">10462</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10463" href="#t10463">10463</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10464" href="#t10464">10464</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10465" href="#t10465">10465</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10466" href="#t10466">10466</a></span><span class="t">        <span class="str">'input'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10467" href="#t10467">10467</a></span><span class="t">        <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10468" href="#t10468">10468</a></span><span class="t">        <span class="str">"pad2d"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10469" href="#t10469">10469</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10470" href="#t10470">10470</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10471" href="#t10471">10471</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'mode'</span><span class="op">:</span> <span class="nam">mode</span><span class="op">,</span> <span class="str">'pad_value'</span><span class="op">:</span> <span class="nam">pad_value</span><span class="op">,</span> <span class="str">'data_format'</span><span class="op">:</span> <span class="nam">data_format</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10472" href="#t10472">10472</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="op">[</span><span class="nam">input</span><span class="op">]</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10473" href="#t10473">10473</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">paddings</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10474" href="#t10474">10474</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">'Paddings'</span><span class="op">]</span> <span class="op">=</span> <span class="op">[</span><span class="nam">paddings</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10475" href="#t10475">10475</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">'paddings'</span><span class="op">]</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10476" href="#t10476">10476</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10477" href="#t10477">10477</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">'paddings'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">paddings</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10478" href="#t10478">10478</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10479" href="#t10479">10479</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'pad2d'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10480" href="#t10480">10480</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10481" href="#t10481">10481</a></span><span class="t">    <span class="key">assert</span> <span class="nam">mode</span> <span class="key">in</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10482" href="#t10482">10482</a></span><span class="t">        <span class="str">'reflect'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10483" href="#t10483">10483</a></span><span class="t">        <span class="str">'edge'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10484" href="#t10484">10484</a></span><span class="t">        <span class="str">'constant'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10485" href="#t10485">10485</a></span><span class="t">    <span class="op">]</span><span class="op">,</span> <span class="str">"mode should be one of constant, reflect, edge."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10486" href="#t10486">10486</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10487" href="#t10487">10487</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="nam">input_param_name</span><span class="op">=</span><span class="str">'input'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10488" href="#t10488">10488</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10489" href="#t10489">10489</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10490" href="#t10490">10490</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10491" href="#t10491">10491</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'pad2d'</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span> <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10492" href="#t10492">10492</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10493" href="#t10493">10493</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10494" href="#t10494">10494</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10495" href="#t10495">10495</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10496" href="#t10496">10496</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t10497" href="#t10497">10497</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.nn.functional.elu"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t10498" href="#t10498">10498</a></span><span class="t"><span class="key">def</span> <span class="nam">elu</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">alpha</span><span class="op">=</span><span class="num">1.0</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10499" href="#t10499">10499</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10500" href="#t10500">10500</a></span><span class="t"><span class="str">    :alias_main: paddle.nn.functional.elu</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10501" href="#t10501">10501</a></span><span class="t"><span class="str">        :alias: paddle.nn.functional.elu,paddle.nn.functional.activation.elu</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10502" href="#t10502">10502</a></span><span class="t"><span class="str">        :old_api: paddle.fluid.layers.elu</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10503" href="#t10503">10503</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10504" href="#t10504">10504</a></span><span class="t"><span class="str">    ${comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10505" href="#t10505">10505</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10506" href="#t10506">10506</a></span><span class="t"><span class="str">        x(${x_type}): ${x_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10507" href="#t10507">10507</a></span><span class="t"><span class="str">        alpha(${alpha_type}|1.0): ${alpha_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10508" href="#t10508">10508</a></span><span class="t"><span class="str">        name(str|None): The default value is None. Normally there is no need for user to set this property.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10509" href="#t10509">10509</a></span><span class="t"><span class="str">                        For more information, please refer to :ref:`api_guide_Name`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10510" href="#t10510">10510</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10511" href="#t10511">10511</a></span><span class="t"><span class="str">        ${out_type}: ${out_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10512" href="#t10512">10512</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10513" href="#t10513">10513</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10514" href="#t10514">10514</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10515" href="#t10515">10515</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10516" href="#t10516">10516</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10517" href="#t10517">10517</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10518" href="#t10518">10518</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10519" href="#t10519">10519</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10520" href="#t10520">10520</a></span><span class="t"><span class="str">            input_elu = np.array([[-1,6],[1,15.6]])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10521" href="#t10521">10521</a></span><span class="t"><span class="str">            with fluid.dygraph.guard():</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10522" href="#t10522">10522</a></span><span class="t"><span class="str">                x = fluid.dygraph.to_variable(input_elu)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10523" href="#t10523">10523</a></span><span class="t"><span class="str">                y = fluid.layers.elu(x, alpha=0.2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10524" href="#t10524">10524</a></span><span class="t"><span class="str">                print(y.numpy())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10525" href="#t10525">10525</a></span><span class="t"><span class="str">                # [[-0.12642411  6.        ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10526" href="#t10526">10526</a></span><span class="t"><span class="str">                # [ 1.          15.6       ]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10527" href="#t10527">10527</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10528" href="#t10528">10528</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'elu'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10529" href="#t10529">10529</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'elu'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10530" href="#t10530">10530</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10531" href="#t10531">10531</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10532" href="#t10532">10532</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'elu'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10533" href="#t10533">10533</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10534" href="#t10534">10534</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10535" href="#t10535">10535</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'alpha'</span><span class="op">:</span> <span class="nam">alpha</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10536" href="#t10536">10536</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10537" href="#t10537">10537</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10538" href="#t10538">10538</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10539" href="#t10539">10539</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t10540" href="#t10540">10540</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.nn.functional.relu6"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t10541" href="#t10541">10541</a></span><span class="t"><span class="key">def</span> <span class="nam">relu6</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">threshold</span><span class="op">=</span><span class="num">6.0</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10542" href="#t10542">10542</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10543" href="#t10543">10543</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10544" href="#t10544">10544</a></span><span class="t"><span class="str">    ${comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10545" href="#t10545">10545</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10546" href="#t10546">10546</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10547" href="#t10547">10547</a></span><span class="t"><span class="str">        x(${x_type}): ${x_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10548" href="#t10548">10548</a></span><span class="t"><span class="str">        threshold(float, optional): ${threshold_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10549" href="#t10549">10549</a></span><span class="t"><span class="str">        name(str, optional): The default value is None. Normally there is no</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10550" href="#t10550">10550</a></span><span class="t"><span class="str">            need for user to set this property. For more information, please</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10551" href="#t10551">10551</a></span><span class="t"><span class="str">            refer to :ref:`api_guide_Name`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10552" href="#t10552">10552</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10553" href="#t10553">10553</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10554" href="#t10554">10554</a></span><span class="t"><span class="str">        output(${out_type}): ${out_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10555" href="#t10555">10555</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10556" href="#t10556">10556</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10557" href="#t10557">10557</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10558" href="#t10558">10558</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10559" href="#t10559">10559</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10560" href="#t10560">10560</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10561" href="#t10561">10561</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10562" href="#t10562">10562</a></span><span class="t"><span class="str">            in1 = np.array([[-1,0],[2.5,7.8]])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10563" href="#t10563">10563</a></span><span class="t"><span class="str">            with fluid.dygraph.guard():</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10564" href="#t10564">10564</a></span><span class="t"><span class="str">                x1 = fluid.dygraph.to_variable(in1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10565" href="#t10565">10565</a></span><span class="t"><span class="str">                out1 = fluid.layers.relu6(x=x1, threshold=6.0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10566" href="#t10566">10566</a></span><span class="t"><span class="str">                print(out1.numpy())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10567" href="#t10567">10567</a></span><span class="t"><span class="str">                # [[0.  0. ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10568" href="#t10568">10568</a></span><span class="t"><span class="str">                #  [2.5 6. ]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10569" href="#t10569">10569</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10570" href="#t10570">10570</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'relu6'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10571" href="#t10571">10571</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10572" href="#t10572">10572</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'relu6'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10573" href="#t10573">10573</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10574" href="#t10574">10574</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10575" href="#t10575">10575</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'relu6'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10576" href="#t10576">10576</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10577" href="#t10577">10577</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10578" href="#t10578">10578</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10579" href="#t10579">10579</a></span><span class="t">            <span class="str">'threshold'</span><span class="op">:</span> <span class="nam">threshold</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10580" href="#t10580">10580</a></span><span class="t">            <span class="str">'use_mkldnn'</span><span class="op">:</span> <span class="nam">_global_flags</span><span class="op">(</span><span class="op">)</span><span class="op">[</span><span class="str">"FLAGS_use_mkldnn"</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10581" href="#t10581">10581</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10582" href="#t10582">10582</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10583" href="#t10583">10583</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10584" href="#t10584">10584</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10585" href="#t10585">10585</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t10586" href="#t10586">10586</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t10587" href="#t10587">10587</a></span><span class="t"><span class="key">def</span> <span class="nam">pow</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">factor</span><span class="op">=</span><span class="num">1.0</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10588" href="#t10588">10588</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10589" href="#t10589">10589</a></span><span class="t"><span class="str">    This is Pow Activation Operator.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10590" href="#t10590">10590</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10591" href="#t10591">10591</a></span><span class="t"><span class="str">    :math:`out = x^{factor}`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10592" href="#t10592">10592</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10593" href="#t10593">10593</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10594" href="#t10594">10594</a></span><span class="t"><span class="str">        x(Variable): A ``Tensor`` or ``LoDTensor`` . The data type is ``float32`` or ``float64``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10595" href="#t10595">10595</a></span><span class="t"><span class="str">        factor(float32|Variable, optional): A scalar with type ``float32`` or a ``Tensor`` with shape [1] and type ``float32``.  The exponential factor of Pow. Default 1.0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10596" href="#t10596">10596</a></span><span class="t"><span class="str">        name(str, optional): The default value is None. Normally there is no need for user to set this property. For more information, please refer to :ref:`api_guide_Name` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10597" href="#t10597">10597</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10598" href="#t10598">10598</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10599" href="#t10599">10599</a></span><span class="t"><span class="str">        Variable: A ``Tensor`` or ``LoDTensor``. The data type is same as ``x``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10600" href="#t10600">10600</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10601" href="#t10601">10601</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10602" href="#t10602">10602</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10603" href="#t10603">10603</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10604" href="#t10604">10604</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10605" href="#t10605">10605</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10606" href="#t10606">10606</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10607" href="#t10607">10607</a></span><span class="t"><span class="str">            x = fluid.data(name="x", shape=[32,32], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10608" href="#t10608">10608</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10609" href="#t10609">10609</a></span><span class="t"><span class="str">            # example 1: argument factor is float</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10610" href="#t10610">10610</a></span><span class="t"><span class="str">            y_1 = fluid.layers.pow(x, factor=2.0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10611" href="#t10611">10611</a></span><span class="t"><span class="str">            # y_1 is x^{2.0}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10612" href="#t10612">10612</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10613" href="#t10613">10613</a></span><span class="t"><span class="str">            # example 2: argument factor is Variable</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10614" href="#t10614">10614</a></span><span class="t"><span class="str">            factor_tensor = fluid.layers.fill_constant([1], "float32", 3.0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10615" href="#t10615">10615</a></span><span class="t"><span class="str">            y_2 = fluid.layers.pow(x, factor=factor_tensor)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10616" href="#t10616">10616</a></span><span class="t"><span class="str">            # y_2 is x^{3.0}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10617" href="#t10617">10617</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10618" href="#t10618">10618</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10619" href="#t10619">10619</a></span><span class="t">        <span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">,</span> <span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'pow'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10620" href="#t10620">10620</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10621" href="#t10621">10621</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10622" href="#t10622">10622</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'pow'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10623" href="#t10623">10623</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10624" href="#t10624">10624</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10625" href="#t10625">10625</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">factor</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10626" href="#t10626">10626</a></span><span class="t">        <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">factor</span><span class="op">,</span> <span class="str">'factor'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">]</span><span class="op">,</span> <span class="str">'pow'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10627" href="#t10627">10627</a></span><span class="t">        <span class="nam">factor</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10628" href="#t10628">10628</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">'FactorTensor'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">factor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10629" href="#t10629">10629</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10630" href="#t10630">10630</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">'factor'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">factor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10631" href="#t10631">10631</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10632" href="#t10632">10632</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10633" href="#t10633">10633</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10634" href="#t10634">10634</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'pow'</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span> <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10635" href="#t10635">10635</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10636" href="#t10636">10636</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10637" href="#t10637">10637</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10638" href="#t10638">10638</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t10639" href="#t10639">10639</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t10640" href="#t10640">10640</a></span><span class="t"><span class="key">def</span> <span class="nam">stanh</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">scale_a</span><span class="op">=</span><span class="num">0.67</span><span class="op">,</span> <span class="nam">scale_b</span><span class="op">=</span><span class="num">1.7159</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10641" href="#t10641">10641</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10642" href="#t10642">10642</a></span><span class="t"><span class="str">    stanh activation.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10643" href="#t10643">10643</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10644" href="#t10644">10644</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10645" href="#t10645">10645</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10646" href="#t10646">10646</a></span><span class="t"><span class="str">        out = b * \\frac{e^{a * x} - e^{-a * x}}{e^{a * x} + e^{-a * x}}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10647" href="#t10647">10647</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10648" href="#t10648">10648</a></span><span class="t"><span class="str">    Parameters:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10649" href="#t10649">10649</a></span><span class="t"><span class="str">        x (Tensor): The input Tensor with data type float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10650" href="#t10650">10650</a></span><span class="t"><span class="str">        scale_a (float, optional): The scale factor a of the input. Default is 0.67.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10651" href="#t10651">10651</a></span><span class="t"><span class="str">        scale_b (float, optional): The scale factor b of the output. Default is 1.7159.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10652" href="#t10652">10652</a></span><span class="t"><span class="str">        name (str, optional): Name for the operation (optional, default is None).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10653" href="#t10653">10653</a></span><span class="t"><span class="str">            For more information, please refer to :ref:`api_guide_Name`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10654" href="#t10654">10654</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10655" href="#t10655">10655</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10656" href="#t10656">10656</a></span><span class="t"><span class="str">        A Tensor with the same data type and shape as ``x`` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10657" href="#t10657">10657</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10658" href="#t10658">10658</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10659" href="#t10659">10659</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10660" href="#t10660">10660</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10661" href="#t10661">10661</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10662" href="#t10662">10662</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10663" href="#t10663">10663</a></span><span class="t"><span class="str">            x = paddle.to_tensor([1.0, 2.0, 3.0, 4.0])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10664" href="#t10664">10664</a></span><span class="t"><span class="str">            out = paddle.stanh(x, scale_a=0.67, scale_b=1.72) # [1.00616539, 1.49927628, 1.65933108, 1.70390463]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10665" href="#t10665">10665</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10666" href="#t10666">10666</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10667" href="#t10667">10667</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10668" href="#t10668">10668</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10669" href="#t10669">10669</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">stanh</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'scale_a'</span><span class="op">,</span> <span class="nam">scale_a</span><span class="op">,</span> <span class="str">'scale_b'</span><span class="op">,</span> <span class="nam">scale_b</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10670" href="#t10670">10670</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10671" href="#t10671">10671</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'stanh'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10672" href="#t10672">10672</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10673" href="#t10673">10673</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'stanh'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10674" href="#t10674">10674</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10675" href="#t10675">10675</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10676" href="#t10676">10676</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'stanh'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10677" href="#t10677">10677</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10678" href="#t10678">10678</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10679" href="#t10679">10679</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'scale_a'</span><span class="op">:</span> <span class="nam">scale_a</span><span class="op">,</span> <span class="str">'scale_b'</span><span class="op">:</span> <span class="nam">scale_b</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10680" href="#t10680">10680</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10681" href="#t10681">10681</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10682" href="#t10682">10682</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10683" href="#t10683">10683</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t10684" href="#t10684">10684</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t10685" href="#t10685">10685</a></span><span class="t"><span class="key">def</span> <span class="nam">hard_sigmoid</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">slope</span><span class="op">=</span><span class="num">0.2</span><span class="op">,</span> <span class="nam">offset</span><span class="op">=</span><span class="num">0.5</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10686" href="#t10686">10686</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10687" href="#t10687">10687</a></span><span class="t"><span class="str">    ${comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10688" href="#t10688">10688</a></span><span class="t"><span class="str">    Parameters:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10689" href="#t10689">10689</a></span><span class="t"><span class="str">        x (${x_type}): ${x_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10690" href="#t10690">10690</a></span><span class="t"><span class="str">        slope (float, optional): ${slope_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10691" href="#t10691">10691</a></span><span class="t"><span class="str">        offset (float, optional): ${offset_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10692" href="#t10692">10692</a></span><span class="t"><span class="str">        name (str, optional): The default value is None. Normally there is no</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10693" href="#t10693">10693</a></span><span class="t"><span class="str">            need for user to set this property. For more information, please</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10694" href="#t10694">10694</a></span><span class="t"><span class="str">            refer to :ref:`api_guide_Name`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10695" href="#t10695">10695</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10696" href="#t10696">10696</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10697" href="#t10697">10697</a></span><span class="t"><span class="str">        ${out_type}: ${out_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10698" href="#t10698">10698</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10699" href="#t10699">10699</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10700" href="#t10700">10700</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10701" href="#t10701">10701</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10702" href="#t10702">10702</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10703" href="#t10703">10703</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10704" href="#t10704">10704</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10705" href="#t10705">10705</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10706" href="#t10706">10706</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10707" href="#t10707">10707</a></span><span class="t"><span class="str">            data = fluid.layers.fill_constant(shape=[3, 2], value=0.5, dtype='float32') # [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10708" href="#t10708">10708</a></span><span class="t"><span class="str">            result = fluid.layers.hard_sigmoid(data) # [[0.6, 0.6], [0.6, 0.6], [0.6, 0.6]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10709" href="#t10709">10709</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10710" href="#t10710">10710</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10711" href="#t10711">10711</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">hard_sigmoid</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'slope'</span><span class="op">,</span> <span class="nam">slope</span><span class="op">,</span> <span class="str">'offset'</span><span class="op">,</span> <span class="nam">offset</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10712" href="#t10712">10712</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10713" href="#t10713">10713</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10714" href="#t10714">10714</a></span><span class="t">        <span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'hard_sigmoid'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10715" href="#t10715">10715</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10716" href="#t10716">10716</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10717" href="#t10717">10717</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'hard_sigmoid'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10718" href="#t10718">10718</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10719" href="#t10719">10719</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10720" href="#t10720">10720</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'hard_sigmoid'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10721" href="#t10721">10721</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10722" href="#t10722">10722</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10723" href="#t10723">10723</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'slope'</span><span class="op">:</span> <span class="nam">slope</span><span class="op">,</span> <span class="str">'offset'</span><span class="op">:</span> <span class="nam">offset</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10724" href="#t10724">10724</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10725" href="#t10725">10725</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10726" href="#t10726">10726</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10727" href="#t10727">10727</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t10728" href="#t10728">10728</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t10729" href="#t10729">10729</a></span><span class="t"><span class="key">def</span> <span class="nam">swish</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">beta</span><span class="op">=</span><span class="num">1.0</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10730" href="#t10730">10730</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10731" href="#t10731">10731</a></span><span class="t"><span class="str">    :alias_main: paddle.nn.functional.swish</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10732" href="#t10732">10732</a></span><span class="t"><span class="str">        :alias: paddle.nn.functional.swish,paddle.nn.functional.activation.swish</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10733" href="#t10733">10733</a></span><span class="t"><span class="str">        :old_api: paddle.fluid.layers.swish</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10734" href="#t10734">10734</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10735" href="#t10735">10735</a></span><span class="t"><span class="str">    Elementwise swish activation function. See `Searching for Activation Functions &lt;https://arxiv.org/abs/1710.05941>`_ for more details.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10736" href="#t10736">10736</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10737" href="#t10737">10737</a></span><span class="t"><span class="str">    Equation:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10738" href="#t10738">10738</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10739" href="#t10739">10739</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10740" href="#t10740">10740</a></span><span class="t"><span class="str">        out = \\frac{x}{1 + e^{- beta * x}}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10741" href="#t10741">10741</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10742" href="#t10742">10742</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10743" href="#t10743">10743</a></span><span class="t"><span class="str">        x(Variable): Tensor or LoDTensor, dtype: float32 or float64, the input of swish activation.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10744" href="#t10744">10744</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10745" href="#t10745">10745</a></span><span class="t"><span class="str">        beta(float): Constant beta of swish operator, default 1.0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10746" href="#t10746">10746</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10747" href="#t10747">10747</a></span><span class="t"><span class="str">        name(str, optional): The default value is None. Normally there is no need for user to set this property. For more information, please refer to :ref:`api_guide_Name`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10748" href="#t10748">10748</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10749" href="#t10749">10749</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10750" href="#t10750">10750</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10751" href="#t10751">10751</a></span><span class="t"><span class="str">        Variable: Output of the swish activation, Tensor or LoDTensor, with the same dtype and shape with the input x.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10752" href="#t10752">10752</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10753" href="#t10753">10753</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10754" href="#t10754">10754</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10755" href="#t10755">10755</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10756" href="#t10756">10756</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10757" href="#t10757">10757</a></span><span class="t"><span class="str">            # declarative mode</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10758" href="#t10758">10758</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10759" href="#t10759">10759</a></span><span class="t"><span class="str">            from paddle import fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10760" href="#t10760">10760</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10761" href="#t10761">10761</a></span><span class="t"><span class="str">            x = fluid.data(name="x", shape=(-1, 3), dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10762" href="#t10762">10762</a></span><span class="t"><span class="str">            y = fluid.layers.swish(x, beta=2.0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10763" href="#t10763">10763</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10764" href="#t10764">10764</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10765" href="#t10765">10765</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10766" href="#t10766">10766</a></span><span class="t"><span class="str">            start = fluid.default_startup_program()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10767" href="#t10767">10767</a></span><span class="t"><span class="str">            main = fluid.default_main_program()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10768" href="#t10768">10768</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10769" href="#t10769">10769</a></span><span class="t"><span class="str">            data = np.random.randn(2, 3).astype("float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10770" href="#t10770">10770</a></span><span class="t"><span class="str">            exe.run(start)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10771" href="#t10771">10771</a></span><span class="t"><span class="str">            y_np, = exe.run(main, feed={"x": data}, fetch_list=[y])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10772" href="#t10772">10772</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10773" href="#t10773">10773</a></span><span class="t"><span class="str">            data</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10774" href="#t10774">10774</a></span><span class="t"><span class="str">            # array([[-1.1239197 ,  1.3391294 ,  0.03921051],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10775" href="#t10775">10775</a></span><span class="t"><span class="str">            #        [ 1.1970421 ,  0.02440812,  1.2055548 ]], dtype=float32)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10776" href="#t10776">10776</a></span><span class="t"><span class="str">            y_np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10777" href="#t10777">10777</a></span><span class="t"><span class="str">            # array([[-0.2756806 ,  1.0610548 ,  0.01998957],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10778" href="#t10778">10778</a></span><span class="t"><span class="str">            #        [ 0.9193261 ,  0.01235299,  0.9276883 ]], dtype=float32)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10779" href="#t10779">10779</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10780" href="#t10780">10780</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10781" href="#t10781">10781</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10782" href="#t10782">10782</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10783" href="#t10783">10783</a></span><span class="t"><span class="str">            # imperative mode</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10784" href="#t10784">10784</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10785" href="#t10785">10785</a></span><span class="t"><span class="str">            from paddle import fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10786" href="#t10786">10786</a></span><span class="t"><span class="str">            import paddle.fluid.dygraph as dg</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10787" href="#t10787">10787</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10788" href="#t10788">10788</a></span><span class="t"><span class="str">            data = np.random.randn(2, 3).astype("float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10789" href="#t10789">10789</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10790" href="#t10790">10790</a></span><span class="t"><span class="str">            with dg.guard(place) as g:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10791" href="#t10791">10791</a></span><span class="t"><span class="str">                x = dg.to_variable(data)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10792" href="#t10792">10792</a></span><span class="t"><span class="str">                y = fluid.layers.swish(x)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10793" href="#t10793">10793</a></span><span class="t"><span class="str">                y_np = y.numpy()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10794" href="#t10794">10794</a></span><span class="t"><span class="str">            data</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10795" href="#t10795">10795</a></span><span class="t"><span class="str">            # array([[-0.0816701 ,  1.1603649 , -0.88325626],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10796" href="#t10796">10796</a></span><span class="t"><span class="str">            #        [ 0.7522361 ,  1.0978601 ,  0.12987892]], dtype=float32)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10797" href="#t10797">10797</a></span><span class="t"><span class="str">            y_np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10798" href="#t10798">10798</a></span><span class="t"><span class="str">            # array([[-0.03916847,  0.8835007 , -0.25835553],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10799" href="#t10799">10799</a></span><span class="t"><span class="str">            #        [ 0.51126915,  0.82324016,  0.06915068]], dtype=float32)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10800" href="#t10800">10800</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10801" href="#t10801">10801</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'swish'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10802" href="#t10802">10802</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10803" href="#t10803">10803</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'swish'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10804" href="#t10804">10804</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10805" href="#t10805">10805</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10806" href="#t10806">10806</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'swish'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10807" href="#t10807">10807</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10808" href="#t10808">10808</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10809" href="#t10809">10809</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'slope'</span><span class="op">:</span> <span class="nam">beta</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10810" href="#t10810">10810</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10811" href="#t10811">10811</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10812" href="#t10812">10812</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10813" href="#t10813">10813</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t10814" href="#t10814">10814</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.static.nn.prelu"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t10815" href="#t10815">10815</a></span><span class="t"><span class="key">def</span> <span class="nam">prelu</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">mode</span><span class="op">,</span> <span class="nam">param_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">data_format</span><span class="op">=</span><span class="str">"NCHW"</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10816" href="#t10816">10816</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10817" href="#t10817">10817</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10818" href="#t10818">10818</a></span><span class="t"><span class="str">    prelu activation.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10819" href="#t10819">10819</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10820" href="#t10820">10820</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10821" href="#t10821">10821</a></span><span class="t"><span class="str">        prelu(x) = max(0, x) + \alpha * min(0, x)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10822" href="#t10822">10822</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10823" href="#t10823">10823</a></span><span class="t"><span class="str">    There are three modes for the activation:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10824" href="#t10824">10824</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10825" href="#t10825">10825</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10826" href="#t10826">10826</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10827" href="#t10827">10827</a></span><span class="t"><span class="str">        all: All elements share same alpha.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10828" href="#t10828">10828</a></span><span class="t"><span class="str">        channel: Elements in same channel share same alpha.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10829" href="#t10829">10829</a></span><span class="t"><span class="str">        element: All elements do not share alpha. Each element has its own alpha.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10830" href="#t10830">10830</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10831" href="#t10831">10831</a></span><span class="t"><span class="str">    Parameters:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10832" href="#t10832">10832</a></span><span class="t"><span class="str">        x (Tensor): The input Tensor or LoDTensor with data type float32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10833" href="#t10833">10833</a></span><span class="t"><span class="str">        mode (str): The mode for weight sharing.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10834" href="#t10834">10834</a></span><span class="t"><span class="str">        param_attr (ParamAttr|None, optional): The parameter attribute for the learnable</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10835" href="#t10835">10835</a></span><span class="t"><span class="str">            weight (alpha), it can be create by ParamAttr. None by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10836" href="#t10836">10836</a></span><span class="t"><span class="str">        data_format(str, optional): Data format that specifies the layout of input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10837" href="#t10837">10837</a></span><span class="t"><span class="str">            It may be "NC", "NCL", "NCHW", "NCDHW", "NLC", "NHWC" or "NDHWC". Default: "NCHW".</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10838" href="#t10838">10838</a></span><span class="t"><span class="str">        name (str, optional): Name for the operation (optional, default is None).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10839" href="#t10839">10839</a></span><span class="t"><span class="str">            For more information, please refer to :ref:`api_guide_Name`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10840" href="#t10840">10840</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10841" href="#t10841">10841</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10842" href="#t10842">10842</a></span><span class="t"><span class="str">        Tensor, A tensor with the same shape and data type as x.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10843" href="#t10843">10843</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10844" href="#t10844">10844</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10845" href="#t10845">10845</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10846" href="#t10846">10846</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10847" href="#t10847">10847</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10848" href="#t10848">10848</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10849" href="#t10849">10849</a></span><span class="t"><span class="str">            x = paddle.to_tensor([-1., 2., 3.])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10850" href="#t10850">10850</a></span><span class="t"><span class="str">            param = paddle.ParamAttr(initializer=paddle.nn.initializer.Constant(0.2))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10851" href="#t10851">10851</a></span><span class="t"><span class="str">            out = paddle.static.nn.prelu(x, 'all', param)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10852" href="#t10852">10852</a></span><span class="t"><span class="str">            # [-0.2, 2., 3.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10853" href="#t10853">10853</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10854" href="#t10854">10854</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10855" href="#t10855">10855</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'prelu'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10856" href="#t10856">10856</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10857" href="#t10857">10857</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'prelu'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10858" href="#t10858">10858</a></span><span class="t">    <span class="key">if</span> <span class="nam">mode</span> <span class="key">not</span> <span class="key">in</span> <span class="op">[</span><span class="str">'all'</span><span class="op">,</span> <span class="str">'channel'</span><span class="op">,</span> <span class="str">'element'</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10859" href="#t10859">10859</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">'mode should be one of all, channel, element.'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10860" href="#t10860">10860</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10861" href="#t10861">10861</a></span><span class="t">    <span class="nam">alpha_shape</span> <span class="op">=</span> <span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10862" href="#t10862">10862</a></span><span class="t">    <span class="key">if</span> <span class="nam">mode</span> <span class="op">==</span> <span class="str">'channel'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10863" href="#t10863">10863</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10864" href="#t10864">10864</a></span><span class="t">        <span class="nam">true_data_format</span> <span class="op">=</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10865" href="#t10865">10865</a></span><span class="t">            <span class="str">'NC'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10866" href="#t10866">10866</a></span><span class="t">            <span class="str">'NCL'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10867" href="#t10867">10867</a></span><span class="t">            <span class="str">'NCHW'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10868" href="#t10868">10868</a></span><span class="t">            <span class="str">'NCDHW'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10869" href="#t10869">10869</a></span><span class="t">            <span class="str">'NLC'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10870" href="#t10870">10870</a></span><span class="t">            <span class="str">'NHWC'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10871" href="#t10871">10871</a></span><span class="t">            <span class="str">'NDHWC'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10872" href="#t10872">10872</a></span><span class="t">        <span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10873" href="#t10873">10873</a></span><span class="t">        <span class="key">if</span> <span class="nam">data_format</span> <span class="key">not</span> <span class="key">in</span> <span class="nam">true_data_format</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10874" href="#t10874">10874</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10875" href="#t10875">10875</a></span><span class="t">                <span class="str">"data_format must be one of 'NC', 'NCL', 'NCHW', 'NCDHW', "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10876" href="#t10876">10876</a></span><span class="t">                <span class="str">"'NLC', 'NHWC', 'NDHWC' but receive {}"</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">data_format</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10877" href="#t10877">10877</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10878" href="#t10878">10878</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10879" href="#t10879">10879</a></span><span class="t">        <span class="nam">data_format</span> <span class="op">=</span> <span class="str">'NCHW'</span> <span class="key">if</span> <span class="nam">data_format</span><span class="op">[</span><span class="num">1</span><span class="op">]</span> <span class="op">==</span> <span class="str">'C'</span> <span class="key">else</span> <span class="str">'NHWC'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10880" href="#t10880">10880</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10881" href="#t10881">10881</a></span><span class="t">        <span class="key">assert</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10882" href="#t10882">10882</a></span><span class="t">            <span class="nam">len</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">>=</span> <span class="num">2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10883" href="#t10883">10883</a></span><span class="t">        <span class="op">)</span><span class="op">,</span> <span class="str">"The size of input shape should be equal or larger than 2 in prelu() when mode is 'channel'"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10884" href="#t10884">10884</a></span><span class="t">        <span class="com"># NOTE(zhiqiu): The alpha_shape should be [1, channel] + [1] * len(x.shape[2:]).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10885" href="#t10885">10885</a></span><span class="t">        <span class="com"># To be consistent with Prelu, it is simplified.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10886" href="#t10886">10886</a></span><span class="t">        <span class="com"># NOTE(zhiqiu): Revert shape to [1, channel, 1, 1] for compatibility with saved model of old version.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10887" href="#t10887">10887</a></span><span class="t">        <span class="com"># NOTE(GuoxiaWang): support NHWC data format</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10888" href="#t10888">10888</a></span><span class="t">        <span class="key">if</span> <span class="nam">data_format</span> <span class="op">==</span> <span class="str">'NHWC'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10889" href="#t10889">10889</a></span><span class="t">            <span class="nam">alpha_shape</span> <span class="op">=</span> <span class="op">[</span><span class="num">1</span><span class="op">,</span> <span class="num">1</span><span class="op">,</span> <span class="num">1</span><span class="op">,</span> <span class="nam">x</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10890" href="#t10890">10890</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10891" href="#t10891">10891</a></span><span class="t">            <span class="nam">alpha_shape</span> <span class="op">=</span> <span class="op">[</span><span class="num">1</span><span class="op">,</span> <span class="nam">x</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">,</span> <span class="num">1</span><span class="op">,</span> <span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10892" href="#t10892">10892</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10893" href="#t10893">10893</a></span><span class="t">    <span class="key">elif</span> <span class="nam">mode</span> <span class="op">==</span> <span class="str">'element'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10894" href="#t10894">10894</a></span><span class="t">        <span class="key">assert</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10895" href="#t10895">10895</a></span><span class="t">            <span class="nam">len</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">>=</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10896" href="#t10896">10896</a></span><span class="t">        <span class="op">)</span><span class="op">,</span> <span class="str">"The size of input shape should be equal or larger than 1 in prelu() when mode is 'element'"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10897" href="#t10897">10897</a></span><span class="t">        <span class="nam">alpha_shape</span> <span class="op">=</span> <span class="op">[</span><span class="num">1</span><span class="op">]</span> <span class="op">+</span> <span class="nam">list</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span><span class="op">[</span><span class="num">1</span><span class="op">:</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10898" href="#t10898">10898</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="nam">input_param_name</span><span class="op">=</span><span class="str">'x'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10899" href="#t10899">10899</a></span><span class="t">    <span class="nam">alpha</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10900" href="#t10900">10900</a></span><span class="t">        <span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">param_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10901" href="#t10901">10901</a></span><span class="t">        <span class="nam">shape</span><span class="op">=</span><span class="nam">alpha_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10902" href="#t10902">10902</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10903" href="#t10903">10903</a></span><span class="t">        <span class="nam">is_bias</span><span class="op">=</span><span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10904" href="#t10904">10904</a></span><span class="t">        <span class="nam">default_initializer</span><span class="op">=</span><span class="nam">Constant</span><span class="op">(</span><span class="num">0.25</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10905" href="#t10905">10905</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10906" href="#t10906">10906</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10907" href="#t10907">10907</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">prelu</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">alpha</span><span class="op">,</span> <span class="nam">data_format</span><span class="op">,</span> <span class="nam">mode</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10908" href="#t10908">10908</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10909" href="#t10909">10909</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10910" href="#t10910">10910</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10911" href="#t10911">10911</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"prelu"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10912" href="#t10912">10912</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">x</span><span class="op">,</span> <span class="str">'Alpha'</span><span class="op">:</span> <span class="nam">alpha</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10913" href="#t10913">10913</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">"mode"</span><span class="op">:</span> <span class="nam">mode</span><span class="op">,</span> <span class="str">"data_format"</span><span class="op">:</span> <span class="nam">data_format</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10914" href="#t10914">10914</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10915" href="#t10915">10915</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10916" href="#t10916">10916</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10917" href="#t10917">10917</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10918" href="#t10918">10918</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t10919" href="#t10919">10919</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t10920" href="#t10920">10920</a></span><span class="t"><span class="key">def</span> <span class="nam">brelu</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">t_min</span><span class="op">=</span><span class="num">0.0</span><span class="op">,</span> <span class="nam">t_max</span><span class="op">=</span><span class="num">24.0</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10921" href="#t10921">10921</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10922" href="#t10922">10922</a></span><span class="t"><span class="str">    ${comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10923" href="#t10923">10923</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10924" href="#t10924">10924</a></span><span class="t"><span class="str">        x(${x_type}): ${x_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10925" href="#t10925">10925</a></span><span class="t"><span class="str">        t_min(${t_min_type}|0.0): ${t_min_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10926" href="#t10926">10926</a></span><span class="t"><span class="str">        t_max(${t_max_type}|24.0): ${t_max_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10927" href="#t10927">10927</a></span><span class="t"><span class="str">        name(str|None): The default value is None. Normally there is no need for user to set this property.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10928" href="#t10928">10928</a></span><span class="t"><span class="str">                        For more information, please refer to :ref:`api_guide_Name`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10929" href="#t10929">10929</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10930" href="#t10930">10930</a></span><span class="t"><span class="str">        ${out_type}: ${out_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10931" href="#t10931">10931</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10932" href="#t10932">10932</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10933" href="#t10933">10933</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10934" href="#t10934">10934</a></span><span class="t"><span class="str">    .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10935" href="#t10935">10935</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10936" href="#t10936">10936</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10937" href="#t10937">10937</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10938" href="#t10938">10938</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10939" href="#t10939">10939</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10940" href="#t10940">10940</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10941" href="#t10941">10941</a></span><span class="t"><span class="str">            input_brelu = np.array([[-1,6],[1,15.6]])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10942" href="#t10942">10942</a></span><span class="t"><span class="str">            with fluid.dygraph.guard():</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10943" href="#t10943">10943</a></span><span class="t"><span class="str">                x = fluid.dygraph.to_variable(input_brelu)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10944" href="#t10944">10944</a></span><span class="t"><span class="str">                y = fluid.layers.brelu(x, t_min=1.0, t_max=10.0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10945" href="#t10945">10945</a></span><span class="t"><span class="str">                print(y.numpy())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10946" href="#t10946">10946</a></span><span class="t"><span class="str">                #[[ 1.  6.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10947" href="#t10947">10947</a></span><span class="t"><span class="str">                #[ 1. 10.]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10948" href="#t10948">10948</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10949" href="#t10949">10949</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10950" href="#t10950">10950</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">brelu</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'t_min'</span><span class="op">,</span> <span class="nam">t_min</span><span class="op">,</span> <span class="str">'t_max'</span><span class="op">,</span> <span class="nam">t_max</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10951" href="#t10951">10951</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10952" href="#t10952">10952</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'brelu'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10953" href="#t10953">10953</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10954" href="#t10954">10954</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'brelu'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10955" href="#t10955">10955</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10956" href="#t10956">10956</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10957" href="#t10957">10957</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'brelu'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10958" href="#t10958">10958</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10959" href="#t10959">10959</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10960" href="#t10960">10960</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'t_min'</span><span class="op">:</span> <span class="nam">t_min</span><span class="op">,</span> <span class="str">'t_max'</span><span class="op">:</span> <span class="nam">t_max</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10961" href="#t10961">10961</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10962" href="#t10962">10962</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10963" href="#t10963">10963</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10964" href="#t10964">10964</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t10965" href="#t10965">10965</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.nn.functional.leaky_relu"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t10966" href="#t10966">10966</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t10967" href="#t10967">10967</a></span><span class="t"><span class="key">def</span> <span class="nam">leaky_relu</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">alpha</span><span class="op">=</span><span class="num">0.02</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10968" href="#t10968">10968</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10969" href="#t10969">10969</a></span><span class="t"><span class="str">    ${comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10970" href="#t10970">10970</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10971" href="#t10971">10971</a></span><span class="t"><span class="str">        x(${x_type}): ${x_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10972" href="#t10972">10972</a></span><span class="t"><span class="str">        alpha(${alpha_type}|0.02): ${alpha_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10973" href="#t10973">10973</a></span><span class="t"><span class="str">        name(str|None): The default value is None. Normally there is no need for user to set this property. For more information, please refer to :ref:`api_guide_Name`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10974" href="#t10974">10974</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10975" href="#t10975">10975</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10976" href="#t10976">10976</a></span><span class="t"><span class="str">        output(${out_type}): ${out_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10977" href="#t10977">10977</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10978" href="#t10978">10978</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10979" href="#t10979">10979</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10980" href="#t10980">10980</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10981" href="#t10981">10981</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10982" href="#t10982">10982</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10983" href="#t10983">10983</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10984" href="#t10984">10984</a></span><span class="t"><span class="str">            x = paddle.to_tensor([[-1, 2], [3, -4]], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10985" href="#t10985">10985</a></span><span class="t"><span class="str">            y = paddle.fluid.layers.leaky_relu(x, alpha=0.1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10986" href="#t10986">10986</a></span><span class="t"><span class="str">            print(y) # [[-0.1, 2], [3, -0.4]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10987" href="#t10987">10987</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10988" href="#t10988">10988</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t10989" href="#t10989">10989</a></span><span class="t">    <span class="key">return</span> <span class="nam">paddle</span><span class="op">.</span><span class="nam">nn</span><span class="op">.</span><span class="nam">functional</span><span class="op">.</span><span class="nam">leaky_relu</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">alpha</span><span class="op">,</span> <span class="nam">name</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10990" href="#t10990">10990</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10991" href="#t10991">10991</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t10992" href="#t10992">10992</a></span><span class="t"><span class="key">def</span> <span class="nam">soft_relu</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">threshold</span><span class="op">=</span><span class="num">40.0</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10993" href="#t10993">10993</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10994" href="#t10994">10994</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10995" href="#t10995">10995</a></span><span class="t"><span class="str">    SoftRelu Activation Operator.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10996" href="#t10996">10996</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10997" href="#t10997">10997</a></span><span class="t"><span class="str">    $out = \ln(1 + \exp(\max(\min(x, threshold), -threshold)))$</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10998" href="#t10998">10998</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t10999" href="#t10999">10999</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11000" href="#t11000">11000</a></span><span class="t"><span class="str">        x(Variable): Input of soft_relu operator. Data type can be float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11001" href="#t11001">11001</a></span><span class="t"><span class="str">        threshold(float, optional): The threshold value of soft_relu, default value being 40.0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11002" href="#t11002">11002</a></span><span class="t"><span class="str">        name(str, optional): The default value is None.  Normally there is no need for user to set this property.  For more information, please refer to :ref:`api_guide_Name` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11003" href="#t11003">11003</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11004" href="#t11004">11004</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11005" href="#t11005">11005</a></span><span class="t"><span class="str">        Variable(Tensor|LoDTensor)): Output of soft_relu operator, shape and LoD same as input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11006" href="#t11006">11006</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11007" href="#t11007">11007</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11008" href="#t11008">11008</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11009" href="#t11009">11009</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11010" href="#t11010">11010</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11011" href="#t11011">11011</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11012" href="#t11012">11012</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11013" href="#t11013">11013</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11014" href="#t11014">11014</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11015" href="#t11015">11015</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11016" href="#t11016">11016</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11017" href="#t11017">11017</a></span><span class="t"><span class="str">            inputs = fluid.layers.data(name="x", shape=[2, 2], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11018" href="#t11018">11018</a></span><span class="t"><span class="str">            output = fluid.layers.soft_relu(inputs, threshold=20.0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11019" href="#t11019">11019</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11020" href="#t11020">11020</a></span><span class="t"><span class="str">            exe = fluid.Executor(fluid.CPUPlace())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11021" href="#t11021">11021</a></span><span class="t"><span class="str">            exe.run(fluid.default_startup_program())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11022" href="#t11022">11022</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11023" href="#t11023">11023</a></span><span class="t"><span class="str">            img = np.array([[0, 1],[2, 3]]).astype(np.float32)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11024" href="#t11024">11024</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11025" href="#t11025">11025</a></span><span class="t"><span class="str">            res = exe.run(fluid.default_main_program(), feed={'x':img}, fetch_list=[output])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11026" href="#t11026">11026</a></span><span class="t"><span class="str">            print(res) # [array([[0.6931472, 1.3132616], [2.126928 , 3.0485873]], dtype=float32)]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11027" href="#t11027">11027</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11028" href="#t11028">11028</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11029" href="#t11029">11029</a></span><span class="t">        <span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'soft_relu'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11030" href="#t11030">11030</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11031" href="#t11031">11031</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11032" href="#t11032">11032</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'soft_relu'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11033" href="#t11033">11033</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11034" href="#t11034">11034</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11035" href="#t11035">11035</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'soft_relu'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11036" href="#t11036">11036</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11037" href="#t11037">11037</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11038" href="#t11038">11038</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'threshold'</span><span class="op">:</span> <span class="nam">threshold</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11039" href="#t11039">11039</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11040" href="#t11040">11040</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11041" href="#t11041">11041</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11042" href="#t11042">11042</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11043" href="#t11043">11043</a></span><span class="t"><span class="key">def</span> <span class="nam">flatten</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="num">1</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11044" href="#t11044">11044</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11045" href="#t11045">11045</a></span><span class="t"><span class="str">    **Flatten op**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11046" href="#t11046">11046</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11047" href="#t11047">11047</a></span><span class="t"><span class="str">    Flatten the input tensor into a 2D matrix.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11048" href="#t11048">11048</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11049" href="#t11049">11049</a></span><span class="t"><span class="str">    For Example:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11050" href="#t11050">11050</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11051" href="#t11051">11051</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11052" href="#t11052">11052</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11053" href="#t11053">11053</a></span><span class="t"><span class="str">        Case 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11054" href="#t11054">11054</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11055" href="#t11055">11055</a></span><span class="t"><span class="str">          Given</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11056" href="#t11056">11056</a></span><span class="t"><span class="str">            X.shape = (3, 100, 100, 4)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11057" href="#t11057">11057</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11058" href="#t11058">11058</a></span><span class="t"><span class="str">          and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11059" href="#t11059">11059</a></span><span class="t"><span class="str">            axis = 2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11060" href="#t11060">11060</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11061" href="#t11061">11061</a></span><span class="t"><span class="str">          We get:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11062" href="#t11062">11062</a></span><span class="t"><span class="str">            Out.shape = (3 * 100, 4 * 100)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11063" href="#t11063">11063</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11064" href="#t11064">11064</a></span><span class="t"><span class="str">        Case 2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11065" href="#t11065">11065</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11066" href="#t11066">11066</a></span><span class="t"><span class="str">          Given</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11067" href="#t11067">11067</a></span><span class="t"><span class="str">            X.shape = (3, 100, 100, 4)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11068" href="#t11068">11068</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11069" href="#t11069">11069</a></span><span class="t"><span class="str">          and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11070" href="#t11070">11070</a></span><span class="t"><span class="str">            axis = 0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11071" href="#t11071">11071</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11072" href="#t11072">11072</a></span><span class="t"><span class="str">          We get:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11073" href="#t11073">11073</a></span><span class="t"><span class="str">            Out.shape = (1, 3 * 100 * 100 * 4)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11074" href="#t11074">11074</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11075" href="#t11075">11075</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11076" href="#t11076">11076</a></span><span class="t"><span class="str">        x (Variable): A tensor of rank >= axis. A tensor with type float32,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11077" href="#t11077">11077</a></span><span class="t"><span class="str">                      float64, int8, int32, int64, uint8.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11078" href="#t11078">11078</a></span><span class="t"><span class="str">        axis (int): Indicate up to which input dimensions (exclusive) should</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11079" href="#t11079">11079</a></span><span class="t"><span class="str">                    be flattened to the outer dimension of the output.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11080" href="#t11080">11080</a></span><span class="t"><span class="str">                    The value for axis must be in the range [0, R], where R</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11081" href="#t11081">11081</a></span><span class="t"><span class="str">                    is the rank of the input tensor. Default: 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11082" href="#t11082">11082</a></span><span class="t"><span class="str">        name(str, Optional): For details, please refer to :ref:`api_guide_Name`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11083" href="#t11083">11083</a></span><span class="t"><span class="str">                        Generally, no setting is required. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11084" href="#t11084">11084</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11085" href="#t11085">11085</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11086" href="#t11086">11086</a></span><span class="t"><span class="str">        Variable: A 2D tensor with the contents of the input tensor, with input \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11087" href="#t11087">11087</a></span><span class="t"><span class="str">                  dimensions up to axis flattened to the outer dimension of \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11088" href="#t11088">11088</a></span><span class="t"><span class="str">                  the output and remaining input dimensions flattened into the \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11089" href="#t11089">11089</a></span><span class="t"><span class="str">                  inner dimension of the output. A Tensor with type same as input x.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11090" href="#t11090">11090</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11091" href="#t11091">11091</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11092" href="#t11092">11092</a></span><span class="t"><span class="str">        ValueError: If x is not a variable.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11093" href="#t11093">11093</a></span><span class="t"><span class="str">        ValueError: If axis is not in range [0, rank(x)].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11094" href="#t11094">11094</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11095" href="#t11095">11095</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11096" href="#t11096">11096</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11097" href="#t11097">11097</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11098" href="#t11098">11098</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11099" href="#t11099">11099</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11100" href="#t11100">11100</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11101" href="#t11101">11101</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11102" href="#t11102">11102</a></span><span class="t"><span class="str">            x = fluid.data(name="x", shape=[4, 4, 3], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11103" href="#t11103">11103</a></span><span class="t"><span class="str">            # x shape is [4, 4, 3]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11104" href="#t11104">11104</a></span><span class="t"><span class="str">            out = fluid.layers.flatten(x=x, axis=2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11105" href="#t11105">11105</a></span><span class="t"><span class="str">            # out shape is [16, 3]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11106" href="#t11106">11106</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11107" href="#t11107">11107</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11108" href="#t11108">11108</a></span><span class="t">        <span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11109" href="#t11109">11109</a></span><span class="t">        <span class="str">'x'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11110" href="#t11110">11110</a></span><span class="t">        <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int8'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">,</span> <span class="str">'uint8'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11111" href="#t11111">11111</a></span><span class="t">        <span class="str">'flatten'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11112" href="#t11112">11112</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11113" href="#t11113">11113</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11114" href="#t11114">11114</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">flatten2</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'axis'</span><span class="op">,</span> <span class="nam">axis</span><span class="op">)</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11115" href="#t11115">11115</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11116" href="#t11116">11116</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'flatten'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11117" href="#t11117">11117</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11118" href="#t11118">11118</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="op">(</span><span class="nam">isinstance</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11119" href="#t11119">11119</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"The input x should be a Variable"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11120" href="#t11120">11120</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11121" href="#t11121">11121</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="op">(</span><span class="nam">isinstance</span><span class="op">(</span><span class="nam">axis</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">)</span> <span class="key">or</span> <span class="nam">axis</span> <span class="op">></span> <span class="nam">len</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="key">or</span> <span class="nam">axis</span> <span class="op">&lt;</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11122" href="#t11122">11122</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"The axis should be a int, and in range [0, rank(x)]"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11123" href="#t11123">11123</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11124" href="#t11124">11124</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11125" href="#t11125">11125</a></span><span class="t">    <span class="nam">x_shape</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11126" href="#t11126">11126</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11127" href="#t11127">11127</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'flatten2'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11128" href="#t11128">11128</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11129" href="#t11129">11129</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">,</span> <span class="str">'XShape'</span><span class="op">:</span> <span class="nam">x_shape</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11130" href="#t11130">11130</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">"axis"</span><span class="op">:</span> <span class="nam">axis</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11131" href="#t11131">11131</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11132" href="#t11132">11132</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11133" href="#t11133">11133</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11134" href="#t11134">11134</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11135" href="#t11135">11135</a></span><span class="t"><span class="key">def</span> <span class="nam">stack</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="num">0</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11136" href="#t11136">11136</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11137" href="#t11137">11137</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11138" href="#t11138">11138</a></span><span class="t"><span class="str">    This OP stacks all the inputs :code:`x` along axis.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11139" href="#t11139">11139</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11140" href="#t11140">11140</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11141" href="#t11141">11141</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11142" href="#t11142">11142</a></span><span class="t"><span class="str">        Case 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11143" href="#t11143">11143</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11144" href="#t11144">11144</a></span><span class="t"><span class="str">          Input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11145" href="#t11145">11145</a></span><span class="t"><span class="str">            x[0].shape = [1, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11146" href="#t11146">11146</a></span><span class="t"><span class="str">            x[0].data = [ [1.0 , 2.0 ] ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11147" href="#t11147">11147</a></span><span class="t"><span class="str">            x[1].shape = [1, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11148" href="#t11148">11148</a></span><span class="t"><span class="str">            x[1].data = [ [3.0 , 4.0 ] ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11149" href="#t11149">11149</a></span><span class="t"><span class="str">            x[2].shape = [1, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11150" href="#t11150">11150</a></span><span class="t"><span class="str">            x[2].data = [ [5.0 , 6.0 ] ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11151" href="#t11151">11151</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11152" href="#t11152">11152</a></span><span class="t"><span class="str">          Attrs:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11153" href="#t11153">11153</a></span><span class="t"><span class="str">            axis = 0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11154" href="#t11154">11154</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11155" href="#t11155">11155</a></span><span class="t"><span class="str">          Output:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11156" href="#t11156">11156</a></span><span class="t"><span class="str">            Out.dims = [3, 1, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11157" href="#t11157">11157</a></span><span class="t"><span class="str">            Out.data =[ [ [1.0, 2.0] ],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11158" href="#t11158">11158</a></span><span class="t"><span class="str">                        [ [3.0, 4.0] ],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11159" href="#t11159">11159</a></span><span class="t"><span class="str">                        [ [5.0, 6.0] ] ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11160" href="#t11160">11160</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11161" href="#t11161">11161</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11162" href="#t11162">11162</a></span><span class="t"><span class="str">        Case 2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11163" href="#t11163">11163</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11164" href="#t11164">11164</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11165" href="#t11165">11165</a></span><span class="t"><span class="str">          Input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11166" href="#t11166">11166</a></span><span class="t"><span class="str">            x[0].shape = [1, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11167" href="#t11167">11167</a></span><span class="t"><span class="str">            x[0].data = [ [1.0 , 2.0 ] ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11168" href="#t11168">11168</a></span><span class="t"><span class="str">            x[1].shape = [1, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11169" href="#t11169">11169</a></span><span class="t"><span class="str">            x[1].data = [ [3.0 , 4.0 ] ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11170" href="#t11170">11170</a></span><span class="t"><span class="str">            x[2].shape = [1, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11171" href="#t11171">11171</a></span><span class="t"><span class="str">            x[2].data = [ [5.0 , 6.0 ] ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11172" href="#t11172">11172</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11173" href="#t11173">11173</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11174" href="#t11174">11174</a></span><span class="t"><span class="str">          Attrs:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11175" href="#t11175">11175</a></span><span class="t"><span class="str">            axis = 1 or axis = -2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11176" href="#t11176">11176</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11177" href="#t11177">11177</a></span><span class="t"><span class="str">          Output:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11178" href="#t11178">11178</a></span><span class="t"><span class="str">            Out.shape = [1, 3, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11179" href="#t11179">11179</a></span><span class="t"><span class="str">            Out.data =[ [ [1.0, 2.0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11180" href="#t11180">11180</a></span><span class="t"><span class="str">                          [3.0, 4.0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11181" href="#t11181">11181</a></span><span class="t"><span class="str">                          [5.0, 6.0] ] ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11182" href="#t11182">11182</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11183" href="#t11183">11183</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11184" href="#t11184">11184</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11185" href="#t11185">11185</a></span><span class="t"><span class="str">        x (list(Variable)|tuple(Variable)): Input :code:`x` can be a :code:`list` or :code:`tuple` of Tensors, the shapes of all these Tensors</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11186" href="#t11186">11186</a></span><span class="t"><span class="str">                                     must be the same. Supposing input is N dims</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11187" href="#t11187">11187</a></span><span class="t"><span class="str">                                     Tensors :math:`[d_0, d_1, ..., d_{n-1}]`, the output is N+1 dims</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11188" href="#t11188">11188</a></span><span class="t"><span class="str">                                     Tensor :math:`[d_0, d_1, d_{axis-1}, len(x), d_{axis}, ..., d_{n-1}]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11189" href="#t11189">11189</a></span><span class="t"><span class="str">                                     Supported data types: float32, float64, int32, int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11190" href="#t11190">11190</a></span><span class="t"><span class="str">        axis (int, optional): The axis along which all inputs are stacked. ``axis`` range is ``[-(R+1), R+1)``,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11191" href="#t11191">11191</a></span><span class="t"><span class="str">                              where ``R`` is the number of dimensions of the first input tensor ``x[0]``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11192" href="#t11192">11192</a></span><span class="t"><span class="str">                              If ``axis &lt; 0``, ``axis = axis+R+1``. The default value of axis is 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11193" href="#t11193">11193</a></span><span class="t"><span class="str">        name (str, optional): Please refer to :ref:`api_guide_Name`, Default None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11194" href="#t11194">11194</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11195" href="#t11195">11195</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11196" href="#t11196">11196</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11197" href="#t11197">11197</a></span><span class="t"><span class="str">        Variable: The stacked Tensor, has same data type with input Tensors. Output dim is :math:`rank(x[0])+1`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11198" href="#t11198">11198</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11199" href="#t11199">11199</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11200" href="#t11200">11200</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11201" href="#t11201">11201</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11202" href="#t11202">11202</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11203" href="#t11203">11203</a></span><span class="t"><span class="str">            import paddle.fluid.layers as layers</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11204" href="#t11204">11204</a></span><span class="t"><span class="str">            # set batch size=None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11205" href="#t11205">11205</a></span><span class="t"><span class="str">            x1 = fluid.data(name='x1', shape=[None, 1, 2], dtype='int32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11206" href="#t11206">11206</a></span><span class="t"><span class="str">            x2 = fluid.data(name='x2', shape=[None, 1, 2], dtype='int32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11207" href="#t11207">11207</a></span><span class="t"><span class="str">            # stack Tensor list</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11208" href="#t11208">11208</a></span><span class="t"><span class="str">            data = layers.stack([x1,x2]) # stack according to axis 0, data.shape=[2, None, 1, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11209" href="#t11209">11209</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11210" href="#t11210">11210</a></span><span class="t"><span class="str">            data = layers.stack([x1,x2], axis=1) # stack according to axis 1, data.shape=[None, 2, 1, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11211" href="#t11211">11211</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11212" href="#t11212">11212</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11213" href="#t11213">11213</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11214" href="#t11214">11214</a></span><span class="t">    <span class="nam">axis</span> <span class="op">=</span> <span class="num">0</span> <span class="key">if</span> <span class="nam">axis</span> <span class="key">is</span> <span class="key">None</span> <span class="key">else</span> <span class="nam">axis</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11215" href="#t11215">11215</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t11216" href="#t11216">11216</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">11216&#x202F;&#x219B;&#x202F;11217</span><span class="annotate long">line 11216 didn't jump to line 11217, because the condition on line 11216 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11217" href="#t11217">11217</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">stack</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">axis</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11218" href="#t11218">11218</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t11219" href="#t11219">11219</a></span><span class="t">    <span class="key">if</span> <span class="nam">_in_legacy_dygraph</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">11219&#x202F;&#x219B;&#x202F;11220</span><span class="annotate long">line 11219 didn't jump to line 11220, because the condition on line 11219 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11220" href="#t11220">11220</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">stack</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'axis'</span><span class="op">,</span> <span class="nam">axis</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11221" href="#t11221">11221</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t11222" href="#t11222">11222</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span> <span class="key">and</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">11222&#x202F;&#x219B;&#x202F;11225</span><span class="annotate long">line 11222 didn't jump to line 11225, because the condition on line 11222 was never true</span></span></p>
    <p class="pln"><span class="n"><a id="t11223" href="#t11223">11223</a></span><span class="t">        <span class="com"># NOTE:(zhiqiu) Only support Variable as input if the Variable is a LOD_TENSOR_ARRAY create by create_array, array_write, array_read, etc.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11224" href="#t11224">11224</a></span><span class="t">        <span class="com"># In that case, Variable is array of tensors indeed.</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11225" href="#t11225">11225</a></span><span class="t">        <span class="key">if</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11226" href="#t11226">11226</a></span><span class="t">            <span class="nam">isinstance</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11227" href="#t11227">11227</a></span><span class="t">            <span class="key">and</span> <span class="nam">x</span><span class="op">.</span><span class="nam">desc</span><span class="op">.</span><span class="nam">type</span><span class="op">(</span><span class="op">)</span> <span class="op">==</span> <span class="nam">core</span><span class="op">.</span><span class="nam">VarDesc</span><span class="op">.</span><span class="nam">VarType</span><span class="op">.</span><span class="nam">LOD_TENSOR_ARRAY</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11228" href="#t11228">11228</a></span><span class="t">        <span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11229" href="#t11229">11229</a></span><span class="t">            <span class="nam">x</span> <span class="op">=</span> <span class="op">[</span><span class="nam">x</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11230" href="#t11230">11230</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11231" href="#t11231">11231</a></span><span class="t">            <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11232" href="#t11232">11232</a></span><span class="t">                <span class="str">"The type of '%s' in %s must be %s, but received %s"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11233" href="#t11233">11233</a></span><span class="t">                <span class="op">%</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11234" href="#t11234">11234</a></span><span class="t">                    <span class="str">'x'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11235" href="#t11235">11235</a></span><span class="t">                    <span class="str">'stack'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11236" href="#t11236">11236</a></span><span class="t">                    <span class="str">'list[Tensor], tuple[Tensor] or TensorArray'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11237" href="#t11237">11237</a></span><span class="t">                    <span class="nam">type</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11238" href="#t11238">11238</a></span><span class="t">                <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11239" href="#t11239">11239</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11240" href="#t11240">11240</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11241" href="#t11241">11241</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'stack'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11242" href="#t11242">11242</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11243" href="#t11243">11243</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">x</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t11244" href="#t11244">11244</a></span><span class="t">    <span class="key">if</span> <span class="nam">x</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">.</span><span class="nam">desc</span><span class="op">.</span><span class="nam">type</span><span class="op">(</span><span class="op">)</span> <span class="op">==</span> <span class="nam">core</span><span class="op">.</span><span class="nam">VarDesc</span><span class="op">.</span><span class="nam">VarType</span><span class="op">.</span><span class="nam">LOD_TENSOR_ARRAY</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">11244&#x202F;&#x219B;&#x202F;11245</span><span class="annotate long">line 11244 didn't jump to line 11245, because the condition on line 11244 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11245" href="#t11245">11245</a></span><span class="t">        <span class="key">assert</span> <span class="nam">len</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span> <span class="op">==</span> <span class="num">1</span><span class="op">,</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11246" href="#t11246">11246</a></span><span class="t">            <span class="str">"If the elements of 'x' in stack are Variable(LoDTensorArray), "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11247" href="#t11247">11247</a></span><span class="t">            <span class="str">"number of the elements must be 1, but received %s."</span> <span class="op">%</span> <span class="nam">len</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11248" href="#t11248">11248</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11249" href="#t11249">11249</a></span><span class="t">        <span class="nam">out_index</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="str">"int32"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11250" href="#t11250">11250</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11251" href="#t11251">11251</a></span><span class="t">        <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span> <span class="nam">x</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11252" href="#t11252">11252</a></span><span class="t">            <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11253" href="#t11253">11253</a></span><span class="t">                <span class="nam">i</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11254" href="#t11254">11254</a></span><span class="t">                <span class="str">'x'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11255" href="#t11255">11255</a></span><span class="t">                <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11256" href="#t11256">11256</a></span><span class="t">                <span class="str">'stack'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11257" href="#t11257">11257</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11258" href="#t11258">11258</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11259" href="#t11259">11259</a></span><span class="t">        <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11260" href="#t11260">11260</a></span><span class="t">            <span class="nam">type</span><span class="op">=</span><span class="str">'tensor_array_to_tensor'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11261" href="#t11261">11261</a></span><span class="t">            <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11262" href="#t11262">11262</a></span><span class="t">            <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="op">[</span><span class="nam">out</span><span class="op">]</span><span class="op">,</span> <span class="str">'OutIndex'</span><span class="op">:</span> <span class="op">[</span><span class="nam">out_index</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11263" href="#t11263">11263</a></span><span class="t">            <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'axis'</span><span class="op">:</span> <span class="nam">axis</span><span class="op">,</span> <span class="str">'use_stack'</span><span class="op">:</span> <span class="key">True</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11264" href="#t11264">11264</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11265" href="#t11265">11265</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11266" href="#t11266">11266</a></span><span class="t">        <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11267" href="#t11267">11267</a></span><span class="t">            <span class="nam">type</span><span class="op">=</span><span class="str">'stack'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11268" href="#t11268">11268</a></span><span class="t">            <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11269" href="#t11269">11269</a></span><span class="t">            <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Y'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11270" href="#t11270">11270</a></span><span class="t">            <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'axis'</span><span class="op">:</span> <span class="nam">axis</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11271" href="#t11271">11271</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11272" href="#t11272">11272</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11273" href="#t11273">11273</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11274" href="#t11274">11274</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11275" href="#t11275">11275</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11276" href="#t11276">11276</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="nam">op_type</span><span class="op">=</span><span class="str">"filter_by_instag"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11277" href="#t11277">11277</a></span><span class="t"><span class="key">def</span> <span class="nam">filter_by_instag</span><span class="op">(</span><span class="nam">ins</span><span class="op">,</span> <span class="nam">ins_tag</span><span class="op">,</span> <span class="nam">filter_tag</span><span class="op">,</span> <span class="nam">is_lod</span><span class="op">,</span> <span class="nam">out_val_if_empty</span><span class="op">=</span><span class="num">0</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11278" href="#t11278">11278</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11279" href="#t11279">11279</a></span><span class="t"><span class="str">    **Filter By Instag Layer**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11280" href="#t11280">11280</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11281" href="#t11281">11281</a></span><span class="t"><span class="str">    This function filter a batch of ins by instag,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11282" href="#t11282">11282</a></span><span class="t"><span class="str">    There are multiple ins, and every ins belongs to some tags.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11283" href="#t11283">11283</a></span><span class="t"><span class="str">    We can specify some tags we want. So the ins which belongs to that tags</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11284" href="#t11284">11284</a></span><span class="t"><span class="str">    remains in the output, and others removed.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11285" href="#t11285">11285</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11286" href="#t11286">11286</a></span><span class="t"><span class="str">    For example, one batch has 4 ins. Every ins has its tag list.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11287" href="#t11287">11287</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11288" href="#t11288">11288</a></span><span class="t"><span class="str">       | Ins   |   Ins_Tag |</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11289" href="#t11289">11289</a></span><span class="t"><span class="str">       |:-----:|:------:|</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11290" href="#t11290">11290</a></span><span class="t"><span class="str">       |  0    |   0, 1 |</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11291" href="#t11291">11291</a></span><span class="t"><span class="str">       |  1    |   1, 3 |</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11292" href="#t11292">11292</a></span><span class="t"><span class="str">       |  2    |   0, 3 |</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11293" href="#t11293">11293</a></span><span class="t"><span class="str">       |  3    |   2, 6 |</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11294" href="#t11294">11294</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11295" href="#t11295">11295</a></span><span class="t"><span class="str">    And Lod is [1,1,1,1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11296" href="#t11296">11296</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11297" href="#t11297">11297</a></span><span class="t"><span class="str">    And the filter tags [1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11298" href="#t11298">11298</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11299" href="#t11299">11299</a></span><span class="t"><span class="str">    From the definition above, ins which has tag 1 can pass the filter</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11300" href="#t11300">11300</a></span><span class="t"><span class="str">    So Ins 0 and Ins 1 can pass and be seen in the output,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11301" href="#t11301">11301</a></span><span class="t"><span class="str">    Ins 2 and 3 cannot pass because they do not has tag 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11302" href="#t11302">11302</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11303" href="#t11303">11303</a></span><span class="t"><span class="str">    Actually, if is_lod is false, it is normal tensor that equals to</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11304" href="#t11304">11304</a></span><span class="t"><span class="str">    lod_tensor with all 1, similar to the example above.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11305" href="#t11305">11305</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11306" href="#t11306">11306</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11307" href="#t11307">11307</a></span><span class="t"><span class="str">        ins (Variable): Input Variable (LoDTensor), usually it is 2D tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11308" href="#t11308">11308</a></span><span class="t"><span class="str">                        And first dimension can have lod info or not.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11309" href="#t11309">11309</a></span><span class="t"><span class="str">        ins_tag (Variable): Input Variable (LoDTensor), usually it is 1D list</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11310" href="#t11310">11310</a></span><span class="t"><span class="str">                        And split them by lod info</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11311" href="#t11311">11311</a></span><span class="t"><span class="str">        filter_tag (Variable): Input Variable (1D Tensor/List), usually it is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11312" href="#t11312">11312</a></span><span class="t"><span class="str">                        list that holds the tags.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11313" href="#t11313">11313</a></span><span class="t"><span class="str">        is_lod (Bool): Boolean value to indicate ins is lod tensor or not.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11314" href="#t11314">11314</a></span><span class="t"><span class="str">        out_val_if_empty(Int64): If the output after filter is empty, this value</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11315" href="#t11315">11315</a></span><span class="t"><span class="str">                        will be set to Output tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11316" href="#t11316">11316</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11317" href="#t11317">11317</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11318" href="#t11318">11318</a></span><span class="t"><span class="str">        Variable: filtered ins (LoDTensor) and loss weight (Tensor)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11319" href="#t11319">11319</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11320" href="#t11320">11320</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11321" href="#t11321">11321</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11322" href="#t11322">11322</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11323" href="#t11323">11323</a></span><span class="t"><span class="str">          import paddle.fluid.layers as layers</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11324" href="#t11324">11324</a></span><span class="t"><span class="str">          ins = layers.data(name='Ins', shape=[-1,32], lod_level=0, dtype='float64')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11325" href="#t11325">11325</a></span><span class="t"><span class="str">          ins_tag = layers.data(name='Ins_tag', shape=[-1,16], lod_level=0, dtype='int64')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11326" href="#t11326">11326</a></span><span class="t"><span class="str">          filter_tag = layers.data(name='Filter_tag', shape=[-1,16], dtype='int64')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11327" href="#t11327">11327</a></span><span class="t"><span class="str">          out, loss_weight = layers.filter_by_instag(ins,  ins_tag,  filter_tag, True)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11328" href="#t11328">11328</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11329" href="#t11329">11329</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11330" href="#t11330">11330</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'filter_by_instag'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11331" href="#t11331">11331</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11332" href="#t11332">11332</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">ins</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11333" href="#t11333">11333</a></span><span class="t">    <span class="nam">loss_weight</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">np</span><span class="op">.</span><span class="nam">float64</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11334" href="#t11334">11334</a></span><span class="t">    <span class="nam">mmap</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">ins_tag</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11335" href="#t11335">11335</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11336" href="#t11336">11336</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'filter_by_instag'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11337" href="#t11337">11337</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Ins'</span><span class="op">:</span> <span class="nam">ins</span><span class="op">,</span> <span class="str">'Ins_tag'</span><span class="op">:</span> <span class="nam">ins_tag</span><span class="op">,</span> <span class="str">'Filter_tag'</span><span class="op">:</span> <span class="nam">filter_tag</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11338" href="#t11338">11338</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">,</span> <span class="str">'LossWeight'</span><span class="op">:</span> <span class="nam">loss_weight</span><span class="op">,</span> <span class="str">'IndexMap'</span><span class="op">:</span> <span class="nam">mmap</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11339" href="#t11339">11339</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'is_lod'</span><span class="op">:</span> <span class="nam">is_lod</span><span class="op">,</span> <span class="str">'out_val_if_empty'</span><span class="op">:</span> <span class="nam">out_val_if_empty</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11340" href="#t11340">11340</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11341" href="#t11341">11341</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11342" href="#t11342">11342</a></span><span class="t">    <span class="key">return</span> <span class="op">[</span><span class="nam">out</span><span class="op">,</span> <span class="nam">loss_weight</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11343" href="#t11343">11343</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11344" href="#t11344">11344</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11345" href="#t11345">11345</a></span><span class="t"><span class="key">def</span> <span class="nam">unstack</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="num">0</span><span class="op">,</span> <span class="nam">num</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11346" href="#t11346">11346</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11347" href="#t11347">11347</a></span><span class="t"><span class="str">    :alias_main: paddle.unstack</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11348" href="#t11348">11348</a></span><span class="t"><span class="str">        :alias: paddle.unstack,paddle.tensor.unstack,paddle.tensor.manipulation.unstack</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11349" href="#t11349">11349</a></span><span class="t"><span class="str">        :old_api: paddle.fluid.layers.unstack</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11350" href="#t11350">11350</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11351" href="#t11351">11351</a></span><span class="t"><span class="str">    **UnStack Layer**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11352" href="#t11352">11352</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11353" href="#t11353">11353</a></span><span class="t"><span class="str">    This layer unstacks input Tensor :code:`x` into several Tensors along :code:`axis`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11354" href="#t11354">11354</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11355" href="#t11355">11355</a></span><span class="t"><span class="str">    If :code:`axis` &lt; 0, it would be replaced with :code:`axis+rank(x)`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11356" href="#t11356">11356</a></span><span class="t"><span class="str">    If :code:`num` is None, it would be inferred from :code:`x.shape[axis]`,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11357" href="#t11357">11357</a></span><span class="t"><span class="str">    and if :code:`x.shape[axis]` &lt;= 0 or is unknown, :code:`ValueError` is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11358" href="#t11358">11358</a></span><span class="t"><span class="str">    raised.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11359" href="#t11359">11359</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11360" href="#t11360">11360</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11361" href="#t11361">11361</a></span><span class="t"><span class="str">        x (Tensor): Input Tensor. It is a N-D Tensors of data types float32, float64, int32, int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11362" href="#t11362">11362</a></span><span class="t"><span class="str">        axis (int): The axis along which the input is unstacked.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11363" href="#t11363">11363</a></span><span class="t"><span class="str">        num (int|None): The number of output variables.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11364" href="#t11364">11364</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11365" href="#t11365">11365</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11366" href="#t11366">11366</a></span><span class="t"><span class="str">        list(Tensor): The unstacked Tensors list. The list elements are N-D Tensors of data types float32, float64, int32, int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11367" href="#t11367">11367</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11368" href="#t11368">11368</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11369" href="#t11369">11369</a></span><span class="t"><span class="str">        ValueError: If x.shape[axis] &lt;= 0 or axis is not in range [-D, D).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11370" href="#t11370">11370</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11371" href="#t11371">11371</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11372" href="#t11372">11372</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11373" href="#t11373">11373</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11374" href="#t11374">11374</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11375" href="#t11375">11375</a></span><span class="t"><span class="str">            x = paddle.ones(name='x', shape=[2, 3, 5], dtype='float32')  # create a tensor with shape=[2, 3, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11376" href="#t11376">11376</a></span><span class="t"><span class="str">            y = paddle.unstack(x, axis=1)  # unstack with second axis, which results 3 tensors with shape=[2, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11377" href="#t11377">11377</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11378" href="#t11378">11378</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11379" href="#t11379">11379</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11380" href="#t11380">11380</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11381" href="#t11381">11381</a></span><span class="t">        <span class="key">if</span> <span class="nam">num</span> <span class="op">==</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11382" href="#t11382">11382</a></span><span class="t">            <span class="nam">num</span> <span class="op">=</span> <span class="nam">x</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="nam">axis</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11383" href="#t11383">11383</a></span><span class="t">        <span class="key">if</span> <span class="nam">num</span> <span class="op">==</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11384" href="#t11384">11384</a></span><span class="t">            <span class="key">return</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11385" href="#t11385">11385</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">unstack</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">num</span><span class="op">,</span> <span class="str">'axis'</span><span class="op">,</span> <span class="nam">int</span><span class="op">(</span><span class="nam">axis</span><span class="op">)</span><span class="op">,</span> <span class="str">'num'</span><span class="op">,</span> <span class="nam">num</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11386" href="#t11386">11386</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11387" href="#t11387">11387</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'unstack'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11388" href="#t11388">11388</a></span><span class="t">    <span class="key">if</span> <span class="nam">num</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11389" href="#t11389">11389</a></span><span class="t">        <span class="key">if</span> <span class="nam">axis</span> <span class="key">is</span> <span class="key">None</span> <span class="key">or</span> <span class="nam">x</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="nam">axis</span><span class="op">]</span> <span class="op">&lt;=</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11390" href="#t11390">11390</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">'unknown unstack number'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11391" href="#t11391">11391</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11392" href="#t11392">11392</a></span><span class="t">            <span class="nam">num</span> <span class="op">=</span> <span class="nam">x</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="nam">axis</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11393" href="#t11393">11393</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11394" href="#t11394">11394</a></span><span class="t">    <span class="nam">outs</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11395" href="#t11395">11395</a></span><span class="t">    <span class="key">for</span> <span class="nam">_</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">num</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11396" href="#t11396">11396</a></span><span class="t">        <span class="nam">outs</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11397" href="#t11397">11397</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11398" href="#t11398">11398</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11399" href="#t11399">11399</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'unstack'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11400" href="#t11400">11400</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="op">[</span><span class="nam">x</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11401" href="#t11401">11401</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Y'</span><span class="op">:</span> <span class="nam">outs</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11402" href="#t11402">11402</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'axis'</span><span class="op">:</span> <span class="nam">axis</span><span class="op">,</span> <span class="str">'num'</span><span class="op">:</span> <span class="nam">num</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11403" href="#t11403">11403</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11404" href="#t11404">11404</a></span><span class="t">    <span class="key">return</span> <span class="nam">outs</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11405" href="#t11405">11405</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11406" href="#t11406">11406</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11407" href="#t11407">11407</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">'2.0.0'</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.expand"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11408" href="#t11408">11408</a></span><span class="t"><span class="key">def</span> <span class="nam">expand</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">expand_times</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11409" href="#t11409">11409</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11410" href="#t11410">11410</a></span><span class="t"><span class="str">    :alias_main: paddle.expand</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11411" href="#t11411">11411</a></span><span class="t"><span class="str">        :alias: paddle.expand,paddle.tensor.expand,paddle.tensor.manipulation.expand</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11412" href="#t11412">11412</a></span><span class="t"><span class="str">        :old_api: paddle.fluid.layers.expand</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11413" href="#t11413">11413</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11414" href="#t11414">11414</a></span><span class="t"><span class="str">    This operation tiles ``x`` multiple times according to the parameter ``expand_times``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11415" href="#t11415">11415</a></span><span class="t"><span class="str">    The times number for each dimension of ``x`` is set by the parameter ``expand_times``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11416" href="#t11416">11416</a></span><span class="t"><span class="str">    The rank of ``x`` should be less than or equal to 6. Please note that size of ``expand_times`` must be the same</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11417" href="#t11417">11417</a></span><span class="t"><span class="str">    with X's rank. Following is a using case:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11418" href="#t11418">11418</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11419" href="#t11419">11419</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11420" href="#t11420">11420</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11421" href="#t11421">11421</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11422" href="#t11422">11422</a></span><span class="t"><span class="str">        Input(X) is a 3-D tensor with shape [2, 3, 1]:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11423" href="#t11423">11423</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11424" href="#t11424">11424</a></span><span class="t"><span class="str">                [</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11425" href="#t11425">11425</a></span><span class="t"><span class="str">                   [[1], [2], [3]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11426" href="#t11426">11426</a></span><span class="t"><span class="str">                   [[4], [5], [6]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11427" href="#t11427">11427</a></span><span class="t"><span class="str">                ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11428" href="#t11428">11428</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11429" href="#t11429">11429</a></span><span class="t"><span class="str">        Attr(expand_times):  [1, 2, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11430" href="#t11430">11430</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11431" href="#t11431">11431</a></span><span class="t"><span class="str">        Output(Out) is a 3-D tensor with shape [2, 6, 2]:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11432" href="#t11432">11432</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11433" href="#t11433">11433</a></span><span class="t"><span class="str">                [</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11434" href="#t11434">11434</a></span><span class="t"><span class="str">                    [[1, 1], [2, 2], [3, 3], [1, 1], [2, 2], [3, 3]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11435" href="#t11435">11435</a></span><span class="t"><span class="str">                    [[4, 4], [5, 5], [6, 6], [4, 4], [5, 5], [6, 6]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11436" href="#t11436">11436</a></span><span class="t"><span class="str">                ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11437" href="#t11437">11437</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11438" href="#t11438">11438</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11439" href="#t11439">11439</a></span><span class="t"><span class="str">        x (Variable): A ``Tensor`` or ``LoDTensor`` with dimension in [1, 6]. The data type is ``bool``, ``float32``, ``float64`` or ``int32`` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11440" href="#t11440">11440</a></span><span class="t"><span class="str">        expand_times (list|tuple|Variable): The data type is ``int32`` . If ``expand_times`` is a list or tuple, the elements of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11441" href="#t11441">11441</a></span><span class="t"><span class="str">                it should be integers or Tensors with shape [1]. If ``expand_times`` is an Variable, it should be an 1-D Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11442" href="#t11442">11442</a></span><span class="t"><span class="str">                Expand times number for each dimension of ``x`` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11443" href="#t11443">11443</a></span><span class="t"><span class="str">        name (str, optional): The default value is None. Normally there is no need for user to set this property. For more information, please refer to :ref:`api_guide_Name` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11444" href="#t11444">11444</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11445" href="#t11445">11445</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11446" href="#t11446">11446</a></span><span class="t"><span class="str">        Variable: A ``Tensor`` or ``LoDTensor``. The data type is same as ``x``. After expanding, size of each dimension of output is equal to the size of the corresponding dimension of ``x`` multiplying the corresponding value given by ``expand_times`` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11447" href="#t11447">11447</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11448" href="#t11448">11448</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11449" href="#t11449">11449</a></span><span class="t"><span class="str">        TypeError: The type of ``expand_times`` must be list, tuple or Variable.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11450" href="#t11450">11450</a></span><span class="t"><span class="str">        ValueError: The elements of ``expand_times`` cannot be negative.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11451" href="#t11451">11451</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11452" href="#t11452">11452</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11453" href="#t11453">11453</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11454" href="#t11454">11454</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11455" href="#t11455">11455</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11456" href="#t11456">11456</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11457" href="#t11457">11457</a></span><span class="t"><span class="str">            # example 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11458" href="#t11458">11458</a></span><span class="t"><span class="str">            data_1 = fluid.layers.fill_constant(shape=[2, 3, 1], dtype='int32', value=0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11459" href="#t11459">11459</a></span><span class="t"><span class="str">            expanded_1 = fluid.layers.expand(data_1, expand_times=[1, 2, 2])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11460" href="#t11460">11460</a></span><span class="t"><span class="str">            # the shape of expanded_1 is [2, 6, 2].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11461" href="#t11461">11461</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11462" href="#t11462">11462</a></span><span class="t"><span class="str">            # example 2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11463" href="#t11463">11463</a></span><span class="t"><span class="str">            data_2 = fluid.layers.fill_constant(shape=[12, 14], dtype="int32", value=3)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11464" href="#t11464">11464</a></span><span class="t"><span class="str">            expand_times = fluid.layers.fill_constant(shape=[2], dtype="int32", value=4)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11465" href="#t11465">11465</a></span><span class="t"><span class="str">            expanded_2 = fluid.layers.expand(data_2, expand_times=expand_times)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11466" href="#t11466">11466</a></span><span class="t"><span class="str">            # the shape of expanded_2 is [48, 56].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11467" href="#t11467">11467</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11468" href="#t11468">11468</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11469" href="#t11469">11469</a></span><span class="t">        <span class="nam">attrs</span> <span class="op">=</span> <span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11470" href="#t11470">11470</a></span><span class="t">        <span class="nam">expand_times_tensor</span> <span class="op">=</span> <span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11471" href="#t11471">11471</a></span><span class="t">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">expand_times</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11472" href="#t11472">11472</a></span><span class="t">            <span class="nam">expand_times</span> <span class="op">=</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11473" href="#t11473">11473</a></span><span class="t">                <span class="nam">item</span><span class="op">.</span><span class="nam">numpy</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">item</span><span class="op">(</span><span class="num">0</span><span class="op">)</span> <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">item</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span> <span class="key">else</span> <span class="nam">item</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11474" href="#t11474">11474</a></span><span class="t">                <span class="key">for</span> <span class="nam">item</span> <span class="key">in</span> <span class="nam">expand_times</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11475" href="#t11475">11475</a></span><span class="t">            <span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11476" href="#t11476">11476</a></span><span class="t">            <span class="nam">attrs</span> <span class="op">+=</span> <span class="op">(</span><span class="str">'expand_times'</span><span class="op">,</span> <span class="nam">expand_times</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11477" href="#t11477">11477</a></span><span class="t">        <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">expand_times</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11478" href="#t11478">11478</a></span><span class="t">            <span class="nam">expand_times_tensor</span> <span class="op">=</span> <span class="nam">expand_times</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11479" href="#t11479">11479</a></span><span class="t">            <span class="nam">expand_times_tensor</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11480" href="#t11480">11480</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11481" href="#t11481">11481</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">expand</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">expand_times_tensor</span><span class="op">,</span> <span class="op">*</span><span class="nam">attrs</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11482" href="#t11482">11482</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11483" href="#t11483">11483</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="op">[</span><span class="nam">x</span><span class="op">]</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11484" href="#t11484">11484</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11485" href="#t11485">11485</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11486" href="#t11486">11486</a></span><span class="t">        <span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11487" href="#t11487">11487</a></span><span class="t">        <span class="str">'x'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11488" href="#t11488">11488</a></span><span class="t">        <span class="op">[</span><span class="str">'bool'</span><span class="op">,</span> <span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11489" href="#t11489">11489</a></span><span class="t">        <span class="str">'expand'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11490" href="#t11490">11490</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11491" href="#t11491">11491</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">expand_times</span><span class="op">,</span> <span class="str">'expand_times'</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">,</span> <span class="str">'expand'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11492" href="#t11492">11492</a></span><span class="t">    <span class="key">if</span> <span class="nam">convert_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span> <span class="op">==</span> <span class="str">'bool'</span> <span class="key">and</span> <span class="nam">x</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">==</span> <span class="key">True</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11493" href="#t11493">11493</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11494" href="#t11494">11494</a></span><span class="t">            <span class="str">"expand op bool date type must set the stop_gradient to be False"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11495" href="#t11495">11495</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11496" href="#t11496">11496</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11497" href="#t11497">11497</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'expand'</span><span class="op">,</span> <span class="nam">input</span><span class="op">=</span><span class="nam">x</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11498" href="#t11498">11498</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11499" href="#t11499">11499</a></span><span class="t">    <span class="key">def</span> <span class="nam">get_attr_expand_times</span><span class="op">(</span><span class="nam">list_expand_times</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11500" href="#t11500">11500</a></span><span class="t">        <span class="nam">attrs_expand_times</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11501" href="#t11501">11501</a></span><span class="t">        <span class="key">for</span> <span class="nam">idx</span><span class="op">,</span> <span class="nam">times</span> <span class="key">in</span> <span class="nam">enumerate</span><span class="op">(</span><span class="nam">list_expand_times</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11502" href="#t11502">11502</a></span><span class="t">            <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">times</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11503" href="#t11503">11503</a></span><span class="t">                <span class="nam">attrs_expand_times</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="op">-</span><span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11504" href="#t11504">11504</a></span><span class="t">            <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11505" href="#t11505">11505</a></span><span class="t">                <span class="nam">attrs_expand_times</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">times</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11506" href="#t11506">11506</a></span><span class="t">                <span class="key">assert</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11507" href="#t11507">11507</a></span><span class="t">                    <span class="nam">times</span> <span class="op">></span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11508" href="#t11508">11508</a></span><span class="t">                <span class="op">)</span><span class="op">,</span> <span class="str">"Each element given in expand_times must not be negative."</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11509" href="#t11509">11509</a></span><span class="t">        <span class="key">return</span> <span class="nam">attrs_expand_times</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11510" href="#t11510">11510</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11511" href="#t11511">11511</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">expand_times</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11512" href="#t11512">11512</a></span><span class="t">        <span class="nam">expand_times</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11513" href="#t11513">11513</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">'ExpandTimes'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">expand_times</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11514" href="#t11514">11514</a></span><span class="t">    <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">expand_times</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11515" href="#t11515">11515</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">'expand_times'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">get_attr_expand_times</span><span class="op">(</span><span class="nam">expand_times</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11516" href="#t11516">11516</a></span><span class="t">        <span class="key">if</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_contain_var</span><span class="op">(</span><span class="nam">expand_times</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11517" href="#t11517">11517</a></span><span class="t">            <span class="nam">inputs</span><span class="op">[</span><span class="str">'expand_times_tensor'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_convert_to_tensor_list</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11518" href="#t11518">11518</a></span><span class="t">                <span class="nam">expand_times</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11519" href="#t11519">11519</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11520" href="#t11520">11520</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11521" href="#t11521">11521</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="nam">input_param_name</span><span class="op">=</span><span class="str">'x'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11522" href="#t11522">11522</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11523" href="#t11523">11523</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11524" href="#t11524">11524</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'expand'</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span> <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11525" href="#t11525">11525</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11526" href="#t11526">11526</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11527" href="#t11527">11527</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11528" href="#t11528">11528</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11529" href="#t11529">11529</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">'2.0.0'</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.expand_as"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11530" href="#t11530">11530</a></span><span class="t"><span class="key">def</span> <span class="nam">expand_as</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">target_tensor</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11531" href="#t11531">11531</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11532" href="#t11532">11532</a></span><span class="t"><span class="str">    :alias_main: paddle.expand_as</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11533" href="#t11533">11533</a></span><span class="t"><span class="str">        :alias: paddle.expand_as,paddle.tensor.expand_as,paddle.tensor.manipulation.expand_as</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11534" href="#t11534">11534</a></span><span class="t"><span class="str">        :old_api: paddle.fluid.layers.expand_as</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11535" href="#t11535">11535</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11536" href="#t11536">11536</a></span><span class="t"><span class="str">    expand_as operator tiles to the input by given expand tensor. You should set expand tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11537" href="#t11537">11537</a></span><span class="t"><span class="str">    for each dimension by providing tensor 'target_tensor'. The rank of X</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11538" href="#t11538">11538</a></span><span class="t"><span class="str">    should be in [1, 6]. Please note that size of 'target_tensor' must be the same</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11539" href="#t11539">11539</a></span><span class="t"><span class="str">    with X's rank. Following is a using case:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11540" href="#t11540">11540</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11541" href="#t11541">11541</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11542" href="#t11542">11542</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11543" href="#t11543">11543</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11544" href="#t11544">11544</a></span><span class="t"><span class="str">        Input(X) is a 3-D tensor with shape [2, 3, 1]:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11545" href="#t11545">11545</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11546" href="#t11546">11546</a></span><span class="t"><span class="str">                [</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11547" href="#t11547">11547</a></span><span class="t"><span class="str">                   [[1], [2], [3]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11548" href="#t11548">11548</a></span><span class="t"><span class="str">                   [[4], [5], [6]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11549" href="#t11549">11549</a></span><span class="t"><span class="str">                ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11550" href="#t11550">11550</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11551" href="#t11551">11551</a></span><span class="t"><span class="str">        target_tensor's shape:  [2, 6, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11552" href="#t11552">11552</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11553" href="#t11553">11553</a></span><span class="t"><span class="str">        Output(Out) is a 3-D tensor with shape [2, 6, 2]:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11554" href="#t11554">11554</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11555" href="#t11555">11555</a></span><span class="t"><span class="str">                [</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11556" href="#t11556">11556</a></span><span class="t"><span class="str">                    [[1, 1], [2, 2], [3, 3], [1, 1], [2, 2], [3, 3]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11557" href="#t11557">11557</a></span><span class="t"><span class="str">                    [[4, 4], [5, 5], [6, 6], [4, 4], [5, 5], [6, 6]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11558" href="#t11558">11558</a></span><span class="t"><span class="str">                ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11559" href="#t11559">11559</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11560" href="#t11560">11560</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11561" href="#t11561">11561</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11562" href="#t11562">11562</a></span><span class="t"><span class="str">        x (Variable): A Tensor with dtype float64, float32, int32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11563" href="#t11563">11563</a></span><span class="t"><span class="str">        A tensor with rank in [1, 6].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11564" href="#t11564">11564</a></span><span class="t"><span class="str">        target_tensor (Variable): A Tensor with dtype float64, float32, int32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11565" href="#t11565">11565</a></span><span class="t"><span class="str">        target_tensor for expanding to Input(X). Only use target_tensor'shape.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11566" href="#t11566">11566</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11567" href="#t11567">11567</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11568" href="#t11568">11568</a></span><span class="t"><span class="str">        Variable: A Tensor with dtype float64, float32, int32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11569" href="#t11569">11569</a></span><span class="t"><span class="str">        After expanding, size of each dimension of Output(Out) is equal to the size</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11570" href="#t11570">11570</a></span><span class="t"><span class="str">        of the corresponding dimension of target_tensor multiplying the corresponding</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11571" href="#t11571">11571</a></span><span class="t"><span class="str">        value given by target_tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11572" href="#t11572">11572</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11573" href="#t11573">11573</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11574" href="#t11574">11574</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11575" href="#t11575">11575</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11576" href="#t11576">11576</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11577" href="#t11577">11577</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11578" href="#t11578">11578</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11579" href="#t11579">11579</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11580" href="#t11580">11580</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11581" href="#t11581">11581</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11582" href="#t11582">11582</a></span><span class="t"><span class="str">            data = fluid.layers.data(name="data", shape=[-1,10], dtype='float64')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11583" href="#t11583">11583</a></span><span class="t"><span class="str">            target_tensor = fluid.layers.data(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11584" href="#t11584">11584</a></span><span class="t"><span class="str">              name="target_tensor", shape=[-1,20], dtype='float64')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11585" href="#t11585">11585</a></span><span class="t"><span class="str">            result = fluid.layers.expand_as(x=data, target_tensor=target_tensor)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11586" href="#t11586">11586</a></span><span class="t"><span class="str">            use_cuda = False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11587" href="#t11587">11587</a></span><span class="t"><span class="str">            place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11588" href="#t11588">11588</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11589" href="#t11589">11589</a></span><span class="t"><span class="str">            exe.run(fluid.default_startup_program())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11590" href="#t11590">11590</a></span><span class="t"><span class="str">            x = np.random.rand(3,10)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11591" href="#t11591">11591</a></span><span class="t"><span class="str">            y = np.random.rand(3,20)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11592" href="#t11592">11592</a></span><span class="t"><span class="str">            output= exe.run(feed={"data":x,"target_tensor":y},fetch_list=[result.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11593" href="#t11593">11593</a></span><span class="t"><span class="str">            print(output[0].shape)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11594" href="#t11594">11594</a></span><span class="t"><span class="str">            #(3,20)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11595" href="#t11595">11595</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11596" href="#t11596">11596</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11597" href="#t11597">11597</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11598" href="#t11598">11598</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">expand_as</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">target_tensor</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11599" href="#t11599">11599</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11600" href="#t11600">11600</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11601" href="#t11601">11601</a></span><span class="t">        <span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">,</span> <span class="str">'bool'</span><span class="op">]</span><span class="op">,</span> <span class="str">'expand_as'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11602" href="#t11602">11602</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11603" href="#t11603">11603</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11604" href="#t11604">11604</a></span><span class="t">        <span class="nam">target_tensor</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11605" href="#t11605">11605</a></span><span class="t">        <span class="str">'target_tensor'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11606" href="#t11606">11606</a></span><span class="t">        <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">,</span> <span class="str">'bool'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11607" href="#t11607">11607</a></span><span class="t">        <span class="str">'expand_as'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11608" href="#t11608">11608</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11609" href="#t11609">11609</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'expand_as'</span><span class="op">,</span> <span class="nam">input</span><span class="op">=</span><span class="nam">x</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11610" href="#t11610">11610</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="nam">input_param_name</span><span class="op">=</span><span class="str">'x'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11611" href="#t11611">11611</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11612" href="#t11612">11612</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">,</span> <span class="str">'target_tensor'</span><span class="op">:</span> <span class="nam">target_tensor</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11613" href="#t11613">11613</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">'expand_as'</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11614" href="#t11614">11614</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11615" href="#t11615">11615</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11616" href="#t11616">11616</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11617" href="#t11617">11617</a></span><span class="t"><span class="key">from</span> <span class="nam">paddle</span><span class="op">.</span><span class="nam">fluid</span><span class="op">.</span><span class="nam">framework</span> <span class="key">import</span> <span class="nam">convert_np_dtype_to_dtype_</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11618" href="#t11618">11618</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11619" href="#t11619">11619</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11620" href="#t11620">11620</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">'1.8.0'</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.uniform"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11621" href="#t11621">11621</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11622" href="#t11622">11622</a></span><span class="t"><span class="key">def</span> <span class="nam">uniform_random_batch_size_like</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11623" href="#t11623">11623</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11624" href="#t11624">11624</a></span><span class="t">    <span class="nam">shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11625" href="#t11625">11625</a></span><span class="t">    <span class="nam">dtype</span><span class="op">=</span><span class="str">'float32'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11626" href="#t11626">11626</a></span><span class="t">    <span class="nam">input_dim_idx</span><span class="op">=</span><span class="num">0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11627" href="#t11627">11627</a></span><span class="t">    <span class="nam">output_dim_idx</span><span class="op">=</span><span class="num">0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11628" href="#t11628">11628</a></span><span class="t">    <span class="nam">min</span><span class="op">=</span><span class="op">-</span><span class="num">1.0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11629" href="#t11629">11629</a></span><span class="t">    <span class="nam">max</span><span class="op">=</span><span class="num">1.0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11630" href="#t11630">11630</a></span><span class="t">    <span class="nam">seed</span><span class="op">=</span><span class="num">0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11631" href="#t11631">11631</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11632" href="#t11632">11632</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11633" href="#t11633">11633</a></span><span class="t"><span class="str">    This OP initializes a variable with random values sampled from a</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11634" href="#t11634">11634</a></span><span class="t"><span class="str">    uniform distribution in the range [min, max). The input_dim_idx used to get the input dimension value which will be used to resize the output dimension.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11635" href="#t11635">11635</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11636" href="#t11636">11636</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11637" href="#t11637">11637</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11638" href="#t11638">11638</a></span><span class="t"><span class="str">        *Case 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11639" href="#t11639">11639</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11640" href="#t11640">11640</a></span><span class="t"><span class="str">            Given:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11641" href="#t11641">11641</a></span><span class="t"><span class="str">                input =[[0.946741  , 0.1357001 , 0.38086128]]    # input.shape=[1,3]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11642" href="#t11642">11642</a></span><span class="t"><span class="str">                shape=[2,4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11643" href="#t11643">11643</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11644" href="#t11644">11644</a></span><span class="t"><span class="str">            result.shape[output_dim_idx] = input.shape[input_dim_idx],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11645" href="#t11645">11645</a></span><span class="t"><span class="str">            output_dim_idx = 0,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11646" href="#t11646">11646</a></span><span class="t"><span class="str">            input_dim_idx = 0,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11647" href="#t11647">11647</a></span><span class="t"><span class="str">            result.shape[0] = input.shape[0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11648" href="#t11648">11648</a></span><span class="t"><span class="str">            then:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11649" href="#t11649">11649</a></span><span class="t"><span class="str">                result=[[ 0.3443427 , -0.23056602,  0.3477049 ,  0.06139076]]    # result.shape=[1,4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11650" href="#t11650">11650</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11651" href="#t11651">11651</a></span><span class="t"><span class="str">       *Case 2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11652" href="#t11652">11652</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11653" href="#t11653">11653</a></span><span class="t"><span class="str">           Given:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11654" href="#t11654">11654</a></span><span class="t"><span class="str">               input =[[0.946741  , 0.1357001 , 0.38086128]]     # input.shape=[1,3]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11655" href="#t11655">11655</a></span><span class="t"><span class="str">               shape=[2,4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11656" href="#t11656">11656</a></span><span class="t"><span class="str">               input_dim_idx=1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11657" href="#t11657">11657</a></span><span class="t"><span class="str">               output_dim_idx=1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11658" href="#t11658">11658</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11659" href="#t11659">11659</a></span><span class="t"><span class="str">           result.shape[output_dim_idx] = input.shape[input_dim_idx],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11660" href="#t11660">11660</a></span><span class="t"><span class="str">           output_dim_idx = 1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11661" href="#t11661">11661</a></span><span class="t"><span class="str">           input_dim_idx = 1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11662" href="#t11662">11662</a></span><span class="t"><span class="str">           result.shape[1] = input.shape[1],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11663" href="#t11663">11663</a></span><span class="t"><span class="str">           then:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11664" href="#t11664">11664</a></span><span class="t"><span class="str">               result=[[-0.23133647, -0.84195036,  0.21441269],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11665" href="#t11665">11665</a></span><span class="t"><span class="str">                       [-0.08774924,  0.25605237, -0.09403259]]    # result.shape=[2,3]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11666" href="#t11666">11666</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11667" href="#t11667">11667</a></span><span class="t"><span class="str">        input (Variable): A Tensor. Supported data types: float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11668" href="#t11668">11668</a></span><span class="t"><span class="str">        shape (tuple|list): A python list or python tuple. The shape of the output Tensor, the data type is int.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11669" href="#t11669">11669</a></span><span class="t"><span class="str">        input_dim_idx (int, optional): An index used to get the input dimension value which will be used to resize the output dimension. Default  0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11670" href="#t11670">11670</a></span><span class="t"><span class="str">        output_dim_idx (int, optional): An index used to indicate the specific dimension that will be replaced by corresponding input dimension value. Default 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11671" href="#t11671">11671</a></span><span class="t"><span class="str">        min (float, optional): The lower bound on the range of random values to generate, the min is included in the range. Default -1.0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11672" href="#t11672">11672</a></span><span class="t"><span class="str">        max (float, optional): The upper bound on the range of random values to generate, the max is excluded in the range. Default 1.0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11673" href="#t11673">11673</a></span><span class="t"><span class="str">        seed (int, optional):  Random seed used for generating samples. 0 means use a seed generated by the system.Note that if seed is not 0, this operator will always generate the same random numbers every time.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11674" href="#t11674">11674</a></span><span class="t"><span class="str">        dtype(np.dtype|core.VarDesc.VarType|str, optional): The data type of output Tensor. Supported data types: float32, float64. Default float32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11675" href="#t11675">11675</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11676" href="#t11676">11676</a></span><span class="t"><span class="str">        Variable: A Tensor of the specified shape filled with uniform_random values. The shape of the Tensor is determined by the shape parameter and the specified dimension of the input Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11677" href="#t11677">11677</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11678" href="#t11678">11678</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11679" href="#t11679">11679</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11680" href="#t11680">11680</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11681" href="#t11681">11681</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11682" href="#t11682">11682</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11683" href="#t11683">11683</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11684" href="#t11684">11684</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11685" href="#t11685">11685</a></span><span class="t"><span class="str">            # example 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11686" href="#t11686">11686</a></span><span class="t"><span class="str">            input = fluid.data(name="input", shape=[1, 3], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11687" href="#t11687">11687</a></span><span class="t"><span class="str">            out_1 = fluid.layers.uniform_random_batch_size_like(input, [2, 4]) # out_1.shape=[1, 4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11688" href="#t11688">11688</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11689" href="#t11689">11689</a></span><span class="t"><span class="str">            # example 2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11690" href="#t11690">11690</a></span><span class="t"><span class="str">            out_2 = fluid.layers.uniform_random_batch_size_like(input, [2, 4], input_dim_idx=1, output_dim_idx=1) # out_2.shape=[2, 3]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11691" href="#t11691">11691</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11692" href="#t11692">11692</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11693" href="#t11693">11693</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11694" href="#t11694">11694</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11695" href="#t11695">11695</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11696" href="#t11696">11696</a></span><span class="t">        <span class="str">'Input'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11697" href="#t11697">11697</a></span><span class="t">        <span class="op">(</span><span class="str">"float32"</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">"uint16"</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11698" href="#t11698">11698</a></span><span class="t">        <span class="str">'uniform_random_batch_size_like'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11699" href="#t11699">11699</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11700" href="#t11700">11700</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">shape</span><span class="op">,</span> <span class="str">'shape'</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">,</span> <span class="str">'uniform_random_batch_size_like'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11701" href="#t11701">11701</a></span><span class="t">    <span class="nam">check_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11702" href="#t11702">11702</a></span><span class="t">        <span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11703" href="#t11703">11703</a></span><span class="t">        <span class="str">'dtype'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11704" href="#t11704">11704</a></span><span class="t">        <span class="op">(</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">"uint16"</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11705" href="#t11705">11705</a></span><span class="t">        <span class="str">'uniform_random_batch_size_like'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11706" href="#t11706">11706</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11707" href="#t11707">11707</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11708" href="#t11708">11708</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'uniform_random_batch_size_like'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11709" href="#t11709">11709</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11710" href="#t11710">11710</a></span><span class="t">    <span class="nam">c_dtype</span> <span class="op">=</span> <span class="nam">convert_np_dtype_to_dtype_</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11711" href="#t11711">11711</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11712" href="#t11712">11712</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'uniform_random_batch_size_like'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11713" href="#t11713">11713</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Input'</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11714" href="#t11714">11714</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11715" href="#t11715">11715</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11716" href="#t11716">11716</a></span><span class="t">            <span class="str">'shape'</span><span class="op">:</span> <span class="nam">shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11717" href="#t11717">11717</a></span><span class="t">            <span class="str">'input_dim_idx'</span><span class="op">:</span> <span class="nam">input_dim_idx</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11718" href="#t11718">11718</a></span><span class="t">            <span class="str">'output_dim_idx'</span><span class="op">:</span> <span class="nam">output_dim_idx</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11719" href="#t11719">11719</a></span><span class="t">            <span class="str">'min'</span><span class="op">:</span> <span class="nam">min</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11720" href="#t11720">11720</a></span><span class="t">            <span class="str">'max'</span><span class="op">:</span> <span class="nam">max</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11721" href="#t11721">11721</a></span><span class="t">            <span class="str">'seed'</span><span class="op">:</span> <span class="nam">seed</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11722" href="#t11722">11722</a></span><span class="t">            <span class="str">'dtype'</span><span class="op">:</span> <span class="nam">c_dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11723" href="#t11723">11723</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11724" href="#t11724">11724</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11725" href="#t11725">11725</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11726" href="#t11726">11726</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11727" href="#t11727">11727</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11728" href="#t11728">11728</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11729" href="#t11729">11729</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.normal"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11730" href="#t11730">11730</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11731" href="#t11731">11731</a></span><span class="t"><span class="key">def</span> <span class="nam">gaussian_random</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11732" href="#t11732">11732</a></span><span class="t">    <span class="nam">shape</span><span class="op">,</span> <span class="nam">mean</span><span class="op">=</span><span class="num">0.0</span><span class="op">,</span> <span class="nam">std</span><span class="op">=</span><span class="num">1.0</span><span class="op">,</span> <span class="nam">seed</span><span class="op">=</span><span class="num">0</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="str">'float32'</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11733" href="#t11733">11733</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11734" href="#t11734">11734</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11735" href="#t11735">11735</a></span><span class="t"><span class="str">    This OP returns a Tensor filled with random values sampled from a Gaussian</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11736" href="#t11736">11736</a></span><span class="t"><span class="str">    distribution, with ``shape`` and ``dtype``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11737" href="#t11737">11737</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11738" href="#t11738">11738</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11739" href="#t11739">11739</a></span><span class="t"><span class="str">        shape(list|tuple|Tensor): The shape of the output Tensor. If ``shape``</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11740" href="#t11740">11740</a></span><span class="t"><span class="str">            is a list or tuple, the elements of it should be integers or Tensors</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11741" href="#t11741">11741</a></span><span class="t"><span class="str">            (with the shape [1], and the data type int32 or int64). If ``shape``</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11742" href="#t11742">11742</a></span><span class="t"><span class="str">            is a Tensor, it should be a 1-D Tensor(with the data type int32 or</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11743" href="#t11743">11743</a></span><span class="t"><span class="str">            int64).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11744" href="#t11744">11744</a></span><span class="t"><span class="str">        mean(float|int, optional): Mean of the output tensor, default is 0.0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11745" href="#t11745">11745</a></span><span class="t"><span class="str">        std(float|int, optional): Standard deviation of the output tensor, default</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11746" href="#t11746">11746</a></span><span class="t"><span class="str">            is 1.0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11747" href="#t11747">11747</a></span><span class="t"><span class="str">        seed(int, optional): ${seed_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11748" href="#t11748">11748</a></span><span class="t"><span class="str">        dtype(str|np.dtype|core.VarDesc.VarType, optional): The data type of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11749" href="#t11749">11749</a></span><span class="t"><span class="str">            the output Tensor. Supported data types: float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11750" href="#t11750">11750</a></span><span class="t"><span class="str">            Default is float32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11751" href="#t11751">11751</a></span><span class="t"><span class="str">        name(str, optional): The default value is None. Normally there is no</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11752" href="#t11752">11752</a></span><span class="t"><span class="str">            need for user to set this property. For more information, please</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11753" href="#t11753">11753</a></span><span class="t"><span class="str">            refer to :ref:`api_guide_Name`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11754" href="#t11754">11754</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11755" href="#t11755">11755</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11756" href="#t11756">11756</a></span><span class="t"><span class="str">        Tensor: A Tensor filled with random values sampled from a Gaussian</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11757" href="#t11757">11757</a></span><span class="t"><span class="str">        distribution, with ``shape`` and ``dtype``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11758" href="#t11758">11758</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11759" href="#t11759">11759</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11760" href="#t11760">11760</a></span><span class="t"><span class="str">       .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11761" href="#t11761">11761</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11762" href="#t11762">11762</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11763" href="#t11763">11763</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11764" href="#t11764">11764</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11765" href="#t11765">11765</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11766" href="#t11766">11766</a></span><span class="t"><span class="str">            # example 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11767" href="#t11767">11767</a></span><span class="t"><span class="str">            # attr shape is a list which doesn't contain Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11768" href="#t11768">11768</a></span><span class="t"><span class="str">            result_1 = fluid.layers.gaussian_random(shape=[3, 4])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11769" href="#t11769">11769</a></span><span class="t"><span class="str">            # [[-0.31261674,  1.8736548,  -0.6274357,   0.96988016],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11770" href="#t11770">11770</a></span><span class="t"><span class="str">            #  [-0.12294637,  0.9554768,   1.5690808,  -1.2894802 ],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11771" href="#t11771">11771</a></span><span class="t"><span class="str">            #  [-0.60082096, -0.61138713,  1.5345167,  -0.21834975]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11772" href="#t11772">11772</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11773" href="#t11773">11773</a></span><span class="t"><span class="str">            # example 2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11774" href="#t11774">11774</a></span><span class="t"><span class="str">            # attr shape is a list which contains Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11775" href="#t11775">11775</a></span><span class="t"><span class="str">            dim_1 = fluid.layers.fill_constant([1], "int64", 2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11776" href="#t11776">11776</a></span><span class="t"><span class="str">            dim_2 = fluid.layers.fill_constant([1], "int32", 3)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11777" href="#t11777">11777</a></span><span class="t"><span class="str">            result_2 = fluid.layers.gaussian_random(shape=[dim_1, dim_2])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11778" href="#t11778">11778</a></span><span class="t"><span class="str">            # [[ 0.51398206, -0.3389769,   0.23597084],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11779" href="#t11779">11779</a></span><span class="t"><span class="str">            #  [ 1.0388143,  -1.2015356,  -1.0499583 ]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11780" href="#t11780">11780</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11781" href="#t11781">11781</a></span><span class="t"><span class="str">            # example 3:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11782" href="#t11782">11782</a></span><span class="t"><span class="str">            # attr shape is a Tensor, the data type must be int64 or int32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11783" href="#t11783">11783</a></span><span class="t"><span class="str">            var_shape = fluid.data(name='var_shape', shape=[2], dtype="int64")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11784" href="#t11784">11784</a></span><span class="t"><span class="str">            result_3 = fluid.layers.gaussian_random(var_shape)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11785" href="#t11785">11785</a></span><span class="t"><span class="str">            # if var_shape's value is [2, 3]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11786" href="#t11786">11786</a></span><span class="t"><span class="str">            # result_3 is:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11787" href="#t11787">11787</a></span><span class="t"><span class="str">            # [[-0.12310527,  0.8187662,   1.923219  ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11788" href="#t11788">11788</a></span><span class="t"><span class="str">            #  [ 0.70721835,  0.5210541,  -0.03214082]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11789" href="#t11789">11789</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11790" href="#t11790">11790</a></span><span class="t"><span class="str">       .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11791" href="#t11791">11791</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11792" href="#t11792">11792</a></span><span class="t"><span class="str">           # declarative mode</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11793" href="#t11793">11793</a></span><span class="t"><span class="str">           # required: skiptest</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11794" href="#t11794">11794</a></span><span class="t"><span class="str">           import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11795" href="#t11795">11795</a></span><span class="t"><span class="str">           from paddle import fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11796" href="#t11796">11796</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11797" href="#t11797">11797</a></span><span class="t"><span class="str">           x = fluid.layers.gaussian_random((2, 3), std=2., seed=10)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11798" href="#t11798">11798</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11799" href="#t11799">11799</a></span><span class="t"><span class="str">           place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11800" href="#t11800">11800</a></span><span class="t"><span class="str">           exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11801" href="#t11801">11801</a></span><span class="t"><span class="str">           start = fluid.default_startup_program()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11802" href="#t11802">11802</a></span><span class="t"><span class="str">           main = fluid.default_main_program()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11803" href="#t11803">11803</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11804" href="#t11804">11804</a></span><span class="t"><span class="str">           exe.run(start)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11805" href="#t11805">11805</a></span><span class="t"><span class="str">           x_np, = exe.run(main, feed={}, fetch_list=[x])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11806" href="#t11806">11806</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11807" href="#t11807">11807</a></span><span class="t"><span class="str">           x_np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11808" href="#t11808">11808</a></span><span class="t"><span class="str">           # array([[2.3060477, 2.676496 , 3.9911983],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11809" href="#t11809">11809</a></span><span class="t"><span class="str">           #        [0.9990833, 2.8675377, 2.2279181]], dtype=float32)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11810" href="#t11810">11810</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11811" href="#t11811">11811</a></span><span class="t"><span class="str">       .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11812" href="#t11812">11812</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11813" href="#t11813">11813</a></span><span class="t"><span class="str">           # imperative mode</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11814" href="#t11814">11814</a></span><span class="t"><span class="str">           import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11815" href="#t11815">11815</a></span><span class="t"><span class="str">           from paddle import fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11816" href="#t11816">11816</a></span><span class="t"><span class="str">           import paddle.fluid.dygraph as dg</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11817" href="#t11817">11817</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11818" href="#t11818">11818</a></span><span class="t"><span class="str">           place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11819" href="#t11819">11819</a></span><span class="t"><span class="str">           with dg.guard(place) as g:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11820" href="#t11820">11820</a></span><span class="t"><span class="str">               x = fluid.layers.gaussian_random((2, 4), mean=2., dtype="float32", seed=10)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11821" href="#t11821">11821</a></span><span class="t"><span class="str">               x_np = x.numpy()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11822" href="#t11822">11822</a></span><span class="t"><span class="str">           x_np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11823" href="#t11823">11823</a></span><span class="t"><span class="str">           # array([[2.3060477 , 2.676496  , 3.9911983 , 0.9990833 ],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11824" href="#t11824">11824</a></span><span class="t"><span class="str">           #        [2.8675377 , 2.2279181 , 0.79029655, 2.8447366 ]], dtype=float32)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11825" href="#t11825">11825</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t11826" href="#t11826">11826</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">core</span><span class="op">.</span><span class="nam">VarDesc</span><span class="op">.</span><span class="nam">VarType</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">11826&#x202F;&#x219B;&#x202F;11829</span><span class="annotate long">line 11826 didn't jump to line 11829, because the condition on line 11826 was never false</span></span></p>
    <p class="run"><span class="n"><a id="t11827" href="#t11827">11827</a></span><span class="t">        <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">convert_np_dtype_to_dtype_</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11828" href="#t11828">11828</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11829" href="#t11829">11829</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11830" href="#t11830">11830</a></span><span class="t">        <span class="nam">shape</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_shape_to_list</span><span class="op">(</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11831" href="#t11831">11831</a></span><span class="t">        <span class="nam">place</span> <span class="op">=</span> <span class="nam">_current_expected_place</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11832" href="#t11832">11832</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">gaussian_random</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11833" href="#t11833">11833</a></span><span class="t">            <span class="nam">shape</span><span class="op">,</span> <span class="nam">float</span><span class="op">(</span><span class="nam">mean</span><span class="op">)</span><span class="op">,</span> <span class="nam">float</span><span class="op">(</span><span class="nam">std</span><span class="op">)</span><span class="op">,</span> <span class="nam">seed</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">,</span> <span class="nam">place</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11834" href="#t11834">11834</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11835" href="#t11835">11835</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t11836" href="#t11836">11836</a></span><span class="t">    <span class="key">if</span> <span class="nam">_in_legacy_dygraph</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">11836&#x202F;&#x219B;&#x202F;11837</span><span class="annotate long">line 11836 didn't jump to line 11837, because the condition on line 11836 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11837" href="#t11837">11837</a></span><span class="t">        <span class="nam">shape</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_shape_to_list</span><span class="op">(</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11838" href="#t11838">11838</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">gaussian_random</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11839" href="#t11839">11839</a></span><span class="t">            <span class="str">'shape'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11840" href="#t11840">11840</a></span><span class="t">            <span class="nam">shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11841" href="#t11841">11841</a></span><span class="t">            <span class="str">'mean'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11842" href="#t11842">11842</a></span><span class="t">            <span class="nam">float</span><span class="op">(</span><span class="nam">mean</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11843" href="#t11843">11843</a></span><span class="t">            <span class="str">'std'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11844" href="#t11844">11844</a></span><span class="t">            <span class="nam">float</span><span class="op">(</span><span class="nam">std</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11845" href="#t11845">11845</a></span><span class="t">            <span class="str">'seed'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11846" href="#t11846">11846</a></span><span class="t">            <span class="nam">seed</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11847" href="#t11847">11847</a></span><span class="t">            <span class="str">'dtype'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11848" href="#t11848">11848</a></span><span class="t">            <span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11849" href="#t11849">11849</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11850" href="#t11850">11850</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11851" href="#t11851">11851</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">shape</span><span class="op">,</span> <span class="str">'shape'</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">,</span> <span class="str">'gaussian_random/randn'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11852" href="#t11852">11852</a></span><span class="t">    <span class="nam">check_dtype</span><span class="op">(</span><span class="nam">dtype</span><span class="op">,</span> <span class="str">'dtype'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'gaussian_random/randn'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11853" href="#t11853">11853</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11854" href="#t11854">11854</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11855" href="#t11855">11855</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11856" href="#t11856">11856</a></span><span class="t">        <span class="str">'mean'</span><span class="op">:</span> <span class="nam">mean</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11857" href="#t11857">11857</a></span><span class="t">        <span class="str">'std'</span><span class="op">:</span> <span class="nam">std</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11858" href="#t11858">11858</a></span><span class="t">        <span class="str">'seed'</span><span class="op">:</span> <span class="nam">seed</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11859" href="#t11859">11859</a></span><span class="t">        <span class="str">'dtype'</span><span class="op">:</span> <span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11860" href="#t11860">11860</a></span><span class="t">        <span class="str">'use_mkldnn'</span><span class="op">:</span> <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11861" href="#t11861">11861</a></span><span class="t">    <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11862" href="#t11862">11862</a></span><span class="t">    <span class="nam">utils</span><span class="op">.</span><span class="nam">get_shape_tensor_inputs</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11863" href="#t11863">11863</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span><span class="op">,</span> <span class="nam">shape</span><span class="op">=</span><span class="nam">shape</span><span class="op">,</span> <span class="nam">op_type</span><span class="op">=</span><span class="str">'gaussian_random/randn'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11864" href="#t11864">11864</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11865" href="#t11865">11865</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11866" href="#t11866">11866</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'gaussian_random'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11867" href="#t11867">11867</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11868" href="#t11868">11868</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11869" href="#t11869">11869</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'gaussian_random'</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span> <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11870" href="#t11870">11870</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11871" href="#t11871">11871</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11872" href="#t11872">11872</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11873" href="#t11873">11873</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11874" href="#t11874">11874</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11875" href="#t11875">11875</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11876" href="#t11876">11876</a></span><span class="t"><span class="key">def</span> <span class="nam">sampling_id</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">min</span><span class="op">=</span><span class="num">0.0</span><span class="op">,</span> <span class="nam">max</span><span class="op">=</span><span class="num">1.0</span><span class="op">,</span> <span class="nam">seed</span><span class="op">=</span><span class="num">0</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="str">'float32'</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11877" href="#t11877">11877</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11878" href="#t11878">11878</a></span><span class="t"><span class="str">    This op is used for sampling id from multinomial distribution from the input, sampling one id for one sample.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11879" href="#t11879">11879</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11880" href="#t11880">11880</a></span><span class="t"><span class="str">    Parameters:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11881" href="#t11881">11881</a></span><span class="t"><span class="str">        x (Variable): 2-D tensor, [batch_size, input_feature_dimensions]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11882" href="#t11882">11882</a></span><span class="t"><span class="str">        min (Float): minimum , default 0.0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11883" href="#t11883">11883</a></span><span class="t"><span class="str">        max (Float): maximum, default 1.0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11884" href="#t11884">11884</a></span><span class="t"><span class="str">        seed (Float): Random seed, default 0. if seed is not 0, will generate same number every time.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11885" href="#t11885">11885</a></span><span class="t"><span class="str">        dtype(np.dtype|core.VarDesc.VarType|str): The type of output data : float32, float_16, int etc</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11886" href="#t11886">11886</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11887" href="#t11887">11887</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11888" href="#t11888">11888</a></span><span class="t"><span class="str">        Variable: sampling tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11889" href="#t11889">11889</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11890" href="#t11890">11890</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11891" href="#t11891">11891</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11892" href="#t11892">11892</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11893" href="#t11893">11893</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11894" href="#t11894">11894</a></span><span class="t"><span class="str">            x = fluid.data(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11895" href="#t11895">11895</a></span><span class="t"><span class="str">                name="X",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11896" href="#t11896">11896</a></span><span class="t"><span class="str">                shape=[13, 11],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11897" href="#t11897">11897</a></span><span class="t"><span class="str">                dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11898" href="#t11898">11898</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11899" href="#t11899">11899</a></span><span class="t"><span class="str">            out = fluid.layers.sampling_id(x)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11900" href="#t11900">11900</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11901" href="#t11901">11901</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11902" href="#t11902">11902</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'sampling_id'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11903" href="#t11903">11903</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11904" href="#t11904">11904</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11905" href="#t11905">11905</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'sampling_id'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11906" href="#t11906">11906</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11907" href="#t11907">11907</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11908" href="#t11908">11908</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'min'</span><span class="op">:</span> <span class="nam">min</span><span class="op">,</span> <span class="str">'max'</span><span class="op">:</span> <span class="nam">max</span><span class="op">,</span> <span class="str">'seed'</span><span class="op">:</span> <span class="nam">seed</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11909" href="#t11909">11909</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11910" href="#t11910">11910</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11911" href="#t11911">11911</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11912" href="#t11912">11912</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11913" href="#t11913">11913</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11914" href="#t11914">11914</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">'1.8.0'</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.normal"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11915" href="#t11915">11915</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11916" href="#t11916">11916</a></span><span class="t"><span class="key">def</span> <span class="nam">gaussian_random_batch_size_like</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11917" href="#t11917">11917</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11918" href="#t11918">11918</a></span><span class="t">    <span class="nam">shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11919" href="#t11919">11919</a></span><span class="t">    <span class="nam">input_dim_idx</span><span class="op">=</span><span class="num">0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11920" href="#t11920">11920</a></span><span class="t">    <span class="nam">output_dim_idx</span><span class="op">=</span><span class="num">0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11921" href="#t11921">11921</a></span><span class="t">    <span class="nam">mean</span><span class="op">=</span><span class="num">0.0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11922" href="#t11922">11922</a></span><span class="t">    <span class="nam">std</span><span class="op">=</span><span class="num">1.0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11923" href="#t11923">11923</a></span><span class="t">    <span class="nam">seed</span><span class="op">=</span><span class="num">0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11924" href="#t11924">11924</a></span><span class="t">    <span class="nam">dtype</span><span class="op">=</span><span class="str">'float32'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11925" href="#t11925">11925</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11926" href="#t11926">11926</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11927" href="#t11927">11927</a></span><span class="t"><span class="str">    ${comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11928" href="#t11928">11928</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11929" href="#t11929">11929</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11930" href="#t11930">11930</a></span><span class="t"><span class="str">        input (Variable): ${input_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11931" href="#t11931">11931</a></span><span class="t"><span class="str">        shape (tuple|list): ${shape_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11932" href="#t11932">11932</a></span><span class="t"><span class="str">        input_dim_idx (int): ${input_dim_idx_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11933" href="#t11933">11933</a></span><span class="t"><span class="str">        output_dim_idx (int): ${output_dim_idx_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11934" href="#t11934">11934</a></span><span class="t"><span class="str">        mean (float): ${mean_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11935" href="#t11935">11935</a></span><span class="t"><span class="str">        std (float): ${std_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11936" href="#t11936">11936</a></span><span class="t"><span class="str">        seed (int): ${seed_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11937" href="#t11937">11937</a></span><span class="t"><span class="str">        dtype(np.dtype|core.VarDesc.VarType|str): The type of output data, float32 or float_64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11938" href="#t11938">11938</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11939" href="#t11939">11939</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11940" href="#t11940">11940</a></span><span class="t"><span class="str">        out (Variable): ${out_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11941" href="#t11941">11941</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11942" href="#t11942">11942</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11943" href="#t11943">11943</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11944" href="#t11944">11944</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11945" href="#t11945">11945</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11946" href="#t11946">11946</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11947" href="#t11947">11947</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11948" href="#t11948">11948</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11949" href="#t11949">11949</a></span><span class="t"><span class="str">            input = fluid.data(name="input", shape=[13, 11], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11950" href="#t11950">11950</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11951" href="#t11951">11951</a></span><span class="t"><span class="str">            out = fluid.layers.gaussian_random_batch_size_like(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11952" href="#t11952">11952</a></span><span class="t"><span class="str">                input, shape=[-1, 11], mean=1.0, std=2.0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11953" href="#t11953">11953</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11954" href="#t11954">11954</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11955" href="#t11955">11955</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'gaussian_random_batch_size_like'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11956" href="#t11956">11956</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11957" href="#t11957">11957</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11958" href="#t11958">11958</a></span><span class="t">        <span class="str">'input'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11959" href="#t11959">11959</a></span><span class="t">        <span class="op">(</span><span class="nam">Variable</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11960" href="#t11960">11960</a></span><span class="t">        <span class="str">'fluid.layers.gaussian_random_batch_size_like'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11961" href="#t11961">11961</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11962" href="#t11962">11962</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11963" href="#t11963">11963</a></span><span class="t">        <span class="nam">shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11964" href="#t11964">11964</a></span><span class="t">        <span class="str">'shape'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11965" href="#t11965">11965</a></span><span class="t">        <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11966" href="#t11966">11966</a></span><span class="t">        <span class="str">'fluid.layers.gaussian_random_batch_size_like'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11967" href="#t11967">11967</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11968" href="#t11968">11968</a></span><span class="t">    <span class="nam">check_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11969" href="#t11969">11969</a></span><span class="t">        <span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11970" href="#t11970">11970</a></span><span class="t">        <span class="str">'dtype'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11971" href="#t11971">11971</a></span><span class="t">        <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'int'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11972" href="#t11972">11972</a></span><span class="t">        <span class="str">'fluid.layers.gaussian_random_batch_size_like'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11973" href="#t11973">11973</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11974" href="#t11974">11974</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11975" href="#t11975">11975</a></span><span class="t">    <span class="nam">c_dtype</span> <span class="op">=</span> <span class="nam">convert_np_dtype_to_dtype_</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11976" href="#t11976">11976</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11977" href="#t11977">11977</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'gaussian_random_batch_size_like'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11978" href="#t11978">11978</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Input'</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11979" href="#t11979">11979</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11980" href="#t11980">11980</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11981" href="#t11981">11981</a></span><span class="t">            <span class="str">'shape'</span><span class="op">:</span> <span class="nam">shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11982" href="#t11982">11982</a></span><span class="t">            <span class="str">'input_dim_idx'</span><span class="op">:</span> <span class="nam">input_dim_idx</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11983" href="#t11983">11983</a></span><span class="t">            <span class="str">'output_dim_idx'</span><span class="op">:</span> <span class="nam">output_dim_idx</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11984" href="#t11984">11984</a></span><span class="t">            <span class="str">'mean'</span><span class="op">:</span> <span class="nam">mean</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11985" href="#t11985">11985</a></span><span class="t">            <span class="str">'std'</span><span class="op">:</span> <span class="nam">std</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11986" href="#t11986">11986</a></span><span class="t">            <span class="str">'seed'</span><span class="op">:</span> <span class="nam">seed</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11987" href="#t11987">11987</a></span><span class="t">            <span class="str">'dtype'</span><span class="op">:</span> <span class="nam">c_dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11988" href="#t11988">11988</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11989" href="#t11989">11989</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11990" href="#t11990">11990</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t11991" href="#t11991">11991</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11992" href="#t11992">11992</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11993" href="#t11993">11993</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11994" href="#t11994">11994</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11995" href="#t11995">11995</a></span><span class="t"><span class="key">def</span> <span class="nam">sum</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11996" href="#t11996">11996</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11997" href="#t11997">11997</a></span><span class="t"><span class="str">    ${comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11998" href="#t11998">11998</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t11999" href="#t11999">11999</a></span><span class="t"><span class="str">    Case 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12000" href="#t12000">12000</a></span><span class="t"><span class="str">    ::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12001" href="#t12001">12001</a></span><span class="t"><span class="str">        Input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12002" href="#t12002">12002</a></span><span class="t"><span class="str">            Input. Shape = [2, 3]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12003" href="#t12003">12003</a></span><span class="t"><span class="str">            Input = [[1, 2, 3],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12004" href="#t12004">12004</a></span><span class="t"><span class="str">                     [4, 5, 6]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12005" href="#t12005">12005</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12006" href="#t12006">12006</a></span><span class="t"><span class="str">        Output:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12007" href="#t12007">12007</a></span><span class="t"><span class="str">            The output. Shape = [2, 3]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12008" href="#t12008">12008</a></span><span class="t"><span class="str">            Output = [[1, 2, 3],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12009" href="#t12009">12009</a></span><span class="t"><span class="str">                      [4, 5, 6]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12010" href="#t12010">12010</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12011" href="#t12011">12011</a></span><span class="t"><span class="str">    Case 2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12012" href="#t12012">12012</a></span><span class="t"><span class="str">    ::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12013" href="#t12013">12013</a></span><span class="t"><span class="str">        Input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12014" href="#t12014">12014</a></span><span class="t"><span class="str">            First input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12015" href="#t12015">12015</a></span><span class="t"><span class="str">            Input1. Shape = [2, 3]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12016" href="#t12016">12016</a></span><span class="t"><span class="str">            Input1 = [[1, 2, 3],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12017" href="#t12017">12017</a></span><span class="t"><span class="str">                      [4, 5, 6]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12018" href="#t12018">12018</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12019" href="#t12019">12019</a></span><span class="t"><span class="str">        The second input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12020" href="#t12020">12020</a></span><span class="t"><span class="str">            Input2. Shape = [2, 3]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12021" href="#t12021">12021</a></span><span class="t"><span class="str">            Input2 = [[7, 8, 9],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12022" href="#t12022">12022</a></span><span class="t"><span class="str">                      [10, 11, 12]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12023" href="#t12023">12023</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12024" href="#t12024">12024</a></span><span class="t"><span class="str">        Output:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12025" href="#t12025">12025</a></span><span class="t"><span class="str">            The output. Shape = [2, 3]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12026" href="#t12026">12026</a></span><span class="t"><span class="str">            Output = [[8, 10, 12],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12027" href="#t12027">12027</a></span><span class="t"><span class="str">                      [14, 16, 18]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12028" href="#t12028">12028</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12029" href="#t12029">12029</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12030" href="#t12030">12030</a></span><span class="t"><span class="str">        x (Variable|list(Variable)): ${x_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12031" href="#t12031">12031</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12032" href="#t12032">12032</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12033" href="#t12033">12033</a></span><span class="t"><span class="str">        Variable: ${out_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12034" href="#t12034">12034</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12035" href="#t12035">12035</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12036" href="#t12036">12036</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12037" href="#t12037">12037</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12038" href="#t12038">12038</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12039" href="#t12039">12039</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12040" href="#t12040">12040</a></span><span class="t"><span class="str">            input0 = fluid.layers.fill_constant(shape=[2, 3], dtype='int64', value=5)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12041" href="#t12041">12041</a></span><span class="t"><span class="str">            input1 = fluid.layers.fill_constant(shape=[2, 3], dtype='int64', value=3)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12042" href="#t12042">12042</a></span><span class="t"><span class="str">            sum = fluid.layers.sum([input0, input1])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12043" href="#t12043">12043</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12044" href="#t12044">12044</a></span><span class="t"><span class="str">            # You can print out 'sum' via executor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12045" href="#t12045">12045</a></span><span class="t"><span class="str">            out = fluid.layers.Print(sum, message="the sum of input0 and input1: ")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12046" href="#t12046">12046</a></span><span class="t"><span class="str">            exe = fluid.Executor(fluid.CPUPlace())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12047" href="#t12047">12047</a></span><span class="t"><span class="str">            exe.run(fluid.default_main_program())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12048" href="#t12048">12048</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12049" href="#t12049">12049</a></span><span class="t"><span class="str">            # The printed result is:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12050" href="#t12050">12050</a></span><span class="t"><span class="str">            # 1570701754        the sum of input0 and input1:   The place is:CPUPlace</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12051" href="#t12051">12051</a></span><span class="t"><span class="str">            # Tensor[sum_0.tmp_0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12052" href="#t12052">12052</a></span><span class="t"><span class="str">            #    shape: [2,3,]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12053" href="#t12053">12053</a></span><span class="t"><span class="str">            #    dtype: l</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12054" href="#t12054">12054</a></span><span class="t"><span class="str">            #    data: 8,8,8,8,8,8,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12055" href="#t12055">12055</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12056" href="#t12056">12056</a></span><span class="t"><span class="str">            # the sum of input0 and input1 is 2-D Tensor with shape [2,3].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12057" href="#t12057">12057</a></span><span class="t"><span class="str">            # dtype is the corresponding C++ data type, which may vary in different environments.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12058" href="#t12058">12058</a></span><span class="t"><span class="str">            # Eg: if the data type of tensor is int64, then the corresponding C++ data type is int64_t,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12059" href="#t12059">12059</a></span><span class="t"><span class="str">            #       so the dtype value is typeid(int64_t).Name(), which is 'x' on MacOS, 'l' on Linux,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12060" href="#t12060">12060</a></span><span class="t"><span class="str">            #       and '__int64' on Windows. They both represent 64-bit integer variables.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12061" href="#t12061">12061</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12062" href="#t12062">12062</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12063" href="#t12063">12063</a></span><span class="t">    <span class="key">return</span> <span class="nam">paddle</span><span class="op">.</span><span class="nam">add_n</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12064" href="#t12064">12064</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12065" href="#t12065">12065</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12066" href="#t12066">12066</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12067" href="#t12067">12067</a></span><span class="t"><span class="key">def</span> <span class="nam">slice</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">axes</span><span class="op">,</span> <span class="nam">starts</span><span class="op">,</span> <span class="nam">ends</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12068" href="#t12068">12068</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12069" href="#t12069">12069</a></span><span class="t"><span class="str">    This operator produces a slice of ``input`` along multiple axes. Similar to numpy:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12070" href="#t12070">12070</a></span><span class="t"><span class="str">    https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12071" href="#t12071">12071</a></span><span class="t"><span class="str">    Slice uses ``axes``, ``starts`` and ``ends`` attributes to specify the start and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12072" href="#t12072">12072</a></span><span class="t"><span class="str">    end dimension for each axis in the list of axes and Slice uses this information</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12073" href="#t12073">12073</a></span><span class="t"><span class="str">    to slice the input data tensor. If a negative value is passed to</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12074" href="#t12074">12074</a></span><span class="t"><span class="str">    ``starts`` or ``ends`` such as :math:`-i`,  it represents the reverse position of the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12075" href="#t12075">12075</a></span><span class="t"><span class="str">    axis :math:`i-1` (here 0 is the initial position).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12076" href="#t12076">12076</a></span><span class="t"><span class="str">    If the value passed to ``starts`` or ``ends`` is greater than n</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12077" href="#t12077">12077</a></span><span class="t"><span class="str">    (the number of elements in this dimension), it represents n.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12078" href="#t12078">12078</a></span><span class="t"><span class="str">    For slicing to the end of a dimension with unknown size, it is recommended</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12079" href="#t12079">12079</a></span><span class="t"><span class="str">    to pass in INT_MAX. The size of ``axes`` must be equal to ``starts`` and ``ends``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12080" href="#t12080">12080</a></span><span class="t"><span class="str">    Following examples will explain how slice works:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12081" href="#t12081">12081</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12082" href="#t12082">12082</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12083" href="#t12083">12083</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12084" href="#t12084">12084</a></span><span class="t"><span class="str">        Case1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12085" href="#t12085">12085</a></span><span class="t"><span class="str">            Given:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12086" href="#t12086">12086</a></span><span class="t"><span class="str">                data = [ [1, 2, 3, 4], [5, 6, 7, 8], ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12087" href="#t12087">12087</a></span><span class="t"><span class="str">                axes = [0, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12088" href="#t12088">12088</a></span><span class="t"><span class="str">                starts = [1, 0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12089" href="#t12089">12089</a></span><span class="t"><span class="str">                ends = [2, 3]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12090" href="#t12090">12090</a></span><span class="t"><span class="str">            Then:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12091" href="#t12091">12091</a></span><span class="t"><span class="str">                result = [ [5, 6, 7], ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12092" href="#t12092">12092</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12093" href="#t12093">12093</a></span><span class="t"><span class="str">        Case2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12094" href="#t12094">12094</a></span><span class="t"><span class="str">            Given:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12095" href="#t12095">12095</a></span><span class="t"><span class="str">                data = [ [1, 2, 3, 4], [5, 6, 7, 8], ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12096" href="#t12096">12096</a></span><span class="t"><span class="str">                axes = [0, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12097" href="#t12097">12097</a></span><span class="t"><span class="str">                starts = [0, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12098" href="#t12098">12098</a></span><span class="t"><span class="str">                ends = [-1, 1000]       # -1 denotes the reverse 0th position of dimension 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12099" href="#t12099">12099</a></span><span class="t"><span class="str">            Then:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12100" href="#t12100">12100</a></span><span class="t"><span class="str">                result = [ [2, 3, 4], ] # result = data[0:1, 1:4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12101" href="#t12101">12101</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12102" href="#t12102">12102</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12103" href="#t12103">12103</a></span><span class="t"><span class="str">        input (Tensor): A ``Tensor`` . The data type is ``float16``, ``float32``, ``float64``, ``int32`` or ``int64``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12104" href="#t12104">12104</a></span><span class="t"><span class="str">        axes (list|tuple): The data type is ``int32`` . Axes that `starts` and `ends` apply to .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12105" href="#t12105">12105</a></span><span class="t"><span class="str">        starts (list|tuple|Tensor): The data type is ``int32`` . If ``starts`` is a list or tuple, the elements of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12106" href="#t12106">12106</a></span><span class="t"><span class="str">                it should be integers or Tensors with shape [1]. If ``starts`` is an Tensor, it should be an 1-D Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12107" href="#t12107">12107</a></span><span class="t"><span class="str">                It represents starting indices of corresponding axis in ``axes``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12108" href="#t12108">12108</a></span><span class="t"><span class="str">        ends (list|tuple|Tensor): The data type is ``int32`` . If ``ends`` is a list or tuple, the elements of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12109" href="#t12109">12109</a></span><span class="t"><span class="str">                it should be integers or Tensors with shape [1]. If ``ends`` is an Tensor, it should be an 1-D Tensor .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12110" href="#t12110">12110</a></span><span class="t"><span class="str">                It represents ending indices of corresponding axis in ``axes``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12111" href="#t12111">12111</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12112" href="#t12112">12112</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12113" href="#t12113">12113</a></span><span class="t"><span class="str">        Tensor:  A ``Tensor``. The data type is same as ``input``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12114" href="#t12114">12114</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12115" href="#t12115">12115</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12116" href="#t12116">12116</a></span><span class="t"><span class="str">        TypeError: The type of ``starts`` must be list, tuple or Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12117" href="#t12117">12117</a></span><span class="t"><span class="str">        TypeError: The type of ``ends`` must be list, tuple or Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12118" href="#t12118">12118</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12119" href="#t12119">12119</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12120" href="#t12120">12120</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12121" href="#t12121">12121</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12122" href="#t12122">12122</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12123" href="#t12123">12123</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12124" href="#t12124">12124</a></span><span class="t"><span class="str">            input = paddle.rand(shape=[4, 5, 6], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12125" href="#t12125">12125</a></span><span class="t"><span class="str">            # example 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12126" href="#t12126">12126</a></span><span class="t"><span class="str">            # attr starts is a list which doesn't contain tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12127" href="#t12127">12127</a></span><span class="t"><span class="str">            axes = [0, 1, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12128" href="#t12128">12128</a></span><span class="t"><span class="str">            starts = [-3, 0, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12129" href="#t12129">12129</a></span><span class="t"><span class="str">            ends = [3, 2, 4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12130" href="#t12130">12130</a></span><span class="t"><span class="str">            sliced_1 = paddle.slice(input, axes=axes, starts=starts, ends=ends)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12131" href="#t12131">12131</a></span><span class="t"><span class="str">            # sliced_1 is input[0:3, 0:2, 2:4].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12132" href="#t12132">12132</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12133" href="#t12133">12133</a></span><span class="t"><span class="str">            # example 2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12134" href="#t12134">12134</a></span><span class="t"><span class="str">            # attr starts is a list which contain tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12135" href="#t12135">12135</a></span><span class="t"><span class="str">            minus_3 = paddle.full([1], -3, "int32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12136" href="#t12136">12136</a></span><span class="t"><span class="str">            sliced_2 = paddle.slice(input, axes=axes, starts=[minus_3, 0, 2], ends=ends)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12137" href="#t12137">12137</a></span><span class="t"><span class="str">            # sliced_2 is input[0:3, 0:2, 2:4].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12138" href="#t12138">12138</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12139" href="#t12139">12139</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12140" href="#t12140">12140</a></span><span class="t">        <span class="nam">attrs</span> <span class="op">=</span> <span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12141" href="#t12141">12141</a></span><span class="t">        <span class="nam">starts_tensor</span> <span class="op">=</span> <span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12142" href="#t12142">12142</a></span><span class="t">        <span class="nam">ends_tensor</span> <span class="op">=</span> <span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12143" href="#t12143">12143</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12144" href="#t12144">12144</a></span><span class="t">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">axes</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12145" href="#t12145">12145</a></span><span class="t">            <span class="nam">axes</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="nam">axes</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12146" href="#t12146">12146</a></span><span class="t">            <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">axes</span><span class="op">)</span> <span class="op">==</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12147" href="#t12147">12147</a></span><span class="t">                <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12148" href="#t12148">12148</a></span><span class="t">                    <span class="str">"Input axes should not be an empty list/tuple."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12149" href="#t12149">12149</a></span><span class="t">                <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12150" href="#t12150">12150</a></span><span class="t">            <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">len</span><span class="op">(</span><span class="nam">axes</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12151" href="#t12151">12151</a></span><span class="t">                <span class="key">if</span> <span class="nam">axes</span><span class="op">[</span><span class="nam">i</span><span class="op">]</span> <span class="op">&lt;</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12152" href="#t12152">12152</a></span><span class="t">                    <span class="nam">axes</span><span class="op">[</span><span class="nam">i</span><span class="op">]</span> <span class="op">=</span> <span class="nam">max</span><span class="op">(</span><span class="num">0</span><span class="op">,</span> <span class="nam">axes</span><span class="op">[</span><span class="nam">i</span><span class="op">]</span> <span class="op">+</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12153" href="#t12153">12153</a></span><span class="t">                <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12154" href="#t12154">12154</a></span><span class="t">                    <span class="nam">axes</span><span class="op">[</span><span class="nam">i</span><span class="op">]</span> <span class="op">=</span> <span class="nam">min</span><span class="op">(</span><span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">-</span> <span class="num">1</span><span class="op">,</span> <span class="nam">axes</span><span class="op">[</span><span class="nam">i</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12155" href="#t12155">12155</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12156" href="#t12156">12156</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12157" href="#t12157">12157</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12158" href="#t12158">12158</a></span><span class="t">                <span class="str">"Input axes must be a python list or tuple, but reveived {}"</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12159" href="#t12159">12159</a></span><span class="t">                    <span class="nam">type</span><span class="op">(</span><span class="nam">axes</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12160" href="#t12160">12160</a></span><span class="t">                <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12161" href="#t12161">12161</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12162" href="#t12162">12162</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12163" href="#t12163">12163</a></span><span class="t">        <span class="nam">infer_flags</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="num">1</span> <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">len</span><span class="op">(</span><span class="nam">axes</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12164" href="#t12164">12164</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12165" href="#t12165">12165</a></span><span class="t">        <span class="nam">tmp_tensor_type</span> <span class="op">=</span> <span class="nam">core</span><span class="op">.</span><span class="nam">eager</span><span class="op">.</span><span class="nam">Tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12166" href="#t12166">12166</a></span><span class="t">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">starts</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12167" href="#t12167">12167</a></span><span class="t">            <span class="nam">starts</span> <span class="op">=</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12168" href="#t12168">12168</a></span><span class="t">                <span class="nam">item</span><span class="op">.</span><span class="nam">numpy</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">item</span><span class="op">(</span><span class="num">0</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12169" href="#t12169">12169</a></span><span class="t">                <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">item</span><span class="op">,</span> <span class="nam">tmp_tensor_type</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12170" href="#t12170">12170</a></span><span class="t">                <span class="key">else</span> <span class="nam">item</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12171" href="#t12171">12171</a></span><span class="t">                <span class="key">for</span> <span class="nam">item</span> <span class="key">in</span> <span class="nam">starts</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12172" href="#t12172">12172</a></span><span class="t">            <span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12173" href="#t12173">12173</a></span><span class="t">        <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">starts</span><span class="op">,</span> <span class="nam">tmp_tensor_type</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12174" href="#t12174">12174</a></span><span class="t">            <span class="nam">tensor_t</span> <span class="op">=</span> <span class="nam">starts</span><span class="op">.</span><span class="nam">numpy</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12175" href="#t12175">12175</a></span><span class="t">            <span class="nam">starts</span> <span class="op">=</span> <span class="op">[</span><span class="nam">ele</span> <span class="key">for</span> <span class="nam">ele</span> <span class="key">in</span> <span class="nam">tensor_t</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12176" href="#t12176">12176</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12177" href="#t12177">12177</a></span><span class="t">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">ends</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12178" href="#t12178">12178</a></span><span class="t">            <span class="nam">ends</span> <span class="op">=</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12179" href="#t12179">12179</a></span><span class="t">                <span class="nam">item</span><span class="op">.</span><span class="nam">numpy</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">item</span><span class="op">(</span><span class="num">0</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12180" href="#t12180">12180</a></span><span class="t">                <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">item</span><span class="op">,</span> <span class="nam">tmp_tensor_type</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12181" href="#t12181">12181</a></span><span class="t">                <span class="key">else</span> <span class="nam">item</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12182" href="#t12182">12182</a></span><span class="t">                <span class="key">for</span> <span class="nam">item</span> <span class="key">in</span> <span class="nam">ends</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12183" href="#t12183">12183</a></span><span class="t">            <span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12184" href="#t12184">12184</a></span><span class="t">            <span class="nam">attrs</span> <span class="op">+=</span> <span class="op">(</span><span class="str">'ends'</span><span class="op">,</span> <span class="nam">ends</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12185" href="#t12185">12185</a></span><span class="t">        <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">ends</span><span class="op">,</span> <span class="nam">tmp_tensor_type</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12186" href="#t12186">12186</a></span><span class="t">            <span class="nam">tensor_t</span> <span class="op">=</span> <span class="nam">ends</span><span class="op">.</span><span class="nam">numpy</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12187" href="#t12187">12187</a></span><span class="t">            <span class="nam">ends</span> <span class="op">=</span> <span class="op">[</span><span class="nam">ele</span> <span class="key">for</span> <span class="nam">ele</span> <span class="key">in</span> <span class="nam">tensor_t</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12188" href="#t12188">12188</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12189" href="#t12189">12189</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">slice</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">axes</span><span class="op">,</span> <span class="nam">starts</span><span class="op">,</span> <span class="nam">ends</span><span class="op">,</span> <span class="nam">infer_flags</span><span class="op">,</span> <span class="op">[</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12190" href="#t12190">12190</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12191" href="#t12191">12191</a></span><span class="t">        <span class="key">if</span> <span class="nam">_in_legacy_dygraph</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12192" href="#t12192">12192</a></span><span class="t">            <span class="nam">attrs</span> <span class="op">=</span> <span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12193" href="#t12193">12193</a></span><span class="t">            <span class="nam">starts_tensor</span> <span class="op">=</span> <span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12194" href="#t12194">12194</a></span><span class="t">            <span class="nam">ends_tensor</span> <span class="op">=</span> <span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12195" href="#t12195">12195</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12196" href="#t12196">12196</a></span><span class="t">            <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">axes</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12197" href="#t12197">12197</a></span><span class="t">                <span class="nam">axes</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="nam">axes</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12198" href="#t12198">12198</a></span><span class="t">                <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">axes</span><span class="op">)</span> <span class="op">==</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12199" href="#t12199">12199</a></span><span class="t">                    <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12200" href="#t12200">12200</a></span><span class="t">                        <span class="str">"Input axes should not be an empty list/tuple."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12201" href="#t12201">12201</a></span><span class="t">                    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12202" href="#t12202">12202</a></span><span class="t">                <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">len</span><span class="op">(</span><span class="nam">axes</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12203" href="#t12203">12203</a></span><span class="t">                    <span class="key">if</span> <span class="nam">axes</span><span class="op">[</span><span class="nam">i</span><span class="op">]</span> <span class="op">&lt;</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12204" href="#t12204">12204</a></span><span class="t">                        <span class="nam">axes</span><span class="op">[</span><span class="nam">i</span><span class="op">]</span> <span class="op">=</span> <span class="nam">max</span><span class="op">(</span><span class="num">0</span><span class="op">,</span> <span class="nam">axes</span><span class="op">[</span><span class="nam">i</span><span class="op">]</span> <span class="op">+</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12205" href="#t12205">12205</a></span><span class="t">                    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12206" href="#t12206">12206</a></span><span class="t">                        <span class="nam">axes</span><span class="op">[</span><span class="nam">i</span><span class="op">]</span> <span class="op">=</span> <span class="nam">min</span><span class="op">(</span><span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">-</span> <span class="num">1</span><span class="op">,</span> <span class="nam">axes</span><span class="op">[</span><span class="nam">i</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12207" href="#t12207">12207</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12208" href="#t12208">12208</a></span><span class="t">            <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12209" href="#t12209">12209</a></span><span class="t">                <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12210" href="#t12210">12210</a></span><span class="t">                    <span class="str">"Input axes must be a python list or tuple, but reveived {}"</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12211" href="#t12211">12211</a></span><span class="t">                        <span class="nam">type</span><span class="op">(</span><span class="nam">axes</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12212" href="#t12212">12212</a></span><span class="t">                    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12213" href="#t12213">12213</a></span><span class="t">                <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12214" href="#t12214">12214</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12215" href="#t12215">12215</a></span><span class="t">            <span class="nam">infer_flags</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="num">1</span> <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">len</span><span class="op">(</span><span class="nam">axes</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12216" href="#t12216">12216</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12217" href="#t12217">12217</a></span><span class="t">            <span class="nam">tmp_tensor_type</span> <span class="op">=</span> <span class="nam">Variable</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12218" href="#t12218">12218</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12219" href="#t12219">12219</a></span><span class="t">            <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">starts</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12220" href="#t12220">12220</a></span><span class="t">                <span class="nam">starts</span> <span class="op">=</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12221" href="#t12221">12221</a></span><span class="t">                    <span class="nam">item</span><span class="op">.</span><span class="nam">numpy</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">item</span><span class="op">(</span><span class="num">0</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12222" href="#t12222">12222</a></span><span class="t">                    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">item</span><span class="op">,</span> <span class="nam">tmp_tensor_type</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12223" href="#t12223">12223</a></span><span class="t">                    <span class="key">else</span> <span class="nam">item</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12224" href="#t12224">12224</a></span><span class="t">                    <span class="key">for</span> <span class="nam">item</span> <span class="key">in</span> <span class="nam">starts</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12225" href="#t12225">12225</a></span><span class="t">                <span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12226" href="#t12226">12226</a></span><span class="t">                <span class="nam">attrs</span> <span class="op">+=</span> <span class="op">(</span><span class="str">'starts'</span><span class="op">,</span> <span class="nam">starts</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12227" href="#t12227">12227</a></span><span class="t">            <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">starts</span><span class="op">,</span> <span class="nam">tmp_tensor_type</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12228" href="#t12228">12228</a></span><span class="t">                <span class="nam">starts_tensor</span> <span class="op">=</span> <span class="nam">starts</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12229" href="#t12229">12229</a></span><span class="t">                <span class="nam">starts</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12230" href="#t12230">12230</a></span><span class="t">                <span class="nam">infer_flags</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="op">-</span><span class="num">1</span> <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">len</span><span class="op">(</span><span class="nam">axes</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12231" href="#t12231">12231</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12232" href="#t12232">12232</a></span><span class="t">            <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">ends</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12233" href="#t12233">12233</a></span><span class="t">                <span class="nam">ends</span> <span class="op">=</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12234" href="#t12234">12234</a></span><span class="t">                    <span class="nam">item</span><span class="op">.</span><span class="nam">numpy</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">item</span><span class="op">(</span><span class="num">0</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12235" href="#t12235">12235</a></span><span class="t">                    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">item</span><span class="op">,</span> <span class="nam">tmp_tensor_type</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12236" href="#t12236">12236</a></span><span class="t">                    <span class="key">else</span> <span class="nam">item</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12237" href="#t12237">12237</a></span><span class="t">                    <span class="key">for</span> <span class="nam">item</span> <span class="key">in</span> <span class="nam">ends</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12238" href="#t12238">12238</a></span><span class="t">                <span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12239" href="#t12239">12239</a></span><span class="t">                <span class="nam">attrs</span> <span class="op">+=</span> <span class="op">(</span><span class="str">'ends'</span><span class="op">,</span> <span class="nam">ends</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12240" href="#t12240">12240</a></span><span class="t">            <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">ends</span><span class="op">,</span> <span class="nam">tmp_tensor_type</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12241" href="#t12241">12241</a></span><span class="t">                <span class="nam">ends_tensor</span> <span class="op">=</span> <span class="nam">ends</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12242" href="#t12242">12242</a></span><span class="t">                <span class="nam">ends_tensor</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12243" href="#t12243">12243</a></span><span class="t">                <span class="nam">infer_flags</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="op">-</span><span class="num">1</span> <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">len</span><span class="op">(</span><span class="nam">axes</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12244" href="#t12244">12244</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12245" href="#t12245">12245</a></span><span class="t">            <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">slice</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12246" href="#t12246">12246</a></span><span class="t">                <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12247" href="#t12247">12247</a></span><span class="t">                <span class="nam">starts_tensor</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12248" href="#t12248">12248</a></span><span class="t">                <span class="nam">ends_tensor</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12249" href="#t12249">12249</a></span><span class="t">                <span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12250" href="#t12250">12250</a></span><span class="t">                <span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12251" href="#t12251">12251</a></span><span class="t">                <span class="str">'axes'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12252" href="#t12252">12252</a></span><span class="t">                <span class="nam">axes</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12253" href="#t12253">12253</a></span><span class="t">                <span class="str">'infer_flags'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12254" href="#t12254">12254</a></span><span class="t">                <span class="nam">infer_flags</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12255" href="#t12255">12255</a></span><span class="t">                <span class="op">*</span><span class="nam">attrs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12256" href="#t12256">12256</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12257" href="#t12257">12257</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12258" href="#t12258">12258</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">starts</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12259" href="#t12259">12259</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12260" href="#t12260">12260</a></span><span class="t">            <span class="str">"Input starts must be an Variable, python list or tuple."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12261" href="#t12261">12261</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12262" href="#t12262">12262</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">ends</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12263" href="#t12263">12263</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12264" href="#t12264">12264</a></span><span class="t">            <span class="str">"Input ends must be an Variable, python list or tuple."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12265" href="#t12265">12265</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12266" href="#t12266">12266</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12267" href="#t12267">12267</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'slice'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12268" href="#t12268">12268</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12269" href="#t12269">12269</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'Input'</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12270" href="#t12270">12270</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'axes'</span><span class="op">:</span> <span class="nam">axes</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12271" href="#t12271">12271</a></span><span class="t">    <span class="nam">infer_flags</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="num">1</span> <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">len</span><span class="op">(</span><span class="nam">axes</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12272" href="#t12272">12272</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12273" href="#t12273">12273</a></span><span class="t">    <span class="com"># starts</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12274" href="#t12274">12274</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">starts</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12275" href="#t12275">12275</a></span><span class="t">        <span class="nam">starts</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12276" href="#t12276">12276</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">'StartsTensor'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">starts</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12277" href="#t12277">12277</a></span><span class="t">        <span class="nam">infer_flags</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="op">-</span><span class="num">1</span> <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">len</span><span class="op">(</span><span class="nam">axes</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12278" href="#t12278">12278</a></span><span class="t">    <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">starts</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12279" href="#t12279">12279</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">'starts'</span><span class="op">]</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12280" href="#t12280">12280</a></span><span class="t">        <span class="key">if</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_contain_var</span><span class="op">(</span><span class="nam">starts</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12281" href="#t12281">12281</a></span><span class="t">            <span class="nam">inputs</span><span class="op">[</span><span class="str">'StartsTensorList'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_convert_to_tensor_list</span><span class="op">(</span><span class="nam">starts</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12282" href="#t12282">12282</a></span><span class="t">            <span class="key">for</span> <span class="nam">i</span><span class="op">,</span> <span class="nam">dim</span> <span class="key">in</span> <span class="nam">enumerate</span><span class="op">(</span><span class="nam">starts</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12283" href="#t12283">12283</a></span><span class="t">                <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12284" href="#t12284">12284</a></span><span class="t">                    <span class="nam">attrs</span><span class="op">[</span><span class="str">'starts'</span><span class="op">]</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="op">-</span><span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12285" href="#t12285">12285</a></span><span class="t">                    <span class="nam">infer_flags</span><span class="op">[</span><span class="nam">i</span><span class="op">]</span> <span class="op">=</span> <span class="op">-</span><span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12286" href="#t12286">12286</a></span><span class="t">                <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12287" href="#t12287">12287</a></span><span class="t">                    <span class="nam">attrs</span><span class="op">[</span><span class="str">'starts'</span><span class="op">]</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">dim</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12288" href="#t12288">12288</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12289" href="#t12289">12289</a></span><span class="t">            <span class="nam">attrs</span><span class="op">[</span><span class="str">'starts'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">starts</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12290" href="#t12290">12290</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12291" href="#t12291">12291</a></span><span class="t">    <span class="com"># ends</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12292" href="#t12292">12292</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">ends</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12293" href="#t12293">12293</a></span><span class="t">        <span class="nam">ends</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12294" href="#t12294">12294</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">'EndsTensor'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">ends</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12295" href="#t12295">12295</a></span><span class="t">        <span class="nam">infer_flags</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="op">-</span><span class="num">1</span> <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">len</span><span class="op">(</span><span class="nam">axes</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12296" href="#t12296">12296</a></span><span class="t">    <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">ends</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12297" href="#t12297">12297</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">'ends'</span><span class="op">]</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12298" href="#t12298">12298</a></span><span class="t">        <span class="key">if</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_contain_var</span><span class="op">(</span><span class="nam">ends</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12299" href="#t12299">12299</a></span><span class="t">            <span class="nam">inputs</span><span class="op">[</span><span class="str">'EndsTensorList'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_convert_to_tensor_list</span><span class="op">(</span><span class="nam">ends</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12300" href="#t12300">12300</a></span><span class="t">            <span class="key">for</span> <span class="nam">i</span><span class="op">,</span> <span class="nam">dim</span> <span class="key">in</span> <span class="nam">enumerate</span><span class="op">(</span><span class="nam">ends</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12301" href="#t12301">12301</a></span><span class="t">                <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12302" href="#t12302">12302</a></span><span class="t">                    <span class="nam">attrs</span><span class="op">[</span><span class="str">'ends'</span><span class="op">]</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="op">-</span><span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12303" href="#t12303">12303</a></span><span class="t">                    <span class="nam">infer_flags</span><span class="op">[</span><span class="nam">i</span><span class="op">]</span> <span class="op">=</span> <span class="op">-</span><span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12304" href="#t12304">12304</a></span><span class="t">                <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12305" href="#t12305">12305</a></span><span class="t">                    <span class="nam">attrs</span><span class="op">[</span><span class="str">'ends'</span><span class="op">]</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">dim</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12306" href="#t12306">12306</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12307" href="#t12307">12307</a></span><span class="t">            <span class="nam">attrs</span><span class="op">[</span><span class="str">'ends'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">ends</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12308" href="#t12308">12308</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12309" href="#t12309">12309</a></span><span class="t">    <span class="com"># infer_flags</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12310" href="#t12310">12310</a></span><span class="t">    <span class="nam">attrs</span><span class="op">[</span><span class="str">'infer_flags'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">infer_flags</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12311" href="#t12311">12311</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12312" href="#t12312">12312</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="str">'input'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12313" href="#t12313">12313</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12314" href="#t12314">12314</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12315" href="#t12315">12315</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'slice'</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12316" href="#t12316">12316</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12317" href="#t12317">12317</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12318" href="#t12318">12318</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12319" href="#t12319">12319</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12320" href="#t12320">12320</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12321" href="#t12321">12321</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">'2.0.0'</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.strided_slice"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12322" href="#t12322">12322</a></span><span class="t"><span class="key">def</span> <span class="nam">strided_slice</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">axes</span><span class="op">,</span> <span class="nam">starts</span><span class="op">,</span> <span class="nam">ends</span><span class="op">,</span> <span class="nam">strides</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12323" href="#t12323">12323</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12324" href="#t12324">12324</a></span><span class="t"><span class="str">    :alias_main: paddle.strided_slice</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12325" href="#t12325">12325</a></span><span class="t"><span class="str">        :alias: paddle.strided_slice,paddle.tensor.strided_slice,paddle.tensor.manipulation.strided_slice</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12326" href="#t12326">12326</a></span><span class="t"><span class="str">        :old_api: paddle.fluid.layers.strided_slice</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12327" href="#t12327">12327</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12328" href="#t12328">12328</a></span><span class="t"><span class="str">    This operator produces a slice of ``input`` along multiple axes. Similar to numpy:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12329" href="#t12329">12329</a></span><span class="t"><span class="str">    https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12330" href="#t12330">12330</a></span><span class="t"><span class="str">    Slice uses ``axes``, ``starts`` and ``ends`` attributes to specify the start and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12331" href="#t12331">12331</a></span><span class="t"><span class="str">    end dimension for each axis in the list of axes and Slice uses this information</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12332" href="#t12332">12332</a></span><span class="t"><span class="str">    to slice the input data tensor. If a negative value is passed to</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12333" href="#t12333">12333</a></span><span class="t"><span class="str">    ``starts`` or ``ends`` such as :math:`-i`,  it represents the reverse position of the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12334" href="#t12334">12334</a></span><span class="t"><span class="str">    axis :math:`i-1` th(here 0 is the initial position). The ``strides`` represents steps of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12335" href="#t12335">12335</a></span><span class="t"><span class="str">    slicing and if the ``strides`` is negative, slice operation is in the opposite direction.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12336" href="#t12336">12336</a></span><span class="t"><span class="str">    If the value passed to ``starts`` or ``ends`` is greater than n</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12337" href="#t12337">12337</a></span><span class="t"><span class="str">    (the number of elements in this dimension), it represents n.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12338" href="#t12338">12338</a></span><span class="t"><span class="str">    For slicing to the end of a dimension with unknown size, it is recommended</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12339" href="#t12339">12339</a></span><span class="t"><span class="str">    to pass in INT_MAX. The size of ``axes`` must be equal to ``starts`` , ``ends`` and ``strides``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12340" href="#t12340">12340</a></span><span class="t"><span class="str">    Following examples will explain how strided_slice works:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12341" href="#t12341">12341</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12342" href="#t12342">12342</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12343" href="#t12343">12343</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12344" href="#t12344">12344</a></span><span class="t"><span class="str">        Case1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12345" href="#t12345">12345</a></span><span class="t"><span class="str">            Given:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12346" href="#t12346">12346</a></span><span class="t"><span class="str">                data = [ [1, 2, 3, 4], [5, 6, 7, 8], ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12347" href="#t12347">12347</a></span><span class="t"><span class="str">                axes = [0, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12348" href="#t12348">12348</a></span><span class="t"><span class="str">                starts = [1, 0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12349" href="#t12349">12349</a></span><span class="t"><span class="str">                ends = [2, 3]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12350" href="#t12350">12350</a></span><span class="t"><span class="str">                strides = [1, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12351" href="#t12351">12351</a></span><span class="t"><span class="str">            Then:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12352" href="#t12352">12352</a></span><span class="t"><span class="str">                result = [ [5, 6, 7], ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12353" href="#t12353">12353</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12354" href="#t12354">12354</a></span><span class="t"><span class="str">        Case2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12355" href="#t12355">12355</a></span><span class="t"><span class="str">            Given:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12356" href="#t12356">12356</a></span><span class="t"><span class="str">                data = [ [1, 2, 3, 4], [5, 6, 7, 8], ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12357" href="#t12357">12357</a></span><span class="t"><span class="str">                axes = [0, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12358" href="#t12358">12358</a></span><span class="t"><span class="str">                starts = [0, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12359" href="#t12359">12359</a></span><span class="t"><span class="str">                ends = [2, 0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12360" href="#t12360">12360</a></span><span class="t"><span class="str">                strides = [1, -1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12361" href="#t12361">12361</a></span><span class="t"><span class="str">            Then:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12362" href="#t12362">12362</a></span><span class="t"><span class="str">                result = [ [8, 7, 6], ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12363" href="#t12363">12363</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12364" href="#t12364">12364</a></span><span class="t"><span class="str">        Case3:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12365" href="#t12365">12365</a></span><span class="t"><span class="str">            Given:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12366" href="#t12366">12366</a></span><span class="t"><span class="str">                data = [ [1, 2, 3, 4], [5, 6, 7, 8], ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12367" href="#t12367">12367</a></span><span class="t"><span class="str">                axes = [0, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12368" href="#t12368">12368</a></span><span class="t"><span class="str">                starts = [0, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12369" href="#t12369">12369</a></span><span class="t"><span class="str">                ends = [-1, 1000]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12370" href="#t12370">12370</a></span><span class="t"><span class="str">                strides = [1, 3]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12371" href="#t12371">12371</a></span><span class="t"><span class="str">            Then:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12372" href="#t12372">12372</a></span><span class="t"><span class="str">                result = [ [2], ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12373" href="#t12373">12373</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12374" href="#t12374">12374</a></span><span class="t"><span class="str">        input (Variable): An N-D ``Tensor`` or ``LoDTensor`` . The data type is ``bool``, ``float32``, ``float64``, ``int32`` or ``int64``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12375" href="#t12375">12375</a></span><span class="t"><span class="str">        axes (list|tuple): The data type is ``int32`` . Axes that `starts` and `ends` apply to.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12376" href="#t12376">12376</a></span><span class="t"><span class="str">                            It's optional. If it is not provides, it will be treated as :math:`[0,1,...,len(starts)-1]`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12377" href="#t12377">12377</a></span><span class="t"><span class="str">        starts (list|tuple|Variable): The data type is ``int32`` . If ``starts`` is a list or tuple, the elements of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12378" href="#t12378">12378</a></span><span class="t"><span class="str">                it should be integers or Tensors with shape [1]. If ``starts`` is an Variable, it should be an 1-D Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12379" href="#t12379">12379</a></span><span class="t"><span class="str">                It represents starting indices of corresponding axis in ``axes``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12380" href="#t12380">12380</a></span><span class="t"><span class="str">        ends (list|tuple|Variable): The data type is ``int32`` . If ``ends`` is a list or tuple, the elements of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12381" href="#t12381">12381</a></span><span class="t"><span class="str">                it should be integers or Tensors with shape [1]. If ``ends`` is an Variable, it should be an 1-D Tensor .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12382" href="#t12382">12382</a></span><span class="t"><span class="str">                It represents ending indices of corresponding axis in ``axes``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12383" href="#t12383">12383</a></span><span class="t"><span class="str">        strides (list|tuple|Variable): The data type is ``int32`` . If ``strides`` is a list or tuple, the elements of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12384" href="#t12384">12384</a></span><span class="t"><span class="str">                it should be integers or Tensors with shape [1]. If ``strides`` is an Variable, it should be an 1-D Tensor .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12385" href="#t12385">12385</a></span><span class="t"><span class="str">                It represents slice step of corresponding axis in ``axes``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12386" href="#t12386">12386</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12387" href="#t12387">12387</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12388" href="#t12388">12388</a></span><span class="t"><span class="str">        Variable:  A ``Tensor`` or ``LoDTensor`` with the same dimension as ``input``. The data type is same as ``input``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12389" href="#t12389">12389</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12390" href="#t12390">12390</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12391" href="#t12391">12391</a></span><span class="t"><span class="str">        TypeError: The type of ``starts`` must be list, tuple or Variable.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12392" href="#t12392">12392</a></span><span class="t"><span class="str">        TypeError: The type of ``ends`` must be list, tuple or Variable.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12393" href="#t12393">12393</a></span><span class="t"><span class="str">        TypeError: The type of ``strides`` must be list, tuple or Variable.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12394" href="#t12394">12394</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12395" href="#t12395">12395</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12396" href="#t12396">12396</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12397" href="#t12397">12397</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12398" href="#t12398">12398</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12399" href="#t12399">12399</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12400" href="#t12400">12400</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12401" href="#t12401">12401</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12402" href="#t12402">12402</a></span><span class="t"><span class="str">            input = fluid.data(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12403" href="#t12403">12403</a></span><span class="t"><span class="str">                name="input", shape=[3, 4, 5, 6], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12404" href="#t12404">12404</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12405" href="#t12405">12405</a></span><span class="t"><span class="str">            # example 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12406" href="#t12406">12406</a></span><span class="t"><span class="str">            # attr starts is a list which doesn't contain tensor Variable.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12407" href="#t12407">12407</a></span><span class="t"><span class="str">            axes = [0, 1, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12408" href="#t12408">12408</a></span><span class="t"><span class="str">            starts = [-3, 0, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12409" href="#t12409">12409</a></span><span class="t"><span class="str">            ends = [3, 2, 4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12410" href="#t12410">12410</a></span><span class="t"><span class="str">            strides_1 = [1, 1, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12411" href="#t12411">12411</a></span><span class="t"><span class="str">            strides_2 = [1, 1, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12412" href="#t12412">12412</a></span><span class="t"><span class="str">            sliced_1 = fluid.layers.strided_slice(input, axes=axes, starts=starts, ends=ends, strides=strides_1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12413" href="#t12413">12413</a></span><span class="t"><span class="str">            # sliced_1 is input[:, 0:3:1, 0:2:1, 2:4:1].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12414" href="#t12414">12414</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12415" href="#t12415">12415</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12416" href="#t12416">12416</a></span><span class="t"><span class="str">            # example 2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12417" href="#t12417">12417</a></span><span class="t"><span class="str">            # attr starts is a list which contain tensor Variable.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12418" href="#t12418">12418</a></span><span class="t"><span class="str">            minus_3 = fluid.layers.fill_constant([1], "int32", -3)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12419" href="#t12419">12419</a></span><span class="t"><span class="str">            sliced_2 = fluid.layers.strided_slice(input, axes=axes, starts=[minus_3, 0, 2], ends=ends, strides=strides_2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12420" href="#t12420">12420</a></span><span class="t"><span class="str">            # sliced_2 is input[:, 0:3:1, 0:2:1, 2:4:2].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12421" href="#t12421">12421</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12422" href="#t12422">12422</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12423" href="#t12423">12423</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">strided_slice</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">axes</span><span class="op">,</span> <span class="nam">starts</span><span class="op">,</span> <span class="nam">ends</span><span class="op">,</span> <span class="nam">strides</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12424" href="#t12424">12424</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12425" href="#t12425">12425</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'strided_slice'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12426" href="#t12426">12426</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12427" href="#t12427">12427</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12428" href="#t12428">12428</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12429" href="#t12429">12429</a></span><span class="t">        <span class="str">'input'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12430" href="#t12430">12430</a></span><span class="t">        <span class="op">[</span><span class="str">'bool'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12431" href="#t12431">12431</a></span><span class="t">        <span class="str">'strided_slice'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12432" href="#t12432">12432</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12433" href="#t12433">12433</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">axes</span><span class="op">,</span> <span class="str">'axes'</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">,</span> <span class="str">'strided_slice'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12434" href="#t12434">12434</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">starts</span><span class="op">,</span> <span class="str">'starts'</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">,</span> <span class="str">'strided_slice'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12435" href="#t12435">12435</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">ends</span><span class="op">,</span> <span class="str">'ends'</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">,</span> <span class="str">'strided_slice'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12436" href="#t12436">12436</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">strides</span><span class="op">,</span> <span class="str">'strides'</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">,</span> <span class="str">'strided_slice'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12437" href="#t12437">12437</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12438" href="#t12438">12438</a></span><span class="t">    <span class="key">def</span> <span class="nam">check_list_elements_dtype</span><span class="op">(</span><span class="nam">list_input</span><span class="op">,</span> <span class="nam">input_name</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12439" href="#t12439">12439</a></span><span class="t">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">list_input</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12440" href="#t12440">12440</a></span><span class="t">            <span class="nam">check_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12441" href="#t12441">12441</a></span><span class="t">                <span class="nam">list_input</span><span class="op">.</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">input_name</span><span class="op">,</span> <span class="op">[</span><span class="str">'int32'</span><span class="op">]</span><span class="op">,</span> <span class="str">'strided_slice'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12442" href="#t12442">12442</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12443" href="#t12443">12443</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12444" href="#t12444">12444</a></span><span class="t">            <span class="key">for</span> <span class="nam">i</span><span class="op">,</span> <span class="nam">var</span> <span class="key">in</span> <span class="nam">enumerate</span><span class="op">(</span><span class="nam">list_input</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12445" href="#t12445">12445</a></span><span class="t">                <span class="nam">var_name</span> <span class="op">=</span> <span class="nam">input_name</span> <span class="op">+</span> <span class="str">'['</span> <span class="op">+</span> <span class="nam">str</span><span class="op">(</span><span class="nam">i</span><span class="op">)</span> <span class="op">+</span> <span class="str">']'</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12446" href="#t12446">12446</a></span><span class="t">                <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">var</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12447" href="#t12447">12447</a></span><span class="t">                    <span class="nam">check_dtype</span><span class="op">(</span><span class="nam">var</span><span class="op">.</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">var_name</span><span class="op">,</span> <span class="op">[</span><span class="str">'int32'</span><span class="op">]</span><span class="op">,</span> <span class="str">'strided_slice'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12448" href="#t12448">12448</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12449" href="#t12449">12449</a></span><span class="t">    <span class="nam">check_list_elements_dtype</span><span class="op">(</span><span class="nam">axes</span><span class="op">,</span> <span class="str">'axes'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12450" href="#t12450">12450</a></span><span class="t">    <span class="nam">check_list_elements_dtype</span><span class="op">(</span><span class="nam">starts</span><span class="op">,</span> <span class="str">'starts'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12451" href="#t12451">12451</a></span><span class="t">    <span class="nam">check_list_elements_dtype</span><span class="op">(</span><span class="nam">ends</span><span class="op">,</span> <span class="str">'ends'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12452" href="#t12452">12452</a></span><span class="t">    <span class="nam">check_list_elements_dtype</span><span class="op">(</span><span class="nam">strides</span><span class="op">,</span> <span class="str">'strides'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12453" href="#t12453">12453</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12454" href="#t12454">12454</a></span><span class="t">    <span class="key">def</span> <span class="nam">get_new_list_tensor</span><span class="op">(</span><span class="nam">old_list</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12455" href="#t12455">12455</a></span><span class="t">        <span class="nam">new_list_tensor</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12456" href="#t12456">12456</a></span><span class="t">        <span class="key">for</span> <span class="nam">dim</span> <span class="key">in</span> <span class="nam">old_list</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12457" href="#t12457">12457</a></span><span class="t">            <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12458" href="#t12458">12458</a></span><span class="t">                <span class="nam">dim</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12459" href="#t12459">12459</a></span><span class="t">                <span class="nam">new_list_tensor</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">dim</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12460" href="#t12460">12460</a></span><span class="t">            <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12461" href="#t12461">12461</a></span><span class="t">                <span class="key">assert</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12462" href="#t12462">12462</a></span><span class="t">                <span class="nam">temp_out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="str">'int32'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12463" href="#t12463">12463</a></span><span class="t">                <span class="nam">fill_constant</span><span class="op">(</span><span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="nam">dim</span><span class="op">,</span> <span class="nam">force_cpu</span><span class="op">=</span><span class="key">True</span><span class="op">,</span> <span class="nam">out</span><span class="op">=</span><span class="nam">temp_out</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12464" href="#t12464">12464</a></span><span class="t">                <span class="nam">new_list_tensor</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">temp_out</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12465" href="#t12465">12465</a></span><span class="t">        <span class="key">return</span> <span class="nam">new_list_tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12466" href="#t12466">12466</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12467" href="#t12467">12467</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'Input'</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12468" href="#t12468">12468</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'axes'</span><span class="op">:</span> <span class="nam">axes</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12469" href="#t12469">12469</a></span><span class="t">    <span class="nam">infer_flags</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="num">1</span> <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">len</span><span class="op">(</span><span class="nam">axes</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12470" href="#t12470">12470</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12471" href="#t12471">12471</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12472" href="#t12472">12472</a></span><span class="t">        <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'Input'</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12473" href="#t12473">12473</a></span><span class="t">        <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12474" href="#t12474">12474</a></span><span class="t">            <span class="str">'axes'</span><span class="op">:</span> <span class="nam">axes</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12475" href="#t12475">12475</a></span><span class="t">            <span class="str">'starts'</span><span class="op">:</span> <span class="nam">starts</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12476" href="#t12476">12476</a></span><span class="t">            <span class="str">'ends'</span><span class="op">:</span> <span class="nam">ends</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12477" href="#t12477">12477</a></span><span class="t">            <span class="str">'strides'</span><span class="op">:</span> <span class="nam">strides</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12478" href="#t12478">12478</a></span><span class="t">            <span class="str">'infer_flags'</span><span class="op">:</span> <span class="nam">infer_flags</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12479" href="#t12479">12479</a></span><span class="t">        <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12480" href="#t12480">12480</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12481" href="#t12481">12481</a></span><span class="t">        <span class="com"># starts</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12482" href="#t12482">12482</a></span><span class="t">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">starts</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12483" href="#t12483">12483</a></span><span class="t">            <span class="nam">starts</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12484" href="#t12484">12484</a></span><span class="t">            <span class="nam">inputs</span><span class="op">[</span><span class="str">'StartsTensor'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">starts</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12485" href="#t12485">12485</a></span><span class="t">        <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">starts</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12486" href="#t12486">12486</a></span><span class="t">            <span class="nam">attrs</span><span class="op">[</span><span class="str">'starts'</span><span class="op">]</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12487" href="#t12487">12487</a></span><span class="t">            <span class="key">if</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_contain_var</span><span class="op">(</span><span class="nam">starts</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12488" href="#t12488">12488</a></span><span class="t">                <span class="nam">inputs</span><span class="op">[</span><span class="str">'StartsTensorList'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">get_new_list_tensor</span><span class="op">(</span><span class="nam">starts</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12489" href="#t12489">12489</a></span><span class="t">                <span class="key">for</span> <span class="nam">i</span><span class="op">,</span> <span class="nam">dim</span> <span class="key">in</span> <span class="nam">enumerate</span><span class="op">(</span><span class="nam">starts</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12490" href="#t12490">12490</a></span><span class="t">                    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12491" href="#t12491">12491</a></span><span class="t">                        <span class="nam">attrs</span><span class="op">[</span><span class="str">'starts'</span><span class="op">]</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="op">-</span><span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12492" href="#t12492">12492</a></span><span class="t">                        <span class="nam">infer_flags</span><span class="op">[</span><span class="nam">i</span><span class="op">]</span> <span class="op">=</span> <span class="op">-</span><span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12493" href="#t12493">12493</a></span><span class="t">                    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12494" href="#t12494">12494</a></span><span class="t">                        <span class="nam">attrs</span><span class="op">[</span><span class="str">'starts'</span><span class="op">]</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">dim</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12495" href="#t12495">12495</a></span><span class="t">            <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12496" href="#t12496">12496</a></span><span class="t">                <span class="nam">attrs</span><span class="op">[</span><span class="str">'starts'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">starts</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12497" href="#t12497">12497</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12498" href="#t12498">12498</a></span><span class="t">        <span class="com"># ends</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12499" href="#t12499">12499</a></span><span class="t">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">ends</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12500" href="#t12500">12500</a></span><span class="t">            <span class="nam">ends</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12501" href="#t12501">12501</a></span><span class="t">            <span class="nam">inputs</span><span class="op">[</span><span class="str">'EndsTensor'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">ends</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12502" href="#t12502">12502</a></span><span class="t">        <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">ends</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12503" href="#t12503">12503</a></span><span class="t">            <span class="nam">attrs</span><span class="op">[</span><span class="str">'ends'</span><span class="op">]</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12504" href="#t12504">12504</a></span><span class="t">            <span class="key">if</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_contain_var</span><span class="op">(</span><span class="nam">ends</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12505" href="#t12505">12505</a></span><span class="t">                <span class="nam">inputs</span><span class="op">[</span><span class="str">'EndsTensorList'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">get_new_list_tensor</span><span class="op">(</span><span class="nam">ends</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12506" href="#t12506">12506</a></span><span class="t">                <span class="key">for</span> <span class="nam">i</span><span class="op">,</span> <span class="nam">dim</span> <span class="key">in</span> <span class="nam">enumerate</span><span class="op">(</span><span class="nam">ends</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12507" href="#t12507">12507</a></span><span class="t">                    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12508" href="#t12508">12508</a></span><span class="t">                        <span class="nam">attrs</span><span class="op">[</span><span class="str">'ends'</span><span class="op">]</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="op">-</span><span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12509" href="#t12509">12509</a></span><span class="t">                        <span class="nam">infer_flags</span><span class="op">[</span><span class="nam">i</span><span class="op">]</span> <span class="op">=</span> <span class="op">-</span><span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12510" href="#t12510">12510</a></span><span class="t">                    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12511" href="#t12511">12511</a></span><span class="t">                        <span class="nam">attrs</span><span class="op">[</span><span class="str">'ends'</span><span class="op">]</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">dim</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12512" href="#t12512">12512</a></span><span class="t">            <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12513" href="#t12513">12513</a></span><span class="t">                <span class="nam">attrs</span><span class="op">[</span><span class="str">'ends'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">ends</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12514" href="#t12514">12514</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12515" href="#t12515">12515</a></span><span class="t">        <span class="com"># strides</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12516" href="#t12516">12516</a></span><span class="t">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">strides</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12517" href="#t12517">12517</a></span><span class="t">            <span class="nam">strides</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12518" href="#t12518">12518</a></span><span class="t">            <span class="nam">inputs</span><span class="op">[</span><span class="str">'StridesTensor'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">strides</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12519" href="#t12519">12519</a></span><span class="t">        <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">strides</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12520" href="#t12520">12520</a></span><span class="t">            <span class="nam">attrs</span><span class="op">[</span><span class="str">'strides'</span><span class="op">]</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12521" href="#t12521">12521</a></span><span class="t">            <span class="key">if</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">_contain_var</span><span class="op">(</span><span class="nam">strides</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12522" href="#t12522">12522</a></span><span class="t">                <span class="nam">inputs</span><span class="op">[</span><span class="str">'StridesTensorList'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">get_new_list_tensor</span><span class="op">(</span><span class="nam">strides</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12523" href="#t12523">12523</a></span><span class="t">                <span class="key">for</span> <span class="nam">i</span><span class="op">,</span> <span class="nam">dim</span> <span class="key">in</span> <span class="nam">enumerate</span><span class="op">(</span><span class="nam">strides</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12524" href="#t12524">12524</a></span><span class="t">                    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12525" href="#t12525">12525</a></span><span class="t">                        <span class="nam">attrs</span><span class="op">[</span><span class="str">'strides'</span><span class="op">]</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="op">-</span><span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12526" href="#t12526">12526</a></span><span class="t">                        <span class="nam">infer_flags</span><span class="op">[</span><span class="nam">i</span><span class="op">]</span> <span class="op">=</span> <span class="op">-</span><span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12527" href="#t12527">12527</a></span><span class="t">                    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12528" href="#t12528">12528</a></span><span class="t">                        <span class="nam">attrs</span><span class="op">[</span><span class="str">'strides'</span><span class="op">]</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">dim</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12529" href="#t12529">12529</a></span><span class="t">            <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12530" href="#t12530">12530</a></span><span class="t">                <span class="nam">attrs</span><span class="op">[</span><span class="str">'strides'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">strides</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12531" href="#t12531">12531</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">'infer_flags'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">infer_flags</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12532" href="#t12532">12532</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12533" href="#t12533">12533</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="str">'input'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12534" href="#t12534">12534</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12535" href="#t12535">12535</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12536" href="#t12536">12536</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'strided_slice'</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12537" href="#t12537">12537</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12538" href="#t12538">12538</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12539" href="#t12539">12539</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12540" href="#t12540">12540</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12541" href="#t12541">12541</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12542" href="#t12542">12542</a></span><span class="t"><span class="key">def</span> <span class="nam">shape</span><span class="op">(</span><span class="nam">input</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12543" href="#t12543">12543</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12544" href="#t12544">12544</a></span><span class="t"><span class="str">    :alias_main: paddle.shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12545" href="#t12545">12545</a></span><span class="t"><span class="str">        :alias: paddle.shape,paddle.tensor.shape,paddle.tensor.attribute.shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12546" href="#t12546">12546</a></span><span class="t"><span class="str">        :old_api: paddle.fluid.layers.shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12547" href="#t12547">12547</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12548" href="#t12548">12548</a></span><span class="t"><span class="str">    **Shape Layer**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12549" href="#t12549">12549</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12550" href="#t12550">12550</a></span><span class="t"><span class="str">    Get the shape of the input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12551" href="#t12551">12551</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12552" href="#t12552">12552</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12553" href="#t12553">12553</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12554" href="#t12554">12554</a></span><span class="t"><span class="str">        Case1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12555" href="#t12555">12555</a></span><span class="t"><span class="str">            Given N-D Tensor:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12556" href="#t12556">12556</a></span><span class="t"><span class="str">                input = [ [1, 2, 3, 4], [5, 6, 7, 8] ]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12557" href="#t12557">12557</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12558" href="#t12558">12558</a></span><span class="t"><span class="str">            Then:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12559" href="#t12559">12559</a></span><span class="t"><span class="str">                input.shape = [2, 4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12560" href="#t12560">12560</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12561" href="#t12561">12561</a></span><span class="t"><span class="str">        Case2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12562" href="#t12562">12562</a></span><span class="t"><span class="str">            Given SelectedRows:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12563" href="#t12563">12563</a></span><span class="t"><span class="str">                input.rows = [0, 4, 19]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12564" href="#t12564">12564</a></span><span class="t"><span class="str">                input.height = 20</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12565" href="#t12565">12565</a></span><span class="t"><span class="str">                input.value = [ [1, 2], [3, 4], [5, 6] ]  # inner tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12566" href="#t12566">12566</a></span><span class="t"><span class="str">            Then:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12567" href="#t12567">12567</a></span><span class="t"><span class="str">                input.shape = [3, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12568" href="#t12568">12568</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12569" href="#t12569">12569</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12570" href="#t12570">12570</a></span><span class="t"><span class="str">        input (Variable): The input can be N-D Tensor or SelectedRows with data type bool, float16, float32, float64, int32, int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12571" href="#t12571">12571</a></span><span class="t"><span class="str">                          If input variable is type of SelectedRows, returns the shape of it's inner tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12572" href="#t12572">12572</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12573" href="#t12573">12573</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12574" href="#t12574">12574</a></span><span class="t"><span class="str">        Variable (Tensor): The shape of the input variable.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12575" href="#t12575">12575</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12576" href="#t12576">12576</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12577" href="#t12577">12577</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12578" href="#t12578">12578</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12579" href="#t12579">12579</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12580" href="#t12580">12580</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12581" href="#t12581">12581</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12582" href="#t12582">12582</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12583" href="#t12583">12583</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12584" href="#t12584">12584</a></span><span class="t"><span class="str">            inputs = fluid.data(name="x", shape=[3, 100, 100], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12585" href="#t12585">12585</a></span><span class="t"><span class="str">            output = fluid.layers.shape(inputs)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12586" href="#t12586">12586</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12587" href="#t12587">12587</a></span><span class="t"><span class="str">            exe = fluid.Executor(fluid.CPUPlace())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12588" href="#t12588">12588</a></span><span class="t"><span class="str">            exe.run(fluid.default_startup_program())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12589" href="#t12589">12589</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12590" href="#t12590">12590</a></span><span class="t"><span class="str">            img = np.ones((3, 100, 100)).astype(np.float32)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12591" href="#t12591">12591</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12592" href="#t12592">12592</a></span><span class="t"><span class="str">            res = exe.run(fluid.default_main_program(), feed={'x':img}, fetch_list=[output])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12593" href="#t12593">12593</a></span><span class="t"><span class="str">            print(res) # [array([  3, 100, 100], dtype=int32)]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12594" href="#t12594">12594</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12595" href="#t12595">12595</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12596" href="#t12596">12596</a></span><span class="t">        <span class="nam">out</span> <span class="op">=</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">shape</span><span class="op">(</span><span class="nam">input</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12597" href="#t12597">12597</a></span><span class="t">        <span class="nam">out</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12598" href="#t12598">12598</a></span><span class="t">        <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12599" href="#t12599">12599</a></span><span class="t">    <span class="key">if</span> <span class="nam">_in_legacy_dygraph</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12600" href="#t12600">12600</a></span><span class="t">        <span class="nam">out</span> <span class="op">=</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">shape</span><span class="op">(</span><span class="nam">input</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12601" href="#t12601">12601</a></span><span class="t">        <span class="nam">out</span><span class="op">.</span><span class="nam">stop_gradient</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12602" href="#t12602">12602</a></span><span class="t">        <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12603" href="#t12603">12603</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12604" href="#t12604">12604</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12605" href="#t12605">12605</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12606" href="#t12606">12606</a></span><span class="t">        <span class="str">'input'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12607" href="#t12607">12607</a></span><span class="t">        <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12608" href="#t12608">12608</a></span><span class="t">            <span class="str">'bool'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12609" href="#t12609">12609</a></span><span class="t">            <span class="str">'float16'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12610" href="#t12610">12610</a></span><span class="t">            <span class="str">'float32'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12611" href="#t12611">12611</a></span><span class="t">            <span class="str">'float64'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12612" href="#t12612">12612</a></span><span class="t">            <span class="str">'int32'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12613" href="#t12613">12613</a></span><span class="t">            <span class="str">'int64'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12614" href="#t12614">12614</a></span><span class="t">            <span class="str">'complex64'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12615" href="#t12615">12615</a></span><span class="t">            <span class="str">'complex128'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12616" href="#t12616">12616</a></span><span class="t">        <span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12617" href="#t12617">12617</a></span><span class="t">        <span class="str">'shape'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12618" href="#t12618">12618</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12619" href="#t12619">12619</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'shape'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12620" href="#t12620">12620</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="str">'int32'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12621" href="#t12621">12621</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12622" href="#t12622">12622</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'shape'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12623" href="#t12623">12623</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Input'</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12624" href="#t12624">12624</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12625" href="#t12625">12625</a></span><span class="t">        <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12626" href="#t12626">12626</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12627" href="#t12627">12627</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12628" href="#t12628">12628</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12629" href="#t12629">12629</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12630" href="#t12630">12630</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12631" href="#t12631">12631</a></span><span class="t"><span class="key">def</span> <span class="nam">rank</span><span class="op">(</span><span class="nam">input</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12632" href="#t12632">12632</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12633" href="#t12633">12633</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12634" href="#t12634">12634</a></span><span class="t"><span class="str">    The OP returns the number of dimensions for a tensor, which is a 0-D int32 Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12635" href="#t12635">12635</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12636" href="#t12636">12636</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12637" href="#t12637">12637</a></span><span class="t"><span class="str">        input (Tensor): The input N-D tensor with shape of :math:`[N_1, N_2, ..., N_k]`, the data type is arbitrary.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12638" href="#t12638">12638</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12639" href="#t12639">12639</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12640" href="#t12640">12640</a></span><span class="t"><span class="str">        Tensor, the output data type is int32.: The 0-D tensor with the dimensions of the input Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12641" href="#t12641">12641</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12642" href="#t12642">12642</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12643" href="#t12643">12643</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12644" href="#t12644">12644</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12645" href="#t12645">12645</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12646" href="#t12646">12646</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12647" href="#t12647">12647</a></span><span class="t"><span class="str">            input = paddle.rand((3, 100, 100))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12648" href="#t12648">12648</a></span><span class="t"><span class="str">            rank = paddle.rank(input)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12649" href="#t12649">12649</a></span><span class="t"><span class="str">            print(rank)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12650" href="#t12650">12650</a></span><span class="t"><span class="str">            # 3</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12651" href="#t12651">12651</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12652" href="#t12652">12652</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">(</span><span class="nam">Variable</span><span class="op">)</span><span class="op">,</span> <span class="str">'input'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12653" href="#t12653">12653</a></span><span class="t">    <span class="nam">ndims</span> <span class="op">=</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12654" href="#t12654">12654</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">assign</span><span class="op">(</span><span class="nam">np</span><span class="op">.</span><span class="nam">array</span><span class="op">(</span><span class="nam">ndims</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12655" href="#t12655">12655</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12656" href="#t12656">12656</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12657" href="#t12657">12657</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12658" href="#t12658">12658</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12659" href="#t12659">12659</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.numel"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12660" href="#t12660">12660</a></span><span class="t"><span class="key">def</span> <span class="nam">size</span><span class="op">(</span><span class="nam">input</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12661" href="#t12661">12661</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12662" href="#t12662">12662</a></span><span class="t"><span class="str">    **Size Layer**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12663" href="#t12663">12663</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12664" href="#t12664">12664</a></span><span class="t"><span class="str">    Returns the number of elements for a tensor, which is a int64 Tensor with shape [1].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12665" href="#t12665">12665</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12666" href="#t12666">12666</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12667" href="#t12667">12667</a></span><span class="t"><span class="str">        input (Tensor): The input Tensor, it's data type can be bool, float16, float32, float64, int32, int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12668" href="#t12668">12668</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12669" href="#t12669">12669</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12670" href="#t12670">12670</a></span><span class="t"><span class="str">        Tensor: The number of elements for the input Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12671" href="#t12671">12671</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12672" href="#t12672">12672</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12673" href="#t12673">12673</a></span><span class="t"><span class="str">        TypeError: ``input`` must be a Tensor and the data type of ``input`` must be one of bool, float16, float32, float64, int32, int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12674" href="#t12674">12674</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12675" href="#t12675">12675</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12676" href="#t12676">12676</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12677" href="#t12677">12677</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12678" href="#t12678">12678</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12679" href="#t12679">12679</a></span><span class="t"><span class="str">            import paddle.fluid.layers as layers</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12680" href="#t12680">12680</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12681" href="#t12681">12681</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12682" href="#t12682">12682</a></span><span class="t"><span class="str">            input = layers.data(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12683" href="#t12683">12683</a></span><span class="t"><span class="str">                name="input", shape=[3, 100], dtype="float32", append_batch_size=False)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12684" href="#t12684">12684</a></span><span class="t"><span class="str">            rank = layers.size(input) # 300</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12685" href="#t12685">12685</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12686" href="#t12686">12686</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12687" href="#t12687">12687</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12688" href="#t12688">12688</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">size</span><span class="op">(</span><span class="nam">input</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12689" href="#t12689">12689</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12690" href="#t12690">12690</a></span><span class="t">    <span class="key">if</span> <span class="nam">_in_legacy_dygraph</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12691" href="#t12691">12691</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">size</span><span class="op">(</span><span class="nam">input</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12692" href="#t12692">12692</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12693" href="#t12693">12693</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12694" href="#t12694">12694</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12695" href="#t12695">12695</a></span><span class="t">        <span class="str">'input'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12696" href="#t12696">12696</a></span><span class="t">        <span class="op">[</span><span class="str">'bool'</span><span class="op">,</span> <span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12697" href="#t12697">12697</a></span><span class="t">        <span class="str">"size"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12698" href="#t12698">12698</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12699" href="#t12699">12699</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'size'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12700" href="#t12700">12700</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="str">'int64'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12701" href="#t12701">12701</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">'size'</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Input'</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12702" href="#t12702">12702</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12703" href="#t12703">12703</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12704" href="#t12704">12704</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12705" href="#t12705">12705</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12706" href="#t12706">12706</a></span><span class="t"><span class="key">def</span> <span class="nam">_elementwise_op</span><span class="op">(</span><span class="nam">helper</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12707" href="#t12707">12707</a></span><span class="t">    <span class="nam">op_type</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">layer_type</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12708" href="#t12708">12708</a></span><span class="t">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">kwargs</span><span class="op">.</span><span class="nam">get</span><span class="op">(</span><span class="str">'x'</span><span class="op">,</span> <span class="key">None</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12709" href="#t12709">12709</a></span><span class="t">    <span class="nam">y</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">kwargs</span><span class="op">.</span><span class="nam">get</span><span class="op">(</span><span class="str">'y'</span><span class="op">,</span> <span class="key">None</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12710" href="#t12710">12710</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12711" href="#t12711">12711</a></span><span class="t">    <span class="key">assert</span> <span class="nam">x</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">,</span> <span class="str">'x cannot be None in {}'</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">op_type</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12712" href="#t12712">12712</a></span><span class="t">    <span class="key">assert</span> <span class="nam">y</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">,</span> <span class="str">'y cannot be None in {}'</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">op_type</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12713" href="#t12713">12713</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12714" href="#t12714">12714</a></span><span class="t">        <span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12715" href="#t12715">12715</a></span><span class="t">        <span class="str">'x'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12716" href="#t12716">12716</a></span><span class="t">        <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'uint16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12717" href="#t12717">12717</a></span><span class="t">        <span class="nam">op_type</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12718" href="#t12718">12718</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12719" href="#t12719">12719</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12720" href="#t12720">12720</a></span><span class="t">        <span class="nam">y</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12721" href="#t12721">12721</a></span><span class="t">        <span class="str">'y'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12722" href="#t12722">12722</a></span><span class="t">        <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'uint16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12723" href="#t12723">12723</a></span><span class="t">        <span class="nam">op_type</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12724" href="#t12724">12724</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12725" href="#t12725">12725</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12726" href="#t12726">12726</a></span><span class="t">    <span class="nam">axis</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">kwargs</span><span class="op">.</span><span class="nam">get</span><span class="op">(</span><span class="str">'axis'</span><span class="op">,</span> <span class="op">-</span><span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12727" href="#t12727">12727</a></span><span class="t">    <span class="nam">use_mkldnn</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">kwargs</span><span class="op">.</span><span class="nam">get</span><span class="op">(</span><span class="str">'use_mkldnn'</span><span class="op">,</span> <span class="key">False</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12728" href="#t12728">12728</a></span><span class="t">    <span class="nam">name</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">kwargs</span><span class="op">.</span><span class="nam">get</span><span class="op">(</span><span class="str">'name'</span><span class="op">,</span> <span class="key">None</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12729" href="#t12729">12729</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12730" href="#t12730">12730</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12731" href="#t12731">12731</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12732" href="#t12732">12732</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="nam">op_type</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12733" href="#t12733">12733</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">,</span> <span class="str">'Y'</span><span class="op">:</span> <span class="nam">y</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12734" href="#t12734">12734</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12735" href="#t12735">12735</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'axis'</span><span class="op">:</span> <span class="nam">axis</span><span class="op">,</span> <span class="str">'use_mkldnn'</span><span class="op">:</span> <span class="nam">use_mkldnn</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12736" href="#t12736">12736</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12737" href="#t12737">12737</a></span><span class="t">    <span class="key">return</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_activation</span><span class="op">(</span><span class="nam">out</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12738" href="#t12738">12738</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12739" href="#t12739">12739</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12740" href="#t12740">12740</a></span><span class="t"><span class="key">def</span> <span class="nam">scale</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">scale</span><span class="op">=</span><span class="num">1.0</span><span class="op">,</span> <span class="nam">bias</span><span class="op">=</span><span class="num">0.0</span><span class="op">,</span> <span class="nam">bias_after_scale</span><span class="op">=</span><span class="key">True</span><span class="op">,</span> <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12741" href="#t12741">12741</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12742" href="#t12742">12742</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12743" href="#t12743">12743</a></span><span class="t"><span class="str">    Putting scale and bias to the input Tensor as following:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12744" href="#t12744">12744</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12745" href="#t12745">12745</a></span><span class="t"><span class="str">    ``bias_after_scale`` is True:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12746" href="#t12746">12746</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12747" href="#t12747">12747</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12748" href="#t12748">12748</a></span><span class="t"><span class="str">                            Out=scale*X+bias</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12749" href="#t12749">12749</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12750" href="#t12750">12750</a></span><span class="t"><span class="str">    ``bias_after_scale`` is False:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12751" href="#t12751">12751</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12752" href="#t12752">12752</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12753" href="#t12753">12753</a></span><span class="t"><span class="str">                            Out=scale*(X+bias)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12754" href="#t12754">12754</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12755" href="#t12755">12755</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12756" href="#t12756">12756</a></span><span class="t"><span class="str">        x(Tensor): Input N-D Tensor of scale operator. Data type can be float32, float64, int8, int16, int32, int64, uint8.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12757" href="#t12757">12757</a></span><span class="t"><span class="str">        scale(float|Tensor): The scale factor of the input, it should be a float number or a Tensor with shape [1] and data type as float32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12758" href="#t12758">12758</a></span><span class="t"><span class="str">        bias(float): The bias to be put on the input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12759" href="#t12759">12759</a></span><span class="t"><span class="str">        bias_after_scale(bool): Apply bias addition after or before scaling. It is useful for numeric stability in some circumstances.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12760" href="#t12760">12760</a></span><span class="t"><span class="str">        act(str, optional): Activation applied to the output such as tanh, softmax, sigmoid, relu.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12761" href="#t12761">12761</a></span><span class="t"><span class="str">        name(str, optional): The default value is None. Normally there is no need for user to set this property.  For more information, please refer to :ref:`api_guide_Name`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12762" href="#t12762">12762</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12763" href="#t12763">12763</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12764" href="#t12764">12764</a></span><span class="t"><span class="str">        Tensor: Output tensor of scale operator, with shape and data type same as input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12765" href="#t12765">12765</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12766" href="#t12766">12766</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12767" href="#t12767">12767</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12768" href="#t12768">12768</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12769" href="#t12769">12769</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12770" href="#t12770">12770</a></span><span class="t"><span class="str">            # scale as a float32 number</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12771" href="#t12771">12771</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12772" href="#t12772">12772</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12773" href="#t12773">12773</a></span><span class="t"><span class="str">            data = paddle.randn(shape=[2,3], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12774" href="#t12774">12774</a></span><span class="t"><span class="str">            res = paddle.scale(data, scale=2.0, bias=1.0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12775" href="#t12775">12775</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12776" href="#t12776">12776</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12777" href="#t12777">12777</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12778" href="#t12778">12778</a></span><span class="t"><span class="str">            # scale with parameter scale as a Tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12779" href="#t12779">12779</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12780" href="#t12780">12780</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12781" href="#t12781">12781</a></span><span class="t"><span class="str">            data = paddle.randn(shape=[2, 3], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12782" href="#t12782">12782</a></span><span class="t"><span class="str">            factor = paddle.to_tensor([2], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12783" href="#t12783">12783</a></span><span class="t"><span class="str">            res = paddle.scale(data, scale=factor, bias=1.0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12784" href="#t12784">12784</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12785" href="#t12785">12785</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12786" href="#t12786">12786</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12787" href="#t12787">12787</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12788" href="#t12788">12788</a></span><span class="t">        <span class="nam">out</span> <span class="op">=</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">scale</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">scale</span><span class="op">,</span> <span class="nam">float</span><span class="op">(</span><span class="nam">bias</span><span class="op">)</span><span class="op">,</span> <span class="nam">bias_after_scale</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12789" href="#t12789">12789</a></span><span class="t">        <span class="key">return</span> <span class="nam">dygraph_utils</span><span class="op">.</span><span class="nam">_append_activation_in_dygraph</span><span class="op">(</span><span class="nam">out</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12790" href="#t12790">12790</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12791" href="#t12791">12791</a></span><span class="t">        <span class="nam">_scale</span> <span class="op">=</span> <span class="nam">scale</span><span class="op">.</span><span class="nam">numpy</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">item</span><span class="op">(</span><span class="num">0</span><span class="op">)</span> <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">scale</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span> <span class="key">else</span> <span class="nam">scale</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12792" href="#t12792">12792</a></span><span class="t">        <span class="nam">out</span> <span class="op">=</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">scale</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12793" href="#t12793">12793</a></span><span class="t">            <span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12794" href="#t12794">12794</a></span><span class="t">            <span class="str">'scale'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12795" href="#t12795">12795</a></span><span class="t">            <span class="nam">float</span><span class="op">(</span><span class="nam">_scale</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12796" href="#t12796">12796</a></span><span class="t">            <span class="str">'bias'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12797" href="#t12797">12797</a></span><span class="t">            <span class="nam">float</span><span class="op">(</span><span class="nam">bias</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12798" href="#t12798">12798</a></span><span class="t">            <span class="str">'bias_after_scale'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12799" href="#t12799">12799</a></span><span class="t">            <span class="nam">bias_after_scale</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12800" href="#t12800">12800</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12801" href="#t12801">12801</a></span><span class="t">        <span class="key">return</span> <span class="nam">dygraph_utils</span><span class="op">.</span><span class="nam">_append_activation_in_dygraph</span><span class="op">(</span><span class="nam">out</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12802" href="#t12802">12802</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12803" href="#t12803">12803</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12804" href="#t12804">12804</a></span><span class="t">        <span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12805" href="#t12805">12805</a></span><span class="t">        <span class="str">"x"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12806" href="#t12806">12806</a></span><span class="t">        <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12807" href="#t12807">12807</a></span><span class="t">            <span class="str">'float16'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12808" href="#t12808">12808</a></span><span class="t">            <span class="str">'uint16'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12809" href="#t12809">12809</a></span><span class="t">            <span class="str">'float32'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12810" href="#t12810">12810</a></span><span class="t">            <span class="str">'float64'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12811" href="#t12811">12811</a></span><span class="t">            <span class="str">'int8'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12812" href="#t12812">12812</a></span><span class="t">            <span class="str">'int16'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12813" href="#t12813">12813</a></span><span class="t">            <span class="str">'int32'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12814" href="#t12814">12814</a></span><span class="t">            <span class="str">'int64'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12815" href="#t12815">12815</a></span><span class="t">            <span class="str">'uint8'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12816" href="#t12816">12816</a></span><span class="t">        <span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12817" href="#t12817">12817</a></span><span class="t">        <span class="str">"scale"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12818" href="#t12818">12818</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12819" href="#t12819">12819</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="op">[</span><span class="nam">x</span><span class="op">]</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12820" href="#t12820">12820</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12821" href="#t12821">12821</a></span><span class="t">        <span class="str">'bias'</span><span class="op">:</span> <span class="nam">float</span><span class="op">(</span><span class="nam">bias</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12822" href="#t12822">12822</a></span><span class="t">        <span class="str">'bias_after_scale'</span><span class="op">:</span> <span class="nam">bias_after_scale</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12823" href="#t12823">12823</a></span><span class="t">    <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12824" href="#t12824">12824</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">scale</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12825" href="#t12825">12825</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">'ScaleTensor'</span><span class="op">]</span> <span class="op">=</span> <span class="op">[</span><span class="nam">scale</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12826" href="#t12826">12826</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12827" href="#t12827">12827</a></span><span class="t">        <span class="nam">attrs</span><span class="op">[</span><span class="str">'scale'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">float</span><span class="op">(</span><span class="nam">scale</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12828" href="#t12828">12828</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'scale'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12829" href="#t12829">12829</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12830" href="#t12830">12830</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12831" href="#t12831">12831</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12832" href="#t12832">12832</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'scale'</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span> <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12833" href="#t12833">12833</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t12834" href="#t12834">12834</a></span><span class="t">    <span class="key">return</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_activation</span><span class="op">(</span><span class="nam">out</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12835" href="#t12835">12835</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12836" href="#t12836">12836</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12837" href="#t12837">12837</a></span><span class="t"><span class="key">def</span> <span class="nam">elementwise_add</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12838" href="#t12838">12838</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12839" href="#t12839">12839</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12840" href="#t12840">12840</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12841" href="#t12841">12841</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12842" href="#t12842">12842</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12843" href="#t12843">12843</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12844" href="#t12844">12844</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12845" href="#t12845">12845</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12846" href="#t12846">12846</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12847" href="#t12847">12847</a></span><span class="t"><span class="str">            def gen_data():</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12848" href="#t12848">12848</a></span><span class="t"><span class="str">                return {</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12849" href="#t12849">12849</a></span><span class="t"><span class="str">                    "x": np.array([2, 3, 4]).astype('float32'),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12850" href="#t12850">12850</a></span><span class="t"><span class="str">                    "y": np.array([1, 5, 2]).astype('float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12851" href="#t12851">12851</a></span><span class="t"><span class="str">                }</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12852" href="#t12852">12852</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12853" href="#t12853">12853</a></span><span class="t"><span class="str">            x = fluid.data(name="x", shape=[3], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12854" href="#t12854">12854</a></span><span class="t"><span class="str">            y = fluid.data(name="y", shape=[3], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12855" href="#t12855">12855</a></span><span class="t"><span class="str">            z = fluid.layers.elementwise_add(x, y)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12856" href="#t12856">12856</a></span><span class="t"><span class="str">            # z = x + y</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12857" href="#t12857">12857</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12858" href="#t12858">12858</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12859" href="#t12859">12859</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12860" href="#t12860">12860</a></span><span class="t"><span class="str">            z_value = exe.run(feed=gen_data(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12861" href="#t12861">12861</a></span><span class="t"><span class="str">                                fetch_list=[z.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12862" href="#t12862">12862</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12863" href="#t12863">12863</a></span><span class="t"><span class="str">            print(z_value) # [3., 8., 6.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12864" href="#t12864">12864</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12865" href="#t12865">12865</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12866" href="#t12866">12866</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12867" href="#t12867">12867</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12868" href="#t12868">12868</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12869" href="#t12869">12869</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12870" href="#t12870">12870</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12871" href="#t12871">12871</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12872" href="#t12872">12872</a></span><span class="t"><span class="str">            def gen_data():</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12873" href="#t12873">12873</a></span><span class="t"><span class="str">                return {</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12874" href="#t12874">12874</a></span><span class="t"><span class="str">                    "x": np.ones((2, 3, 4, 5)).astype('float32'),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12875" href="#t12875">12875</a></span><span class="t"><span class="str">                    "y": np.zeros((3, 4)).astype('float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12876" href="#t12876">12876</a></span><span class="t"><span class="str">                }</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12877" href="#t12877">12877</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12878" href="#t12878">12878</a></span><span class="t"><span class="str">            x = fluid.data(name="x", shape=[2,3,4,5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12879" href="#t12879">12879</a></span><span class="t"><span class="str">            y = fluid.data(name="y", shape=[3,4], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12880" href="#t12880">12880</a></span><span class="t"><span class="str">            z = fluid.layers.elementwise_add(x, y, axis=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12881" href="#t12881">12881</a></span><span class="t"><span class="str">            # z = x + y</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12882" href="#t12882">12882</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12883" href="#t12883">12883</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12884" href="#t12884">12884</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12885" href="#t12885">12885</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12886" href="#t12886">12886</a></span><span class="t"><span class="str">            z_value = exe.run(feed=gen_data(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12887" href="#t12887">12887</a></span><span class="t"><span class="str">                                fetch_list=[z.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12888" href="#t12888">12888</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12889" href="#t12889">12889</a></span><span class="t"><span class="str">            print(z_value) # z.shape=[2,3,4,5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12890" href="#t12890">12890</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12891" href="#t12891">12891</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12892" href="#t12892">12892</a></span><span class="t"><span class="str">        ..  code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12893" href="#t12893">12893</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12894" href="#t12894">12894</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12895" href="#t12895">12895</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12896" href="#t12896">12896</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12897" href="#t12897">12897</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12898" href="#t12898">12898</a></span><span class="t"><span class="str">            def gen_data():</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12899" href="#t12899">12899</a></span><span class="t"><span class="str">                return {</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12900" href="#t12900">12900</a></span><span class="t"><span class="str">                    "x": np.random.randint(1, 5, size=[2, 3, 4, 5]).astype('float32'),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12901" href="#t12901">12901</a></span><span class="t"><span class="str">                    "y": np.random.randint(1, 5, size=[5]).astype('float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12902" href="#t12902">12902</a></span><span class="t"><span class="str">                }</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12903" href="#t12903">12903</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12904" href="#t12904">12904</a></span><span class="t"><span class="str">            x = fluid.data(name="x", shape=[2,3,4,5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12905" href="#t12905">12905</a></span><span class="t"><span class="str">            y = fluid.data(name="y", shape=[5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12906" href="#t12906">12906</a></span><span class="t"><span class="str">            z = fluid.layers.elementwise_add(x, y, axis=3)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12907" href="#t12907">12907</a></span><span class="t"><span class="str">            # z = x + y</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12908" href="#t12908">12908</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12909" href="#t12909">12909</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12910" href="#t12910">12910</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12911" href="#t12911">12911</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12912" href="#t12912">12912</a></span><span class="t"><span class="str">            z_value = exe.run(feed=gen_data(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12913" href="#t12913">12913</a></span><span class="t"><span class="str">                                fetch_list=[z.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12914" href="#t12914">12914</a></span><span class="t"><span class="str">            print(z_value) # z.shape=[2,3,4,5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12915" href="#t12915">12915</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12916" href="#t12916">12916</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12917" href="#t12917">12917</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12918" href="#t12918">12918</a></span><span class="t">        <span class="key">return</span> <span class="nam">_elementwise_op_in_dygraph</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12919" href="#t12919">12919</a></span><span class="t">            <span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12920" href="#t12920">12920</a></span><span class="t">            <span class="nam">y</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12921" href="#t12921">12921</a></span><span class="t">            <span class="nam">axis</span><span class="op">=</span><span class="nam">axis</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12922" href="#t12922">12922</a></span><span class="t">            <span class="nam">act</span><span class="op">=</span><span class="nam">act</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12923" href="#t12923">12923</a></span><span class="t">            <span class="nam">op_name</span><span class="op">=</span><span class="str">'elementwise_add'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12924" href="#t12924">12924</a></span><span class="t">            <span class="nam">use_mkldnn</span><span class="op">=</span><span class="nam">_global_flags</span><span class="op">(</span><span class="op">)</span><span class="op">[</span><span class="str">"FLAGS_use_mkldnn"</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12925" href="#t12925">12925</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12926" href="#t12926">12926</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12927" href="#t12927">12927</a></span><span class="t">    <span class="key">return</span> <span class="nam">_elementwise_op</span><span class="op">(</span><span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'elementwise_add'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12928" href="#t12928">12928</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12929" href="#t12929">12929</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12930" href="#t12930">12930</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.divide"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12931" href="#t12931">12931</a></span><span class="t"><span class="key">def</span> <span class="nam">elementwise_div</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12932" href="#t12932">12932</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12933" href="#t12933">12933</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12934" href="#t12934">12934</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12935" href="#t12935">12935</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12936" href="#t12936">12936</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12937" href="#t12937">12937</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12938" href="#t12938">12938</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12939" href="#t12939">12939</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12940" href="#t12940">12940</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12941" href="#t12941">12941</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12942" href="#t12942">12942</a></span><span class="t"><span class="str">            def gen_data():</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12943" href="#t12943">12943</a></span><span class="t"><span class="str">                return {</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12944" href="#t12944">12944</a></span><span class="t"><span class="str">                    "x": np.array([2, 3, 4]).astype('float32'),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12945" href="#t12945">12945</a></span><span class="t"><span class="str">                    "y": np.array([1, 5, 2]).astype('float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12946" href="#t12946">12946</a></span><span class="t"><span class="str">                }</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12947" href="#t12947">12947</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12948" href="#t12948">12948</a></span><span class="t"><span class="str">            x = fluid.data(name="x", shape=[3], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12949" href="#t12949">12949</a></span><span class="t"><span class="str">            y = fluid.data(name="y", shape=[3], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12950" href="#t12950">12950</a></span><span class="t"><span class="str">            z = fluid.layers.elementwise_div(x, y)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12951" href="#t12951">12951</a></span><span class="t"><span class="str">            # z = x / y</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12952" href="#t12952">12952</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12953" href="#t12953">12953</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12954" href="#t12954">12954</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12955" href="#t12955">12955</a></span><span class="t"><span class="str">            z_value = exe.run(feed=gen_data(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12956" href="#t12956">12956</a></span><span class="t"><span class="str">                                fetch_list=[z.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12957" href="#t12957">12957</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12958" href="#t12958">12958</a></span><span class="t"><span class="str">            print(z_value) # [2., 0.6, 2.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12959" href="#t12959">12959</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12960" href="#t12960">12960</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12961" href="#t12961">12961</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12962" href="#t12962">12962</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12963" href="#t12963">12963</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12964" href="#t12964">12964</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12965" href="#t12965">12965</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12966" href="#t12966">12966</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12967" href="#t12967">12967</a></span><span class="t"><span class="str">            def gen_data():</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12968" href="#t12968">12968</a></span><span class="t"><span class="str">                return {</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12969" href="#t12969">12969</a></span><span class="t"><span class="str">                    "x": np.ones((2, 3, 4, 5)).astype('float32'),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12970" href="#t12970">12970</a></span><span class="t"><span class="str">                    "y": np.zeros((3, 4)).astype('float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12971" href="#t12971">12971</a></span><span class="t"><span class="str">                }</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12972" href="#t12972">12972</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12973" href="#t12973">12973</a></span><span class="t"><span class="str">            x = fluid.data(name="x", shape=[2,3,4,5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12974" href="#t12974">12974</a></span><span class="t"><span class="str">            y = fluid.data(name="y", shape=[3,4], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12975" href="#t12975">12975</a></span><span class="t"><span class="str">            z = fluid.layers.elementwise_div(x, y, axis=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12976" href="#t12976">12976</a></span><span class="t"><span class="str">            # z = x / y</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12977" href="#t12977">12977</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12978" href="#t12978">12978</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12979" href="#t12979">12979</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12980" href="#t12980">12980</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12981" href="#t12981">12981</a></span><span class="t"><span class="str">            z_value = exe.run(feed=gen_data(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12982" href="#t12982">12982</a></span><span class="t"><span class="str">                                fetch_list=[z.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12983" href="#t12983">12983</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12984" href="#t12984">12984</a></span><span class="t"><span class="str">            print(z_value) # z.shape=[2,3,4,5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12985" href="#t12985">12985</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12986" href="#t12986">12986</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12987" href="#t12987">12987</a></span><span class="t"><span class="str">        ..  code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12988" href="#t12988">12988</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12989" href="#t12989">12989</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12990" href="#t12990">12990</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12991" href="#t12991">12991</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12992" href="#t12992">12992</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12993" href="#t12993">12993</a></span><span class="t"><span class="str">            def gen_data():</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12994" href="#t12994">12994</a></span><span class="t"><span class="str">                return {</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12995" href="#t12995">12995</a></span><span class="t"><span class="str">                    "x": np.random.randint(1, 5, size=[2, 3, 4, 5]).astype('float32'),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12996" href="#t12996">12996</a></span><span class="t"><span class="str">                    "y": np.random.randint(1, 5, size=[5]).astype('float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12997" href="#t12997">12997</a></span><span class="t"><span class="str">                }</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12998" href="#t12998">12998</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t12999" href="#t12999">12999</a></span><span class="t"><span class="str">            x = fluid.data(name="x", shape=[2,3,4,5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13000" href="#t13000">13000</a></span><span class="t"><span class="str">            y = fluid.data(name="y", shape=[5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13001" href="#t13001">13001</a></span><span class="t"><span class="str">            z = fluid.layers.elementwise_div(x, y, axis=3)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13002" href="#t13002">13002</a></span><span class="t"><span class="str">            # z = x / y</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13003" href="#t13003">13003</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13004" href="#t13004">13004</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13005" href="#t13005">13005</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13006" href="#t13006">13006</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13007" href="#t13007">13007</a></span><span class="t"><span class="str">            z_value = exe.run(feed=gen_data(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13008" href="#t13008">13008</a></span><span class="t"><span class="str">                                fetch_list=[z.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13009" href="#t13009">13009</a></span><span class="t"><span class="str">            print(z_value) # z.shape=[2,3,4,5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13010" href="#t13010">13010</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13011" href="#t13011">13011</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13012" href="#t13012">13012</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13013" href="#t13013">13013</a></span><span class="t">        <span class="key">return</span> <span class="nam">_elementwise_op_in_dygraph</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13014" href="#t13014">13014</a></span><span class="t">            <span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="nam">axis</span><span class="op">,</span> <span class="nam">act</span><span class="op">=</span><span class="nam">act</span><span class="op">,</span> <span class="nam">op_name</span><span class="op">=</span><span class="str">'elementwise_div'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13015" href="#t13015">13015</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13016" href="#t13016">13016</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13017" href="#t13017">13017</a></span><span class="t">    <span class="key">return</span> <span class="nam">_elementwise_op</span><span class="op">(</span><span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'elementwise_div'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13018" href="#t13018">13018</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13019" href="#t13019">13019</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13020" href="#t13020">13020</a></span><span class="t"><span class="key">def</span> <span class="nam">elementwise_sub</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13021" href="#t13021">13021</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13022" href="#t13022">13022</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13023" href="#t13023">13023</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13024" href="#t13024">13024</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13025" href="#t13025">13025</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13026" href="#t13026">13026</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13027" href="#t13027">13027</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13028" href="#t13028">13028</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13029" href="#t13029">13029</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13030" href="#t13030">13030</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13031" href="#t13031">13031</a></span><span class="t"><span class="str">            def gen_data():</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13032" href="#t13032">13032</a></span><span class="t"><span class="str">                return {</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13033" href="#t13033">13033</a></span><span class="t"><span class="str">                    "x": np.array([2, 3, 4]).astype('float32'),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13034" href="#t13034">13034</a></span><span class="t"><span class="str">                    "y": np.array([1, 5, 2]).astype('float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13035" href="#t13035">13035</a></span><span class="t"><span class="str">                }</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13036" href="#t13036">13036</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13037" href="#t13037">13037</a></span><span class="t"><span class="str">            x = fluid.data(name="x", shape=[3], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13038" href="#t13038">13038</a></span><span class="t"><span class="str">            y = fluid.data(name="y", shape=[3], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13039" href="#t13039">13039</a></span><span class="t"><span class="str">            z = fluid.layers.elementwise_sub(x, y)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13040" href="#t13040">13040</a></span><span class="t"><span class="str">            # z = x - y</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13041" href="#t13041">13041</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13042" href="#t13042">13042</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13043" href="#t13043">13043</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13044" href="#t13044">13044</a></span><span class="t"><span class="str">            z_value = exe.run(feed=gen_data(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13045" href="#t13045">13045</a></span><span class="t"><span class="str">                                fetch_list=[z.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13046" href="#t13046">13046</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13047" href="#t13047">13047</a></span><span class="t"><span class="str">            print(z_value) # [1., -2., 2.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13048" href="#t13048">13048</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13049" href="#t13049">13049</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13050" href="#t13050">13050</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13051" href="#t13051">13051</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13052" href="#t13052">13052</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13053" href="#t13053">13053</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13054" href="#t13054">13054</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13055" href="#t13055">13055</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13056" href="#t13056">13056</a></span><span class="t"><span class="str">            def gen_data():</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13057" href="#t13057">13057</a></span><span class="t"><span class="str">                return {</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13058" href="#t13058">13058</a></span><span class="t"><span class="str">                    "x": np.ones((2, 3, 4, 5)).astype('float32'),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13059" href="#t13059">13059</a></span><span class="t"><span class="str">                    "y": np.zeros((3, 4)).astype('float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13060" href="#t13060">13060</a></span><span class="t"><span class="str">                }</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13061" href="#t13061">13061</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13062" href="#t13062">13062</a></span><span class="t"><span class="str">            x = fluid.data(name="x", shape=[2,3,4,5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13063" href="#t13063">13063</a></span><span class="t"><span class="str">            y = fluid.data(name="y", shape=[3,4], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13064" href="#t13064">13064</a></span><span class="t"><span class="str">            z = fluid.layers.elementwise_sub(x, y, axis=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13065" href="#t13065">13065</a></span><span class="t"><span class="str">            # z = x - y</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13066" href="#t13066">13066</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13067" href="#t13067">13067</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13068" href="#t13068">13068</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13069" href="#t13069">13069</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13070" href="#t13070">13070</a></span><span class="t"><span class="str">            z_value = exe.run(feed=gen_data(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13071" href="#t13071">13071</a></span><span class="t"><span class="str">                                fetch_list=[z.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13072" href="#t13072">13072</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13073" href="#t13073">13073</a></span><span class="t"><span class="str">            print(z_value) # z.shape=[2,3,4,5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13074" href="#t13074">13074</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13075" href="#t13075">13075</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13076" href="#t13076">13076</a></span><span class="t"><span class="str">        ..  code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13077" href="#t13077">13077</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13078" href="#t13078">13078</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13079" href="#t13079">13079</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13080" href="#t13080">13080</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13081" href="#t13081">13081</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13082" href="#t13082">13082</a></span><span class="t"><span class="str">            def gen_data():</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13083" href="#t13083">13083</a></span><span class="t"><span class="str">                return {</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13084" href="#t13084">13084</a></span><span class="t"><span class="str">                    "x": np.random.randint(1, 5, size=[2, 3, 4, 5]).astype('float32'),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13085" href="#t13085">13085</a></span><span class="t"><span class="str">                    "y": np.random.randint(1, 5, size=[5]).astype('float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13086" href="#t13086">13086</a></span><span class="t"><span class="str">                }</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13087" href="#t13087">13087</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13088" href="#t13088">13088</a></span><span class="t"><span class="str">            x = fluid.data(name="x", shape=[2,3,4,5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13089" href="#t13089">13089</a></span><span class="t"><span class="str">            y = fluid.data(name="y", shape=[5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13090" href="#t13090">13090</a></span><span class="t"><span class="str">            z = fluid.layers.elementwise_sub(x, y, axis=3)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13091" href="#t13091">13091</a></span><span class="t"><span class="str">            # z = x - y</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13092" href="#t13092">13092</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13093" href="#t13093">13093</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13094" href="#t13094">13094</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13095" href="#t13095">13095</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13096" href="#t13096">13096</a></span><span class="t"><span class="str">            z_value = exe.run(feed=gen_data(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13097" href="#t13097">13097</a></span><span class="t"><span class="str">                                fetch_list=[z.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13098" href="#t13098">13098</a></span><span class="t"><span class="str">            print(z_value) # z.shape=[2,3,4,5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13099" href="#t13099">13099</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13100" href="#t13100">13100</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t13101" href="#t13101">13101</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">13101&#x202F;&#x219B;&#x202F;13102</span><span class="annotate long">line 13101 didn't jump to line 13102, because the condition on line 13101 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13102" href="#t13102">13102</a></span><span class="t">        <span class="key">return</span> <span class="nam">_elementwise_op_in_dygraph</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13103" href="#t13103">13103</a></span><span class="t">            <span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="nam">axis</span><span class="op">,</span> <span class="nam">act</span><span class="op">=</span><span class="nam">act</span><span class="op">,</span> <span class="nam">op_name</span><span class="op">=</span><span class="str">'elementwise_sub'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13104" href="#t13104">13104</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13105" href="#t13105">13105</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13106" href="#t13106">13106</a></span><span class="t">    <span class="key">return</span> <span class="nam">_elementwise_op</span><span class="op">(</span><span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'elementwise_sub'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13107" href="#t13107">13107</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13108" href="#t13108">13108</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13109" href="#t13109">13109</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.multiply"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13110" href="#t13110">13110</a></span><span class="t"><span class="key">def</span> <span class="nam">elementwise_mul</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13111" href="#t13111">13111</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13112" href="#t13112">13112</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13113" href="#t13113">13113</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13114" href="#t13114">13114</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13115" href="#t13115">13115</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13116" href="#t13116">13116</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13117" href="#t13117">13117</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13118" href="#t13118">13118</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13119" href="#t13119">13119</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13120" href="#t13120">13120</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13121" href="#t13121">13121</a></span><span class="t"><span class="str">            def gen_data():</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13122" href="#t13122">13122</a></span><span class="t"><span class="str">                return {</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13123" href="#t13123">13123</a></span><span class="t"><span class="str">                    "x": np.array([2, 3, 4]).astype('float32'),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13124" href="#t13124">13124</a></span><span class="t"><span class="str">                    "y": np.array([1, 5, 2]).astype('float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13125" href="#t13125">13125</a></span><span class="t"><span class="str">                }</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13126" href="#t13126">13126</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13127" href="#t13127">13127</a></span><span class="t"><span class="str">            x = fluid.data(name="x", shape=[3], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13128" href="#t13128">13128</a></span><span class="t"><span class="str">            y = fluid.data(name="y", shape=[3], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13129" href="#t13129">13129</a></span><span class="t"><span class="str">            z = fluid.layers.elementwise_mul(x, y)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13130" href="#t13130">13130</a></span><span class="t"><span class="str">            # z = x * y</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13131" href="#t13131">13131</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13132" href="#t13132">13132</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13133" href="#t13133">13133</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13134" href="#t13134">13134</a></span><span class="t"><span class="str">            z_value = exe.run(feed=gen_data(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13135" href="#t13135">13135</a></span><span class="t"><span class="str">                                fetch_list=[z.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13136" href="#t13136">13136</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13137" href="#t13137">13137</a></span><span class="t"><span class="str">            print(z_value) # [2., 15., 8.]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13138" href="#t13138">13138</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13139" href="#t13139">13139</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13140" href="#t13140">13140</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13141" href="#t13141">13141</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13142" href="#t13142">13142</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13143" href="#t13143">13143</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13144" href="#t13144">13144</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13145" href="#t13145">13145</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13146" href="#t13146">13146</a></span><span class="t"><span class="str">            def gen_data():</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13147" href="#t13147">13147</a></span><span class="t"><span class="str">                return {</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13148" href="#t13148">13148</a></span><span class="t"><span class="str">                    "x": np.ones((2, 3, 4, 5)).astype('float32'),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13149" href="#t13149">13149</a></span><span class="t"><span class="str">                    "y": np.zeros((3, 4)).astype('float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13150" href="#t13150">13150</a></span><span class="t"><span class="str">                }</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13151" href="#t13151">13151</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13152" href="#t13152">13152</a></span><span class="t"><span class="str">            x = fluid.data(name="x", shape=[2,3,4,5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13153" href="#t13153">13153</a></span><span class="t"><span class="str">            y = fluid.data(name="y", shape=[3,4], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13154" href="#t13154">13154</a></span><span class="t"><span class="str">            z = fluid.layers.elementwise_mul(x, y, axis=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13155" href="#t13155">13155</a></span><span class="t"><span class="str">            # z = x * y</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13156" href="#t13156">13156</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13157" href="#t13157">13157</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13158" href="#t13158">13158</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13159" href="#t13159">13159</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13160" href="#t13160">13160</a></span><span class="t"><span class="str">            z_value = exe.run(feed=gen_data(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13161" href="#t13161">13161</a></span><span class="t"><span class="str">                                fetch_list=[z.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13162" href="#t13162">13162</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13163" href="#t13163">13163</a></span><span class="t"><span class="str">            print(z_value) # z.shape=[2,3,4,5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13164" href="#t13164">13164</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13165" href="#t13165">13165</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13166" href="#t13166">13166</a></span><span class="t"><span class="str">        ..  code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13167" href="#t13167">13167</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13168" href="#t13168">13168</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13169" href="#t13169">13169</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13170" href="#t13170">13170</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13171" href="#t13171">13171</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13172" href="#t13172">13172</a></span><span class="t"><span class="str">            def gen_data():</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13173" href="#t13173">13173</a></span><span class="t"><span class="str">                return {</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13174" href="#t13174">13174</a></span><span class="t"><span class="str">                    "x": np.random.randint(1, 5, size=[2, 3, 4, 5]).astype('float32'),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13175" href="#t13175">13175</a></span><span class="t"><span class="str">                    "y": np.random.randint(1, 5, size=[5]).astype('float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13176" href="#t13176">13176</a></span><span class="t"><span class="str">                }</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13177" href="#t13177">13177</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13178" href="#t13178">13178</a></span><span class="t"><span class="str">            x = fluid.data(name="x", shape=[2,3,4,5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13179" href="#t13179">13179</a></span><span class="t"><span class="str">            y = fluid.data(name="y", shape=[5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13180" href="#t13180">13180</a></span><span class="t"><span class="str">            z = fluid.layers.elementwise_mul(x, y, axis=3)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13181" href="#t13181">13181</a></span><span class="t"><span class="str">            # z = x * y</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13182" href="#t13182">13182</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13183" href="#t13183">13183</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13184" href="#t13184">13184</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13185" href="#t13185">13185</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13186" href="#t13186">13186</a></span><span class="t"><span class="str">            z_value = exe.run(feed=gen_data(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13187" href="#t13187">13187</a></span><span class="t"><span class="str">                                fetch_list=[z.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13188" href="#t13188">13188</a></span><span class="t"><span class="str">            print(z_value) # z.shape=[2,3,4,5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13189" href="#t13189">13189</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13190" href="#t13190">13190</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t13191" href="#t13191">13191</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">13191&#x202F;&#x219B;&#x202F;13192</span><span class="annotate long">line 13191 didn't jump to line 13192, because the condition on line 13191 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13192" href="#t13192">13192</a></span><span class="t">        <span class="key">return</span> <span class="nam">_elementwise_op_in_dygraph</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13193" href="#t13193">13193</a></span><span class="t">            <span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="nam">axis</span><span class="op">,</span> <span class="nam">act</span><span class="op">=</span><span class="nam">act</span><span class="op">,</span> <span class="nam">op_name</span><span class="op">=</span><span class="str">'elementwise_mul'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13194" href="#t13194">13194</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13195" href="#t13195">13195</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13196" href="#t13196">13196</a></span><span class="t">    <span class="key">return</span> <span class="nam">_elementwise_op</span><span class="op">(</span><span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'elementwise_mul'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13197" href="#t13197">13197</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13198" href="#t13198">13198</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13199" href="#t13199">13199</a></span><span class="t"><span class="key">def</span> <span class="nam">elementwise_max</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13200" href="#t13200">13200</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13201" href="#t13201">13201</a></span><span class="t"><span class="str">        :alias_main: paddle.elementwise_max</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13202" href="#t13202">13202</a></span><span class="t"><span class="str">            :alias: paddle.elementwise_max,paddle.tensor.elementwise_max,paddle.tensor.math.elementwise_max</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13203" href="#t13203">13203</a></span><span class="t"><span class="str">            :old_api: paddle.fluid.layers.elementwise_max</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13204" href="#t13204">13204</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13205" href="#t13205">13205</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13206" href="#t13206">13206</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13207" href="#t13207">13207</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13208" href="#t13208">13208</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13209" href="#t13209">13209</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13210" href="#t13210">13210</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13211" href="#t13211">13211</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13212" href="#t13212">13212</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13213" href="#t13213">13213</a></span><span class="t"><span class="str">            def gen_data():</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13214" href="#t13214">13214</a></span><span class="t"><span class="str">                return {</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13215" href="#t13215">13215</a></span><span class="t"><span class="str">                    "x": np.array([2, 3, 4]).astype('float32'),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13216" href="#t13216">13216</a></span><span class="t"><span class="str">                    "y": np.array([1, 5, 2]).astype('float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13217" href="#t13217">13217</a></span><span class="t"><span class="str">                }</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13218" href="#t13218">13218</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13219" href="#t13219">13219</a></span><span class="t"><span class="str">            x = fluid.data(name="x", shape=[3], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13220" href="#t13220">13220</a></span><span class="t"><span class="str">            y = fluid.data(name="y", shape=[3], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13221" href="#t13221">13221</a></span><span class="t"><span class="str">            z = fluid.layers.elementwise_max(x, y)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13222" href="#t13222">13222</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13223" href="#t13223">13223</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13224" href="#t13224">13224</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13225" href="#t13225">13225</a></span><span class="t"><span class="str">            z_value = exe.run(feed=gen_data(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13226" href="#t13226">13226</a></span><span class="t"><span class="str">                                fetch_list=[z.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13227" href="#t13227">13227</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13228" href="#t13228">13228</a></span><span class="t"><span class="str">            print(z_value) #[2, 5, 4]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13229" href="#t13229">13229</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13230" href="#t13230">13230</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13231" href="#t13231">13231</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13232" href="#t13232">13232</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13233" href="#t13233">13233</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13234" href="#t13234">13234</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13235" href="#t13235">13235</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13236" href="#t13236">13236</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13237" href="#t13237">13237</a></span><span class="t"><span class="str">            def gen_data():</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13238" href="#t13238">13238</a></span><span class="t"><span class="str">                return {</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13239" href="#t13239">13239</a></span><span class="t"><span class="str">                    "x": np.ones((2, 3, 4, 5)).astype('float32'),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13240" href="#t13240">13240</a></span><span class="t"><span class="str">                    "y": np.zeros((3, 4)).astype('float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13241" href="#t13241">13241</a></span><span class="t"><span class="str">                }</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13242" href="#t13242">13242</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13243" href="#t13243">13243</a></span><span class="t"><span class="str">            x = fluid.data(name="x", shape=[2,3,4,5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13244" href="#t13244">13244</a></span><span class="t"><span class="str">            y = fluid.data(name="y", shape=[3,4], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13245" href="#t13245">13245</a></span><span class="t"><span class="str">            z = fluid.layers.elementwise_max(x, y, axis=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13246" href="#t13246">13246</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13247" href="#t13247">13247</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13248" href="#t13248">13248</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13249" href="#t13249">13249</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13250" href="#t13250">13250</a></span><span class="t"><span class="str">            z_value = exe.run(feed=gen_data(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13251" href="#t13251">13251</a></span><span class="t"><span class="str">                                fetch_list=[z.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13252" href="#t13252">13252</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13253" href="#t13253">13253</a></span><span class="t"><span class="str">            print(z_value)#[[[[1., 1., 1., 1., 1.] .... [1., 1., 1., 1., 1.]]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13254" href="#t13254">13254</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13255" href="#t13255">13255</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13256" href="#t13256">13256</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13257" href="#t13257">13257</a></span><span class="t">        <span class="key">return</span> <span class="nam">_elementwise_op_in_dygraph</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13258" href="#t13258">13258</a></span><span class="t">            <span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="nam">axis</span><span class="op">,</span> <span class="nam">act</span><span class="op">=</span><span class="nam">act</span><span class="op">,</span> <span class="nam">op_name</span><span class="op">=</span><span class="str">'elementwise_max'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13259" href="#t13259">13259</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13260" href="#t13260">13260</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13261" href="#t13261">13261</a></span><span class="t">    <span class="key">return</span> <span class="nam">_elementwise_op</span><span class="op">(</span><span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'elementwise_max'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13262" href="#t13262">13262</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13263" href="#t13263">13263</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13264" href="#t13264">13264</a></span><span class="t"><span class="key">def</span> <span class="nam">elementwise_min</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13265" href="#t13265">13265</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13266" href="#t13266">13266</a></span><span class="t"><span class="str">        :alias_main: paddle.elementwise_min</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13267" href="#t13267">13267</a></span><span class="t"><span class="str">            :alias: paddle.elementwise_min,paddle.tensor.elementwise_min,paddle.tensor.math.elementwise_min</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13268" href="#t13268">13268</a></span><span class="t"><span class="str">            :old_api: paddle.fluid.layers.elementwise_min</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13269" href="#t13269">13269</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13270" href="#t13270">13270</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13271" href="#t13271">13271</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13272" href="#t13272">13272</a></span><span class="t"><span class="str">        ..  code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13273" href="#t13273">13273</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13274" href="#t13274">13274</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13275" href="#t13275">13275</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13276" href="#t13276">13276</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13277" href="#t13277">13277</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13278" href="#t13278">13278</a></span><span class="t"><span class="str">            def gen_data():</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13279" href="#t13279">13279</a></span><span class="t"><span class="str">                return {</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13280" href="#t13280">13280</a></span><span class="t"><span class="str">                    "x": np.array([2, 3, 4]).astype('float32'),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13281" href="#t13281">13281</a></span><span class="t"><span class="str">                    "y": np.array([1, 5, 2]).astype('float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13282" href="#t13282">13282</a></span><span class="t"><span class="str">                }</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13283" href="#t13283">13283</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13284" href="#t13284">13284</a></span><span class="t"><span class="str">            x = fluid.data(name="x", shape=[3], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13285" href="#t13285">13285</a></span><span class="t"><span class="str">            y = fluid.data(name="y", shape=[3], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13286" href="#t13286">13286</a></span><span class="t"><span class="str">            z = fluid.layers.elementwise_min(x, y)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13287" href="#t13287">13287</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13288" href="#t13288">13288</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13289" href="#t13289">13289</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13290" href="#t13290">13290</a></span><span class="t"><span class="str">            z_value = exe.run(feed=gen_data(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13291" href="#t13291">13291</a></span><span class="t"><span class="str">                                fetch_list=[z.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13292" href="#t13292">13292</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13293" href="#t13293">13293</a></span><span class="t"><span class="str">            print(z_value) #[1, 3, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13294" href="#t13294">13294</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13295" href="#t13295">13295</a></span><span class="t"><span class="str">        ..  code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13296" href="#t13296">13296</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13297" href="#t13297">13297</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13298" href="#t13298">13298</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13299" href="#t13299">13299</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13300" href="#t13300">13300</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13301" href="#t13301">13301</a></span><span class="t"><span class="str">            def gen_data():</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13302" href="#t13302">13302</a></span><span class="t"><span class="str">                return {</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13303" href="#t13303">13303</a></span><span class="t"><span class="str">                    "x": np.ones((2, 3, 4, 5)).astype('float32'),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13304" href="#t13304">13304</a></span><span class="t"><span class="str">                    "y": np.zeros((3, 4)).astype('float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13305" href="#t13305">13305</a></span><span class="t"><span class="str">                }</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13306" href="#t13306">13306</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13307" href="#t13307">13307</a></span><span class="t"><span class="str">            x = fluid.data(name="x", shape=[2,3,4,5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13308" href="#t13308">13308</a></span><span class="t"><span class="str">            y = fluid.data(name="y", shape=[3,4], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13309" href="#t13309">13309</a></span><span class="t"><span class="str">            z = fluid.layers.elementwise_min(x, y, axis=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13310" href="#t13310">13310</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13311" href="#t13311">13311</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13312" href="#t13312">13312</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13313" href="#t13313">13313</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13314" href="#t13314">13314</a></span><span class="t"><span class="str">            z_value = exe.run(feed=gen_data(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13315" href="#t13315">13315</a></span><span class="t"><span class="str">                                fetch_list=[z.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13316" href="#t13316">13316</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13317" href="#t13317">13317</a></span><span class="t"><span class="str">            print(z_value)#[[[[0., 0., 0., 0., 0.] .... [0., 0., 0., 0., 0.]]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13318" href="#t13318">13318</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t13319" href="#t13319">13319</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">13319&#x202F;&#x219B;&#x202F;13320</span><span class="annotate long">line 13319 didn't jump to line 13320, because the condition on line 13319 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13320" href="#t13320">13320</a></span><span class="t">        <span class="key">return</span> <span class="nam">_elementwise_op_in_dygraph</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13321" href="#t13321">13321</a></span><span class="t">            <span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="nam">axis</span><span class="op">,</span> <span class="nam">act</span><span class="op">=</span><span class="nam">act</span><span class="op">,</span> <span class="nam">op_name</span><span class="op">=</span><span class="str">'elementwise_min'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13322" href="#t13322">13322</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13323" href="#t13323">13323</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13324" href="#t13324">13324</a></span><span class="t">    <span class="key">return</span> <span class="nam">_elementwise_op</span><span class="op">(</span><span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'elementwise_min'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13325" href="#t13325">13325</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13326" href="#t13326">13326</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13327" href="#t13327">13327</a></span><span class="t"><span class="key">def</span> <span class="nam">elementwise_pow</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13328" href="#t13328">13328</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13329" href="#t13329">13329</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13330" href="#t13330">13330</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13331" href="#t13331">13331</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13332" href="#t13332">13332</a></span><span class="t"><span class="str">        ..  code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13333" href="#t13333">13333</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13334" href="#t13334">13334</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13335" href="#t13335">13335</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13336" href="#t13336">13336</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13337" href="#t13337">13337</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13338" href="#t13338">13338</a></span><span class="t"><span class="str">            def gen_data():</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13339" href="#t13339">13339</a></span><span class="t"><span class="str">                return {</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13340" href="#t13340">13340</a></span><span class="t"><span class="str">                    "x": np.array([2, 3, 4]).astype('float32'),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13341" href="#t13341">13341</a></span><span class="t"><span class="str">                    "y": np.array([1, 5, 2]).astype('float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13342" href="#t13342">13342</a></span><span class="t"><span class="str">                }</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13343" href="#t13343">13343</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13344" href="#t13344">13344</a></span><span class="t"><span class="str">            x = fluid.data(name="x", shape=[3], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13345" href="#t13345">13345</a></span><span class="t"><span class="str">            y = fluid.data(name="y", shape=[3], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13346" href="#t13346">13346</a></span><span class="t"><span class="str">            z = fluid.layers.elementwise_pow(x, y)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13347" href="#t13347">13347</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13348" href="#t13348">13348</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13349" href="#t13349">13349</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13350" href="#t13350">13350</a></span><span class="t"><span class="str">            z_value = exe.run(feed=gen_data(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13351" href="#t13351">13351</a></span><span class="t"><span class="str">                                fetch_list=[z.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13352" href="#t13352">13352</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13353" href="#t13353">13353</a></span><span class="t"><span class="str">            print(z_value) #[2, 243, 16]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13354" href="#t13354">13354</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13355" href="#t13355">13355</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13356" href="#t13356">13356</a></span><span class="t">        <span class="key">return</span> <span class="nam">_elementwise_op_in_dygraph</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13357" href="#t13357">13357</a></span><span class="t">            <span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="nam">axis</span><span class="op">,</span> <span class="nam">act</span><span class="op">=</span><span class="nam">act</span><span class="op">,</span> <span class="nam">op_name</span><span class="op">=</span><span class="str">'elementwise_pow'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13358" href="#t13358">13358</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13359" href="#t13359">13359</a></span><span class="t">    <span class="key">return</span> <span class="nam">_elementwise_op</span><span class="op">(</span><span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'elementwise_pow'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13360" href="#t13360">13360</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13361" href="#t13361">13361</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13362" href="#t13362">13362</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.remainder"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13363" href="#t13363">13363</a></span><span class="t"><span class="key">def</span> <span class="nam">elementwise_mod</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13364" href="#t13364">13364</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13365" href="#t13365">13365</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13366" href="#t13366">13366</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13367" href="#t13367">13367</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13368" href="#t13368">13368</a></span><span class="t"><span class="str">        ..  code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13369" href="#t13369">13369</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13370" href="#t13370">13370</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13371" href="#t13371">13371</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13372" href="#t13372">13372</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13373" href="#t13373">13373</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13374" href="#t13374">13374</a></span><span class="t"><span class="str">            def gen_data():</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13375" href="#t13375">13375</a></span><span class="t"><span class="str">                return {</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13376" href="#t13376">13376</a></span><span class="t"><span class="str">                    "x": np.array([10, 15, 8]).astype('int32'),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13377" href="#t13377">13377</a></span><span class="t"><span class="str">                    "y": np.array([3, 6, 5]).astype('int32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13378" href="#t13378">13378</a></span><span class="t"><span class="str">                }</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13379" href="#t13379">13379</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13380" href="#t13380">13380</a></span><span class="t"><span class="str">            x = fluid.data(name="x", shape=[3], dtype='int32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13381" href="#t13381">13381</a></span><span class="t"><span class="str">            y = fluid.data(name="y", shape=[3], dtype='int32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13382" href="#t13382">13382</a></span><span class="t"><span class="str">            z = fluid.layers.elementwise_mod(x, y)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13383" href="#t13383">13383</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13384" href="#t13384">13384</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13385" href="#t13385">13385</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13386" href="#t13386">13386</a></span><span class="t"><span class="str">            z_value = exe.run(feed=gen_data(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13387" href="#t13387">13387</a></span><span class="t"><span class="str">                                fetch_list=[z.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13388" href="#t13388">13388</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13389" href="#t13389">13389</a></span><span class="t"><span class="str">            print(z_value) #[1, 3, 3]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13390" href="#t13390">13390</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t13391" href="#t13391">13391</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">13391&#x202F;&#x219B;&#x202F;13396</span><span class="annotate long">line 13391 didn't jump to line 13396, because the condition on line 13391 was never false</span></span></p>
    <p class="run"><span class="n"><a id="t13392" href="#t13392">13392</a></span><span class="t">        <span class="key">return</span> <span class="nam">_elementwise_op_in_dygraph</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13393" href="#t13393">13393</a></span><span class="t">            <span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="nam">axis</span><span class="op">,</span> <span class="nam">act</span><span class="op">=</span><span class="nam">act</span><span class="op">,</span> <span class="nam">op_name</span><span class="op">=</span><span class="str">'elementwise_mod'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13394" href="#t13394">13394</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13395" href="#t13395">13395</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13396" href="#t13396">13396</a></span><span class="t">    <span class="key">return</span> <span class="nam">_elementwise_op</span><span class="op">(</span><span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'elementwise_mod'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13397" href="#t13397">13397</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13398" href="#t13398">13398</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13399" href="#t13399">13399</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.floor_divide"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13400" href="#t13400">13400</a></span><span class="t"><span class="key">def</span> <span class="nam">elementwise_floordiv</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13401" href="#t13401">13401</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13402" href="#t13402">13402</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13403" href="#t13403">13403</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13404" href="#t13404">13404</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13405" href="#t13405">13405</a></span><span class="t"><span class="str">        ..  code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13406" href="#t13406">13406</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13407" href="#t13407">13407</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13408" href="#t13408">13408</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13409" href="#t13409">13409</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13410" href="#t13410">13410</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13411" href="#t13411">13411</a></span><span class="t"><span class="str">            def gen_data():</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13412" href="#t13412">13412</a></span><span class="t"><span class="str">                return {</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13413" href="#t13413">13413</a></span><span class="t"><span class="str">                    "x": np.array([10, 15, 8]).astype('int32'),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13414" href="#t13414">13414</a></span><span class="t"><span class="str">                    "y": np.array([3, 7, 5]).astype('int32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13415" href="#t13415">13415</a></span><span class="t"><span class="str">                }</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13416" href="#t13416">13416</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13417" href="#t13417">13417</a></span><span class="t"><span class="str">            x = fluid.data(name="x", shape=[3], dtype='int32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13418" href="#t13418">13418</a></span><span class="t"><span class="str">            y = fluid.data(name="y", shape=[3], dtype='int32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13419" href="#t13419">13419</a></span><span class="t"><span class="str">            z = fluid.layers.elementwise_floordiv(x, y)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13420" href="#t13420">13420</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13421" href="#t13421">13421</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13422" href="#t13422">13422</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13423" href="#t13423">13423</a></span><span class="t"><span class="str">            z_value = exe.run(feed=gen_data(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13424" href="#t13424">13424</a></span><span class="t"><span class="str">                                fetch_list=[z.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13425" href="#t13425">13425</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13426" href="#t13426">13426</a></span><span class="t"><span class="str">            print(z_value) #[3, 2, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13427" href="#t13427">13427</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t13428" href="#t13428">13428</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">13428&#x202F;&#x219B;&#x202F;13429</span><span class="annotate long">line 13428 didn't jump to line 13429, because the condition on line 13428 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13429" href="#t13429">13429</a></span><span class="t">        <span class="key">return</span> <span class="nam">_elementwise_op_in_dygraph</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13430" href="#t13430">13430</a></span><span class="t">            <span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="nam">axis</span><span class="op">,</span> <span class="nam">act</span><span class="op">=</span><span class="nam">act</span><span class="op">,</span> <span class="nam">op_name</span><span class="op">=</span><span class="str">'elementwise_floordiv'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13431" href="#t13431">13431</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13432" href="#t13432">13432</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13433" href="#t13433">13433</a></span><span class="t">    <span class="key">return</span> <span class="nam">_elementwise_op</span><span class="op">(</span><span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'elementwise_floordiv'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13434" href="#t13434">13434</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13435" href="#t13435">13435</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13436" href="#t13436">13436</a></span><span class="t"><span class="key">for</span> <span class="nam">func</span> <span class="key">in</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13437" href="#t13437">13437</a></span><span class="t">    <span class="nam">elementwise_add</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13438" href="#t13438">13438</a></span><span class="t">    <span class="nam">elementwise_div</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13439" href="#t13439">13439</a></span><span class="t">    <span class="nam">elementwise_sub</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13440" href="#t13440">13440</a></span><span class="t">    <span class="nam">elementwise_mul</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13441" href="#t13441">13441</a></span><span class="t">    <span class="nam">elementwise_max</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13442" href="#t13442">13442</a></span><span class="t">    <span class="nam">elementwise_pow</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13443" href="#t13443">13443</a></span><span class="t">    <span class="nam">elementwise_min</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13444" href="#t13444">13444</a></span><span class="t">    <span class="nam">elementwise_mod</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13445" href="#t13445">13445</a></span><span class="t">    <span class="nam">elementwise_floordiv</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13446" href="#t13446">13446</a></span><span class="t"><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13447" href="#t13447">13447</a></span><span class="t">    <span class="nam">op_proto</span> <span class="op">=</span> <span class="nam">OpProtoHolder</span><span class="op">.</span><span class="nam">instance</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">get_op_proto</span><span class="op">(</span><span class="nam">func</span><span class="op">.</span><span class="nam">__name__</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13448" href="#t13448">13448</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13449" href="#t13449">13449</a></span><span class="t">    <span class="com"># insert the c++ doc string on top of python doc string</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13450" href="#t13450">13450</a></span><span class="t">    <span class="nam">func</span><span class="op">.</span><span class="nam">__doc__</span> <span class="op">=</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13451" href="#t13451">13451</a></span><span class="t">        <span class="nam">_generate_doc_string_</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13452" href="#t13452">13452</a></span><span class="t">            <span class="nam">op_proto</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13453" href="#t13453">13453</a></span><span class="t">            <span class="nam">additional_args_lines</span><span class="op">=</span><span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13454" href="#t13454">13454</a></span><span class="t">                <span class="str">"axis (int32, optional): If X.dimension != Y.dimension, \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13455" href="#t13455">13455</a></span><span class="t"><span class="str">            Y.dimension must be a subsequence of x.dimension. \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13456" href="#t13456">13456</a></span><span class="t"><span class="str">            And axis is the start dimension index for broadcasting Y onto X. "</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13457" href="#t13457">13457</a></span><span class="t">                <span class="str">"act (string, optional): Activation applied to the output. \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13458" href="#t13458">13458</a></span><span class="t"><span class="str">            Default is None. Details: :ref:`api_guide_activations_en` "</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13459" href="#t13459">13459</a></span><span class="t">                <span class="str">"name (string, optional): Name of the output. \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13460" href="#t13460">13460</a></span><span class="t"><span class="str">            Default is None. It's used to print debug info for developers. Details: \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13461" href="#t13461">13461</a></span><span class="t"><span class="str">            :ref:`api_guide_Name` "</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13462" href="#t13462">13462</a></span><span class="t">            <span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13463" href="#t13463">13463</a></span><span class="t">            <span class="nam">skip_attrs_set</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13464" href="#t13464">13464</a></span><span class="t">                <span class="str">"x_data_format"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13465" href="#t13465">13465</a></span><span class="t">                <span class="str">"y_data_format"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13466" href="#t13466">13466</a></span><span class="t">                <span class="str">"axis"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13467" href="#t13467">13467</a></span><span class="t">                <span class="str">"use_quantizer"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13468" href="#t13468">13468</a></span><span class="t">                <span class="str">"mkldnn_data_type"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13469" href="#t13469">13469</a></span><span class="t">                <span class="str">"Scale_x"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13470" href="#t13470">13470</a></span><span class="t">                <span class="str">"Scale_y"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13471" href="#t13471">13471</a></span><span class="t">                <span class="str">"Scale_out"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13472" href="#t13472">13472</a></span><span class="t">            <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13473" href="#t13473">13473</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13474" href="#t13474">13474</a></span><span class="t">        <span class="op">+</span> <span class="str">"""\n"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13475" href="#t13475">13475</a></span><span class="t">        <span class="op">+</span> <span class="nam">str</span><span class="op">(</span><span class="nam">func</span><span class="op">.</span><span class="nam">__doc__</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13476" href="#t13476">13476</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13477" href="#t13477">13477</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13478" href="#t13478">13478</a></span><span class="t">    <span class="nam">doc_list</span> <span class="op">=</span> <span class="nam">func</span><span class="op">.</span><span class="nam">__doc__</span><span class="op">.</span><span class="nam">splitlines</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13479" href="#t13479">13479</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13480" href="#t13480">13480</a></span><span class="t">    <span class="key">for</span> <span class="nam">idx</span><span class="op">,</span> <span class="nam">val</span> <span class="key">in</span> <span class="nam">enumerate</span><span class="op">(</span><span class="nam">doc_list</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t13481" href="#t13481">13481</a></span><span class="t">        <span class="key">if</span> <span class="op">(</span>&nbsp;</span><span class="r"><span class="annotate short">13481&#x202F;&#x219B;&#x202F;13486</span><span class="annotate long">line 13481 didn't jump to line 13486</span></span></p>
    <p class="pln"><span class="n"><a id="t13482" href="#t13482">13482</a></span><span class="t">            <span class="nam">val</span><span class="op">.</span><span class="nam">startswith</span><span class="op">(</span><span class="str">"Warning: "</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13483" href="#t13483">13483</a></span><span class="t">            <span class="key">and</span> <span class="nam">val</span><span class="op">.</span><span class="nam">endswith</span><span class="op">(</span><span class="str">" instead."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13484" href="#t13484">13484</a></span><span class="t">            <span class="key">and</span> <span class="str">"and will be removed in future versions."</span> <span class="key">in</span> <span class="nam">val</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13485" href="#t13485">13485</a></span><span class="t">        <span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13486" href="#t13486">13486</a></span><span class="t">            <span class="nam">doc_list</span><span class="op">.</span><span class="nam">insert</span><span class="op">(</span><span class="num">0</span><span class="op">,</span> <span class="nam">doc_list</span><span class="op">.</span><span class="nam">pop</span><span class="op">(</span><span class="nam">idx</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13487" href="#t13487">13487</a></span><span class="t">            <span class="nam">func</span><span class="op">.</span><span class="nam">__doc__</span> <span class="op">=</span> <span class="str">"\n"</span> <span class="op">+</span> <span class="str">"\n"</span><span class="op">.</span><span class="nam">join</span><span class="op">(</span><span class="nam">i</span> <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span> <span class="nam">doc_list</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13488" href="#t13488">13488</a></span><span class="t">            <span class="key">break</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13489" href="#t13489">13489</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t13490" href="#t13490">13490</a></span><span class="t"><span class="key">for</span> <span class="nam">func</span> <span class="key">in</span> <span class="op">[</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">13490&#x202F;&#x219B;&#x202F;13491</span><span class="annotate long">line 13490 didn't jump to line 13491, because the loop on line 13490 never started</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13491" href="#t13491">13491</a></span><span class="t">    <span class="nam">op_proto</span> <span class="op">=</span> <span class="nam">OpProtoHolder</span><span class="op">.</span><span class="nam">instance</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">get_op_proto</span><span class="op">(</span><span class="nam">func</span><span class="op">.</span><span class="nam">__name__</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13492" href="#t13492">13492</a></span><span class="t">    <span class="nam">func</span><span class="op">.</span><span class="nam">__doc__</span> <span class="op">=</span> <span class="nam">_generate_doc_string_</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13493" href="#t13493">13493</a></span><span class="t">        <span class="nam">op_proto</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13494" href="#t13494">13494</a></span><span class="t">        <span class="nam">additional_args_lines</span><span class="op">=</span><span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13495" href="#t13495">13495</a></span><span class="t">            <span class="str">"act (basestring|None): Activation applied to the output."</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13496" href="#t13496">13496</a></span><span class="t">            <span class="str">"name (basestring|None): Name of the output."</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13497" href="#t13497">13497</a></span><span class="t">        <span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13498" href="#t13498">13498</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13499" href="#t13499">13499</a></span><span class="t">    <span class="nam">func</span><span class="op">.</span><span class="nam">__doc__</span> <span class="op">=</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13500" href="#t13500">13500</a></span><span class="t">        <span class="nam">func</span><span class="op">.</span><span class="nam">__doc__</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13501" href="#t13501">13501</a></span><span class="t">        <span class="op">+</span> <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13502" href="#t13502">13502</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13503" href="#t13503">13503</a></span><span class="t"><span class="str">Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13504" href="#t13504">13504</a></span><span class="t"><span class="str">  .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13505" href="#t13505">13505</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13506" href="#t13506">13506</a></span><span class="t"><span class="str">    import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13507" href="#t13507">13507</a></span><span class="t"><span class="str">    # example 1: shape(x) = (2, 3, 4, 5), shape(y) = (2, 3, 4, 5)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13508" href="#t13508">13508</a></span><span class="t"><span class="str">    x0 = fluid.layers.data(name="x0", shape=[2, 3, 4, 5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13509" href="#t13509">13509</a></span><span class="t"><span class="str">    y0 = fluid.layers.data(name="y0", shape=[2, 3, 4, 5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13510" href="#t13510">13510</a></span><span class="t"><span class="str">    z0 = fluid.layers.%s(x0, y0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13511" href="#t13511">13511</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13512" href="#t13512">13512</a></span><span class="t"><span class="str">    # example 2: shape(X) = (2, 3, 4, 5), shape(Y) = (5)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13513" href="#t13513">13513</a></span><span class="t"><span class="str">    x1 = fluid.layers.data(name="x1", shape=[2, 3, 4, 5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13514" href="#t13514">13514</a></span><span class="t"><span class="str">    y1 = fluid.layers.data(name="y1", shape=[5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13515" href="#t13515">13515</a></span><span class="t"><span class="str">    z1 = fluid.layers.%s(x1, y1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13516" href="#t13516">13516</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13517" href="#t13517">13517</a></span><span class="t"><span class="str">    # example 3: shape(X) = (2, 3, 4, 5), shape(Y) = (4, 5), with axis=-1(default) or axis=2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13518" href="#t13518">13518</a></span><span class="t"><span class="str">    x2 = fluid.layers.data(name="x2", shape=[2, 3, 4, 5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13519" href="#t13519">13519</a></span><span class="t"><span class="str">    y2 = fluid.layers.data(name="y2", shape=[4, 5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13520" href="#t13520">13520</a></span><span class="t"><span class="str">    z2 = fluid.layers.%s(x2, y2, axis=2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13521" href="#t13521">13521</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13522" href="#t13522">13522</a></span><span class="t"><span class="str">    # example 4: shape(X) = (2, 3, 4, 5), shape(Y) = (3, 4), with axis=1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13523" href="#t13523">13523</a></span><span class="t"><span class="str">    x3 = fluid.layers.data(name="x3", shape=[2, 3, 4, 5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13524" href="#t13524">13524</a></span><span class="t"><span class="str">    y3 = fluid.layers.data(name="y3", shape=[3, 4], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13525" href="#t13525">13525</a></span><span class="t"><span class="str">    z3 = fluid.layers.%s(x3, y3, axis=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13526" href="#t13526">13526</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13527" href="#t13527">13527</a></span><span class="t"><span class="str">    # example 5: shape(X) = (2, 3, 4, 5), shape(Y) = (2), with axis=0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13528" href="#t13528">13528</a></span><span class="t"><span class="str">    x4 = fluid.layers.data(name="x4", shape=[2, 3, 4, 5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13529" href="#t13529">13529</a></span><span class="t"><span class="str">    y4 = fluid.layers.data(name="y4", shape=[2], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13530" href="#t13530">13530</a></span><span class="t"><span class="str">    z4 = fluid.layers.%s(x4, y4, axis=0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13531" href="#t13531">13531</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13532" href="#t13532">13532</a></span><span class="t"><span class="str">    # example 6: shape(X) = (2, 3, 4, 5), shape(Y) = (2, 1), with axis=0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13533" href="#t13533">13533</a></span><span class="t"><span class="str">    x5 = fluid.layers.data(name="x5", shape=[2, 3, 4, 5], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13534" href="#t13534">13534</a></span><span class="t"><span class="str">    y5 = fluid.layers.data(name="y5", shape=[2], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13535" href="#t13535">13535</a></span><span class="t"><span class="str">    z5 = fluid.layers.%s(x5, y5, axis=0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13536" href="#t13536">13536</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13537" href="#t13537">13537</a></span><span class="t">        <span class="op">%</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13538" href="#t13538">13538</a></span><span class="t">            <span class="nam">func</span><span class="op">.</span><span class="nam">__name__</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13539" href="#t13539">13539</a></span><span class="t">            <span class="nam">func</span><span class="op">.</span><span class="nam">__name__</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13540" href="#t13540">13540</a></span><span class="t">            <span class="nam">func</span><span class="op">.</span><span class="nam">__name__</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13541" href="#t13541">13541</a></span><span class="t">            <span class="nam">func</span><span class="op">.</span><span class="nam">__name__</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13542" href="#t13542">13542</a></span><span class="t">            <span class="nam">func</span><span class="op">.</span><span class="nam">__name__</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13543" href="#t13543">13543</a></span><span class="t">            <span class="nam">func</span><span class="op">.</span><span class="nam">__name__</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13544" href="#t13544">13544</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13545" href="#t13545">13545</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13546" href="#t13546">13546</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13547" href="#t13547">13547</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13548" href="#t13548">13548</a></span><span class="t"><span class="key">def</span> <span class="nam">_logical_op</span><span class="op">(</span><span class="nam">op_name</span><span class="op">,</span> <span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">out</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">binary_op</span><span class="op">=</span><span class="key">True</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13549" href="#t13549">13549</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13550" href="#t13550">13550</a></span><span class="t">        <span class="nam">op</span> <span class="op">=</span> <span class="nam">getattr</span><span class="op">(</span><span class="nam">_legacy_C_ops</span><span class="op">,</span> <span class="nam">op_name</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13551" href="#t13551">13551</a></span><span class="t">        <span class="key">if</span> <span class="nam">binary_op</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13552" href="#t13552">13552</a></span><span class="t">            <span class="key">return</span> <span class="nam">op</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13553" href="#t13553">13553</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13554" href="#t13554">13554</a></span><span class="t">            <span class="key">return</span> <span class="nam">op</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13555" href="#t13555">13555</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13556" href="#t13556">13556</a></span><span class="t">        <span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13557" href="#t13557">13557</a></span><span class="t">        <span class="str">"x"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13558" href="#t13558">13558</a></span><span class="t">        <span class="op">[</span><span class="str">"bool"</span><span class="op">,</span> <span class="str">"int8"</span><span class="op">,</span> <span class="str">"int16"</span><span class="op">,</span> <span class="str">"int32"</span><span class="op">,</span> <span class="str">"int64"</span><span class="op">,</span> <span class="str">"float32"</span><span class="op">,</span> <span class="str">"float64"</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13559" href="#t13559">13559</a></span><span class="t">        <span class="nam">op_name</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13560" href="#t13560">13560</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13561" href="#t13561">13561</a></span><span class="t">    <span class="key">if</span> <span class="nam">y</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13562" href="#t13562">13562</a></span><span class="t">        <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13563" href="#t13563">13563</a></span><span class="t">            <span class="nam">y</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13564" href="#t13564">13564</a></span><span class="t">            <span class="str">"y"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13565" href="#t13565">13565</a></span><span class="t">            <span class="op">[</span><span class="str">"bool"</span><span class="op">,</span> <span class="str">"int8"</span><span class="op">,</span> <span class="str">"int16"</span><span class="op">,</span> <span class="str">"int32"</span><span class="op">,</span> <span class="str">"int64"</span><span class="op">,</span> <span class="str">"float32"</span><span class="op">,</span> <span class="str">"float64"</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13566" href="#t13566">13566</a></span><span class="t">            <span class="nam">op_name</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13567" href="#t13567">13567</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13568" href="#t13568">13568</a></span><span class="t">    <span class="key">if</span> <span class="nam">out</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13569" href="#t13569">13569</a></span><span class="t">        <span class="nam">check_type</span><span class="op">(</span><span class="nam">out</span><span class="op">,</span> <span class="str">"out"</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">,</span> <span class="nam">op_name</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13570" href="#t13570">13570</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13571" href="#t13571">13571</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="nam">op_name</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13572" href="#t13572">13572</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13573" href="#t13573">13573</a></span><span class="t">    <span class="key">if</span> <span class="nam">binary_op</span> <span class="key">and</span> <span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span> <span class="op">!=</span> <span class="nam">y</span><span class="op">.</span><span class="nam">dtype</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13574" href="#t13574">13574</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13575" href="#t13575">13575</a></span><span class="t">            <span class="str">"(InvalidArgument) The DataType of %s Op's Variable must be consistent, but received %s and %s."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13576" href="#t13576">13576</a></span><span class="t">            <span class="op">%</span> <span class="op">(</span><span class="nam">op_name</span><span class="op">,</span> <span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">y</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13577" href="#t13577">13577</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13578" href="#t13578">13578</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13579" href="#t13579">13579</a></span><span class="t">    <span class="key">if</span> <span class="nam">out</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13580" href="#t13580">13580</a></span><span class="t">        <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13581" href="#t13581">13581</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13582" href="#t13582">13582</a></span><span class="t">    <span class="key">if</span> <span class="nam">binary_op</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13583" href="#t13583">13583</a></span><span class="t">        <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13584" href="#t13584">13584</a></span><span class="t">            <span class="nam">type</span><span class="op">=</span><span class="nam">op_name</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">x</span><span class="op">,</span> <span class="str">"Y"</span><span class="op">:</span> <span class="nam">y</span><span class="op">}</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13585" href="#t13585">13585</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13586" href="#t13586">13586</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13587" href="#t13587">13587</a></span><span class="t">        <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="nam">op_name</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13588" href="#t13588">13588</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13589" href="#t13589">13589</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13590" href="#t13590">13590</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13591" href="#t13591">13591</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13592" href="#t13592">13592</a></span><span class="t"><span class="key">def</span> <span class="nam">logical_and</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">out</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13593" href="#t13593">13593</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13594" href="#t13594">13594</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13595" href="#t13595">13595</a></span><span class="t"><span class="str">    ``logical_and`` operator computes element-wise logical AND on ``x`` and ``y``, and returns ``out``. ``out`` is N-dim boolean ``Tensor``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13596" href="#t13596">13596</a></span><span class="t"><span class="str">    Each element of ``out`` is calculated by</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13597" href="#t13597">13597</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13598" href="#t13598">13598</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13599" href="#t13599">13599</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13600" href="#t13600">13600</a></span><span class="t"><span class="str">        out = x \&amp;\&amp; y</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13601" href="#t13601">13601</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13602" href="#t13602">13602</a></span><span class="t"><span class="str">    .. note::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13603" href="#t13603">13603</a></span><span class="t"><span class="str">        ``paddle.logical_and`` supports broadcasting. If you want know more about broadcasting, please refer to :ref:`user_guide_broadcasting`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13604" href="#t13604">13604</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13605" href="#t13605">13605</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13606" href="#t13606">13606</a></span><span class="t"><span class="str">        x (Tensor): the input tensor, it's data type should be one of bool, int8, int16, in32, in64, float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13607" href="#t13607">13607</a></span><span class="t"><span class="str">        y (Tensor): the input tensor, it's data type should be one of bool, int8, int16, in32, in64, float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13608" href="#t13608">13608</a></span><span class="t"><span class="str">        out(Tensor): The ``Tensor`` that specifies the output of the operator, which can be any ``Tensor`` that has been created in the program. The default value is None, and a new ``Tensor`` will be created to save the output.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13609" href="#t13609">13609</a></span><span class="t"><span class="str">        name (str, optional): Name for the operation (optional, default is None). For more information, please refer to :ref:`api_guide_Name`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13610" href="#t13610">13610</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13611" href="#t13611">13611</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13612" href="#t13612">13612</a></span><span class="t"><span class="str">        N-D Tensor. A location into which the result is stored. It's dimension equals with ``x``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13613" href="#t13613">13613</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13614" href="#t13614">13614</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13615" href="#t13615">13615</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13616" href="#t13616">13616</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13617" href="#t13617">13617</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13618" href="#t13618">13618</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13619" href="#t13619">13619</a></span><span class="t"><span class="str">            x = paddle.to_tensor([True])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13620" href="#t13620">13620</a></span><span class="t"><span class="str">            y = paddle.to_tensor([True, False, True, False])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13621" href="#t13621">13621</a></span><span class="t"><span class="str">            res = paddle.logical_and(x, y)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13622" href="#t13622">13622</a></span><span class="t"><span class="str">            print(res) # [True False True False]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13623" href="#t13623">13623</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13624" href="#t13624">13624</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13625" href="#t13625">13625</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">logical_and</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13626" href="#t13626">13626</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13627" href="#t13627">13627</a></span><span class="t">    <span class="key">return</span> <span class="nam">_logical_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13628" href="#t13628">13628</a></span><span class="t">        <span class="nam">op_name</span><span class="op">=</span><span class="str">"logical_and"</span><span class="op">,</span> <span class="nam">x</span><span class="op">=</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">=</span><span class="nam">y</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="nam">name</span><span class="op">,</span> <span class="nam">out</span><span class="op">=</span><span class="nam">out</span><span class="op">,</span> <span class="nam">binary_op</span><span class="op">=</span><span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13629" href="#t13629">13629</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13630" href="#t13630">13630</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13631" href="#t13631">13631</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13632" href="#t13632">13632</a></span><span class="t"><span class="key">def</span> <span class="nam">logical_or</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">out</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13633" href="#t13633">13633</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13634" href="#t13634">13634</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13635" href="#t13635">13635</a></span><span class="t"><span class="str">    ``logical_or`` operator computes element-wise logical OR on ``x`` and ``y``, and returns ``out``. ``out`` is N-dim boolean ``Tensor``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13636" href="#t13636">13636</a></span><span class="t"><span class="str">    Each element of ``out`` is calculated by</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13637" href="#t13637">13637</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13638" href="#t13638">13638</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13639" href="#t13639">13639</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13640" href="#t13640">13640</a></span><span class="t"><span class="str">        out = x || y</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13641" href="#t13641">13641</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13642" href="#t13642">13642</a></span><span class="t"><span class="str">    .. note::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13643" href="#t13643">13643</a></span><span class="t"><span class="str">        ``paddle.logical_or`` supports broadcasting. If you want know more about broadcasting, please refer to :ref:`user_guide_broadcasting`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13644" href="#t13644">13644</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13645" href="#t13645">13645</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13646" href="#t13646">13646</a></span><span class="t"><span class="str">        x (Tensor): the input tensor, it's data type should be one of bool, int8, int16, in32, in64, float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13647" href="#t13647">13647</a></span><span class="t"><span class="str">        y (Tensor): the input tensor, it's data type should be one of bool, int8, int16, in32, in64, float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13648" href="#t13648">13648</a></span><span class="t"><span class="str">        out(Tensor): The ``Variable`` that specifies the output of the operator, which can be any ``Tensor`` that has been created in the program. The default value is None, and a new ``Tensor`` will be created to save the output.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13649" href="#t13649">13649</a></span><span class="t"><span class="str">        name (str, optional): Name for the operation (optional, default is None). For more information, please refer to :ref:`api_guide_Name`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13650" href="#t13650">13650</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13651" href="#t13651">13651</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13652" href="#t13652">13652</a></span><span class="t"><span class="str">        N-D Tensor. A location into which the result is stored. It's dimension equals with ``x``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13653" href="#t13653">13653</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13654" href="#t13654">13654</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13655" href="#t13655">13655</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13656" href="#t13656">13656</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13657" href="#t13657">13657</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13658" href="#t13658">13658</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13659" href="#t13659">13659</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13660" href="#t13660">13660</a></span><span class="t"><span class="str">            x_data = np.array([True, False], dtype=np.bool_).reshape(2, 1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13661" href="#t13661">13661</a></span><span class="t"><span class="str">            y_data = np.array([True, False, True, False], dtype=np.bool_).reshape(2, 2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13662" href="#t13662">13662</a></span><span class="t"><span class="str">            x = paddle.to_tensor(x_data)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13663" href="#t13663">13663</a></span><span class="t"><span class="str">            y = paddle.to_tensor(y_data)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13664" href="#t13664">13664</a></span><span class="t"><span class="str">            res = paddle.logical_or(x, y)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13665" href="#t13665">13665</a></span><span class="t"><span class="str">            print(res) # [[ True  True] [ True False]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13666" href="#t13666">13666</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13667" href="#t13667">13667</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13668" href="#t13668">13668</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">logical_or</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13669" href="#t13669">13669</a></span><span class="t">    <span class="key">return</span> <span class="nam">_logical_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13670" href="#t13670">13670</a></span><span class="t">        <span class="nam">op_name</span><span class="op">=</span><span class="str">"logical_or"</span><span class="op">,</span> <span class="nam">x</span><span class="op">=</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">=</span><span class="nam">y</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="nam">name</span><span class="op">,</span> <span class="nam">out</span><span class="op">=</span><span class="nam">out</span><span class="op">,</span> <span class="nam">binary_op</span><span class="op">=</span><span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13671" href="#t13671">13671</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13672" href="#t13672">13672</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13673" href="#t13673">13673</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13674" href="#t13674">13674</a></span><span class="t"><span class="key">def</span> <span class="nam">logical_xor</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">out</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13675" href="#t13675">13675</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13676" href="#t13676">13676</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13677" href="#t13677">13677</a></span><span class="t"><span class="str">    ``logical_xor`` operator computes element-wise logical XOR on ``x`` and ``y``, and returns ``out``. ``out`` is N-dim boolean ``Tensor``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13678" href="#t13678">13678</a></span><span class="t"><span class="str">    Each element of ``out`` is calculated by</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13679" href="#t13679">13679</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13680" href="#t13680">13680</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13681" href="#t13681">13681</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13682" href="#t13682">13682</a></span><span class="t"><span class="str">        out = (x || y) \&amp;\&amp; !(x \&amp;\&amp; y)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13683" href="#t13683">13683</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13684" href="#t13684">13684</a></span><span class="t"><span class="str">    .. note::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13685" href="#t13685">13685</a></span><span class="t"><span class="str">        ``paddle.logical_xor`` supports broadcasting. If you want know more about broadcasting, please refer to :ref:`user_guide_broadcasting`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13686" href="#t13686">13686</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13687" href="#t13687">13687</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13688" href="#t13688">13688</a></span><span class="t"><span class="str">        x (Tensor): the input tensor, it's data type should be one of bool, int8, int16, in32, in64, float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13689" href="#t13689">13689</a></span><span class="t"><span class="str">        y (Tensor): the input tensor, it's data type should be one of bool, int8, int16, in32, in64, float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13690" href="#t13690">13690</a></span><span class="t"><span class="str">        out(Tensor): The ``Tensor`` that specifies the output of the operator, which can be any ``Tensor`` that has been created in the program. The default value is None, and a new ``Tensor`` will be created to save the output.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13691" href="#t13691">13691</a></span><span class="t"><span class="str">        name (str, optional): Name for the operation (optional, default is None). For more information, please refer to :ref:`api_guide_Name`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13692" href="#t13692">13692</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13693" href="#t13693">13693</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13694" href="#t13694">13694</a></span><span class="t"><span class="str">        N-D Tensor. A location into which the result is stored. It's dimension equals with ``x``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13695" href="#t13695">13695</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13696" href="#t13696">13696</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13697" href="#t13697">13697</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13698" href="#t13698">13698</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13699" href="#t13699">13699</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13700" href="#t13700">13700</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13701" href="#t13701">13701</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13702" href="#t13702">13702</a></span><span class="t"><span class="str">            x_data = np.array([True, False], dtype=np.bool_).reshape([2, 1])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13703" href="#t13703">13703</a></span><span class="t"><span class="str">            y_data = np.array([True, False, True, False], dtype=np.bool_).reshape([2, 2])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13704" href="#t13704">13704</a></span><span class="t"><span class="str">            x = paddle.to_tensor(x_data)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13705" href="#t13705">13705</a></span><span class="t"><span class="str">            y = paddle.to_tensor(y_data)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13706" href="#t13706">13706</a></span><span class="t"><span class="str">            res = paddle.logical_xor(x, y)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13707" href="#t13707">13707</a></span><span class="t"><span class="str">            print(res) # [[False,  True], [ True, False]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13708" href="#t13708">13708</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13709" href="#t13709">13709</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13710" href="#t13710">13710</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">logical_xor</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13711" href="#t13711">13711</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13712" href="#t13712">13712</a></span><span class="t">    <span class="key">return</span> <span class="nam">_logical_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13713" href="#t13713">13713</a></span><span class="t">        <span class="nam">op_name</span><span class="op">=</span><span class="str">"logical_xor"</span><span class="op">,</span> <span class="nam">x</span><span class="op">=</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">=</span><span class="nam">y</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="nam">name</span><span class="op">,</span> <span class="nam">out</span><span class="op">=</span><span class="nam">out</span><span class="op">,</span> <span class="nam">binary_op</span><span class="op">=</span><span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13714" href="#t13714">13714</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13715" href="#t13715">13715</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13716" href="#t13716">13716</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13717" href="#t13717">13717</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13718" href="#t13718">13718</a></span><span class="t"><span class="key">def</span> <span class="nam">logical_not</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">out</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13719" href="#t13719">13719</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13720" href="#t13720">13720</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13721" href="#t13721">13721</a></span><span class="t"><span class="str">    ``logical_not`` operator computes element-wise logical NOT on ``x``, and returns ``out``. ``out`` is N-dim boolean ``Variable``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13722" href="#t13722">13722</a></span><span class="t"><span class="str">    Each element of ``out`` is calculated by</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13723" href="#t13723">13723</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13724" href="#t13724">13724</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13725" href="#t13725">13725</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13726" href="#t13726">13726</a></span><span class="t"><span class="str">        out = !x</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13727" href="#t13727">13727</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13728" href="#t13728">13728</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13729" href="#t13729">13729</a></span><span class="t"><span class="str">        x(Tensor):  Operand of logical_not operator. Must be a Tensor of type bool, int8, int16, in32, in64, float32, or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13730" href="#t13730">13730</a></span><span class="t"><span class="str">        out(Tensor): The ``Tensor`` that specifies the output of the operator, which can be any ``Tensor`` that has been created in the program. The default value is None, and a new ``Tensor` will be created to save the output.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13731" href="#t13731">13731</a></span><span class="t"><span class="str">        name(str|None): The default value is None. Normally there is no need for users to set this property. For more information, please refer to :ref:`api_guide_Name`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13732" href="#t13732">13732</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13733" href="#t13733">13733</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13734" href="#t13734">13734</a></span><span class="t"><span class="str">        Tensor: ${out_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13735" href="#t13735">13735</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13736" href="#t13736">13736</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13737" href="#t13737">13737</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13738" href="#t13738">13738</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13739" href="#t13739">13739</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13740" href="#t13740">13740</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13741" href="#t13741">13741</a></span><span class="t"><span class="str">            x = paddle.to_tensor([True, False, True, False])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13742" href="#t13742">13742</a></span><span class="t"><span class="str">            res = paddle.logical_not(x)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13743" href="#t13743">13743</a></span><span class="t"><span class="str">            print(res) # [False  True False  True]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13744" href="#t13744">13744</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t13745" href="#t13745">13745</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">13745&#x202F;&#x219B;&#x202F;13747</span><span class="annotate long">line 13745 didn't jump to line 13747, because the condition on line 13745 was never false</span></span></p>
    <p class="run"><span class="n"><a id="t13746" href="#t13746">13746</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">logical_not</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13747" href="#t13747">13747</a></span><span class="t">    <span class="key">return</span> <span class="nam">_logical_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13748" href="#t13748">13748</a></span><span class="t">        <span class="nam">op_name</span><span class="op">=</span><span class="str">"logical_not"</span><span class="op">,</span> <span class="nam">x</span><span class="op">=</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="nam">name</span><span class="op">,</span> <span class="nam">out</span><span class="op">=</span><span class="nam">out</span><span class="op">,</span> <span class="nam">binary_op</span><span class="op">=</span><span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13749" href="#t13749">13749</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13750" href="#t13750">13750</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13751" href="#t13751">13751</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13752" href="#t13752">13752</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13753" href="#t13753">13753</a></span><span class="t"><span class="key">def</span> <span class="nam">clip</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">min</span><span class="op">,</span> <span class="nam">max</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13754" href="#t13754">13754</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13755" href="#t13755">13755</a></span><span class="t"><span class="str">        :old_api: paddle.fluid.layers.clip</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13756" href="#t13756">13756</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13757" href="#t13757">13757</a></span><span class="t"><span class="str">    ${comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13758" href="#t13758">13758</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13759" href="#t13759">13759</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13760" href="#t13760">13760</a></span><span class="t"><span class="str">        x(${x_type}): ${x_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13761" href="#t13761">13761</a></span><span class="t"><span class="str">        min(float): ${min_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13762" href="#t13762">13762</a></span><span class="t"><span class="str">        max(float): ${max_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13763" href="#t13763">13763</a></span><span class="t"><span class="str">        name(str, optional): The default value is None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13764" href="#t13764">13764</a></span><span class="t"><span class="str">                             Normally there is no need for user to set this property.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13765" href="#t13765">13765</a></span><span class="t"><span class="str">                             For more information, please refer to :ref:`api_guide_Name`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13766" href="#t13766">13766</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13767" href="#t13767">13767</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13768" href="#t13768">13768</a></span><span class="t"><span class="str">        ${out_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13769" href="#t13769">13769</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13770" href="#t13770">13770</a></span><span class="t"><span class="str">    Return Type:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13771" href="#t13771">13771</a></span><span class="t"><span class="str">        ${out_type}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13772" href="#t13772">13772</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13773" href="#t13773">13773</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13774" href="#t13774">13774</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13775" href="#t13775">13775</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13776" href="#t13776">13776</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13777" href="#t13777">13777</a></span><span class="t"><span class="str">            input = fluid.data(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13778" href="#t13778">13778</a></span><span class="t"><span class="str">                name='data', shape=[1], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13779" href="#t13779">13779</a></span><span class="t"><span class="str">            reward = fluid.layers.clip(x=input, min=-1.0, max=1.0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13780" href="#t13780">13780</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13781" href="#t13781">13781</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13782" href="#t13782">13782</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"clip"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13783" href="#t13783">13783</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'clip'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13784" href="#t13784">13784</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13785" href="#t13785">13785</a></span><span class="t">    <span class="key">if</span> <span class="nam">name</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13786" href="#t13786">13786</a></span><span class="t">        <span class="nam">name</span> <span class="op">=</span> <span class="nam">unique_name</span><span class="op">.</span><span class="nam">generate_with_ignorable_key</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13787" href="#t13787">13787</a></span><span class="t">            <span class="str">"."</span><span class="op">.</span><span class="nam">join</span><span class="op">(</span><span class="op">[</span><span class="nam">helper</span><span class="op">.</span><span class="nam">name</span><span class="op">,</span> <span class="str">'tmp'</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13788" href="#t13788">13788</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13789" href="#t13789">13789</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13790" href="#t13790">13790</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13791" href="#t13791">13791</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">type</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="nam">name</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">persistable</span><span class="op">=</span><span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13792" href="#t13792">13792</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13793" href="#t13793">13793</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13794" href="#t13794">13794</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13795" href="#t13795">13795</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"clip"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13796" href="#t13796">13796</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13797" href="#t13797">13797</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">"min"</span><span class="op">:</span> <span class="nam">min</span><span class="op">,</span> <span class="str">"max"</span><span class="op">:</span> <span class="nam">max</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13798" href="#t13798">13798</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13799" href="#t13799">13799</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13800" href="#t13800">13800</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13801" href="#t13801">13801</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13802" href="#t13802">13802</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13803" href="#t13803">13803</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13804" href="#t13804">13804</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13805" href="#t13805">13805</a></span><span class="t"><span class="key">def</span> <span class="nam">clip_by_norm</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">max_norm</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13806" href="#t13806">13806</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13807" href="#t13807">13807</a></span><span class="t"><span class="str">    ${comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13808" href="#t13808">13808</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13809" href="#t13809">13809</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13810" href="#t13810">13810</a></span><span class="t"><span class="str">        x(${x_type}): ${x_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13811" href="#t13811">13811</a></span><span class="t"><span class="str">        max_norm(${max_norm_type}): ${max_norm_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13812" href="#t13812">13812</a></span><span class="t"><span class="str">        name(str, optional): For detailed information, please refer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13813" href="#t13813">13813</a></span><span class="t"><span class="str">            to :ref:`api_guide_Name`. Usually name is no need to set and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13814" href="#t13814">13814</a></span><span class="t"><span class="str">            None by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13815" href="#t13815">13815</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13816" href="#t13816">13816</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13817" href="#t13817">13817</a></span><span class="t"><span class="str">        Tensor:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13818" href="#t13818">13818</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13819" href="#t13819">13819</a></span><span class="t"><span class="str">        out(${out_type}): ${out_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13820" href="#t13820">13820</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13821" href="#t13821">13821</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13822" href="#t13822">13822</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13823" href="#t13823">13823</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13824" href="#t13824">13824</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13825" href="#t13825">13825</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13826" href="#t13826">13826</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13827" href="#t13827">13827</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13828" href="#t13828">13828</a></span><span class="t"><span class="str">            input = paddle.to_tensor([[2.0, 2.0], [2.0, 2.0]], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13829" href="#t13829">13829</a></span><span class="t"><span class="str">            reward = fluid.layers.clip_by_norm(x=input, max_norm=1.0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13830" href="#t13830">13830</a></span><span class="t"><span class="str">            # [[0.5, 0.5], [0.5, 0.5]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13831" href="#t13831">13831</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13832" href="#t13832">13832</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13833" href="#t13833">13833</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13834" href="#t13834">13834</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">clip_by_norm</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">max_norm</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13835" href="#t13835">13835</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13836" href="#t13836">13836</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">clip_by_norm</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'max_norm'</span><span class="op">,</span> <span class="nam">max_norm</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13837" href="#t13837">13837</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13838" href="#t13838">13838</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"clip_by_norm"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13839" href="#t13839">13839</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'X'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float16'</span><span class="op">]</span><span class="op">,</span> <span class="str">'clip_by_norm'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13840" href="#t13840">13840</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">max_norm</span><span class="op">,</span> <span class="str">'max_norm'</span><span class="op">,</span> <span class="op">(</span><span class="nam">float</span><span class="op">)</span><span class="op">,</span> <span class="str">'clip_by_norm'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13841" href="#t13841">13841</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13842" href="#t13842">13842</a></span><span class="t">    <span class="key">if</span> <span class="nam">name</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13843" href="#t13843">13843</a></span><span class="t">        <span class="nam">name</span> <span class="op">=</span> <span class="nam">unique_name</span><span class="op">.</span><span class="nam">generate_with_ignorable_key</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13844" href="#t13844">13844</a></span><span class="t">            <span class="str">"."</span><span class="op">.</span><span class="nam">join</span><span class="op">(</span><span class="op">[</span><span class="nam">helper</span><span class="op">.</span><span class="nam">name</span><span class="op">,</span> <span class="str">'tmp'</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13845" href="#t13845">13845</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13846" href="#t13846">13846</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13847" href="#t13847">13847</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13848" href="#t13848">13848</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">type</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="nam">name</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">persistable</span><span class="op">=</span><span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13849" href="#t13849">13849</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13850" href="#t13850">13850</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13851" href="#t13851">13851</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13852" href="#t13852">13852</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"clip_by_norm"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13853" href="#t13853">13853</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13854" href="#t13854">13854</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">"max_norm"</span><span class="op">:</span> <span class="nam">max_norm</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13855" href="#t13855">13855</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13856" href="#t13856">13856</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13857" href="#t13857">13857</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13858" href="#t13858">13858</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13859" href="#t13859">13859</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13860" href="#t13860">13860</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13861" href="#t13861">13861</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.mean"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13862" href="#t13862">13862</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13863" href="#t13863">13863</a></span><span class="t"><span class="key">def</span> <span class="nam">mean</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13864" href="#t13864">13864</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13865" href="#t13865">13865</a></span><span class="t"><span class="str">    ${comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13866" href="#t13866">13866</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13867" href="#t13867">13867</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13868" href="#t13868">13868</a></span><span class="t"><span class="str">        x(${x_type}): ${x_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13869" href="#t13869">13869</a></span><span class="t"><span class="str">        name(basestring|None): Name of the output.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13870" href="#t13870">13870</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13871" href="#t13871">13871</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13872" href="#t13872">13872</a></span><span class="t"><span class="str">        out(${out_type}): ${out_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13873" href="#t13873">13873</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13874" href="#t13874">13874</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13875" href="#t13875">13875</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13876" href="#t13876">13876</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13877" href="#t13877">13877</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13878" href="#t13878">13878</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13879" href="#t13879">13879</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13880" href="#t13880">13880</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13881" href="#t13881">13881</a></span><span class="t"><span class="str">            input = fluid.layers.data(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13882" href="#t13882">13882</a></span><span class="t"><span class="str">                name='data', shape=[2, 3], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13883" href="#t13883">13883</a></span><span class="t"><span class="str">            mean = paddle.mean(input)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13884" href="#t13884">13884</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13885" href="#t13885">13885</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13886" href="#t13886">13886</a></span><span class="t">    <span class="key">if</span> <span class="nam">_in_legacy_dygraph</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13887" href="#t13887">13887</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">mean</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13888" href="#t13888">13888</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13889" href="#t13889">13889</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">mean_all</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13890" href="#t13890">13890</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13891" href="#t13891">13891</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"mean"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13892" href="#t13892">13892</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'mean'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13893" href="#t13893">13893</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13894" href="#t13894">13894</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13895" href="#t13895">13895</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13896" href="#t13896">13896</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"mean"</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span> <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="op">}</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13897" href="#t13897">13897</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13898" href="#t13898">13898</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13899" href="#t13899">13899</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13900" href="#t13900">13900</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13901" href="#t13901">13901</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13902" href="#t13902">13902</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13903" href="#t13903">13903</a></span><span class="t"><span class="key">def</span> <span class="nam">merge_selected_rows</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13904" href="#t13904">13904</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13905" href="#t13905">13905</a></span><span class="t"><span class="str">    ${comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13906" href="#t13906">13906</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13907" href="#t13907">13907</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13908" href="#t13908">13908</a></span><span class="t"><span class="str">        x(${x_type}): ${x_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13909" href="#t13909">13909</a></span><span class="t"><span class="str">        name(basestring|None): Name of the output.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13910" href="#t13910">13910</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13911" href="#t13911">13911</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13912" href="#t13912">13912</a></span><span class="t"><span class="str">        out(${out_type}): ${out_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13913" href="#t13913">13913</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13914" href="#t13914">13914</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13915" href="#t13915">13915</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13916" href="#t13916">13916</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13917" href="#t13917">13917</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13918" href="#t13918">13918</a></span><span class="t"><span class="str">            b = fluid.default_main_program().global_block()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13919" href="#t13919">13919</a></span><span class="t"><span class="str">            var = b.create_var(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13920" href="#t13920">13920</a></span><span class="t"><span class="str">                name="X", dtype="float32", persistable=True,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13921" href="#t13921">13921</a></span><span class="t"><span class="str">                type=fluid.core.VarDesc.VarType.SELECTED_ROWS)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13922" href="#t13922">13922</a></span><span class="t"><span class="str">            y = fluid.layers.merge_selected_rows(var)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13923" href="#t13923">13923</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13924" href="#t13924">13924</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13925" href="#t13925">13925</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">merge_selected_rows</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13926" href="#t13926">13926</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13927" href="#t13927">13927</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"merge_selected_rows"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13928" href="#t13928">13928</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13929" href="#t13929">13929</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13930" href="#t13930">13930</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"merge_selected_rows"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13931" href="#t13931">13931</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13932" href="#t13932">13932</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13933" href="#t13933">13933</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13934" href="#t13934">13934</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13935" href="#t13935">13935</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13936" href="#t13936">13936</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13937" href="#t13937">13937</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13938" href="#t13938">13938</a></span><span class="t"><span class="key">def</span> <span class="nam">mul</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">x_num_col_dims</span><span class="op">=</span><span class="num">1</span><span class="op">,</span> <span class="nam">y_num_col_dims</span><span class="op">=</span><span class="num">1</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13939" href="#t13939">13939</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13940" href="#t13940">13940</a></span><span class="t"><span class="str">    Mul Operator.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13941" href="#t13941">13941</a></span><span class="t"><span class="str">    This operator is used to perform matrix multiplication for input $x$ and $y$.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13942" href="#t13942">13942</a></span><span class="t"><span class="str">    The equation is:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13943" href="#t13943">13943</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13944" href="#t13944">13944</a></span><span class="t"><span class="str">    ..  math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13945" href="#t13945">13945</a></span><span class="t"><span class="str">        Out = x * y</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13946" href="#t13946">13946</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13947" href="#t13947">13947</a></span><span class="t"><span class="str">    Both the input $x$ and $y$ can carry the LoD (Level of Details) information, or not. But the output only shares the LoD information with input $x$.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13948" href="#t13948">13948</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13949" href="#t13949">13949</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13950" href="#t13950">13950</a></span><span class="t"><span class="str">        x (Variable): The first input Tensor/LoDTensor of mul_op.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13951" href="#t13951">13951</a></span><span class="t"><span class="str">        y (Variable): The second input Tensor/LoDTensor of mul_op.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13952" href="#t13952">13952</a></span><span class="t"><span class="str">        x_num_col_dims (int, optional): The mul_op can take tensors with more than two dimensions as its inputs. If the input $x$ is a tensor with more than two dimensions, $x$ will be flattened into a two-dimensional matrix first. The flattening rule is: the first `num_col_dims` will be flattened to form the first dimension of the final matrix (the height of the matrix), and the rest `rank(x) - num_col_dims` dimensions are flattened to form the second dimension of the final matrix (the width of the matrix). As a result, height of the flattened matrix is equal to the product of $x$'s first `x_num_col_dims` dimensions' sizes, and width of the flattened matrix is equal to the product of $x$'s last `rank(x) - num_col_dims` dimensions' size. For example, suppose $x$ is a 6-dimensional tensor with the shape [2, 3, 4, 5, 6], and `x_num_col_dims` = 3. Thus, the flattened matrix will have a shape [2 x 3 x 4, 5 x 6] = [24, 30]. Default is 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13953" href="#t13953">13953</a></span><span class="t"><span class="str">        y_num_col_dims (int, optional): The mul_op can take tensors with more than two dimensions as its inputs. If the input $y$ is a tensor with more than two dimensions, $y$ will be flattened into a two-dimensional matrix first. The attribute `y_num_col_dims` determines how $y$ is flattened. See comments of `x_num_col_dims` for more details. Default is 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13954" href="#t13954">13954</a></span><span class="t"><span class="str">        name (str, optional): Name of the output. Normally there is no need for user to set this property. For more information, please refer to :ref:`api_guide_Name`. Default is None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13955" href="#t13955">13955</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13956" href="#t13956">13956</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13957" href="#t13957">13957</a></span><span class="t"><span class="str">        Variable(Tensor/LoDTensor): The output Tensor/LoDTensor of mul op.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13958" href="#t13958">13958</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13959" href="#t13959">13959</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13960" href="#t13960">13960</a></span><span class="t"><span class="str">        ..  code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13961" href="#t13961">13961</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13962" href="#t13962">13962</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13963" href="#t13963">13963</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13964" href="#t13964">13964</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13965" href="#t13965">13965</a></span><span class="t"><span class="str">            dataX = fluid.layers.data(name="dataX", append_batch_size = False, shape=[2, 5], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13966" href="#t13966">13966</a></span><span class="t"><span class="str">            dataY = fluid.layers.data(name="dataY", append_batch_size = False, shape=[5, 3], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13967" href="#t13967">13967</a></span><span class="t"><span class="str">            output = fluid.layers.mul(dataX, dataY,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13968" href="#t13968">13968</a></span><span class="t"><span class="str">                                      x_num_col_dims = 1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13969" href="#t13969">13969</a></span><span class="t"><span class="str">                                      y_num_col_dims = 1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13970" href="#t13970">13970</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13971" href="#t13971">13971</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13972" href="#t13972">13972</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13973" href="#t13973">13973</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13974" href="#t13974">13974</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">mul</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13975" href="#t13975">13975</a></span><span class="t">            <span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13976" href="#t13976">13976</a></span><span class="t">            <span class="nam">y</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13977" href="#t13977">13977</a></span><span class="t">            <span class="str">'x_num_col_dims'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13978" href="#t13978">13978</a></span><span class="t">            <span class="nam">x_num_col_dims</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13979" href="#t13979">13979</a></span><span class="t">            <span class="str">'y_num_col_dims'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13980" href="#t13980">13980</a></span><span class="t">            <span class="nam">y_num_col_dims</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13981" href="#t13981">13981</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13982" href="#t13982">13982</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13983" href="#t13983">13983</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="op">[</span><span class="nam">x</span><span class="op">]</span><span class="op">,</span> <span class="str">"Y"</span><span class="op">:</span> <span class="op">[</span><span class="nam">y</span><span class="op">]</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13984" href="#t13984">13984</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="str">"x_num_col_dims"</span><span class="op">:</span> <span class="nam">x_num_col_dims</span><span class="op">,</span> <span class="str">"y_num_col_dims"</span><span class="op">:</span> <span class="nam">y_num_col_dims</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13985" href="#t13985">13985</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"mul"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13986" href="#t13986">13986</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'mul'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13987" href="#t13987">13987</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">y</span><span class="op">,</span> <span class="str">'y'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'mul'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13988" href="#t13988">13988</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13989" href="#t13989">13989</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13990" href="#t13990">13990</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13991" href="#t13991">13991</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"mul"</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">x</span><span class="op">,</span> <span class="str">"Y"</span><span class="op">:</span> <span class="nam">y</span><span class="op">}</span><span class="op">,</span> <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13992" href="#t13992">13992</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t13993" href="#t13993">13993</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13994" href="#t13994">13994</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13995" href="#t13995">13995</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13996" href="#t13996">13996</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.nn.functional.maxout"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13997" href="#t13997">13997</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13998" href="#t13998">13998</a></span><span class="t"><span class="key">def</span> <span class="nam">maxout</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">groups</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="num">1</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t13999" href="#t13999">13999</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14000" href="#t14000">14000</a></span><span class="t"><span class="str">    ${comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14001" href="#t14001">14001</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14002" href="#t14002">14002</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14003" href="#t14003">14003</a></span><span class="t"><span class="str">        x(${x_type}): ${x_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14004" href="#t14004">14004</a></span><span class="t"><span class="str">        groups(int): ${groups_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14005" href="#t14005">14005</a></span><span class="t"><span class="str">        axis(int, optional): ${axis_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14006" href="#t14006">14006</a></span><span class="t"><span class="str">        name(str, optional): For detailed information, please refer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14007" href="#t14007">14007</a></span><span class="t"><span class="str">            to :ref:`api_guide_Name`. Usually name is no need to set and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14008" href="#t14008">14008</a></span><span class="t"><span class="str">            None by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14009" href="#t14009">14009</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14010" href="#t14010">14010</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14011" href="#t14011">14011</a></span><span class="t"><span class="str">        Variable: ${out_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14012" href="#t14012">14012</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14013" href="#t14013">14013</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14014" href="#t14014">14014</a></span><span class="t"><span class="str">        ValueError: If `axis` is not 1, -1 or 3.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14015" href="#t14015">14015</a></span><span class="t"><span class="str">        ValueError: If the number of input channels can not be divisible by `groups`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14016" href="#t14016">14016</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14017" href="#t14017">14017</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14018" href="#t14018">14018</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14019" href="#t14019">14019</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14020" href="#t14020">14020</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14021" href="#t14021">14021</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14022" href="#t14022">14022</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14023" href="#t14023">14023</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14024" href="#t14024">14024</a></span><span class="t"><span class="str">            input = fluid.data(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14025" href="#t14025">14025</a></span><span class="t"><span class="str">                name='data',</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14026" href="#t14026">14026</a></span><span class="t"><span class="str">                shape=[None, 256, 32, 32],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14027" href="#t14027">14027</a></span><span class="t"><span class="str">                dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14028" href="#t14028">14028</a></span><span class="t"><span class="str">            out = fluid.layers.maxout(input, groups=2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14029" href="#t14029">14029</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14030" href="#t14030">14030</a></span><span class="t">    <span class="key">return</span> <span class="nam">paddle</span><span class="op">.</span><span class="nam">nn</span><span class="op">.</span><span class="nam">functional</span><span class="op">.</span><span class="nam">maxout</span><span class="op">(</span><span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14031" href="#t14031">14031</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14032" href="#t14032">14032</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14033" href="#t14033">14033</a></span><span class="t"><span class="key">def</span> <span class="nam">space_to_depth</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">blocksize</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14034" href="#t14034">14034</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14035" href="#t14035">14035</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14036" href="#t14036">14036</a></span><span class="t"><span class="str">    Gives a blocksize to space_to_depth the input LoDtensor with Layout: [batch, channel, height, width]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14037" href="#t14037">14037</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14038" href="#t14038">14038</a></span><span class="t"><span class="str">    This op rearranges blocks of spatial data, into depth. More specifically, this op outputs a copy of \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14039" href="#t14039">14039</a></span><span class="t"><span class="str">        theinput LoDtensor where values from the height and width dimensions are moved to the channel \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14040" href="#t14040">14040</a></span><span class="t"><span class="str">        dimension.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14041" href="#t14041">14041</a></span><span class="t"><span class="str">    The attr blocksize indicates the input block size.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14042" href="#t14042">14042</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14043" href="#t14043">14043</a></span><span class="t"><span class="str">    space_to_depth will reorganize the elements of input with shape[batch, channel, height, width] \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14044" href="#t14044">14044</a></span><span class="t"><span class="str">        according to blocksize to construct output with shape \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14045" href="#t14045">14045</a></span><span class="t"><span class="str">        [batch, channel * blocksize * blocksize, height/blocksize, width/blocksize]:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14046" href="#t14046">14046</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14047" href="#t14047">14047</a></span><span class="t"><span class="str">    - Non-overlapping blocks of size block_size x block size are rearranged into depth at each location.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14048" href="#t14048">14048</a></span><span class="t"><span class="str">    - The Y, X coordinates within each block of the input become the high order component of the output channel index</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14049" href="#t14049">14049</a></span><span class="t"><span class="str">    - channel should be divisible by square of blocksize</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14050" href="#t14050">14050</a></span><span class="t"><span class="str">    - height, width should be divsible by blocksize</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14051" href="#t14051">14051</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14052" href="#t14052">14052</a></span><span class="t"><span class="str">    This OP is useful for resizing the activations between convolutions \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14053" href="#t14053">14053</a></span><span class="t"><span class="str">        (but keeping all data)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14054" href="#t14054">14054</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14055" href="#t14055">14055</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14056" href="#t14056">14056</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14057" href="#t14057">14057</a></span><span class="t"><span class="str">        Given the input x with the shape [1, 1, 4, 4]:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14058" href="#t14058">14058</a></span><span class="t"><span class="str">        x.data = [[[[1,   2,  5,  6],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14059" href="#t14059">14059</a></span><span class="t"><span class="str">                    [3,   4,  7,  8],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14060" href="#t14060">14060</a></span><span class="t"><span class="str">                    [9,  10, 13, 14],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14061" href="#t14061">14061</a></span><span class="t"><span class="str">                    [11, 12, 15, 16]]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14062" href="#t14062">14062</a></span><span class="t"><span class="str">        blocksize = 2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14063" href="#t14063">14063</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14064" href="#t14064">14064</a></span><span class="t"><span class="str">        then get the output with the shape [1, 4, 2, 2]:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14065" href="#t14065">14065</a></span><span class="t"><span class="str">        out.data = [[[[1,   2],  [3,  4]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14066" href="#t14066">14066</a></span><span class="t"><span class="str">                     [[5,   6],  [7,  8]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14067" href="#t14067">14067</a></span><span class="t"><span class="str">                     [[9,  10], [11, 12]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14068" href="#t14068">14068</a></span><span class="t"><span class="str">                     [[13, 14], [15, 16]]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14069" href="#t14069">14069</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14070" href="#t14070">14070</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14071" href="#t14071">14071</a></span><span class="t"><span class="str">        x (Variable): The input, which should be 4 dims Tensor or LodTensor, with the shape \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14072" href="#t14072">14072</a></span><span class="t"><span class="str">            [batch, channel, height, width]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14073" href="#t14073">14073</a></span><span class="t"><span class="str">        blocksize (int): The blocksize to select the element on each feature map should be > 2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14074" href="#t14074">14074</a></span><span class="t"><span class="str">        name(str, optional): For detailed information, please refer \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14075" href="#t14075">14075</a></span><span class="t"><span class="str">            to :ref:`api_guide_Name`. Usually name is no need to set and \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14076" href="#t14076">14076</a></span><span class="t"><span class="str">            None by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14077" href="#t14077">14077</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14078" href="#t14078">14078</a></span><span class="t"><span class="str">    Returns: </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14079" href="#t14079">14079</a></span><span class="t"><span class="str">            Tensor, The output, which should be 4 dims Tensor or LodTensor, with the shape \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14080" href="#t14080">14080</a></span><span class="t"><span class="str">            [batch, channel * blocksize * blocksize, height/blocksize, width/blocksize]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14081" href="#t14081">14081</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14082" href="#t14082">14082</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14083" href="#t14083">14083</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14084" href="#t14084">14084</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14085" href="#t14085">14085</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14086" href="#t14086">14086</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14087" href="#t14087">14087</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14088" href="#t14088">14088</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14089" href="#t14089">14089</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14090" href="#t14090">14090</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14091" href="#t14091">14091</a></span><span class="t"><span class="str">            data = fluid.data(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14092" href="#t14092">14092</a></span><span class="t"><span class="str">                name='data', shape=[1, 4, 2, 2], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14093" href="#t14093">14093</a></span><span class="t"><span class="str">            space_to_depthed = fluid.layers.space_to_depth(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14094" href="#t14094">14094</a></span><span class="t"><span class="str">                x=data, blocksize=2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14095" href="#t14095">14095</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14096" href="#t14096">14096</a></span><span class="t"><span class="str">            exe = fluid.Executor(fluid.CPUPlace())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14097" href="#t14097">14097</a></span><span class="t"><span class="str">            data_np = np.arange(0,16).reshape((1,4,2,2)).astype('float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14098" href="#t14098">14098</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14099" href="#t14099">14099</a></span><span class="t"><span class="str">            print(data_np)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14100" href="#t14100">14100</a></span><span class="t"><span class="str">            #array([[[[ 0.,  1.], [ 2.,  3.]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14101" href="#t14101">14101</a></span><span class="t"><span class="str">            #        [[ 4.,  5.], [ 6.,  7.]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14102" href="#t14102">14102</a></span><span class="t"><span class="str">            #        [[ 8.,  9.], [10., 11.]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14103" href="#t14103">14103</a></span><span class="t"><span class="str">            #        [[12., 13.], [14., 15.]]]], dtype=float32)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14104" href="#t14104">14104</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14105" href="#t14105">14105</a></span><span class="t"><span class="str">            out_main = exe.run(fluid.default_main_program(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14106" href="#t14106">14106</a></span><span class="t"><span class="str">                        feed={'data': data_np},</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14107" href="#t14107">14107</a></span><span class="t"><span class="str">                        fetch_list=[space_to_depthed])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14108" href="#t14108">14108</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14109" href="#t14109">14109</a></span><span class="t"><span class="str">            print(out_main)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14110" href="#t14110">14110</a></span><span class="t"><span class="str">            #[array([[[[ 0.]], [[ 4.]], [[ 1.]], [[ 5.]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14111" href="#t14111">14111</a></span><span class="t"><span class="str">            #         [[ 8.]], [[12.]], [[ 9.]], [[13.]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14112" href="#t14112">14112</a></span><span class="t"><span class="str">            #         [[ 2.]], [[ 6.]], [[ 3.]], [[ 7.]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14113" href="#t14113">14113</a></span><span class="t"><span class="str">            #         [[10.]], [[14.]], [[11.]], [[15.]]]], dtype=float32)]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14114" href="#t14114">14114</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14115" href="#t14115">14115</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14116" href="#t14116">14116</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14117" href="#t14117">14117</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"space_to_depth"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14118" href="#t14118">14118</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14119" href="#t14119">14119</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="op">(</span><span class="nam">isinstance</span><span class="op">(</span><span class="nam">blocksize</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14120" href="#t14120">14120</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"blocksize must be a python Int"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14121" href="#t14121">14121</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14122" href="#t14122">14122</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14123" href="#t14123">14123</a></span><span class="t">        <span class="nam">x</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14124" href="#t14124">14124</a></span><span class="t">        <span class="str">'x'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14125" href="#t14125">14125</a></span><span class="t">        <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14126" href="#t14126">14126</a></span><span class="t">        <span class="str">'space_to_depth'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14127" href="#t14127">14127</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14128" href="#t14128">14128</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14129" href="#t14129">14129</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14130" href="#t14130">14130</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14131" href="#t14131">14131</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14132" href="#t14132">14132</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"space_to_depth"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14133" href="#t14133">14133</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14134" href="#t14134">14134</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">"blocksize"</span><span class="op">:</span> <span class="nam">blocksize</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14135" href="#t14135">14135</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14136" href="#t14136">14136</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14137" href="#t14137">14137</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14138" href="#t14138">14138</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14139" href="#t14139">14139</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14140" href="#t14140">14140</a></span><span class="t"><span class="key">def</span> <span class="nam">affine_channel</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14141" href="#t14141">14141</a></span><span class="t">    <span class="nam">x</span><span class="op">,</span> <span class="nam">scale</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">bias</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">data_layout</span><span class="op">=</span><span class="str">'NCHW'</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">act</span><span class="op">=</span><span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14142" href="#t14142">14142</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14143" href="#t14143">14143</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14144" href="#t14144">14144</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14145" href="#t14145">14145</a></span><span class="t"><span class="str">    Applies a separate affine transformation to each channel of the input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14146" href="#t14146">14146</a></span><span class="t"><span class="str">    Useful for replacing spatial batch norm with its equivalent fixed</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14147" href="#t14147">14147</a></span><span class="t"><span class="str">    transformation. The input also can be 2D tensor and applies a affine</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14148" href="#t14148">14148</a></span><span class="t"><span class="str">    transformation in second dimension.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14149" href="#t14149">14149</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14150" href="#t14150">14150</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14151" href="#t14151">14151</a></span><span class="t"><span class="str">        x (Variable): Feature map input can be a 4D tensor with order NCHW</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14152" href="#t14152">14152</a></span><span class="t"><span class="str">            or NHWC. It also can be a 2D tensor and the affine transformation</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14153" href="#t14153">14153</a></span><span class="t"><span class="str">            is applied in the second dimension.The data type is float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14154" href="#t14154">14154</a></span><span class="t"><span class="str">        scale (Variable): 1D input of shape (C), the c-th element is the scale</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14155" href="#t14155">14155</a></span><span class="t"><span class="str">            factor of the affine transformation for the c-th channel of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14156" href="#t14156">14156</a></span><span class="t"><span class="str">            the input.The data type is float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14157" href="#t14157">14157</a></span><span class="t"><span class="str">        bias (Variable): 1D input of shape (C), the c-th element is the bias</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14158" href="#t14158">14158</a></span><span class="t"><span class="str">            of the affine transformation for the c-th channel of the input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14159" href="#t14159">14159</a></span><span class="t"><span class="str">            The data type is float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14160" href="#t14160">14160</a></span><span class="t"><span class="str">        data_layout (str, optional): Specify the data format of the input, and the data format of the output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14161" href="#t14161">14161</a></span><span class="t"><span class="str">            will be consistent with that of the input. An optional string from: `"NCHW"`, `"NHWC"`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14162" href="#t14162">14162</a></span><span class="t"><span class="str">            The default is `"NCHW"`. When it is `"NCHW"`, the data is stored in the order of:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14163" href="#t14163">14163</a></span><span class="t"><span class="str">            `[batch_size, input_channels, input_height, input_width]`. If input is 2D Tensor, you can ignore</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14164" href="#t14164">14164</a></span><span class="t"><span class="str">            data_layout.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14165" href="#t14165">14165</a></span><span class="t"><span class="str">        name (str, default None): The name of this layer. For more information,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14166" href="#t14166">14166</a></span><span class="t"><span class="str">            please refer to :ref:`api_guide_Name` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14167" href="#t14167">14167</a></span><span class="t"><span class="str">        act (str, default None): Activation to be applied to the output of this layer.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14168" href="#t14168">14168</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14169" href="#t14169">14169</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14170" href="#t14170">14170</a></span><span class="t"><span class="str">        Variable: A tensor which has the same shape, data layout and data type with x.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14171" href="#t14171">14171</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14172" href="#t14172">14172</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14173" href="#t14173">14173</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14174" href="#t14174">14174</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14175" href="#t14175">14175</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14176" href="#t14176">14176</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14177" href="#t14177">14177</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14178" href="#t14178">14178</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14179" href="#t14179">14179</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14180" href="#t14180">14180</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14181" href="#t14181">14181</a></span><span class="t"><span class="str">            use_gpu = False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14182" href="#t14182">14182</a></span><span class="t"><span class="str">            place = fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14183" href="#t14183">14183</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14184" href="#t14184">14184</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14185" href="#t14185">14185</a></span><span class="t"><span class="str">            data = fluid.data(name='data', shape=[None, 1, 2, 2], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14186" href="#t14186">14186</a></span><span class="t"><span class="str">            input_scale = fluid.layers.create_parameter(shape=[1], dtype="float32",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14187" href="#t14187">14187</a></span><span class="t"><span class="str">                                    default_initializer=fluid.initializer.Constant(2.0))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14188" href="#t14188">14188</a></span><span class="t"><span class="str">            input_bias = fluid.layers.create_parameter(shape=[1],dtype="float32",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14189" href="#t14189">14189</a></span><span class="t"><span class="str">                                    default_initializer=fluid.initializer.Constant(0.5))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14190" href="#t14190">14190</a></span><span class="t"><span class="str">            out = fluid.layers.affine_channel(data,scale=input_scale,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14191" href="#t14191">14191</a></span><span class="t"><span class="str">                                    bias=input_bias)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14192" href="#t14192">14192</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14193" href="#t14193">14193</a></span><span class="t"><span class="str">            exe.run(fluid.default_startup_program())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14194" href="#t14194">14194</a></span><span class="t"><span class="str">            test_program = fluid.default_main_program().clone(for_test=True)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14195" href="#t14195">14195</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14196" href="#t14196">14196</a></span><span class="t"><span class="str">            [out_array] = exe.run(test_program,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14197" href="#t14197">14197</a></span><span class="t"><span class="str">                                  fetch_list=out,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14198" href="#t14198">14198</a></span><span class="t"><span class="str">                                  feed={'data': np.ones([1,1,2,2]).astype('float32')})</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14199" href="#t14199">14199</a></span><span class="t"><span class="str">            # out_array is [[[[2.5, 2.5],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14200" href="#t14200">14200</a></span><span class="t"><span class="str">            #                [2.5, 2.5]]]] with shape: [1, 1, 2, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14201" href="#t14201">14201</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14202" href="#t14202">14202</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14203" href="#t14203">14203</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"affine_channel"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14204" href="#t14204">14204</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'affine_channel'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14205" href="#t14205">14205</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">scale</span><span class="op">,</span> <span class="str">'scale'</span><span class="op">,</span> <span class="op">(</span><span class="nam">Variable</span><span class="op">,</span> <span class="nam">type</span><span class="op">(</span><span class="key">None</span><span class="op">)</span><span class="op">)</span><span class="op">,</span> <span class="str">'affine_channel'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14206" href="#t14206">14206</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">bias</span><span class="op">,</span> <span class="str">'bias'</span><span class="op">,</span> <span class="op">(</span><span class="nam">Variable</span><span class="op">,</span> <span class="nam">type</span><span class="op">(</span><span class="key">None</span><span class="op">)</span><span class="op">)</span><span class="op">,</span> <span class="str">'affine_channel'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14207" href="#t14207">14207</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14208" href="#t14208">14208</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14209" href="#t14209">14209</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14210" href="#t14210">14210</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"affine_channel"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14211" href="#t14211">14211</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">x</span><span class="op">,</span> <span class="str">'Scale'</span><span class="op">:</span> <span class="nam">scale</span><span class="op">,</span> <span class="str">'Bias'</span><span class="op">:</span> <span class="nam">bias</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14212" href="#t14212">14212</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">"data_layout"</span><span class="op">:</span> <span class="nam">data_layout</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14213" href="#t14213">14213</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14214" href="#t14214">14214</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14215" href="#t14215">14215</a></span><span class="t">    <span class="key">return</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_activation</span><span class="op">(</span><span class="nam">out</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14216" href="#t14216">14216</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14217" href="#t14217">14217</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14218" href="#t14218">14218</a></span><span class="t"><span class="key">def</span> <span class="nam">similarity_focus</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">axis</span><span class="op">,</span> <span class="nam">indexes</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14219" href="#t14219">14219</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14220" href="#t14220">14220</a></span><span class="t"><span class="str">    SimilarityFocus Operator</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14221" href="#t14221">14221</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14222" href="#t14222">14222</a></span><span class="t"><span class="str">    Generate a similarity focus mask with the same shape of input using the following method:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14223" href="#t14223">14223</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14224" href="#t14224">14224</a></span><span class="t"><span class="str">    1. Extract the 3-D tensor(here the first dimension is BatchSize) corresponding</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14225" href="#t14225">14225</a></span><span class="t"><span class="str">       to the axis according to the indexes. For example, if axis=1 and indexes=[a],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14226" href="#t14226">14226</a></span><span class="t"><span class="str">       it will get the matrix T=X[:, a, :, :]. In this case, if the shape of input X</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14227" href="#t14227">14227</a></span><span class="t"><span class="str">       is (BatchSize, A, B, C), the shape of tensor T is (BatchSize, B, C).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14228" href="#t14228">14228</a></span><span class="t"><span class="str">    2. For each index, find the largest numbers in the tensor T, so that the same</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14229" href="#t14229">14229</a></span><span class="t"><span class="str">       row and same column has at most one number(what it means is that if the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14230" href="#t14230">14230</a></span><span class="t"><span class="str">       largest number has been found in the i-th row and the j-th column, then</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14231" href="#t14231">14231</a></span><span class="t"><span class="str">       the numbers in the i-th row or j-th column will be skipped. And then the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14232" href="#t14232">14232</a></span><span class="t"><span class="str">       next largest number will be selected from the remaining numbers. Obviously</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14233" href="#t14233">14233</a></span><span class="t"><span class="str">       there will be min(B, C) numbers), and mark the corresponding position of the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14234" href="#t14234">14234</a></span><span class="t"><span class="str">       3-D similarity focus mask as 1, otherwise as 0. Do elementwise-or for</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14235" href="#t14235">14235</a></span><span class="t"><span class="str">       each index.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14236" href="#t14236">14236</a></span><span class="t"><span class="str">    3. Broadcast the 3-D similarity focus mask to the same shape of input X.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14237" href="#t14237">14237</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14238" href="#t14238">14238</a></span><span class="t"><span class="str">    Refer to `Similarity Focus Layer &lt;http://www.aclweb.org/anthology/N16-1108>`_</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14239" href="#t14239">14239</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14240" href="#t14240">14240</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14241" href="#t14241">14241</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14242" href="#t14242">14242</a></span><span class="t"><span class="str">        * Example :</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14243" href="#t14243">14243</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14244" href="#t14244">14244</a></span><span class="t"><span class="str">            Given a 4-D tensor x with the shape (BatchSize, C, A, B), where C is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14245" href="#t14245">14245</a></span><span class="t"><span class="str">            the number of channels and the shape of feature map is (A, B):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14246" href="#t14246">14246</a></span><span class="t"><span class="str">                x.shape = (2, 3, 2, 2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14247" href="#t14247">14247</a></span><span class="t"><span class="str">                x.data = [[[[0.8, 0.1],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14248" href="#t14248">14248</a></span><span class="t"><span class="str">                            [0.4, 0.5]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14249" href="#t14249">14249</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14250" href="#t14250">14250</a></span><span class="t"><span class="str">                           [[0.9, 0.7],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14251" href="#t14251">14251</a></span><span class="t"><span class="str">                            [0.9, 0.9]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14252" href="#t14252">14252</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14253" href="#t14253">14253</a></span><span class="t"><span class="str">                           [[0.8, 0.9],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14254" href="#t14254">14254</a></span><span class="t"><span class="str">                            [0.1, 0.2]]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14255" href="#t14255">14255</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14256" href="#t14256">14256</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14257" href="#t14257">14257</a></span><span class="t"><span class="str">                          [[[0.2, 0.5],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14258" href="#t14258">14258</a></span><span class="t"><span class="str">                            [0.3, 0.4]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14259" href="#t14259">14259</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14260" href="#t14260">14260</a></span><span class="t"><span class="str">                           [[0.9, 0.7],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14261" href="#t14261">14261</a></span><span class="t"><span class="str">                            [0.8, 0.4]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14262" href="#t14262">14262</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14263" href="#t14263">14263</a></span><span class="t"><span class="str">                           [[0.0, 0.2],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14264" href="#t14264">14264</a></span><span class="t"><span class="str">                            [0.4, 0.7]]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14265" href="#t14265">14265</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14266" href="#t14266">14266</a></span><span class="t"><span class="str">            Given axis: 1 (the axis of the channel)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14267" href="#t14267">14267</a></span><span class="t"><span class="str">            Given indexes: [0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14268" href="#t14268">14268</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14269" href="#t14269">14269</a></span><span class="t"><span class="str">            then we get a 4-D tensor out with the same shape of input x:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14270" href="#t14270">14270</a></span><span class="t"><span class="str">                out.shape = (2, 3, 2, 2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14271" href="#t14271">14271</a></span><span class="t"><span class="str">                out.data = [[[[1.0, 0.0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14272" href="#t14272">14272</a></span><span class="t"><span class="str">                              [0.0, 1.0]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14273" href="#t14273">14273</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14274" href="#t14274">14274</a></span><span class="t"><span class="str">                             [[1.0, 0.0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14275" href="#t14275">14275</a></span><span class="t"><span class="str">                              [0.0, 1.0]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14276" href="#t14276">14276</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14277" href="#t14277">14277</a></span><span class="t"><span class="str">                             [[1.0, 0.0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14278" href="#t14278">14278</a></span><span class="t"><span class="str">                              [0.0, 1.0]]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14279" href="#t14279">14279</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14280" href="#t14280">14280</a></span><span class="t"><span class="str">                            [[[0.0, 1.0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14281" href="#t14281">14281</a></span><span class="t"><span class="str">                              [1.0, 0.0]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14282" href="#t14282">14282</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14283" href="#t14283">14283</a></span><span class="t"><span class="str">                             [[0.0, 1.0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14284" href="#t14284">14284</a></span><span class="t"><span class="str">                              [1.0, 0.0]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14285" href="#t14285">14285</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14286" href="#t14286">14286</a></span><span class="t"><span class="str">                             [[0.0, 1.0],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14287" href="#t14287">14287</a></span><span class="t"><span class="str">                              [1.0, 0.0]]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14288" href="#t14288">14288</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14289" href="#t14289">14289</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14290" href="#t14290">14290</a></span><span class="t"><span class="str">        input(Variable): The input tensor variable(default float). It should</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14291" href="#t14291">14291</a></span><span class="t"><span class="str">            be a 4-D tensor with shape [BatchSize, A, B, C]. Data type is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14292" href="#t14292">14292</a></span><span class="t"><span class="str">            float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14293" href="#t14293">14293</a></span><span class="t"><span class="str">        axis(int): Indicating the dimension to be selected. It can only be</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14294" href="#t14294">14294</a></span><span class="t"><span class="str">            1, 2 or 3.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14295" href="#t14295">14295</a></span><span class="t"><span class="str">        indexes(list): Indicating the indexes of the selected dimension.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14296" href="#t14296">14296</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14297" href="#t14297">14297</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14298" href="#t14298">14298</a></span><span class="t"><span class="str">        Variable: A tensor variable with the same shape and same type \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14299" href="#t14299">14299</a></span><span class="t"><span class="str">                  as the input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14300" href="#t14300">14300</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14301" href="#t14301">14301</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14302" href="#t14302">14302</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14303" href="#t14303">14303</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14304" href="#t14304">14304</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14305" href="#t14305">14305</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14306" href="#t14306">14306</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14307" href="#t14307">14307</a></span><span class="t"><span class="str">            data = fluid.data(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14308" href="#t14308">14308</a></span><span class="t"><span class="str">                name='data', shape=[-1, 3, 2, 2], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14309" href="#t14309">14309</a></span><span class="t"><span class="str">            fluid.layers.similarity_focus(input=data, axis=1, indexes=[0])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14310" href="#t14310">14310</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14311" href="#t14311">14311</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'similarity_focus'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14312" href="#t14312">14312</a></span><span class="t">    <span class="com"># check attrs</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14313" href="#t14313">14313</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14314" href="#t14314">14314</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">"similarity_focus"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14315" href="#t14315">14315</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14316" href="#t14316">14316</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">axis</span><span class="op">,</span> <span class="str">'axis'</span><span class="op">,</span> <span class="nam">int</span><span class="op">,</span> <span class="str">"similarity_focus"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14317" href="#t14317">14317</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">indexes</span><span class="op">,</span> <span class="str">'indexes'</span><span class="op">,</span> <span class="nam">list</span><span class="op">,</span> <span class="str">"similarity_focus"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14318" href="#t14318">14318</a></span><span class="t">    <span class="key">if</span> <span class="nam">axis</span> <span class="op">!=</span> <span class="num">1</span> <span class="key">and</span> <span class="nam">axis</span> <span class="op">!=</span> <span class="num">2</span> <span class="key">and</span> <span class="nam">axis</span> <span class="op">!=</span> <span class="num">3</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14319" href="#t14319">14319</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"axis must be 1, 2 or 3."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14320" href="#t14320">14320</a></span><span class="t">    <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">indexes</span><span class="op">)</span> <span class="op">==</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14321" href="#t14321">14321</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"indexes can not be empty."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14322" href="#t14322">14322</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14323" href="#t14323">14323</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">input</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14324" href="#t14324">14324</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14325" href="#t14325">14325</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'similarity_focus'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14326" href="#t14326">14326</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14327" href="#t14327">14327</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14328" href="#t14328">14328</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">"axis"</span><span class="op">:</span> <span class="nam">axis</span><span class="op">,</span> <span class="str">"indexes"</span><span class="op">:</span> <span class="nam">indexes</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14329" href="#t14329">14329</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14330" href="#t14330">14330</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14331" href="#t14331">14331</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14332" href="#t14332">14332</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14333" href="#t14333">14333</a></span><span class="t"><span class="key">def</span> <span class="nam">hash</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">hash_size</span><span class="op">,</span> <span class="nam">num_hash</span><span class="op">=</span><span class="num">1</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14334" href="#t14334">14334</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14335" href="#t14335">14335</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14336" href="#t14336">14336</a></span><span class="t"><span class="str">    This OP hash the input to an integer less than the hash_size.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14337" href="#t14337">14337</a></span><span class="t"><span class="str">    The hash algorithm we used was xxHash - Extremely fast hash algorithm</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14338" href="#t14338">14338</a></span><span class="t"><span class="str">    (https://github.com/Cyan4973/xxHash/tree/v0.6.5)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14339" href="#t14339">14339</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14340" href="#t14340">14340</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14341" href="#t14341">14341</a></span><span class="t"><span class="str">        input(Variable): A **Two-Dimensional** LoDTensor with type int32, int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14342" href="#t14342">14342</a></span><span class="t"><span class="str">             **Only support LoDTensor**.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14343" href="#t14343">14343</a></span><span class="t"><span class="str">        num_hash(int, optional): The times of hash, default is 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14344" href="#t14344">14344</a></span><span class="t"><span class="str">        name(str, optional): The default value is None. Normally there is no</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14345" href="#t14345">14345</a></span><span class="t"><span class="str">            need for user to set this property. For more information, please</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14346" href="#t14346">14346</a></span><span class="t"><span class="str">            refer to :ref:`api_guide_Name`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14347" href="#t14347">14347</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14348" href="#t14348">14348</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14349" href="#t14349">14349</a></span><span class="t"><span class="str">       Variable: A LoDTensor with the same data type as input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14350" href="#t14350">14350</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14351" href="#t14351">14351</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14352" href="#t14352">14352</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14353" href="#t14353">14353</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14354" href="#t14354">14354</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14355" href="#t14355">14355</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14356" href="#t14356">14356</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14357" href="#t14357">14357</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14358" href="#t14358">14358</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14359" href="#t14359">14359</a></span><span class="t"><span class="str">            place = fluid.core.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14360" href="#t14360">14360</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14361" href="#t14361">14361</a></span><span class="t"><span class="str">            x = fluid.data(name="x", shape=[2,2], dtype="int32", lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14362" href="#t14362">14362</a></span><span class="t"><span class="str">            res = fluid.layers.hash(name="res", input=x, hash_size=1000, num_hash=4)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14363" href="#t14363">14363</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14364" href="#t14364">14364</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14365" href="#t14365">14365</a></span><span class="t"><span class="str">            exe.run(fluid.default_startup_program())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14366" href="#t14366">14366</a></span><span class="t"><span class="str">            in1 = np.array([[1,2],[3,4]]).astype("int32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14367" href="#t14367">14367</a></span><span class="t"><span class="str">            print(in1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14368" href="#t14368">14368</a></span><span class="t"><span class="str">            x_i = fluid.create_lod_tensor(in1, [[0, 2]], place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14369" href="#t14369">14369</a></span><span class="t"><span class="str">            res = exe.run(fluid.default_main_program(), feed={'x':x_i}, fetch_list=[res], return_numpy=False)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14370" href="#t14370">14370</a></span><span class="t"><span class="str">            print(np.array(res[0]))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14371" href="#t14371">14371</a></span><span class="t"><span class="str">            # [[[722]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14372" href="#t14372">14372</a></span><span class="t"><span class="str">            #   [407]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14373" href="#t14373">14373</a></span><span class="t"><span class="str">            #   [337]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14374" href="#t14374">14374</a></span><span class="t"><span class="str">            #   [395]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14375" href="#t14375">14375</a></span><span class="t"><span class="str">            #  [[603]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14376" href="#t14376">14376</a></span><span class="t"><span class="str">            #   [590]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14377" href="#t14377">14377</a></span><span class="t"><span class="str">            #   [386]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14378" href="#t14378">14378</a></span><span class="t"><span class="str">            #   [901]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14379" href="#t14379">14379</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14380" href="#t14380">14380</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'hash'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14381" href="#t14381">14381</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">hash_size</span><span class="op">,</span> <span class="str">'hash_size'</span><span class="op">,</span> <span class="nam">int</span><span class="op">,</span> <span class="str">'hash'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14382" href="#t14382">14382</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">num_hash</span><span class="op">,</span> <span class="str">'num_hash'</span><span class="op">,</span> <span class="nam">int</span><span class="op">,</span> <span class="str">'hash'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14383" href="#t14383">14383</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'hash'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14384" href="#t14384">14384</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14385" href="#t14385">14385</a></span><span class="t">        <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span><span class="op">,</span> <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14386" href="#t14386">14386</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14387" href="#t14387">14387</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14388" href="#t14388">14388</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'hash'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14389" href="#t14389">14389</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14390" href="#t14390">14390</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14391" href="#t14391">14391</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'num_hash'</span><span class="op">:</span> <span class="nam">num_hash</span><span class="op">,</span> <span class="str">'mod_by'</span><span class="op">:</span> <span class="nam">hash_size</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14392" href="#t14392">14392</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14393" href="#t14393">14393</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14394" href="#t14394">14394</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14395" href="#t14395">14395</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14396" href="#t14396">14396</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14397" href="#t14397">14397</a></span><span class="t"><span class="key">def</span> <span class="nam">grid_sampler</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">grid</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14398" href="#t14398">14398</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14399" href="#t14399">14399</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14400" href="#t14400">14400</a></span><span class="t"><span class="str">    This operation samples input X by using bilinear interpolation based on</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14401" href="#t14401">14401</a></span><span class="t"><span class="str">    flow field grid, which is usually generated by :code:`affine_grid` . The grid of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14402" href="#t14402">14402</a></span><span class="t"><span class="str">    shape [N, H, W, 2] is the concatenation of (x, y) coordinates</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14403" href="#t14403">14403</a></span><span class="t"><span class="str">    with shape [N, H, W] each, where x is indexing the 4th dimension</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14404" href="#t14404">14404</a></span><span class="t"><span class="str">    (in width dimension) of input data x and y is indexing the 3rd</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14405" href="#t14405">14405</a></span><span class="t"><span class="str">    dimension (in height dimension), finally results is the bilinear</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14406" href="#t14406">14406</a></span><span class="t"><span class="str">    interpolation value of 4 nearest corner points. The output tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14407" href="#t14407">14407</a></span><span class="t"><span class="str">    shape will be [N, C, H, W].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14408" href="#t14408">14408</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14409" href="#t14409">14409</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14410" href="#t14410">14410</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14411" href="#t14411">14411</a></span><span class="t"><span class="str">        Step 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14412" href="#t14412">14412</a></span><span class="t"><span class="str">        Get (x, y) grid coordinates and scale to [0, H-1/W-1].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14413" href="#t14413">14413</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14414" href="#t14414">14414</a></span><span class="t"><span class="str">        .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14415" href="#t14415">14415</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14416" href="#t14416">14416</a></span><span class="t"><span class="str">            grid_x = 0.5 * (grid[:, :, :, 0] + 1) * (W - 1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14417" href="#t14417">14417</a></span><span class="t"><span class="str">            grid_y = 0.5 * (grid[:, :, :, 1] + 1) * (H - 1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14418" href="#t14418">14418</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14419" href="#t14419">14419</a></span><span class="t"><span class="str">        Step 2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14420" href="#t14420">14420</a></span><span class="t"><span class="str">        Indices input data X with grid (x, y) in each [H, W] area, and bilinear</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14421" href="#t14421">14421</a></span><span class="t"><span class="str">        interpolate point value by 4 nearest points.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14422" href="#t14422">14422</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14423" href="#t14423">14423</a></span><span class="t"><span class="str">          wn ------- y_n ------- en</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14424" href="#t14424">14424</a></span><span class="t"><span class="str">          |           |           |</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14425" href="#t14425">14425</a></span><span class="t"><span class="str">          |          d_n          |</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14426" href="#t14426">14426</a></span><span class="t"><span class="str">          |           |           |</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14427" href="#t14427">14427</a></span><span class="t"><span class="str">         x_w --d_w-- grid--d_e-- x_e</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14428" href="#t14428">14428</a></span><span class="t"><span class="str">          |           |           |</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14429" href="#t14429">14429</a></span><span class="t"><span class="str">          |          d_s          |</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14430" href="#t14430">14430</a></span><span class="t"><span class="str">          |           |           |</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14431" href="#t14431">14431</a></span><span class="t"><span class="str">          ws ------- y_s ------- wn</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14432" href="#t14432">14432</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14433" href="#t14433">14433</a></span><span class="t"><span class="str">        x_w = floor(x)              // west side x coord</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14434" href="#t14434">14434</a></span><span class="t"><span class="str">        x_e = x_w + 1               // east side x coord</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14435" href="#t14435">14435</a></span><span class="t"><span class="str">        y_n = floor(y)              // north side y coord</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14436" href="#t14436">14436</a></span><span class="t"><span class="str">        y_s = y_s + 1               // south side y coord</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14437" href="#t14437">14437</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14438" href="#t14438">14438</a></span><span class="t"><span class="str">        d_w = grid_x - x_w          // distance to west side</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14439" href="#t14439">14439</a></span><span class="t"><span class="str">        d_e = x_e - grid_x          // distance to east side</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14440" href="#t14440">14440</a></span><span class="t"><span class="str">        d_n = grid_y - y_n          // distance to north side</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14441" href="#t14441">14441</a></span><span class="t"><span class="str">        d_s = y_s - grid_y          // distance to south side</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14442" href="#t14442">14442</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14443" href="#t14443">14443</a></span><span class="t"><span class="str">        wn = X[:, :, y_n, x_w]      // north-west point value</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14444" href="#t14444">14444</a></span><span class="t"><span class="str">        en = X[:, :, y_n, x_e]      // north-east point value</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14445" href="#t14445">14445</a></span><span class="t"><span class="str">        ws = X[:, :, y_s, x_w]      // south-east point value</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14446" href="#t14446">14446</a></span><span class="t"><span class="str">        es = X[:, :, y_s, x_w]      // north-east point value</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14447" href="#t14447">14447</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14448" href="#t14448">14448</a></span><span class="t"><span class="str">        output = wn * d_e * d_s + en * d_w * d_s</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14449" href="#t14449">14449</a></span><span class="t"><span class="str">               + ws * d_e * d_n + es * d_w * d_n</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14450" href="#t14450">14450</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14451" href="#t14451">14451</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14452" href="#t14452">14452</a></span><span class="t"><span class="str">        x(Variable): The input tensor, which is a 4-D tensor with shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14453" href="#t14453">14453</a></span><span class="t"><span class="str">                     [N, C, H, W], N is the batch size, C is the channel</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14454" href="#t14454">14454</a></span><span class="t"><span class="str">                     number, H and W is the feature height and width.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14455" href="#t14455">14455</a></span><span class="t"><span class="str">                     The data type is float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14456" href="#t14456">14456</a></span><span class="t"><span class="str">        grid(Variable): Input grid tensor of shape [N, H, W, 2]. The</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14457" href="#t14457">14457</a></span><span class="t"><span class="str">                        data type is float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14458" href="#t14458">14458</a></span><span class="t"><span class="str">        name(str, optional): For detailed information, please refer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14459" href="#t14459">14459</a></span><span class="t"><span class="str">                             to :ref:`api_guide_Name`. Usually name is no need to set and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14460" href="#t14460">14460</a></span><span class="t"><span class="str">                             None by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14461" href="#t14461">14461</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14462" href="#t14462">14462</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14463" href="#t14463">14463</a></span><span class="t"><span class="str">        Variable: Output of shape [N, C, H, W] data samples input X</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14464" href="#t14464">14464</a></span><span class="t"><span class="str">                  using bilnear interpolation based on input grid.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14465" href="#t14465">14465</a></span><span class="t"><span class="str">                  The data type is same as input tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14466" href="#t14466">14466</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14467" href="#t14467">14467</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14468" href="#t14468">14468</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14469" href="#t14469">14469</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14470" href="#t14470">14470</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14471" href="#t14471">14471</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14472" href="#t14472">14472</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14473" href="#t14473">14473</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14474" href="#t14474">14474</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14475" href="#t14475">14475</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14476" href="#t14476">14476</a></span><span class="t"><span class="str">            # use with affine_grid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14477" href="#t14477">14477</a></span><span class="t"><span class="str">            x = fluid.data(name='x', shape=[None, 10, 32, 32], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14478" href="#t14478">14478</a></span><span class="t"><span class="str">            theta = fluid.layers.data(name='theta', shape=[2, 3], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14479" href="#t14479">14479</a></span><span class="t"><span class="str">            grid = fluid.layers.affine_grid(theta=theta, out_shape=[3, 10, 32, 32])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14480" href="#t14480">14480</a></span><span class="t"><span class="str">            out = fluid.layers.grid_sampler(x=x, grid=grid)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14481" href="#t14481">14481</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14482" href="#t14482">14482</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14483" href="#t14483">14483</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"grid_sampler"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14484" href="#t14484">14484</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14485" href="#t14485">14485</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'grid_sampler'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14486" href="#t14486">14486</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14487" href="#t14487">14487</a></span><span class="t">        <span class="nam">grid</span><span class="op">,</span> <span class="str">'grid'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'grid_sampler'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14488" href="#t14488">14488</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14489" href="#t14489">14489</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14490" href="#t14490">14490</a></span><span class="t">        <span class="key">return</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"The x should be a Variable"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14491" href="#t14491">14491</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14492" href="#t14492">14492</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">grid</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14493" href="#t14493">14493</a></span><span class="t">        <span class="key">return</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"The grid should be a Variable"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14494" href="#t14494">14494</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14495" href="#t14495">14495</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14496" href="#t14496">14496</a></span><span class="t">    <span class="nam">ipts</span> <span class="op">=</span> <span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">,</span> <span class="str">'Grid'</span><span class="op">:</span> <span class="nam">grid</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14497" href="#t14497">14497</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14498" href="#t14498">14498</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'use_cudnn'</span><span class="op">:</span> <span class="key">False</span><span class="op">}</span> <span class="key">if</span> <span class="nam">core</span><span class="op">.</span><span class="nam">is_compiled_with_rocm</span><span class="op">(</span><span class="op">)</span> <span class="key">else</span> <span class="op">{</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14499" href="#t14499">14499</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14500" href="#t14500">14500</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14501" href="#t14501">14501</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'grid_sampler'</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="nam">ipts</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Output'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span> <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14502" href="#t14502">14502</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14503" href="#t14503">14503</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14504" href="#t14504">14504</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14505" href="#t14505">14505</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14506" href="#t14506">14506</a></span><span class="t"><span class="key">def</span> <span class="nam">log_loss</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">label</span><span class="op">,</span> <span class="nam">epsilon</span><span class="op">=</span><span class="num">1e-4</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14507" href="#t14507">14507</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14508" href="#t14508">14508</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14509" href="#t14509">14509</a></span><span class="t"><span class="str">    **Negative Log Loss Layer**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14510" href="#t14510">14510</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14511" href="#t14511">14511</a></span><span class="t"><span class="str">    This layer accepts input predictions and target label and returns the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14512" href="#t14512">14512</a></span><span class="t"><span class="str">    negative log loss.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14513" href="#t14513">14513</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14514" href="#t14514">14514</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14515" href="#t14515">14515</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14516" href="#t14516">14516</a></span><span class="t"><span class="str">        Out = -label * \log{(input + \epsilon)}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14517" href="#t14517">14517</a></span><span class="t"><span class="str">              - (1 - label) * \log{(1 - input + \epsilon)}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14518" href="#t14518">14518</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14519" href="#t14519">14519</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14520" href="#t14520">14520</a></span><span class="t"><span class="str">        input (Tensor|list):  A 2-D tensor with shape [N x 1], where N is the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14521" href="#t14521">14521</a></span><span class="t"><span class="str">                                batch size. This input is a probability computed</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14522" href="#t14522">14522</a></span><span class="t"><span class="str">                                by the previous operator. Data type float32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14523" href="#t14523">14523</a></span><span class="t"><span class="str">        label (Tensor|list):  The ground truth which is a 2-D tensor with</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14524" href="#t14524">14524</a></span><span class="t"><span class="str">                                shape [N x 1], where N is the batch size.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14525" href="#t14525">14525</a></span><span class="t"><span class="str">                                Data type float32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14526" href="#t14526">14526</a></span><span class="t"><span class="str">        epsilon (float, optional): A small number for numerical stability. Default 1e-4.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14527" href="#t14527">14527</a></span><span class="t"><span class="str">        name(str|None): For detailed information, please refer to</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14528" href="#t14528">14528</a></span><span class="t"><span class="str">            :ref:`api_guide_Name` . Usually name is no need to set and None by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14529" href="#t14529">14529</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14530" href="#t14530">14530</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14531" href="#t14531">14531</a></span><span class="t"><span class="str">        Tensor, which shape is [N x 1], data type is float32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14532" href="#t14532">14532</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14533" href="#t14533">14533</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14534" href="#t14534">14534</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14535" href="#t14535">14535</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14536" href="#t14536">14536</a></span><span class="t"><span class="str">          import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14537" href="#t14537">14537</a></span><span class="t"><span class="str">          import paddle.nn.functional as F</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14538" href="#t14538">14538</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14539" href="#t14539">14539</a></span><span class="t"><span class="str">          label = paddle.randn((10,1))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14540" href="#t14540">14540</a></span><span class="t"><span class="str">          prob = paddle.randn((10,1))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14541" href="#t14541">14541</a></span><span class="t"><span class="str">          cost = F.log_loss(input=prob, label=label)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14542" href="#t14542">14542</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14543" href="#t14543">14543</a></span><span class="t">    <span class="key">return</span> <span class="nam">paddle</span><span class="op">.</span><span class="nam">nn</span><span class="op">.</span><span class="nam">functional</span><span class="op">.</span><span class="nam">log_loss</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">label</span><span class="op">,</span> <span class="nam">epsilon</span><span class="op">,</span> <span class="nam">name</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14544" href="#t14544">14544</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14545" href="#t14545">14545</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14546" href="#t14546">14546</a></span><span class="t"><span class="key">def</span> <span class="nam">add_position_encoding</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">alpha</span><span class="op">,</span> <span class="nam">beta</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14547" href="#t14547">14547</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14548" href="#t14548">14548</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14549" href="#t14549">14549</a></span><span class="t"><span class="str">    This operator performs weighted sum of input feature at each position</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14550" href="#t14550">14550</a></span><span class="t"><span class="str">    (position in the sequence) and the corresponding position encoding.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14551" href="#t14551">14551</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14552" href="#t14552">14552</a></span><span class="t"><span class="str">    For more details of position encoding, please refer to `Attention Is All You</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14553" href="#t14553">14553</a></span><span class="t"><span class="str">    Need &lt;http://arxiv.org/pdf/1706.03762.pdf>`_ .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14554" href="#t14554">14554</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14555" href="#t14555">14555</a></span><span class="t"><span class="str">    The formula is as follows:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14556" href="#t14556">14556</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14557" href="#t14557">14557</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14558" href="#t14558">14558</a></span><span class="t"><span class="str">        PE(pos, 2i) &amp;= \\sin{(pos / 10000^{2i / P})}   \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14559" href="#t14559">14559</a></span><span class="t"><span class="str">        PE(pos, 2i + 1) &amp;= \\cos{(pos / 10000^{2i / P})}  \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14560" href="#t14560">14560</a></span><span class="t"><span class="str">        Out(:, pos, i) &amp;= \\alpha * input(:, pos, i) + \\beta * PE(pos, i)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14561" href="#t14561">14561</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14562" href="#t14562">14562</a></span><span class="t"><span class="str">    Where:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14563" href="#t14563">14563</a></span><span class="t"><span class="str">      - :math:`PE(pos, 2i)` : the value at even index `2i` for encoding of position `pos`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14564" href="#t14564">14564</a></span><span class="t"><span class="str">      - :math:`PE(pos, 2i + 1)` : the value at odd index `2i+1` for encoding of position `pos`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14565" href="#t14565">14565</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14566" href="#t14566">14566</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14567" href="#t14567">14567</a></span><span class="t"><span class="str">        input(Variable): A Tensor or LoDTensor (lod level is 1). If it is a</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14568" href="#t14568">14568</a></span><span class="t"><span class="str">            Tensor, the shape should be `[N, M, P]`, where `N` stands for</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14569" href="#t14569">14569</a></span><span class="t"><span class="str">            batch size, `M` for sequence length, `P` for the size of feature</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14570" href="#t14570">14570</a></span><span class="t"><span class="str">            dimension. If it is a LoDTensor, the shape should be `[N, P]`,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14571" href="#t14571">14571</a></span><span class="t"><span class="str">            where `N` stands for the total sequence lengths in this mini-batch,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14572" href="#t14572">14572</a></span><span class="t"><span class="str">            `P` for the size of feature. The data type should be float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14573" href="#t14573">14573</a></span><span class="t"><span class="str">        alpha(float): Indicate the weight coefficient for `input` when performing</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14574" href="#t14574">14574</a></span><span class="t"><span class="str">            weighted sum.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14575" href="#t14575">14575</a></span><span class="t"><span class="str">        beta(float): Indicate the weight coefficient for position encoding when</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14576" href="#t14576">14576</a></span><span class="t"><span class="str">            performing weighted sum.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14577" href="#t14577">14577</a></span><span class="t"><span class="str">        name(str, optional): For detailed information, please refer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14578" href="#t14578">14578</a></span><span class="t"><span class="str">            to :ref:`api_guide_Name`. Usually name is no need to set and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14579" href="#t14579">14579</a></span><span class="t"><span class="str">            None by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14580" href="#t14580">14580</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14581" href="#t14581">14581</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14582" href="#t14582">14582</a></span><span class="t"><span class="str">        Variable: A Tensor or LoDTensor. It has the same shape, data type and lod as `input`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14583" href="#t14583">14583</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14584" href="#t14584">14584</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14585" href="#t14585">14585</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14586" href="#t14586">14586</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14587" href="#t14587">14587</a></span><span class="t"><span class="str">          import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14588" href="#t14588">14588</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14589" href="#t14589">14589</a></span><span class="t"><span class="str">          tensor = paddle.randn([16, 32, 64])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14590" href="#t14590">14590</a></span><span class="t"><span class="str">          position_tensor = paddle.fluid.layers.add_position_encoding(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14591" href="#t14591">14591</a></span><span class="t"><span class="str">                input=tensor, alpha=1.0, beta=1.0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14592" href="#t14592">14592</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14593" href="#t14593">14593</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14594" href="#t14594">14594</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14595" href="#t14595">14595</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">add_position_encoding</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14596" href="#t14596">14596</a></span><span class="t">            <span class="nam">input</span><span class="op">,</span> <span class="str">"alpha"</span><span class="op">,</span> <span class="nam">alpha</span><span class="op">,</span> <span class="str">"beta"</span><span class="op">,</span> <span class="nam">beta</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14597" href="#t14597">14597</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14598" href="#t14598">14598</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14599" href="#t14599">14599</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'add_position_encoding'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14600" href="#t14600">14600</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14601" href="#t14601">14601</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">"add_position_encoding"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14602" href="#t14602">14602</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14603" href="#t14603">14603</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14604" href="#t14604">14604</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14605" href="#t14605">14605</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14606" href="#t14606">14606</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14607" href="#t14607">14607</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14608" href="#t14608">14608</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"add_position_encoding"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14609" href="#t14609">14609</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14610" href="#t14610">14610</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14611" href="#t14611">14611</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">"alpha"</span><span class="op">:</span> <span class="nam">alpha</span><span class="op">,</span> <span class="str">"beta"</span><span class="op">:</span> <span class="nam">beta</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14612" href="#t14612">14612</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14613" href="#t14613">14613</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14614" href="#t14614">14614</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14615" href="#t14615">14615</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14616" href="#t14616">14616</a></span><span class="t"><span class="key">def</span> <span class="nam">bilinear_tensor_product</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14617" href="#t14617">14617</a></span><span class="t">    <span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">size</span><span class="op">,</span> <span class="nam">act</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">param_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">bias_attr</span><span class="op">=</span><span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14618" href="#t14618">14618</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14619" href="#t14619">14619</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14620" href="#t14620">14620</a></span><span class="t"><span class="str">    :api_attr: Static Graph</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14621" href="#t14621">14621</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14622" href="#t14622">14622</a></span><span class="t"><span class="str">    **Bilinear Tensor Product Layer**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14623" href="#t14623">14623</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14624" href="#t14624">14624</a></span><span class="t"><span class="str">    This layer performs bilinear tensor product on two inputs.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14625" href="#t14625">14625</a></span><span class="t"><span class="str">    For example:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14626" href="#t14626">14626</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14627" href="#t14627">14627</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14628" href="#t14628">14628</a></span><span class="t"><span class="str">       out_{i} = x * W_{i} * {y^\mathrm{T}}, i=0,1,...,size-1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14629" href="#t14629">14629</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14630" href="#t14630">14630</a></span><span class="t"><span class="str">    In this formula:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14631" href="#t14631">14631</a></span><span class="t"><span class="str">      - :math:`x`: the first input contains M elements, shape is [batch_size, M].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14632" href="#t14632">14632</a></span><span class="t"><span class="str">      - :math:`y`: the second input contains N elements, shape is [batch_size, N].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14633" href="#t14633">14633</a></span><span class="t"><span class="str">      - :math:`W_{i}`: the i-th learned weight, shape is [M, N].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14634" href="#t14634">14634</a></span><span class="t"><span class="str">      - :math:`out_{i}`: the i-th element of out, shape is [batch_size, size].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14635" href="#t14635">14635</a></span><span class="t"><span class="str">      - :math:`y^\mathrm{T}`: the transpose of :math:`y_{2}`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14636" href="#t14636">14636</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14637" href="#t14637">14637</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14638" href="#t14638">14638</a></span><span class="t"><span class="str">        x (Variable): 2-D input tensor with shape [batch_size, M]. Data type</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14639" href="#t14639">14639</a></span><span class="t"><span class="str">            is float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14640" href="#t14640">14640</a></span><span class="t"><span class="str">        y (Variable): 2-D input tensor with shape [batch_size, N]. Data type</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14641" href="#t14641">14641</a></span><span class="t"><span class="str">            should be same as **x**.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14642" href="#t14642">14642</a></span><span class="t"><span class="str">        size (int): The dimension of this layer.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14643" href="#t14643">14643</a></span><span class="t"><span class="str">        act (str|None): Activation to be applied to the output of this layer. Default None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14644" href="#t14644">14644</a></span><span class="t"><span class="str">        name(str|None): For detailed information, please refer to</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14645" href="#t14645">14645</a></span><span class="t"><span class="str">            :ref:`api_guide_Name` . Usually name is no need to set and None by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14646" href="#t14646">14646</a></span><span class="t"><span class="str">        param_attr (ParamAttr|None): To specify the weight parameter attribute.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14647" href="#t14647">14647</a></span><span class="t"><span class="str">            Default: None, which means the default weight parameter property is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14648" href="#t14648">14648</a></span><span class="t"><span class="str">            used. See usage for details in :ref:`api_fluid_ParamAttr` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14649" href="#t14649">14649</a></span><span class="t"><span class="str">        bias_attr (ParamAttr|None): To specify the bias parameter attribute.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14650" href="#t14650">14650</a></span><span class="t"><span class="str">            Default: None, which means the default bias parameter property is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14651" href="#t14651">14651</a></span><span class="t"><span class="str">            used. See usage for details in :ref:`api_fluid_ParamAttr` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14652" href="#t14652">14652</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14653" href="#t14653">14653</a></span><span class="t"><span class="str">        Variable: A 2-D Tensor of shape [batch_size, size]. Data type is the same as input **x**.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14654" href="#t14654">14654</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14655" href="#t14655">14655</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14656" href="#t14656">14656</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14657" href="#t14657">14657</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14658" href="#t14658">14658</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14659" href="#t14659">14659</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14660" href="#t14660">14660</a></span><span class="t"><span class="str">            layer1 = paddle.static.data("t1", shape=[-1, 5], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14661" href="#t14661">14661</a></span><span class="t"><span class="str">            layer2 = paddle.static.data("t2", shape=[-1, 4], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14662" href="#t14662">14662</a></span><span class="t"><span class="str">            tensor = paddle.static.nn.bilinear_tensor_product(x=layer1, y=layer2, size=1000)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14663" href="#t14663">14663</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14664" href="#t14664">14664</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'bilinear_tensor_product'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14665" href="#t14665">14665</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="str">'x'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14666" href="#t14666">14666</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14667" href="#t14667">14667</a></span><span class="t">    <span class="nam">param_shape</span> <span class="op">=</span> <span class="op">[</span><span class="nam">size</span><span class="op">,</span> <span class="nam">x</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">,</span> <span class="nam">y</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14668" href="#t14668">14668</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14669" href="#t14669">14669</a></span><span class="t">    <span class="nam">w</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14670" href="#t14670">14670</a></span><span class="t">        <span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">param_attr</span><span class="op">,</span> <span class="nam">shape</span><span class="op">=</span><span class="nam">param_shape</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">is_bias</span><span class="op">=</span><span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14671" href="#t14671">14671</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14672" href="#t14672">14672</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14673" href="#t14673">14673</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14674" href="#t14674">14674</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">x</span><span class="op">,</span> <span class="str">"Y"</span><span class="op">:</span> <span class="nam">y</span><span class="op">,</span> <span class="str">"Weight"</span><span class="op">:</span> <span class="nam">w</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14675" href="#t14675">14675</a></span><span class="t">    <span class="key">if</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">bias_attr</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14676" href="#t14676">14676</a></span><span class="t">        <span class="nam">bias_size</span> <span class="op">=</span> <span class="op">[</span><span class="num">1</span><span class="op">,</span> <span class="nam">size</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14677" href="#t14677">14677</a></span><span class="t">        <span class="nam">bias</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14678" href="#t14678">14678</a></span><span class="t">            <span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">bias_attr</span><span class="op">,</span> <span class="nam">shape</span><span class="op">=</span><span class="nam">bias_size</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">is_bias</span><span class="op">=</span><span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14679" href="#t14679">14679</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14680" href="#t14680">14680</a></span><span class="t">        <span class="nam">inputs</span><span class="op">[</span><span class="str">"Bias"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">bias</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14681" href="#t14681">14681</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14682" href="#t14682">14682</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"bilinear_tensor_product"</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14683" href="#t14683">14683</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14684" href="#t14684">14684</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14685" href="#t14685">14685</a></span><span class="t">    <span class="com"># add activation</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14686" href="#t14686">14686</a></span><span class="t">    <span class="key">return</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_activation</span><span class="op">(</span><span class="nam">out</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14687" href="#t14687">14687</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14688" href="#t14688">14688</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14689" href="#t14689">14689</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14690" href="#t14690">14690</a></span><span class="t"><span class="key">def</span> <span class="nam">get_tensor_from_selected_rows</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14691" href="#t14691">14691</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14692" href="#t14692">14692</a></span><span class="t"><span class="str">    This operator gets tensor data from input with SelectedRows type, and outputs a LoDTensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14693" href="#t14693">14693</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14694" href="#t14694">14694</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14695" href="#t14695">14695</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14696" href="#t14696">14696</a></span><span class="t"><span class="str">        input x is SelectedRows:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14697" href="#t14697">14697</a></span><span class="t"><span class="str">           x.rows = [0, 5, 5, 4, 19]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14698" href="#t14698">14698</a></span><span class="t"><span class="str">           x.height = 20</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14699" href="#t14699">14699</a></span><span class="t"><span class="str">           x.value = [[1, 1] [2, 2] [2, 2] [3, 3] [6, 6]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14700" href="#t14700">14700</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14701" href="#t14701">14701</a></span><span class="t"><span class="str">        Output is LoDTensor:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14702" href="#t14702">14702</a></span><span class="t"><span class="str">           out.shape = [5, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14703" href="#t14703">14703</a></span><span class="t"><span class="str">           out.data = [[1, 1],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14704" href="#t14704">14704</a></span><span class="t"><span class="str">                       [2, 2],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14705" href="#t14705">14705</a></span><span class="t"><span class="str">                       [2, 2],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14706" href="#t14706">14706</a></span><span class="t"><span class="str">                       [3, 3],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14707" href="#t14707">14707</a></span><span class="t"><span class="str">                       [6, 6]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14708" href="#t14708">14708</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14709" href="#t14709">14709</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14710" href="#t14710">14710</a></span><span class="t"><span class="str">        x(SelectedRows): Input with SelectedRows type. The data type is float32, float64, int32 or int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14711" href="#t14711">14711</a></span><span class="t"><span class="str">        name(str, optional): The default value is None.  Normally there is no need for user to set this property.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14712" href="#t14712">14712</a></span><span class="t"><span class="str">            For more information, please refer to :ref:`api_guide_Name` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14713" href="#t14713">14713</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14714" href="#t14714">14714</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14715" href="#t14715">14715</a></span><span class="t"><span class="str">        Variable: LoDTensor transformed from SelectedRows. The data type is same with input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14716" href="#t14716">14716</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14717" href="#t14717">14717</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14718" href="#t14718">14718</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14719" href="#t14719">14719</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14720" href="#t14720">14720</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14721" href="#t14721">14721</a></span><span class="t"><span class="str">            b = fluid.default_main_program().global_block()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14722" href="#t14722">14722</a></span><span class="t"><span class="str">            input = b.create_var(name="X", dtype="float32", persistable=True, type=fluid.core.VarDesc.VarType.SELECTED_ROWS)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14723" href="#t14723">14723</a></span><span class="t"><span class="str">            out = fluid.layers.get_tensor_from_selected_rows(input)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14724" href="#t14724">14724</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14725" href="#t14725">14725</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14726" href="#t14726">14726</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">,</span> <span class="str">'get_tensor_from_selected_rows'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14727" href="#t14727">14727</a></span><span class="t">    <span class="key">if</span> <span class="nam">x</span><span class="op">.</span><span class="nam">type</span> <span class="op">!=</span> <span class="nam">core</span><span class="op">.</span><span class="nam">VarDesc</span><span class="op">.</span><span class="nam">VarType</span><span class="op">.</span><span class="nam">SELECTED_ROWS</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14728" href="#t14728">14728</a></span><span class="t">        <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14729" href="#t14729">14729</a></span><span class="t">            <span class="str">"The type of 'x' in get_tensor_from_selected_rows must be SELECTED_ROWS."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14730" href="#t14730">14730</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14731" href="#t14731">14731</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'get_tensor_from_selected_rows'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14732" href="#t14732">14732</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14733" href="#t14733">14733</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14734" href="#t14734">14734</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'get_tensor_from_selected_rows'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14735" href="#t14735">14735</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14736" href="#t14736">14736</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14737" href="#t14737">14737</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14738" href="#t14738">14738</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14739" href="#t14739">14739</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14740" href="#t14740">14740</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14741" href="#t14741">14741</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14742" href="#t14742">14742</a></span><span class="t"><span class="key">def</span> <span class="nam">shuffle_channel</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">group</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14743" href="#t14743">14743</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14744" href="#t14744">14744</a></span><span class="t"><span class="str">    This operator shuffles the channels of input x.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14745" href="#t14745">14745</a></span><span class="t"><span class="str">    It divide the input channels in each group into :attr:`group` subgroups,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14746" href="#t14746">14746</a></span><span class="t"><span class="str">    and obtain a new order by selecting element from every subgroup one by one.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14747" href="#t14747">14747</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14748" href="#t14748">14748</a></span><span class="t"><span class="str">    Please refer to the paper</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14749" href="#t14749">14749</a></span><span class="t"><span class="str">    https://arxiv.org/pdf/1707.01083.pdf</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14750" href="#t14750">14750</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14751" href="#t14751">14751</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14752" href="#t14752">14752</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14753" href="#t14753">14753</a></span><span class="t"><span class="str">        Given a 4-D tensor input with the shape (N, C, H, W):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14754" href="#t14754">14754</a></span><span class="t"><span class="str">            input.shape = (1, 4, 2, 2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14755" href="#t14755">14755</a></span><span class="t"><span class="str">            input.data =[[[[0.1, 0.2],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14756" href="#t14756">14756</a></span><span class="t"><span class="str">                           [0.2, 0.3]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14757" href="#t14757">14757</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14758" href="#t14758">14758</a></span><span class="t"><span class="str">                          [[0.3, 0.4],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14759" href="#t14759">14759</a></span><span class="t"><span class="str">                           [0.4, 0.5]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14760" href="#t14760">14760</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14761" href="#t14761">14761</a></span><span class="t"><span class="str">                          [[0.5, 0.6],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14762" href="#t14762">14762</a></span><span class="t"><span class="str">                           [0.6, 0.7]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14763" href="#t14763">14763</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14764" href="#t14764">14764</a></span><span class="t"><span class="str">                          [[0.7, 0.8],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14765" href="#t14765">14765</a></span><span class="t"><span class="str">                           [0.8, 0.9]]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14766" href="#t14766">14766</a></span><span class="t"><span class="str">            Given group: 2</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14767" href="#t14767">14767</a></span><span class="t"><span class="str">            then we get a 4-D tensor out with the same shape of input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14768" href="#t14768">14768</a></span><span class="t"><span class="str">            out.shape = (1, 4, 2, 2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14769" href="#t14769">14769</a></span><span class="t"><span class="str">            out.data = [[[[0.1, 0.2],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14770" href="#t14770">14770</a></span><span class="t"><span class="str">                          [0.2, 0.3]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14771" href="#t14771">14771</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14772" href="#t14772">14772</a></span><span class="t"><span class="str">                         [[0.5, 0.6],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14773" href="#t14773">14773</a></span><span class="t"><span class="str">                          [0.6, 0.7]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14774" href="#t14774">14774</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14775" href="#t14775">14775</a></span><span class="t"><span class="str">                         [[0.3, 0.4],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14776" href="#t14776">14776</a></span><span class="t"><span class="str">                          [0.4, 0.5]],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14777" href="#t14777">14777</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14778" href="#t14778">14778</a></span><span class="t"><span class="str">                         [[0.7, 0.8],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14779" href="#t14779">14779</a></span><span class="t"><span class="str">                          [0.8, 0.9]]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14780" href="#t14780">14780</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14781" href="#t14781">14781</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14782" href="#t14782">14782</a></span><span class="t"><span class="str">        x(Variable): The input tensor variable. It should be a 4-D tensor with shape [N, C, H, W]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14783" href="#t14783">14783</a></span><span class="t"><span class="str">        group(int): Indicating the counts of subgroups, It should divide the number of channels.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14784" href="#t14784">14784</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14785" href="#t14785">14785</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14786" href="#t14786">14786</a></span><span class="t"><span class="str">        out(Variable): the channels shuffling result is a tensor variable with the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14787" href="#t14787">14787</a></span><span class="t"><span class="str">        same shape and same type as the input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14788" href="#t14788">14788</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14789" href="#t14789">14789</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14790" href="#t14790">14790</a></span><span class="t"><span class="str">        ValueError: If group is not an int type variable.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14791" href="#t14791">14791</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14792" href="#t14792">14792</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14793" href="#t14793">14793</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14794" href="#t14794">14794</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14795" href="#t14795">14795</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14796" href="#t14796">14796</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14797" href="#t14797">14797</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14798" href="#t14798">14798</a></span><span class="t"><span class="str">            input = fluid.data(name='input', shape=[None,4,2,2], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14799" href="#t14799">14799</a></span><span class="t"><span class="str">            out = fluid.layers.shuffle_channel(x=input, group=2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14800" href="#t14800">14800</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14801" href="#t14801">14801</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"shuffle_channel"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14802" href="#t14802">14802</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14803" href="#t14803">14803</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14804" href="#t14804">14804</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14805" href="#t14805">14805</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">group</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14806" href="#t14806">14806</a></span><span class="t">        <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span><span class="str">"group must be int type"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14807" href="#t14807">14807</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14808" href="#t14808">14808</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14809" href="#t14809">14809</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"shuffle_channel"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14810" href="#t14810">14810</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14811" href="#t14811">14811</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14812" href="#t14812">14812</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">"group"</span><span class="op">:</span> <span class="nam">group</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14813" href="#t14813">14813</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14814" href="#t14814">14814</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14815" href="#t14815">14815</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14816" href="#t14816">14816</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14817" href="#t14817">14817</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14818" href="#t14818">14818</a></span><span class="t"><span class="key">def</span> <span class="nam">temporal_shift</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">seg_num</span><span class="op">,</span> <span class="nam">shift_ratio</span><span class="op">=</span><span class="num">0.25</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">data_format</span><span class="op">=</span><span class="str">"NCHW"</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14819" href="#t14819">14819</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14820" href="#t14820">14820</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14821" href="#t14821">14821</a></span><span class="t"><span class="str">    **Temporal Shift Operator**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14822" href="#t14822">14822</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14823" href="#t14823">14823</a></span><span class="t"><span class="str">    ${comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14824" href="#t14824">14824</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14825" href="#t14825">14825</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14826" href="#t14826">14826</a></span><span class="t"><span class="str">        x(Tensor): ${x_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14827" href="#t14827">14827</a></span><span class="t"><span class="str">        seg_num(int): ${seg_num_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14828" href="#t14828">14828</a></span><span class="t"><span class="str">        shift_ratio(float): ${shift_ratio_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14829" href="#t14829">14829</a></span><span class="t"><span class="str">        name(str, optional): For detailed information, please refer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14830" href="#t14830">14830</a></span><span class="t"><span class="str">                             to :ref:`api_guide_Name`. Usually name is no need to set and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14831" href="#t14831">14831</a></span><span class="t"><span class="str">                             None by default.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14832" href="#t14832">14832</a></span><span class="t"><span class="str">        data_format(str, optional): Data format that specifies the layout of input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14833" href="#t14833">14833</a></span><span class="t"><span class="str">            It can be "NCHW" or "NHWC". Default: "NCHW".</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14834" href="#t14834">14834</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14835" href="#t14835">14835</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14836" href="#t14836">14836</a></span><span class="t"><span class="str">        out(Tensor): The temporal shifting result is a tensor with the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14837" href="#t14837">14837</a></span><span class="t"><span class="str">        same shape and same data type as the input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14838" href="#t14838">14838</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14839" href="#t14839">14839</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14840" href="#t14840">14840</a></span><span class="t"><span class="str">        TypeError: seg_num must be int type.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14841" href="#t14841">14841</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14842" href="#t14842">14842</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14843" href="#t14843">14843</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14844" href="#t14844">14844</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14845" href="#t14845">14845</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14846" href="#t14846">14846</a></span><span class="t"><span class="str">            import paddle.nn.functional as F</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14847" href="#t14847">14847</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14848" href="#t14848">14848</a></span><span class="t"><span class="str">            input = paddle.randn([6, 4, 2, 2])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14849" href="#t14849">14849</a></span><span class="t"><span class="str">            out = F.temporal_shift(x=input, seg_num=2, shift_ratio=0.2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14850" href="#t14850">14850</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14851" href="#t14851">14851</a></span><span class="t">    <span class="key">return</span> <span class="nam">paddle</span><span class="op">.</span><span class="nam">nn</span><span class="op">.</span><span class="nam">functional</span><span class="op">.</span><span class="nam">temporal_shift</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14852" href="#t14852">14852</a></span><span class="t">        <span class="nam">x</span><span class="op">,</span> <span class="nam">seg_num</span><span class="op">,</span> <span class="nam">shift_ratio</span><span class="op">,</span> <span class="nam">name</span><span class="op">,</span> <span class="nam">data_format</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14853" href="#t14853">14853</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14854" href="#t14854">14854</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14855" href="#t14855">14855</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14856" href="#t14856">14856</a></span><span class="t"><span class="key">class</span> <span class="nam">PyFuncRegistry</span><span class="op">(</span><span class="nam">object</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14857" href="#t14857">14857</a></span><span class="t">    <span class="nam">_register_funcs</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14858" href="#t14858">14858</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14859" href="#t14859">14859</a></span><span class="t">    <span class="key">def</span> <span class="nam">__init__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">func</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t14860" href="#t14860">14860</a></span><span class="t">        <span class="key">if</span> <span class="nam">func</span> <span class="key">is</span> <span class="key">None</span> <span class="key">or</span> <span class="key">not</span> <span class="nam">callable</span><span class="op">(</span><span class="nam">func</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">14860&#x202F;&#x219B;&#x202F;14863</span><span class="annotate long">line 14860 didn't jump to line 14863, because the condition on line 14860 was never false</span></span></p>
    <p class="run"><span class="n"><a id="t14861" href="#t14861">14861</a></span><span class="t">            <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span><span class="str">'func must be a Python function'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14862" href="#t14862">14862</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14863" href="#t14863">14863</a></span><span class="t">        <span class="nam">self</span><span class="op">.</span><span class="nam">_func</span> <span class="op">=</span> <span class="nam">func</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14864" href="#t14864">14864</a></span><span class="t">        <span class="com"># find named args using reflection</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14865" href="#t14865">14865</a></span><span class="t">        <span class="nam">args</span> <span class="op">=</span> <span class="nam">inspect</span><span class="op">.</span><span class="nam">getargspec</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">_func</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14866" href="#t14866">14866</a></span><span class="t">        <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">args</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">)</span> <span class="op">==</span> <span class="num">0</span> <span class="key">and</span> <span class="nam">args</span><span class="op">[</span><span class="num">1</span><span class="op">]</span> <span class="key">is</span> <span class="key">None</span> <span class="key">and</span> <span class="nam">args</span><span class="op">[</span><span class="num">2</span><span class="op">]</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14867" href="#t14867">14867</a></span><span class="t">            <span class="com"># Function with no inputs</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14868" href="#t14868">14868</a></span><span class="t">            <span class="nam">self</span><span class="op">.</span><span class="nam">_named_args</span> <span class="op">=</span> <span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14869" href="#t14869">14869</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14870" href="#t14870">14870</a></span><span class="t">            <span class="nam">self</span><span class="op">.</span><span class="nam">_named_args</span> <span class="op">=</span> <span class="nam">args</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14871" href="#t14871">14871</a></span><span class="t">        <span class="nam">self</span><span class="op">.</span><span class="nam">_id</span> <span class="op">=</span> <span class="nam">core</span><span class="op">.</span><span class="nam">_append_python_callable_object_and_return_id</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14872" href="#t14872">14872</a></span><span class="t">        <span class="str">'''</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14873" href="#t14873">14873</a></span><span class="t"><span class="str">        Why record self here?</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14874" href="#t14874">14874</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14875" href="#t14875">14875</a></span><span class="t"><span class="str">        1. For debug usage. Users can call</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14876" href="#t14876">14876</a></span><span class="t"><span class="str">           :code:`py_func.registered_func(idx)` method</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14877" href="#t14877">14877</a></span><span class="t"><span class="str">           to find the registered function corresponding</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14878" href="#t14878">14878</a></span><span class="t"><span class="str">           to :code:`idx`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14879" href="#t14879">14879</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14880" href="#t14880">14880</a></span><span class="t"><span class="str">        2. For increasing reference count of self.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14881" href="#t14881">14881</a></span><span class="t"><span class="str">           It seems that to release Python object</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14882" href="#t14882">14882</a></span><span class="t"><span class="str">           whose reference count is 1 would cause</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14883" href="#t14883">14883</a></span><span class="t"><span class="str">           segmentation fault error in C++ side.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14884" href="#t14884">14884</a></span><span class="t"><span class="str">           May be lack of Python GC in C++ side?</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14885" href="#t14885">14885</a></span><span class="t"><span class="str">        '''</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14886" href="#t14886">14886</a></span><span class="t">        <span class="nam">PyFuncRegistry</span><span class="op">.</span><span class="nam">_register_funcs</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14887" href="#t14887">14887</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14888" href="#t14888">14888</a></span><span class="t">    <span class="op">@</span><span class="nam">classmethod</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14889" href="#t14889">14889</a></span><span class="t">    <span class="key">def</span> <span class="nam">registered_func</span><span class="op">(</span><span class="nam">cls</span><span class="op">,</span> <span class="nam">idx</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14890" href="#t14890">14890</a></span><span class="t">        <span class="key">return</span> <span class="nam">cls</span><span class="op">.</span><span class="nam">_register_funcs</span><span class="op">[</span><span class="nam">idx</span><span class="op">]</span><span class="op">.</span><span class="nam">_func</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14891" href="#t14891">14891</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14892" href="#t14892">14892</a></span><span class="t">    <span class="op">@</span><span class="nam">classmethod</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14893" href="#t14893">14893</a></span><span class="t">    <span class="key">def</span> <span class="nam">registered_func_num</span><span class="op">(</span><span class="nam">cls</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14894" href="#t14894">14894</a></span><span class="t">        <span class="key">return</span> <span class="nam">len</span><span class="op">(</span><span class="nam">cls</span><span class="op">.</span><span class="nam">_register_funcs</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14895" href="#t14895">14895</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14896" href="#t14896">14896</a></span><span class="t">    <span class="op">@</span><span class="nam">property</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14897" href="#t14897">14897</a></span><span class="t">    <span class="key">def</span> <span class="nam">id</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14898" href="#t14898">14898</a></span><span class="t">        <span class="key">return</span> <span class="nam">self</span><span class="op">.</span><span class="nam">_id</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14899" href="#t14899">14899</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14900" href="#t14900">14900</a></span><span class="t">    <span class="key">def</span> <span class="nam">__call__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="op">*</span><span class="nam">args</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14901" href="#t14901">14901</a></span><span class="t">        <span class="key">if</span> <span class="nam">self</span><span class="op">.</span><span class="nam">_named_args</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14902" href="#t14902">14902</a></span><span class="t">            <span class="nam">func_ret</span> <span class="op">=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">_func</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14903" href="#t14903">14903</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14904" href="#t14904">14904</a></span><span class="t">            <span class="nam">kwargs</span> <span class="op">=</span> <span class="nam">dict</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14905" href="#t14905">14905</a></span><span class="t">            <span class="nam">idx</span> <span class="op">=</span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14906" href="#t14906">14906</a></span><span class="t">            <span class="key">for</span> <span class="nam">arg</span> <span class="key">in</span> <span class="nam">self</span><span class="op">.</span><span class="nam">_named_args</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14907" href="#t14907">14907</a></span><span class="t">                <span class="nam">kwargs</span><span class="op">[</span><span class="nam">arg</span><span class="op">]</span> <span class="op">=</span> <span class="nam">args</span><span class="op">[</span><span class="nam">idx</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14908" href="#t14908">14908</a></span><span class="t">                <span class="nam">idx</span> <span class="op">+=</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14909" href="#t14909">14909</a></span><span class="t">            <span class="nam">func_ret</span> <span class="op">=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">_func</span><span class="op">(</span><span class="op">*</span><span class="nam">args</span><span class="op">[</span><span class="nam">idx</span><span class="op">:</span><span class="op">]</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14910" href="#t14910">14910</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14911" href="#t14911">14911</a></span><span class="t">        <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">func_ret</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14912" href="#t14912">14912</a></span><span class="t">            <span class="nam">func_ret</span> <span class="op">=</span> <span class="op">(</span><span class="nam">func_ret</span><span class="op">,</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14913" href="#t14913">14913</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14914" href="#t14914">14914</a></span><span class="t">        <span class="nam">ret</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14915" href="#t14915">14915</a></span><span class="t">        <span class="key">for</span> <span class="nam">each_ret</span> <span class="key">in</span> <span class="nam">func_ret</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14916" href="#t14916">14916</a></span><span class="t">            <span class="key">if</span> <span class="nam">each_ret</span> <span class="key">is</span> <span class="key">None</span> <span class="key">or</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">each_ret</span><span class="op">,</span> <span class="nam">core</span><span class="op">.</span><span class="nam">LoDTensor</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14917" href="#t14917">14917</a></span><span class="t">                <span class="nam">ret</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">each_ret</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14918" href="#t14918">14918</a></span><span class="t">                <span class="key">continue</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14919" href="#t14919">14919</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14920" href="#t14920">14920</a></span><span class="t">            <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">each_ret</span><span class="op">,</span> <span class="nam">np</span><span class="op">.</span><span class="nam">ndarray</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14921" href="#t14921">14921</a></span><span class="t">                <span class="nam">each_ret</span> <span class="op">=</span> <span class="nam">np</span><span class="op">.</span><span class="nam">array</span><span class="op">(</span><span class="nam">each_ret</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14922" href="#t14922">14922</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14923" href="#t14923">14923</a></span><span class="t">            <span class="nam">tensor</span> <span class="op">=</span> <span class="nam">core</span><span class="op">.</span><span class="nam">LoDTensor</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14924" href="#t14924">14924</a></span><span class="t">            <span class="nam">tensor</span><span class="op">.</span><span class="nam">set</span><span class="op">(</span><span class="nam">each_ret</span><span class="op">,</span> <span class="nam">core</span><span class="op">.</span><span class="nam">CPUPlace</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14925" href="#t14925">14925</a></span><span class="t">            <span class="nam">ret</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">tensor</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14926" href="#t14926">14926</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t14927" href="#t14927">14927</a></span><span class="t">        <span class="key">return</span> <span class="nam">tuple</span><span class="op">(</span><span class="nam">ret</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14928" href="#t14928">14928</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14929" href="#t14929">14929</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14930" href="#t14930">14930</a></span><span class="t"><span class="op">@</span><span class="nam">static_only</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14931" href="#t14931">14931</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14932" href="#t14932">14932</a></span><span class="t"><span class="key">def</span> <span class="nam">py_func</span><span class="op">(</span><span class="nam">func</span><span class="op">,</span> <span class="nam">x</span><span class="op">,</span> <span class="nam">out</span><span class="op">,</span> <span class="nam">backward_func</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">skip_vars_in_backward_input</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14933" href="#t14933">14933</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14934" href="#t14934">14934</a></span><span class="t"><span class="str">    :api_attr: Static Graph</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14935" href="#t14935">14935</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14936" href="#t14936">14936</a></span><span class="t"><span class="str">    This OP is used to register customized Python OP to Paddle. The design</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14937" href="#t14937">14937</a></span><span class="t"><span class="str">    principe of py_func is that Tensor and numpy array can be converted to each</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14938" href="#t14938">14938</a></span><span class="t"><span class="str">    other easily. So you can use Python and numpy API to register a python OP.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14939" href="#t14939">14939</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14940" href="#t14940">14940</a></span><span class="t"><span class="str">    The forward function of the registered OP is ``func`` and the backward function</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14941" href="#t14941">14941</a></span><span class="t"><span class="str">    of that is ``backward_func``. Paddle will call ``func`` at forward runtime and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14942" href="#t14942">14942</a></span><span class="t"><span class="str">    call ``backward_func`` at backward runtime(if ``backward_func`` is not  None).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14943" href="#t14943">14943</a></span><span class="t"><span class="str">    ``x`` is the input of ``func``, whose type must be Tensor; ``out`` is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14944" href="#t14944">14944</a></span><span class="t"><span class="str">    the output of ``func``, whose type can be either Tensor or numpy array.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14945" href="#t14945">14945</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14946" href="#t14946">14946</a></span><span class="t"><span class="str">    The input of the backward function ``backward_func`` is ``x``, ``out`` and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14947" href="#t14947">14947</a></span><span class="t"><span class="str">    the gradient of ``out``. If ``out`` have no gradient, the relevant input of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14948" href="#t14948">14948</a></span><span class="t"><span class="str">    ``backward_func`` is None. If ``x`` do not have a gradient, the user should</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14949" href="#t14949">14949</a></span><span class="t"><span class="str">    return None in ``backward_func``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14950" href="#t14950">14950</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14951" href="#t14951">14951</a></span><span class="t"><span class="str">    The data type and shape of ``out`` should also be set correctly before this</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14952" href="#t14952">14952</a></span><span class="t"><span class="str">    API is called, and the data type and shape of the gradient of ``out`` and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14953" href="#t14953">14953</a></span><span class="t"><span class="str">    ``x`` will be inferred automatically.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14954" href="#t14954">14954</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14955" href="#t14955">14955</a></span><span class="t"><span class="str">    This API can also be used to debug the neural network by setting the ``func``</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14956" href="#t14956">14956</a></span><span class="t"><span class="str">    as a function that only print variables.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14957" href="#t14957">14957</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14958" href="#t14958">14958</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14959" href="#t14959">14959</a></span><span class="t"><span class="str">        func (callable): The forward function of the registered OP. When the network</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14960" href="#t14960">14960</a></span><span class="t"><span class="str">            is running, the forward output ``out`` will be calculated according to this</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14961" href="#t14961">14961</a></span><span class="t"><span class="str">            function and the forward input ``x``. In ``func`` , it's suggested that we</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14962" href="#t14962">14962</a></span><span class="t"><span class="str">            actively convert Tensor into a numpy array, so that we can use Python and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14963" href="#t14963">14963</a></span><span class="t"><span class="str">            numpy API arbitrarily. If not, some operations of numpy may not be compatible.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14964" href="#t14964">14964</a></span><span class="t"><span class="str">        x (Tensor|tuple(Tensor)|list[Tensor]): The input of the forward function ``func``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14965" href="#t14965">14965</a></span><span class="t"><span class="str">            It can be Tensor|tuple(Tensor)|list[Tensor]. In addition, Multiple Tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14966" href="#t14966">14966</a></span><span class="t"><span class="str">            should be passed in the form of tuple(Tensor) or list[Tensor].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14967" href="#t14967">14967</a></span><span class="t"><span class="str">        out (T|tuple(T)|list[T]): The output of the forward function ``func``, it can be</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14968" href="#t14968">14968</a></span><span class="t"><span class="str">            T|tuple(T)|list[T], where T can be either Tensor or numpy array. Since Paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14969" href="#t14969">14969</a></span><span class="t"><span class="str">            cannot automatically infer the shape and type of ``out``, you must create</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14970" href="#t14970">14970</a></span><span class="t"><span class="str">            ``out`` in advance.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14971" href="#t14971">14971</a></span><span class="t"><span class="str">        backward_func (callable, optional): The backward function of the registered OP.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14972" href="#t14972">14972</a></span><span class="t"><span class="str">            Its default value is None, which means there is no reverse calculation. If</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14973" href="#t14973">14973</a></span><span class="t"><span class="str">            it is not None, ``backward_func`` is called to calculate the gradient of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14974" href="#t14974">14974</a></span><span class="t"><span class="str">            ``x`` when the network is at backward runtime.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14975" href="#t14975">14975</a></span><span class="t"><span class="str">        skip_vars_in_backward_input (Tensor, optional): It's used to limit the input</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14976" href="#t14976">14976</a></span><span class="t"><span class="str">            list of ``backward_func``, and it can be Tensor|tuple(Tensor)|list[Tensor].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14977" href="#t14977">14977</a></span><span class="t"><span class="str">            It must belong to either ``x`` or ``out``. The default  value is None, which means</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14978" href="#t14978">14978</a></span><span class="t"><span class="str">            that no tensors need to be removed from ``x`` and ``out``. If it is not None,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14979" href="#t14979">14979</a></span><span class="t"><span class="str">            these tensors will not be the input of ``backward_func``. This parameter is only</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14980" href="#t14980">14980</a></span><span class="t"><span class="str">            useful when ``backward_func`` is not None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14981" href="#t14981">14981</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14982" href="#t14982">14982</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14983" href="#t14983">14983</a></span><span class="t"><span class="str">        Tensor|tuple(Tensor)|list[Tensor]: The output ``out`` of the forward function ``func``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14984" href="#t14984">14984</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14985" href="#t14985">14985</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14986" href="#t14986">14986</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14987" href="#t14987">14987</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14988" href="#t14988">14988</a></span><span class="t"><span class="str">            # example 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14989" href="#t14989">14989</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14990" href="#t14990">14990</a></span><span class="t"><span class="str">            import six</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14991" href="#t14991">14991</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14992" href="#t14992">14992</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14993" href="#t14993">14993</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14994" href="#t14994">14994</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14995" href="#t14995">14995</a></span><span class="t"><span class="str">            # Creates a forward function, Tensor can be input directly without</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14996" href="#t14996">14996</a></span><span class="t"><span class="str">            # being converted into numpy array.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14997" href="#t14997">14997</a></span><span class="t"><span class="str">            def tanh(x):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14998" href="#t14998">14998</a></span><span class="t"><span class="str">                return np.tanh(x)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t14999" href="#t14999">14999</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15000" href="#t15000">15000</a></span><span class="t"><span class="str">            # Skip x in backward function and return the gradient of x</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15001" href="#t15001">15001</a></span><span class="t"><span class="str">            # Tensor must be actively converted to numpy array, otherwise,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15002" href="#t15002">15002</a></span><span class="t"><span class="str">            # operations such as +/- can't be used.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15003" href="#t15003">15003</a></span><span class="t"><span class="str">            def tanh_grad(y, dy):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15004" href="#t15004">15004</a></span><span class="t"><span class="str">                return np.array(dy) * (1 - np.square(np.array(y)))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15005" href="#t15005">15005</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15006" href="#t15006">15006</a></span><span class="t"><span class="str">            # Creates a forward function for debugging running networks(print value)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15007" href="#t15007">15007</a></span><span class="t"><span class="str">            def debug_func(x):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15008" href="#t15008">15008</a></span><span class="t"><span class="str">                print(x)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15009" href="#t15009">15009</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15010" href="#t15010">15010</a></span><span class="t"><span class="str">            def create_tmp_var(name, dtype, shape):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15011" href="#t15011">15011</a></span><span class="t"><span class="str">                return paddle.static.default_main_program().current_block().create_var(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15012" href="#t15012">15012</a></span><span class="t"><span class="str">                    name=name, dtype=dtype, shape=shape)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15013" href="#t15013">15013</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15014" href="#t15014">15014</a></span><span class="t"><span class="str">            def simple_net(img, label):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15015" href="#t15015">15015</a></span><span class="t"><span class="str">                hidden = img</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15016" href="#t15016">15016</a></span><span class="t"><span class="str">                for idx in six.moves.range(4):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15017" href="#t15017">15017</a></span><span class="t"><span class="str">                    hidden = paddle.static.nn.fc(hidden, size=200)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15018" href="#t15018">15018</a></span><span class="t"><span class="str">                    new_hidden = create_tmp_var(name='hidden_{}'.format(idx),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15019" href="#t15019">15019</a></span><span class="t"><span class="str">                        dtype=hidden.dtype, shape=hidden.shape)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15020" href="#t15020">15020</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15021" href="#t15021">15021</a></span><span class="t"><span class="str">                    # User-defined forward and backward</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15022" href="#t15022">15022</a></span><span class="t"><span class="str">                    hidden = paddle.static.py_func(func=tanh, x=hidden,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15023" href="#t15023">15023</a></span><span class="t"><span class="str">                        out=new_hidden, backward_func=tanh_grad,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15024" href="#t15024">15024</a></span><span class="t"><span class="str">                        skip_vars_in_backward_input=hidden)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15025" href="#t15025">15025</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15026" href="#t15026">15026</a></span><span class="t"><span class="str">                    # User-defined debug functions that print out the input Tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15027" href="#t15027">15027</a></span><span class="t"><span class="str">                    paddle.static.py_func(func=debug_func, x=hidden, out=None)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15028" href="#t15028">15028</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15029" href="#t15029">15029</a></span><span class="t"><span class="str">                prediction = paddle.static.nn.fc(hidden, size=10, activation='softmax')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15030" href="#t15030">15030</a></span><span class="t"><span class="str">                ce_loss = paddle.nn.loss.CrossEntropyLoss()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15031" href="#t15031">15031</a></span><span class="t"><span class="str">                return ce_loss(prediction, label)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15032" href="#t15032">15032</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15033" href="#t15033">15033</a></span><span class="t"><span class="str">            x = paddle.static.data(name='x', shape=[1,4], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15034" href="#t15034">15034</a></span><span class="t"><span class="str">            y = paddle.static.data(name='y', shape=[1,10], dtype='int64')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15035" href="#t15035">15035</a></span><span class="t"><span class="str">            res = simple_net(x, y)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15036" href="#t15036">15036</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15037" href="#t15037">15037</a></span><span class="t"><span class="str">            exe = paddle.static.Executor(paddle.CPUPlace())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15038" href="#t15038">15038</a></span><span class="t"><span class="str">            exe.run(paddle.static.default_startup_program())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15039" href="#t15039">15039</a></span><span class="t"><span class="str">            input1 = np.random.random(size=[1,4]).astype('float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15040" href="#t15040">15040</a></span><span class="t"><span class="str">            input2 = np.random.randint(1, 10, size=[1,10], dtype='int64')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15041" href="#t15041">15041</a></span><span class="t"><span class="str">            out = exe.run(paddle.static.default_main_program(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15042" href="#t15042">15042</a></span><span class="t"><span class="str">                          feed={'x':input1, 'y':input2},</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15043" href="#t15043">15043</a></span><span class="t"><span class="str">                          fetch_list=[res.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15044" href="#t15044">15044</a></span><span class="t"><span class="str">            print(out)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15045" href="#t15045">15045</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15046" href="#t15046">15046</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15047" href="#t15047">15047</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15048" href="#t15048">15048</a></span><span class="t"><span class="str">            # example 2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15049" href="#t15049">15049</a></span><span class="t"><span class="str">            # This example shows how to turn Tensor into numpy array and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15050" href="#t15050">15050</a></span><span class="t"><span class="str">            # use numpy API to register an Python OP</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15051" href="#t15051">15051</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15052" href="#t15052">15052</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15053" href="#t15053">15053</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15054" href="#t15054">15054</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15055" href="#t15055">15055</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15056" href="#t15056">15056</a></span><span class="t"><span class="str">            def element_wise_add(x, y):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15057" href="#t15057">15057</a></span><span class="t"><span class="str">                # Tensor must be actively converted to numpy array, otherwise,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15058" href="#t15058">15058</a></span><span class="t"><span class="str">                # numpy.shape can't be used.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15059" href="#t15059">15059</a></span><span class="t"><span class="str">                x = np.array(x)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15060" href="#t15060">15060</a></span><span class="t"><span class="str">                y = np.array(y)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15061" href="#t15061">15061</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15062" href="#t15062">15062</a></span><span class="t"><span class="str">                if x.shape != y.shape:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15063" href="#t15063">15063</a></span><span class="t"><span class="str">                    raise AssertionError("the shape of inputs must be the same!")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15064" href="#t15064">15064</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15065" href="#t15065">15065</a></span><span class="t"><span class="str">                result = np.zeros(x.shape, dtype='int32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15066" href="#t15066">15066</a></span><span class="t"><span class="str">                for i in range(len(x)):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15067" href="#t15067">15067</a></span><span class="t"><span class="str">                    for j in range(len(x[0])):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15068" href="#t15068">15068</a></span><span class="t"><span class="str">                        result[i][j] = x[i][j] + y[i][j]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15069" href="#t15069">15069</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15070" href="#t15070">15070</a></span><span class="t"><span class="str">                return result</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15071" href="#t15071">15071</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15072" href="#t15072">15072</a></span><span class="t"><span class="str">            def create_tmp_var(name, dtype, shape):</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15073" href="#t15073">15073</a></span><span class="t"><span class="str">                return paddle.static.default_main_program().current_block().create_var(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15074" href="#t15074">15074</a></span><span class="t"><span class="str">                            name=name, dtype=dtype, shape=shape)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15075" href="#t15075">15075</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15076" href="#t15076">15076</a></span><span class="t"><span class="str">            def py_func_demo():</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15077" href="#t15077">15077</a></span><span class="t"><span class="str">                start_program = paddle.static.default_startup_program()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15078" href="#t15078">15078</a></span><span class="t"><span class="str">                main_program = paddle.static.default_main_program()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15079" href="#t15079">15079</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15080" href="#t15080">15080</a></span><span class="t"><span class="str">                # Input of the forward function</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15081" href="#t15081">15081</a></span><span class="t"><span class="str">                x = paddle.static.data(name='x', shape=[2,3], dtype='int32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15082" href="#t15082">15082</a></span><span class="t"><span class="str">                y = paddle.static.data(name='y', shape=[2,3], dtype='int32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15083" href="#t15083">15083</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15084" href="#t15084">15084</a></span><span class="t"><span class="str">                # Output of the forward function, name/dtype/shape must be specified</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15085" href="#t15085">15085</a></span><span class="t"><span class="str">                output = create_tmp_var('output','int32', [3,1])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15086" href="#t15086">15086</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15087" href="#t15087">15087</a></span><span class="t"><span class="str">                # Multiple Variable should be passed in the form of tuple(Variale) or list[Variale]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15088" href="#t15088">15088</a></span><span class="t"><span class="str">                paddle.static.py_func(func=element_wise_add, x=[x,y], out=output)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15089" href="#t15089">15089</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15090" href="#t15090">15090</a></span><span class="t"><span class="str">                exe=paddle.static.Executor(paddle.CPUPlace())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15091" href="#t15091">15091</a></span><span class="t"><span class="str">                exe.run(start_program)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15092" href="#t15092">15092</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15093" href="#t15093">15093</a></span><span class="t"><span class="str">                # Feed numpy array to main_program</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15094" href="#t15094">15094</a></span><span class="t"><span class="str">                input1 = np.random.randint(1, 10, size=[2,3], dtype='int32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15095" href="#t15095">15095</a></span><span class="t"><span class="str">                input2 = np.random.randint(1, 10, size=[2,3], dtype='int32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15096" href="#t15096">15096</a></span><span class="t"><span class="str">                out = exe.run(main_program,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15097" href="#t15097">15097</a></span><span class="t"><span class="str">                            feed={'x':input1, 'y':input2},</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15098" href="#t15098">15098</a></span><span class="t"><span class="str">                            fetch_list=[output.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15099" href="#t15099">15099</a></span><span class="t"><span class="str">                print("{0} + {1} = {2}".format(input1, input2, out))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15100" href="#t15100">15100</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15101" href="#t15101">15101</a></span><span class="t"><span class="str">            py_func_demo()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15102" href="#t15102">15102</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15103" href="#t15103">15103</a></span><span class="t"><span class="str">            # Reference output:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15104" href="#t15104">15104</a></span><span class="t"><span class="str">            # [[5, 9, 9]   + [[7, 8, 4]  =  [array([[12, 17, 13]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15105" href="#t15105">15105</a></span><span class="t"><span class="str">            #  [7, 5, 2]]     [1, 3, 3]]            [8, 8, 5]], dtype=int32)]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15106" href="#t15106">15106</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t15107" href="#t15107">15107</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'py_func'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t15108" href="#t15108">15108</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'X'</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">,</span> <span class="nam">type</span><span class="op">(</span><span class="key">None</span><span class="op">)</span><span class="op">)</span><span class="op">,</span> <span class="str">'py_func'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t15109" href="#t15109">15109</a></span><span class="t">    <span class="key">if</span> <span class="nam">x</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">15109&#x202F;&#x219B;&#x202F;15110</span><span class="annotate long">line 15109 didn't jump to line 15110, because the condition on line 15109 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15110" href="#t15110">15110</a></span><span class="t">        <span class="nam">x</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t15111" href="#t15111">15111</a></span><span class="t">    <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">15111&#x202F;&#x219B;&#x202F;15113</span><span class="annotate long">line 15111 didn't jump to line 15113, because the condition on line 15111 was never false</span></span></p>
    <p class="run"><span class="n"><a id="t15112" href="#t15112">15112</a></span><span class="t">        <span class="nam">x</span> <span class="op">=</span> <span class="op">[</span><span class="nam">x</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15113" href="#t15113">15113</a></span><span class="t">    <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15114" href="#t15114">15114</a></span><span class="t">        <span class="nam">x</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15115" href="#t15115">15115</a></span><span class="t">    <span class="key">elif</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15116" href="#t15116">15116</a></span><span class="t">        <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span><span class="str">'Input must be Variable/list(Variable)/tuple(Variable)'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t15117" href="#t15117">15117</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">out</span><span class="op">,</span> <span class="str">'Out'</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">,</span> <span class="nam">type</span><span class="op">(</span><span class="key">None</span><span class="op">)</span><span class="op">)</span><span class="op">,</span> <span class="str">'py_func'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t15118" href="#t15118">15118</a></span><span class="t">    <span class="key">if</span> <span class="nam">out</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t15119" href="#t15119">15119</a></span><span class="t">        <span class="nam">out_list</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t15120" href="#t15120">15120</a></span><span class="t">    <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">out</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">15120&#x202F;&#x219B;&#x202F;15122</span><span class="annotate long">line 15120 didn't jump to line 15122, because the condition on line 15120 was never false</span></span></p>
    <p class="run"><span class="n"><a id="t15121" href="#t15121">15121</a></span><span class="t">        <span class="nam">out_list</span> <span class="op">=</span> <span class="op">[</span><span class="nam">out</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15122" href="#t15122">15122</a></span><span class="t">    <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">out</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15123" href="#t15123">15123</a></span><span class="t">        <span class="nam">out_list</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="nam">out</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15124" href="#t15124">15124</a></span><span class="t">    <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">out</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15125" href="#t15125">15125</a></span><span class="t">        <span class="nam">out_list</span> <span class="op">=</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15126" href="#t15126">15126</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15127" href="#t15127">15127</a></span><span class="t">        <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15128" href="#t15128">15128</a></span><span class="t">            <span class="str">'Output must be Variable/list(Variable)/tuple(Variable)'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15129" href="#t15129">15129</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15130" href="#t15130">15130</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t15131" href="#t15131">15131</a></span><span class="t">    <span class="nam">fwd_func_id</span> <span class="op">=</span> <span class="nam">PyFuncRegistry</span><span class="op">(</span><span class="nam">func</span><span class="op">)</span><span class="op">.</span><span class="nam">id</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15132" href="#t15132">15132</a></span><span class="t">    <span class="nam">bwd_func_id</span> <span class="op">=</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15133" href="#t15133">15133</a></span><span class="t">        <span class="nam">PyFuncRegistry</span><span class="op">(</span><span class="nam">backward_func</span><span class="op">)</span><span class="op">.</span><span class="nam">id</span> <span class="key">if</span> <span class="nam">backward_func</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span> <span class="key">else</span> <span class="op">-</span><span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15134" href="#t15134">15134</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15135" href="#t15135">15135</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15136" href="#t15136">15136</a></span><span class="t">    <span class="key">for</span> <span class="nam">each_out</span> <span class="key">in</span> <span class="nam">out_list</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15137" href="#t15137">15137</a></span><span class="t">        <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">each_out</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">==</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15138" href="#t15138">15138</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15139" href="#t15139">15139</a></span><span class="t">                <span class="str">'Output shapes of py_func op should be provided by users manually'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15140" href="#t15140">15140</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15141" href="#t15141">15141</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15142" href="#t15142">15142</a></span><span class="t">    <span class="nam">backward_skip_vars</span> <span class="op">=</span> <span class="nam">set</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15143" href="#t15143">15143</a></span><span class="t">    <span class="key">if</span> <span class="nam">backward_func</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span> <span class="key">and</span> <span class="nam">skip_vars_in_backward_input</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15144" href="#t15144">15144</a></span><span class="t">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">skip_vars_in_backward_input</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15145" href="#t15145">15145</a></span><span class="t">            <span class="nam">skip_vars_in_backward_input</span> <span class="op">=</span> <span class="op">[</span><span class="nam">skip_vars_in_backward_input</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15146" href="#t15146">15146</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15147" href="#t15147">15147</a></span><span class="t">        <span class="nam">fwd_in_out</span> <span class="op">=</span> <span class="op">[</span><span class="nam">v</span><span class="op">.</span><span class="nam">name</span> <span class="key">for</span> <span class="nam">v</span> <span class="key">in</span> <span class="nam">x</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15148" href="#t15148">15148</a></span><span class="t">        <span class="nam">fwd_in_out</span><span class="op">.</span><span class="nam">extend</span><span class="op">(</span><span class="op">[</span><span class="nam">v</span><span class="op">.</span><span class="nam">name</span> <span class="key">for</span> <span class="nam">v</span> <span class="key">in</span> <span class="nam">out_list</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15149" href="#t15149">15149</a></span><span class="t">        <span class="nam">fwd_in_out</span> <span class="op">=</span> <span class="nam">set</span><span class="op">(</span><span class="nam">fwd_in_out</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15150" href="#t15150">15150</a></span><span class="t">        <span class="nam">backward_skip_vars</span> <span class="op">=</span> <span class="nam">set</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15151" href="#t15151">15151</a></span><span class="t">        <span class="key">for</span> <span class="nam">v</span> <span class="key">in</span> <span class="nam">skip_vars_in_backward_input</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15152" href="#t15152">15152</a></span><span class="t">            <span class="key">if</span> <span class="key">not</span> <span class="nam">v</span><span class="op">.</span><span class="nam">name</span> <span class="key">in</span> <span class="nam">fwd_in_out</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15153" href="#t15153">15153</a></span><span class="t">                <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15154" href="#t15154">15154</a></span><span class="t">                    <span class="str">'Variable {} is not found in forward inputs and outputs'</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15155" href="#t15155">15155</a></span><span class="t">                        <span class="nam">v</span><span class="op">.</span><span class="nam">name</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15156" href="#t15156">15156</a></span><span class="t">                    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15157" href="#t15157">15157</a></span><span class="t">                <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15158" href="#t15158">15158</a></span><span class="t">            <span class="nam">backward_skip_vars</span><span class="op">.</span><span class="nam">add</span><span class="op">(</span><span class="nam">v</span><span class="op">.</span><span class="nam">name</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15159" href="#t15159">15159</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15160" href="#t15160">15160</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15161" href="#t15161">15161</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'py_func'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15162" href="#t15162">15162</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15163" href="#t15163">15163</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out_list</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15164" href="#t15164">15164</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15165" href="#t15165">15165</a></span><span class="t">            <span class="str">'forward_callable_id'</span><span class="op">:</span> <span class="nam">fwd_func_id</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15166" href="#t15166">15166</a></span><span class="t">            <span class="str">'backward_callable_id'</span><span class="op">:</span> <span class="nam">bwd_func_id</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15167" href="#t15167">15167</a></span><span class="t">            <span class="str">'backward_skip_vars'</span><span class="op">:</span> <span class="nam">list</span><span class="op">(</span><span class="nam">backward_skip_vars</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15168" href="#t15168">15168</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15169" href="#t15169">15169</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15170" href="#t15170">15170</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15171" href="#t15171">15171</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15172" href="#t15172">15172</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15173" href="#t15173">15173</a></span><span class="t"><span class="com"># For debug usage</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t15174" href="#t15174">15174</a></span><span class="t"><span class="nam">py_func</span><span class="op">.</span><span class="nam">registered_func</span> <span class="op">=</span> <span class="nam">PyFuncRegistry</span><span class="op">.</span><span class="nam">registered_func</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t15175" href="#t15175">15175</a></span><span class="t"><span class="nam">py_func</span><span class="op">.</span><span class="nam">registered_func_num</span> <span class="op">=</span> <span class="nam">PyFuncRegistry</span><span class="op">.</span><span class="nam">registered_func_num</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15176" href="#t15176">15176</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15177" href="#t15177">15177</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t15178" href="#t15178">15178</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t15179" href="#t15179">15179</a></span><span class="t"><span class="key">def</span> <span class="nam">psroi_pool</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15180" href="#t15180">15180</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15181" href="#t15181">15181</a></span><span class="t">    <span class="nam">rois</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15182" href="#t15182">15182</a></span><span class="t">    <span class="nam">output_channels</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15183" href="#t15183">15183</a></span><span class="t">    <span class="nam">spatial_scale</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15184" href="#t15184">15184</a></span><span class="t">    <span class="nam">pooled_height</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15185" href="#t15185">15185</a></span><span class="t">    <span class="nam">pooled_width</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15186" href="#t15186">15186</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15187" href="#t15187">15187</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15188" href="#t15188">15188</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15189" href="#t15189">15189</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15190" href="#t15190">15190</a></span><span class="t"><span class="str">    ${comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15191" href="#t15191">15191</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15192" href="#t15192">15192</a></span><span class="t"><span class="str">    Parameters:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15193" href="#t15193">15193</a></span><span class="t"><span class="str">        input (Variable): ${x_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15194" href="#t15194">15194</a></span><span class="t"><span class="str">        rois (Variable): LoDTensor, ROIs (Regions of Interest) to pool over.It should be</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15195" href="#t15195">15195</a></span><span class="t"><span class="str">                         a 2-D LoDTensor of shape (num_rois, 4), the lod level</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15196" href="#t15196">15196</a></span><span class="t"><span class="str">                         is 1. Given as [[x1, y1, x2, y2], ...], (x1, y1) is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15197" href="#t15197">15197</a></span><span class="t"><span class="str">                         the top left coordinates, and (x2, y2) is the bottom</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15198" href="#t15198">15198</a></span><span class="t"><span class="str">                         right coordinates. The data type is the same as `input`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15199" href="#t15199">15199</a></span><span class="t"><span class="str">        output_channels (int): ${output_channels_comment}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15200" href="#t15200">15200</a></span><span class="t"><span class="str">        spatial_scale (float): ${spatial_scale_comment} Default: 1.0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15201" href="#t15201">15201</a></span><span class="t"><span class="str">        pooled_height (int): ${pooled_height_comment} Default: 1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15202" href="#t15202">15202</a></span><span class="t"><span class="str">        pooled_width (int): ${pooled_width_comment} Default: 1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15203" href="#t15203">15203</a></span><span class="t"><span class="str">        name(str, optional): The default value is None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15204" href="#t15204">15204</a></span><span class="t"><span class="str">                             Normally there is no need for user to set this property.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15205" href="#t15205">15205</a></span><span class="t"><span class="str">                             For more information, please refer to :ref:`api_guide_Name`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15206" href="#t15206">15206</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15207" href="#t15207">15207</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15208" href="#t15208">15208</a></span><span class="t"><span class="str">        ${out_comment}.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15209" href="#t15209">15209</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15210" href="#t15210">15210</a></span><span class="t"><span class="str">    Return Type:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15211" href="#t15211">15211</a></span><span class="t"><span class="str">        Variable</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15212" href="#t15212">15212</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15213" href="#t15213">15213</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15214" href="#t15214">15214</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15215" href="#t15215">15215</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15216" href="#t15216">15216</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15217" href="#t15217">15217</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15218" href="#t15218">15218</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15219" href="#t15219">15219</a></span><span class="t"><span class="str">            x = fluid.data(name='x', shape=[100, 490, 28, 28], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15220" href="#t15220">15220</a></span><span class="t"><span class="str">            rois = fluid.data(name='rois', shape=[None, 4], lod_level=1, dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15221" href="#t15221">15221</a></span><span class="t"><span class="str">            pool_out = fluid.layers.psroi_pool(x, rois, 10, 1.0, 7, 7)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15222" href="#t15222">15222</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15223" href="#t15223">15223</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'psroi_pool'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15224" href="#t15224">15224</a></span><span class="t">    <span class="com"># check attrs</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15225" href="#t15225">15225</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">output_channels</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15226" href="#t15226">15226</a></span><span class="t">        <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span><span class="str">"output_channels must be int type"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15227" href="#t15227">15227</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">spatial_scale</span><span class="op">,</span> <span class="nam">float</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15228" href="#t15228">15228</a></span><span class="t">        <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span><span class="str">"spatial_scale must be float type"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15229" href="#t15229">15229</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">pooled_height</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15230" href="#t15230">15230</a></span><span class="t">        <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span><span class="str">"pooled_height must be int type"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15231" href="#t15231">15231</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">pooled_width</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15232" href="#t15232">15232</a></span><span class="t">        <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span><span class="str">"pooled_width must be int type"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15233" href="#t15233">15233</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15234" href="#t15234">15234</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15235" href="#t15235">15235</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15236" href="#t15236">15236</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'psroi_pool'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15237" href="#t15237">15237</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">input</span><span class="op">,</span> <span class="str">'ROIs'</span><span class="op">:</span> <span class="nam">rois</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15238" href="#t15238">15238</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15239" href="#t15239">15239</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15240" href="#t15240">15240</a></span><span class="t">            <span class="str">'output_channels'</span><span class="op">:</span> <span class="nam">output_channels</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15241" href="#t15241">15241</a></span><span class="t">            <span class="str">'spatial_scale'</span><span class="op">:</span> <span class="nam">spatial_scale</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15242" href="#t15242">15242</a></span><span class="t">            <span class="str">'pooled_height'</span><span class="op">:</span> <span class="nam">pooled_height</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15243" href="#t15243">15243</a></span><span class="t">            <span class="str">'pooled_width'</span><span class="op">:</span> <span class="nam">pooled_width</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15244" href="#t15244">15244</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15245" href="#t15245">15245</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15246" href="#t15246">15246</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15247" href="#t15247">15247</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15248" href="#t15248">15248</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t15249" href="#t15249">15249</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t15250" href="#t15250">15250</a></span><span class="t"><span class="key">def</span> <span class="nam">prroi_pool</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15251" href="#t15251">15251</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15252" href="#t15252">15252</a></span><span class="t">    <span class="nam">rois</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15253" href="#t15253">15253</a></span><span class="t">    <span class="nam">spatial_scale</span><span class="op">=</span><span class="num">1.0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15254" href="#t15254">15254</a></span><span class="t">    <span class="nam">pooled_height</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15255" href="#t15255">15255</a></span><span class="t">    <span class="nam">pooled_width</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15256" href="#t15256">15256</a></span><span class="t">    <span class="nam">batch_roi_nums</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15257" href="#t15257">15257</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15258" href="#t15258">15258</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15259" href="#t15259">15259</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15260" href="#t15260">15260</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15261" href="#t15261">15261</a></span><span class="t"><span class="str">    The precise roi pooling implementation for paddle. Reference: https://arxiv.org/pdf/1807.11590.pdf</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15262" href="#t15262">15262</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15263" href="#t15263">15263</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15264" href="#t15264">15264</a></span><span class="t"><span class="str">        input (Variable):The input of precise roi pooliing.The shape of input tensor is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15265" href="#t15265">15265</a></span><span class="t"><span class="str">                        [N,C,H,W]. Where N is batch size,C is number of input channels,H</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15266" href="#t15266">15266</a></span><span class="t"><span class="str">                        is height of the feature, and W is the width of the feature.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15267" href="#t15267">15267</a></span><span class="t"><span class="str">        rois (Variable): ROIs (Regions of Interest) to pool over.It should be</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15268" href="#t15268">15268</a></span><span class="t"><span class="str">                        a 2-D LoDTensor or Tensor of shape (num_rois, 4), the lod level</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15269" href="#t15269">15269</a></span><span class="t"><span class="str">                        is 1 when it is LoDTensor. The LoD include the rois's batch index</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15270" href="#t15270">15270</a></span><span class="t"><span class="str">                        information. If rois is Tensor, its batch index information should</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15271" href="#t15271">15271</a></span><span class="t"><span class="str">                        be provided by batch_index.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15272" href="#t15272">15272</a></span><span class="t"><span class="str">                        Given as [[x1, y1, x2, y2], ...], (x1, y1) is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15273" href="#t15273">15273</a></span><span class="t"><span class="str">                        the top left coordinates, and (x2, y2) is the bottom</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15274" href="#t15274">15274</a></span><span class="t"><span class="str">                        right coordinates.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15275" href="#t15275">15275</a></span><span class="t"><span class="str">        spatial_scale (float): Ratio of input feature map height (or width) to raw image height (or width).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15276" href="#t15276">15276</a></span><span class="t"><span class="str">                             Equals the reciprocal of total stride in convolutional layers, Default: 1.0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15277" href="#t15277">15277</a></span><span class="t"><span class="str">        pooled_height (integer): The pooled output height. Default: 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15278" href="#t15278">15278</a></span><span class="t"><span class="str">        pooled_width (integer): The pooled output width. Default: 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15279" href="#t15279">15279</a></span><span class="t"><span class="str">        batch_roi_nums (Variable): The number of roi for each image in batch. It</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15280" href="#t15280">15280</a></span><span class="t"><span class="str">                         should be 1-D Tensor, with shape [N] and dtype int64,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15281" href="#t15281">15281</a></span><span class="t"><span class="str">                         where N is the batch size. Default: None. Be note: The lod of input should be</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15282" href="#t15282">15282</a></span><span class="t"><span class="str">                         empty when batch_roi_nums has values;</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15283" href="#t15283">15283</a></span><span class="t"><span class="str">        name (str, default None): The name of this operation.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15284" href="#t15284">15284</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15285" href="#t15285">15285</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15286" href="#t15286">15286</a></span><span class="t"><span class="str">        Variable(Tensor):The shape of the returned Tensor is (N, C, pooled_height, pooled_width), with value type float32,float16. N, C denote batch_size and channels of input respectively.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15287" href="#t15287">15287</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15288" href="#t15288">15288</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15289" href="#t15289">15289</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15290" href="#t15290">15290</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15291" href="#t15291">15291</a></span><span class="t"><span class="str">            ## prroi_pool without batch_roi_num</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15292" href="#t15292">15292</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15293" href="#t15293">15293</a></span><span class="t"><span class="str">            x = fluid.data(name='x', shape=[None, 490, 28, 28], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15294" href="#t15294">15294</a></span><span class="t"><span class="str">            rois = fluid.data(name='rois', shape=[None, 4], lod_level=1, dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15295" href="#t15295">15295</a></span><span class="t"><span class="str">            pool_out = fluid.layers.prroi_pool(x, rois, 1.0, 7, 7)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15296" href="#t15296">15296</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15297" href="#t15297">15297</a></span><span class="t"><span class="str">            ## prroi_pool with batch_roi_num</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15298" href="#t15298">15298</a></span><span class="t"><span class="str">            batchsize=4</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15299" href="#t15299">15299</a></span><span class="t"><span class="str">            x2 = fluid.data(name='x2', shape=[batchsize, 490, 28, 28], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15300" href="#t15300">15300</a></span><span class="t"><span class="str">            rois2 = fluid.data(name='rois2', shape=[batchsize, 4], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15301" href="#t15301">15301</a></span><span class="t"><span class="str">            batch_rois_num = fluid.data(name='rois_nums', shape=[batchsize], dtype='int64')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15302" href="#t15302">15302</a></span><span class="t"><span class="str">            pool_out2 = fluid.layers.prroi_pool(x2, rois2, 1.0, 7, 7, batch_roi_nums=batch_rois_num)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15303" href="#t15303">15303</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15304" href="#t15304">15304</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15305" href="#t15305">15305</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15306" href="#t15306">15306</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">]</span><span class="op">,</span> <span class="str">'prroi_pool'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15307" href="#t15307">15307</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">rois</span><span class="op">,</span> <span class="str">'rois'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">]</span><span class="op">,</span> <span class="str">'prroi_pool'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15308" href="#t15308">15308</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'prroi_pool'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15309" href="#t15309">15309</a></span><span class="t">    <span class="com"># check attrs</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15310" href="#t15310">15310</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">spatial_scale</span><span class="op">,</span> <span class="nam">float</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15311" href="#t15311">15311</a></span><span class="t">        <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span><span class="str">"spatial_scale must be float type"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15312" href="#t15312">15312</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">pooled_height</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15313" href="#t15313">15313</a></span><span class="t">        <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span><span class="str">"pooled_height must be int type"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15314" href="#t15314">15314</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">pooled_width</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15315" href="#t15315">15315</a></span><span class="t">        <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span><span class="str">"pooled_width must be int type"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15316" href="#t15316">15316</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15317" href="#t15317">15317</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15318" href="#t15318">15318</a></span><span class="t">    <span class="nam">inputs_op</span> <span class="op">=</span> <span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">input</span><span class="op">,</span> <span class="str">'ROIs'</span><span class="op">:</span> <span class="nam">rois</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15319" href="#t15319">15319</a></span><span class="t">    <span class="key">if</span> <span class="nam">batch_roi_nums</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15320" href="#t15320">15320</a></span><span class="t">        <span class="nam">inputs_op</span><span class="op">[</span><span class="str">'BatchRoINums'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">batch_roi_nums</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15321" href="#t15321">15321</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15322" href="#t15322">15322</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'prroi_pool'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15323" href="#t15323">15323</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs_op</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15324" href="#t15324">15324</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15325" href="#t15325">15325</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15326" href="#t15326">15326</a></span><span class="t">            <span class="str">'spatial_scale'</span><span class="op">:</span> <span class="nam">spatial_scale</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15327" href="#t15327">15327</a></span><span class="t">            <span class="str">'pooled_height'</span><span class="op">:</span> <span class="nam">pooled_height</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15328" href="#t15328">15328</a></span><span class="t">            <span class="str">'pooled_width'</span><span class="op">:</span> <span class="nam">pooled_width</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15329" href="#t15329">15329</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15330" href="#t15330">15330</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15331" href="#t15331">15331</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15332" href="#t15332">15332</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15333" href="#t15333">15333</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t15334" href="#t15334">15334</a></span><span class="t"><span class="key">def</span> <span class="nam">pixel_shuffle</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">upscale_factor</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15335" href="#t15335">15335</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15336" href="#t15336">15336</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15337" href="#t15337">15337</a></span><span class="t"><span class="str">    This op rearranges elements in a tensor of shape [N, C, H, W]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15338" href="#t15338">15338</a></span><span class="t"><span class="str">    to a tensor of shape [N, C/r**2, H*r, W*r].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15339" href="#t15339">15339</a></span><span class="t"><span class="str">    This is useful for implementing efficient sub-pixel convolution</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15340" href="#t15340">15340</a></span><span class="t"><span class="str">    with a stride of 1/r.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15341" href="#t15341">15341</a></span><span class="t"><span class="str">    Please refer to the paper: `Real-Time Single Image and Video Super-Resolution</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15342" href="#t15342">15342</a></span><span class="t"><span class="str">    Using an Efficient Sub-Pixel Convolutional Neural Network &lt;https://arxiv.org/abs/1609.05158v2>`_ .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15343" href="#t15343">15343</a></span><span class="t"><span class="str">    by Shi et. al (2016) for more details.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15344" href="#t15344">15344</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15345" href="#t15345">15345</a></span><span class="t"><span class="str">    Parameters:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15346" href="#t15346">15346</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15347" href="#t15347">15347</a></span><span class="t"><span class="str">        x(Variable): 4-D tensor, the data type should be float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15348" href="#t15348">15348</a></span><span class="t"><span class="str">        upscale_factor(int): factor to increase spatial resolution.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15349" href="#t15349">15349</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15350" href="#t15350">15350</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15351" href="#t15351">15351</a></span><span class="t"><span class="str">        Out(Variable): Reshaped tensor according to the new dimension.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15352" href="#t15352">15352</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15353" href="#t15353">15353</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15354" href="#t15354">15354</a></span><span class="t"><span class="str">        ValueError: If the square of upscale_factor cannot divide the channels of input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15355" href="#t15355">15355</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15356" href="#t15356">15356</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15357" href="#t15357">15357</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15358" href="#t15358">15358</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15359" href="#t15359">15359</a></span><span class="t"><span class="str">            # declarative mode</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15360" href="#t15360">15360</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15361" href="#t15361">15361</a></span><span class="t"><span class="str">            import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15362" href="#t15362">15362</a></span><span class="t"><span class="str">            input = fluid.data(name="input", shape=[2,9,4,4])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15363" href="#t15363">15363</a></span><span class="t"><span class="str">            output = fluid.layers.pixel_shuffle(x=input, upscale_factor=3)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15364" href="#t15364">15364</a></span><span class="t"><span class="str">            place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15365" href="#t15365">15365</a></span><span class="t"><span class="str">            exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15366" href="#t15366">15366</a></span><span class="t"><span class="str">            exe.run(fluid.default_startup_program())</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15367" href="#t15367">15367</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15368" href="#t15368">15368</a></span><span class="t"><span class="str">            input_data = np.random.rand(2,9,4,4).astype("float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15369" href="#t15369">15369</a></span><span class="t"><span class="str">            output_data = exe.run(fluid.default_main_program(),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15370" href="#t15370">15370</a></span><span class="t"><span class="str">                feed={"input":input_data},</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15371" href="#t15371">15371</a></span><span class="t"><span class="str">                fetch_list=[output],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15372" href="#t15372">15372</a></span><span class="t"><span class="str">                return_numpy=True)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15373" href="#t15373">15373</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15374" href="#t15374">15374</a></span><span class="t"><span class="str">            # print(output.shape)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15375" href="#t15375">15375</a></span><span class="t"><span class="str">            # (2L, 1L, 12L, 12L)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15376" href="#t15376">15376</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15377" href="#t15377">15377</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15378" href="#t15378">15378</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15379" href="#t15379">15379</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'pixel_shuffle'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15380" href="#t15380">15380</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"pixel_shuffle"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15381" href="#t15381">15381</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15382" href="#t15382">15382</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15383" href="#t15383">15383</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15384" href="#t15384">15384</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">upscale_factor</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15385" href="#t15385">15385</a></span><span class="t">        <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span><span class="str">"upscale factor must be int type"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15386" href="#t15386">15386</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15387" href="#t15387">15387</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15388" href="#t15388">15388</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"pixel_shuffle"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15389" href="#t15389">15389</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15390" href="#t15390">15390</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15391" href="#t15391">15391</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">"upscale_factor"</span><span class="op">:</span> <span class="nam">upscale_factor</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15392" href="#t15392">15392</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15393" href="#t15393">15393</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15394" href="#t15394">15394</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15395" href="#t15395">15395</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t15396" href="#t15396">15396</a></span><span class="t"><span class="key">def</span> <span class="nam">fsp_matrix</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">y</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15397" href="#t15397">15397</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15398" href="#t15398">15398</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15399" href="#t15399">15399</a></span><span class="t"><span class="str">    **FSP matrix op**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15400" href="#t15400">15400</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15401" href="#t15401">15401</a></span><span class="t"><span class="str">    This op is used to calculate the flow of solution procedure (FSP) matrix of two 4-D Tensor feature maps.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15402" href="#t15402">15402</a></span><span class="t"><span class="str">    Given feature map x with shape [x_channel, h, w] and feature map y with shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15403" href="#t15403">15403</a></span><span class="t"><span class="str">    [y_channel, h, w], we can get the fsp matrix of x and y in two steps:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15404" href="#t15404">15404</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15405" href="#t15405">15405</a></span><span class="t"><span class="str">    1. reshape x into matrix with shape [x_channel, h * w] and reshape and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15406" href="#t15406">15406</a></span><span class="t"><span class="str">       transpose y into matrix with shape [h * w, y_channel].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15407" href="#t15407">15407</a></span><span class="t"><span class="str">    2. multiply x and y to get fsp matrix with shape [x_channel, y_channel].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15408" href="#t15408">15408</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15409" href="#t15409">15409</a></span><span class="t"><span class="str">    The output is a batch of fsp matrices.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15410" href="#t15410">15410</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15411" href="#t15411">15411</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15412" href="#t15412">15412</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15413" href="#t15413">15413</a></span><span class="t"><span class="str">        x (Variable): A 4-D Tensor feature map with shape [batch_size, x_channel, height, width].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15414" href="#t15414">15414</a></span><span class="t"><span class="str">                      A Tensor with type float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15415" href="#t15415">15415</a></span><span class="t"><span class="str">        y (Variable): A 4-D Tensor feature map with shape [batch_size, y_channel, height, width].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15416" href="#t15416">15416</a></span><span class="t"><span class="str">                      The y_channel can be different with the x_channel of Input(X)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15417" href="#t15417">15417</a></span><span class="t"><span class="str">                      while the other dimensions must be the same with Input(X)'s. A Tensor with</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15418" href="#t15418">15418</a></span><span class="t"><span class="str">                      type float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15419" href="#t15419">15419</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15420" href="#t15420">15420</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15421" href="#t15421">15421</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15422" href="#t15422">15422</a></span><span class="t"><span class="str">        fsp matrix (Variable): The output of FSP op with shape [batch_size, x_channel, y_channel].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15423" href="#t15423">15423</a></span><span class="t"><span class="str">        The x_channel is the channel of x and the y_channel is the channel of y. A Tensor with</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15424" href="#t15424">15424</a></span><span class="t"><span class="str">        type float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15425" href="#t15425">15425</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15426" href="#t15426">15426</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15427" href="#t15427">15427</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15428" href="#t15428">15428</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15429" href="#t15429">15429</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15430" href="#t15430">15430</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15431" href="#t15431">15431</a></span><span class="t"><span class="str">            data = fluid.data(name='data', shape=[None, 3, 32, 32])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15432" href="#t15432">15432</a></span><span class="t"><span class="str">            feature_map_0 = fluid.layers.conv2d(data, num_filters=2,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15433" href="#t15433">15433</a></span><span class="t"><span class="str">                                                filter_size=3)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15434" href="#t15434">15434</a></span><span class="t"><span class="str">            feature_map_1 = fluid.layers.conv2d(feature_map_0, num_filters=2,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15435" href="#t15435">15435</a></span><span class="t"><span class="str">                                                filter_size=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15436" href="#t15436">15436</a></span><span class="t"><span class="str">            loss = fluid.layers.fsp_matrix(feature_map_0, feature_map_1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15437" href="#t15437">15437</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15438" href="#t15438">15438</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15439" href="#t15439">15439</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'fsp_matrix'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15440" href="#t15440">15440</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">y</span><span class="op">,</span> <span class="str">'y'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'fsp_matrix'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15441" href="#t15441">15441</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'fsp_matrix'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15442" href="#t15442">15442</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15443" href="#t15443">15443</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="nam">input_param_name</span><span class="op">=</span><span class="str">'x'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15444" href="#t15444">15444</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15445" href="#t15445">15445</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">'fsp'</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">,</span> <span class="str">'Y'</span><span class="op">:</span> <span class="nam">y</span><span class="op">}</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15446" href="#t15446">15446</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15447" href="#t15447">15447</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15448" href="#t15448">15448</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t15449" href="#t15449">15449</a></span><span class="t"><span class="key">def</span> <span class="nam">continuous_value_model</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">cvm</span><span class="op">,</span> <span class="nam">use_cvm</span><span class="op">=</span><span class="key">True</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15450" href="#t15450">15450</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15451" href="#t15451">15451</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15452" href="#t15452">15452</a></span><span class="t"><span class="str">    **continuous_value_model layers**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15453" href="#t15453">15453</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15454" href="#t15454">15454</a></span><span class="t"><span class="str">    Now, this OP is used in CTR project to remove or dispose show and click value in :attr:`input`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15455" href="#t15455">15455</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15456" href="#t15456">15456</a></span><span class="t"><span class="str">    :attr:`input` is an embedding vector including show and click value, whose shape is :math:`[N, D]` (N is batch size. D is `2 + embedding dim` ).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15457" href="#t15457">15457</a></span><span class="t"><span class="str">    Show and click at first two dims of embedding vector D.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15458" href="#t15458">15458</a></span><span class="t"><span class="str">    If :attr:`use_cvm` is True, it will calculate :math:`log(show)` and :math:`log(click)` , and output shape is :math:`[N, D]` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15459" href="#t15459">15459</a></span><span class="t"><span class="str">    If :attr:`use_cvm` is False, it will remove show and click from :attr:`input` , and output shape is :math:`[N, D - 2]` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15460" href="#t15460">15460</a></span><span class="t"><span class="str">    :attr:`cvm` is show_click info, whose shape is :math:`[N, 2]` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15461" href="#t15461">15461</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15462" href="#t15462">15462</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15463" href="#t15463">15463</a></span><span class="t"><span class="str">        input (Variable): The input variable. A 2-D LoDTensor with shape :math:`[N, D]` , where N is the batch size, D is `2 + the embedding dim` . `lod level = 1` .</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15464" href="#t15464">15464</a></span><span class="t"><span class="str">        A Tensor with type float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15465" href="#t15465">15465</a></span><span class="t"><span class="str">        cvm (Variable): Show and click variable. A 2-D Tensor with shape :math:`[N, 2]` , where N is the batch size, 2 is show and click.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15466" href="#t15466">15466</a></span><span class="t"><span class="str">        A Tensor with type float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15467" href="#t15467">15467</a></span><span class="t"><span class="str">        use_cvm  (bool):  Use show_click or not. if use, the output dim is the same as input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15468" href="#t15468">15468</a></span><span class="t"><span class="str">                          if not use, the output dim is `input dim - 2` (remove show and click)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15469" href="#t15469">15469</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15470" href="#t15470">15470</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15471" href="#t15471">15471</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15472" href="#t15472">15472</a></span><span class="t"><span class="str">        Variable: A 2-D LodTensor with shape :math:`[N, M]` . if :attr:`use_cvm` = True, M is equal to input dim D. if False, M is equal to `D - 2`. \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15473" href="#t15473">15473</a></span><span class="t"><span class="str">        A Tensor with same type as input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15474" href="#t15474">15474</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15475" href="#t15475">15475</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15476" href="#t15476">15476</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15477" href="#t15477">15477</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15478" href="#t15478">15478</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15479" href="#t15479">15479</a></span><span class="t"><span class="str">          import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15480" href="#t15480">15480</a></span><span class="t"><span class="str">          input = fluid.data(name="input", shape=[64, 1], dtype="int64")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15481" href="#t15481">15481</a></span><span class="t"><span class="str">          label = fluid.data(name="label", shape=[64, 1], dtype="int64")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15482" href="#t15482">15482</a></span><span class="t"><span class="str">          embed = fluid.layers.embedding(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15483" href="#t15483">15483</a></span><span class="t"><span class="str">                            input=input,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15484" href="#t15484">15484</a></span><span class="t"><span class="str">                            size=[100, 11],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15485" href="#t15485">15485</a></span><span class="t"><span class="str">                            dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15486" href="#t15486">15486</a></span><span class="t"><span class="str">          ones = fluid.layers.fill_constant_batch_size_like(input=label, shape=[-1, 1], dtype="int64", value=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15487" href="#t15487">15487</a></span><span class="t"><span class="str">          show_clk = fluid.layers.cast(fluid.layers.concat([ones, label], axis=1), dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15488" href="#t15488">15488</a></span><span class="t"><span class="str">          show_clk.stop_gradient = True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15489" href="#t15489">15489</a></span><span class="t"><span class="str">          input_with_cvm = fluid.layers.continuous_value_model(embed, show_clk, True)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15490" href="#t15490">15490</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15491" href="#t15491">15491</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15492" href="#t15492">15492</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'cvm'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15493" href="#t15493">15493</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">input</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15494" href="#t15494">15494</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15495" href="#t15495">15495</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'cvm'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15496" href="#t15496">15496</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15497" href="#t15497">15497</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15498" href="#t15498">15498</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'cvm'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15499" href="#t15499">15499</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="op">[</span><span class="nam">input</span><span class="op">]</span><span class="op">,</span> <span class="str">'CVM'</span><span class="op">:</span> <span class="op">[</span><span class="nam">cvm</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15500" href="#t15500">15500</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Y'</span><span class="op">:</span> <span class="op">[</span><span class="nam">out</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15501" href="#t15501">15501</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">"use_cvm"</span><span class="op">:</span> <span class="nam">use_cvm</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15502" href="#t15502">15502</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15503" href="#t15503">15503</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15504" href="#t15504">15504</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15505" href="#t15505">15505</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t15506" href="#t15506">15506</a></span><span class="t"><span class="key">def</span> <span class="nam">where</span><span class="op">(</span><span class="nam">condition</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15507" href="#t15507">15507</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15508" href="#t15508">15508</a></span><span class="t"><span class="str">    Return an int64 tensor with rank 2, specifying the coordinate of true element in `condition`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15509" href="#t15509">15509</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15510" href="#t15510">15510</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15511" href="#t15511">15511</a></span><span class="t"><span class="str">        condition(Variable): A bool tensor with rank at least 1, the data type is bool.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15512" href="#t15512">15512</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15513" href="#t15513">15513</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15514" href="#t15514">15514</a></span><span class="t"><span class="str">        Variable, the output data type is int64. : The tensor variable storing a 2-D tensor, which involves all coordinate.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15515" href="#t15515">15515</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15516" href="#t15516">15516</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15517" href="#t15517">15517</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15518" href="#t15518">15518</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15519" href="#t15519">15519</a></span><span class="t"><span class="str">             import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15520" href="#t15520">15520</a></span><span class="t"><span class="str">             import paddle.fluid.layers as layers</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15521" href="#t15521">15521</a></span><span class="t"><span class="str">             import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15522" href="#t15522">15522</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15523" href="#t15523">15523</a></span><span class="t"><span class="str">             # condition is a tensor [True, False, True]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15524" href="#t15524">15524</a></span><span class="t"><span class="str">             condition = layers.assign(np.array([1, 0, 1], dtype='int32'))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15525" href="#t15525">15525</a></span><span class="t"><span class="str">             condition = layers.cast(condition, 'bool')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15526" href="#t15526">15526</a></span><span class="t"><span class="str">             out = layers.where(condition) # [[0], [2]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15527" href="#t15527">15527</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15528" href="#t15528">15528</a></span><span class="t"><span class="str">             # condition is a tensor [[True, False], [False, True]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15529" href="#t15529">15529</a></span><span class="t"><span class="str">             condition = layers.assign(np.array([[1, 0], [0, 1]], dtype='int32'))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15530" href="#t15530">15530</a></span><span class="t"><span class="str">             condition = layers.cast(condition, 'bool')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15531" href="#t15531">15531</a></span><span class="t"><span class="str">             out = layers.where(condition) # [[0, 0], [1, 1]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15532" href="#t15532">15532</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15533" href="#t15533">15533</a></span><span class="t"><span class="str">             # condition is a tensor [False, False, False]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15534" href="#t15534">15534</a></span><span class="t"><span class="str">             condition = layers.assign(np.array([0, 0, 0], dtype='int32'))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15535" href="#t15535">15535</a></span><span class="t"><span class="str">             condition = layers.cast(condition, 'bool')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15536" href="#t15536">15536</a></span><span class="t"><span class="str">             out = layers.where(condition) # [[]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15537" href="#t15537">15537</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15538" href="#t15538">15538</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15539" href="#t15539">15539</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15540" href="#t15540">15540</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15541" href="#t15541">15541</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">where_index</span><span class="op">(</span><span class="nam">condition</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15542" href="#t15542">15542</a></span><span class="t">    <span class="key">if</span> <span class="nam">_in_legacy_dygraph</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15543" href="#t15543">15543</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">where_index</span><span class="op">(</span><span class="nam">condition</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15544" href="#t15544">15544</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15545" href="#t15545">15545</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"where_index"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15546" href="#t15546">15546</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15547" href="#t15547">15547</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15548" href="#t15548">15548</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">core</span><span class="op">.</span><span class="nam">VarDesc</span><span class="op">.</span><span class="nam">VarType</span><span class="op">.</span><span class="nam">INT64</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15549" href="#t15549">15549</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15550" href="#t15550">15550</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15551" href="#t15551">15551</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15552" href="#t15552">15552</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'where_index'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15553" href="#t15553">15553</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Condition'</span><span class="op">:</span> <span class="nam">condition</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15554" href="#t15554">15554</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="op">[</span><span class="nam">out</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15555" href="#t15555">15555</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15556" href="#t15556">15556</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15557" href="#t15557">15557</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15558" href="#t15558">15558</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t15559" href="#t15559">15559</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.sign"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t15560" href="#t15560">15560</a></span><span class="t"><span class="key">def</span> <span class="nam">sign</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15561" href="#t15561">15561</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15562" href="#t15562">15562</a></span><span class="t"><span class="str">    This OP returns sign of every element in `x`: 1 for positive, -1 for negative and 0 for zero.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15563" href="#t15563">15563</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15564" href="#t15564">15564</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15565" href="#t15565">15565</a></span><span class="t"><span class="str">        x(Variable|numpy.ndarray): The input variable could be N-D tensor or N-D numpy array, \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15566" href="#t15566">15566</a></span><span class="t"><span class="str">            the input data type is float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15567" href="#t15567">15567</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15568" href="#t15568">15568</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15569" href="#t15569">15569</a></span><span class="t"><span class="str">        Variable, the output data type is the same as input data type. : The output sign tensor with identical shape to input :attr:`x`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15570" href="#t15570">15570</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15571" href="#t15571">15571</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15572" href="#t15572">15572</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15573" href="#t15573">15573</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15574" href="#t15574">15574</a></span><span class="t"><span class="str">          import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15575" href="#t15575">15575</a></span><span class="t"><span class="str">          import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15576" href="#t15576">15576</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15577" href="#t15577">15577</a></span><span class="t"><span class="str">          # [1.0, 0.0, -1.0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15578" href="#t15578">15578</a></span><span class="t"><span class="str">          data = fluid.layers.sign(np.array([3.0, 0.0, -2.0], dtype='float32'))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15579" href="#t15579">15579</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15580" href="#t15580">15580</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15581" href="#t15581">15581</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"sign"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15582" href="#t15582">15582</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">(</span><span class="nam">Variable</span><span class="op">,</span> <span class="nam">np</span><span class="op">.</span><span class="nam">ndarray</span><span class="op">)</span><span class="op">,</span> <span class="str">'sign'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15583" href="#t15583">15583</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">np</span><span class="op">.</span><span class="nam">ndarray</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15584" href="#t15584">15584</a></span><span class="t">        <span class="nam">x</span> <span class="op">=</span> <span class="nam">assign</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15585" href="#t15585">15585</a></span><span class="t">    <span class="nam">check_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'sign'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15586" href="#t15586">15586</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15587" href="#t15587">15587</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15588" href="#t15588">15588</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">'sign'</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="op">[</span><span class="nam">x</span><span class="op">]</span><span class="op">}</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="op">[</span><span class="nam">out</span><span class="op">]</span><span class="op">}</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15589" href="#t15589">15589</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15590" href="#t15590">15590</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15591" href="#t15591">15591</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15592" href="#t15592">15592</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t15593" href="#t15593">15593</a></span><span class="t"><span class="key">def</span> <span class="nam">unique</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="str">'int32'</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15594" href="#t15594">15594</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15595" href="#t15595">15595</a></span><span class="t"><span class="str">    Return a unique tensor for `x` and an index tensor pointing to this unique tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15596" href="#t15596">15596</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15597" href="#t15597">15597</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15598" href="#t15598">15598</a></span><span class="t"><span class="str">        x(Tensor): A 1-D input tensor, it's data type should be float32, float64, int32, int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15599" href="#t15599">15599</a></span><span class="t"><span class="str">        dtype(np.dtype|str, optional): The type of index tensor: int32, int64. Default: int32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15600" href="#t15600">15600</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15601" href="#t15601">15601</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15602" href="#t15602">15602</a></span><span class="t"><span class="str">        tuple: (out, index). `out` is the unique tensor for `x`, with identical dtype to `x`, and \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15603" href="#t15603">15603</a></span><span class="t"><span class="str">            `index` is an index tensor pointing to `out`, by which user can recover the original `x` tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15604" href="#t15604">15604</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15605" href="#t15605">15605</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15606" href="#t15606">15606</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15607" href="#t15607">15607</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15608" href="#t15608">15608</a></span><span class="t"><span class="str">             import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15609" href="#t15609">15609</a></span><span class="t"><span class="str">             import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15610" href="#t15610">15610</a></span><span class="t"><span class="str">             x = fluid.layers.assign(np.array([2, 3, 3, 1, 5, 3], dtype='int32'))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15611" href="#t15611">15611</a></span><span class="t"><span class="str">             out, index = fluid.layers.unique(x) # out is [2, 3, 1, 5]; index is [0, 1, 1, 2, 3, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15612" href="#t15612">15612</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15613" href="#t15613">15613</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15614" href="#t15614">15614</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15615" href="#t15615">15615</a></span><span class="t">        <span class="nam">x</span><span class="op">,</span> <span class="str">"x"</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span> <span class="str">"unique"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15616" href="#t15616">15616</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15617" href="#t15617">15617</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"unique"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15618" href="#t15618">15618</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15619" href="#t15619">15619</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15620" href="#t15620">15620</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15621" href="#t15621">15621</a></span><span class="t">    <span class="nam">index</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15622" href="#t15622">15622</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15623" href="#t15623">15623</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15624" href="#t15624">15624</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'unique'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15625" href="#t15625">15625</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15626" href="#t15626">15626</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'dtype'</span><span class="op">:</span> <span class="nam">convert_np_dtype_to_dtype_</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15627" href="#t15627">15627</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="op">[</span><span class="nam">out</span><span class="op">]</span><span class="op">,</span> <span class="str">'Index'</span><span class="op">:</span> <span class="op">[</span><span class="nam">index</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15628" href="#t15628">15628</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15629" href="#t15629">15629</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15630" href="#t15630">15630</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span><span class="op">,</span> <span class="nam">index</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15631" href="#t15631">15631</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15632" href="#t15632">15632</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t15633" href="#t15633">15633</a></span><span class="t"><span class="key">def</span> <span class="nam">unique_with_counts</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="str">'int32'</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15634" href="#t15634">15634</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15635" href="#t15635">15635</a></span><span class="t"><span class="str">    This OP return a unique tensor for `x` , and count tensor that the count of unique result in raw input, \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15636" href="#t15636">15636</a></span><span class="t"><span class="str">    and an index tensor pointing to this unique tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15637" href="#t15637">15637</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15638" href="#t15638">15638</a></span><span class="t"><span class="str">    **NOTICE**: This op support the variable type of Tensor only.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15639" href="#t15639">15639</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15640" href="#t15640">15640</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15641" href="#t15641">15641</a></span><span class="t"><span class="str">        x(Variable): A 1-D input tensor with input shape of :math:`[N]` , the input data type is float32, float64, int32, int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15642" href="#t15642">15642</a></span><span class="t"><span class="str">        dtype(np.dtype|core.VarDesc.VarType|str): The type of count and index tensor, it could be int32, int64. Default value is int32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15643" href="#t15643">15643</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15644" href="#t15644">15644</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15645" href="#t15645">15645</a></span><span class="t"><span class="str">        tuple, the variable type in tuple is Tensor, the output :attr:`out` data type is the same as input :attr:`x`, \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15646" href="#t15646">15646</a></span><span class="t"><span class="str">        and data type of output :attr:`index` and :attr:`count` will be int32 or int64.: The :attr:`out` is unique tensor for input :attr:`x`,\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15647" href="#t15647">15647</a></span><span class="t"><span class="str">        the data shape is :math:`[K]`, the `K` may be different to the `N` in shape of :attr:`x`. :attr:`index` is an index tensor pointing\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15648" href="#t15648">15648</a></span><span class="t"><span class="str">        to :attr:`out`, the data shape is :math:`[N]` , the data shape is the same as input :attr:`x`. :attr:`count` is count of unique element in\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15649" href="#t15649">15649</a></span><span class="t"><span class="str">        the :attr:`x`, the data shape is :math:`[K]`, the data shape is the same as output :attr:`out`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15650" href="#t15650">15650</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15651" href="#t15651">15651</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15652" href="#t15652">15652</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15653" href="#t15653">15653</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15654" href="#t15654">15654</a></span><span class="t"><span class="str">             import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15655" href="#t15655">15655</a></span><span class="t"><span class="str">             import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15656" href="#t15656">15656</a></span><span class="t"><span class="str">             x = fluid.layers.assign(np.array([2, 3, 3, 1, 5, 3], dtype='int32'))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15657" href="#t15657">15657</a></span><span class="t"><span class="str">             out, index, count = fluid.layers.unique_with_counts(x) # out is [2, 3, 1, 5]; index is [0, 1, 1, 2, 3, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15658" href="#t15658">15658</a></span><span class="t"><span class="str">                                                        # count is [1, 3, 1, 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15659" href="#t15659">15659</a></span><span class="t"><span class="str">            # x.shape=(6,) out.shape=(4,), index.shape=(6,), count.shape=(4,)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15660" href="#t15660">15660</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15661" href="#t15661">15661</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15662" href="#t15662">15662</a></span><span class="t">        <span class="nam">x</span><span class="op">,</span> <span class="str">"x"</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span> <span class="str">"unique_with_counts"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15663" href="#t15663">15663</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15664" href="#t15664">15664</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="op">(</span><span class="nam">dtype</span> <span class="op">==</span> <span class="str">'int32'</span> <span class="key">or</span> <span class="nam">dtype</span> <span class="op">==</span> <span class="str">'int64'</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15665" href="#t15665">15665</a></span><span class="t">        <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15666" href="#t15666">15666</a></span><span class="t">            <span class="str">"Op unique_with_counts, index dtype must be int32 or int64"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15667" href="#t15667">15667</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15668" href="#t15668">15668</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15669" href="#t15669">15669</a></span><span class="t">    <span class="key">if</span> <span class="nam">x</span> <span class="key">is</span> <span class="key">None</span> <span class="key">or</span> <span class="nam">len</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span> <span class="op">!=</span> <span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15670" href="#t15670">15670</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15671" href="#t15671">15671</a></span><span class="t">            <span class="str">"Op unique_with_counts, x must not be null and size of dim must be 1"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15672" href="#t15672">15672</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15673" href="#t15673">15673</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15674" href="#t15674">15674</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"unique_with_counts"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15675" href="#t15675">15675</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15676" href="#t15676">15676</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15677" href="#t15677">15677</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15678" href="#t15678">15678</a></span><span class="t">    <span class="nam">index</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15679" href="#t15679">15679</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15680" href="#t15680">15680</a></span><span class="t">    <span class="nam">count</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15681" href="#t15681">15681</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15682" href="#t15682">15682</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15683" href="#t15683">15683</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'unique_with_counts'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15684" href="#t15684">15684</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15685" href="#t15685">15685</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'dtype'</span><span class="op">:</span> <span class="nam">convert_np_dtype_to_dtype_</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15686" href="#t15686">15686</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="op">[</span><span class="nam">out</span><span class="op">]</span><span class="op">,</span> <span class="str">'Index'</span><span class="op">:</span> <span class="op">[</span><span class="nam">index</span><span class="op">]</span><span class="op">,</span> <span class="str">'Count'</span><span class="op">:</span> <span class="op">[</span><span class="nam">count</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15687" href="#t15687">15687</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15688" href="#t15688">15688</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15689" href="#t15689">15689</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span><span class="op">,</span> <span class="nam">index</span><span class="op">,</span> <span class="nam">count</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15690" href="#t15690">15690</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15691" href="#t15691">15691</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t15692" href="#t15692">15692</a></span><span class="t"><span class="key">def</span> <span class="nam">deformable_conv</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15693" href="#t15693">15693</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15694" href="#t15694">15694</a></span><span class="t">    <span class="nam">offset</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15695" href="#t15695">15695</a></span><span class="t">    <span class="nam">mask</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15696" href="#t15696">15696</a></span><span class="t">    <span class="nam">num_filters</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15697" href="#t15697">15697</a></span><span class="t">    <span class="nam">filter_size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15698" href="#t15698">15698</a></span><span class="t">    <span class="nam">stride</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15699" href="#t15699">15699</a></span><span class="t">    <span class="nam">padding</span><span class="op">=</span><span class="num">0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15700" href="#t15700">15700</a></span><span class="t">    <span class="nam">dilation</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15701" href="#t15701">15701</a></span><span class="t">    <span class="nam">groups</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15702" href="#t15702">15702</a></span><span class="t">    <span class="nam">deformable_groups</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15703" href="#t15703">15703</a></span><span class="t">    <span class="nam">im2col_step</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15704" href="#t15704">15704</a></span><span class="t">    <span class="nam">param_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15705" href="#t15705">15705</a></span><span class="t">    <span class="nam">bias_attr</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15706" href="#t15706">15706</a></span><span class="t">    <span class="nam">modulated</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15707" href="#t15707">15707</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15708" href="#t15708">15708</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15709" href="#t15709">15709</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15710" href="#t15710">15710</a></span><span class="t"><span class="str">    :api_attr: Static Graph</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15711" href="#t15711">15711</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15712" href="#t15712">15712</a></span><span class="t"><span class="str">    **Deformable Convolution op**</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15713" href="#t15713">15713</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15714" href="#t15714">15714</a></span><span class="t"><span class="str">    Compute 2-D deformable convolution on 4-D input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15715" href="#t15715">15715</a></span><span class="t"><span class="str">    Given input image x, output feature map y, the deformable convolution operation can be expressed as follow:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15716" href="#t15716">15716</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15717" href="#t15717">15717</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15718" href="#t15718">15718</a></span><span class="t"><span class="str">    Deformable Convolution v2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15719" href="#t15719">15719</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15720" href="#t15720">15720</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15721" href="#t15721">15721</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15722" href="#t15722">15722</a></span><span class="t"><span class="str">        y(p) = \sum_{k=1}^{K}{w_k * x(p + p_k + \Delta p_k) * \Delta m_k}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15723" href="#t15723">15723</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15724" href="#t15724">15724</a></span><span class="t"><span class="str">    Deformable Convolution v1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15725" href="#t15725">15725</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15726" href="#t15726">15726</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15727" href="#t15727">15727</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15728" href="#t15728">15728</a></span><span class="t"><span class="str">        y(p) = \sum_{k=1}^{K}{w_k * x(p + p_k + \Delta p_k)}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15729" href="#t15729">15729</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15730" href="#t15730">15730</a></span><span class="t"><span class="str">    Where :math:`\Delta p_k` and :math:`\Delta m_k` are the learnable offset and modulation scalar for the k-th location,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15731" href="#t15731">15731</a></span><span class="t"><span class="str">    Which :math:`\Delta m_k` is one in deformable convolution v1. Please refer to `Deformable ConvNets v2: More Deformable, Better Results</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15732" href="#t15732">15732</a></span><span class="t"><span class="str">    &lt;https://arxiv.org/abs/1811.11168v2>`_ and `Deformable Convolutional Networks &lt;https://arxiv.org/abs/1703.06211>`_.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15733" href="#t15733">15733</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15734" href="#t15734">15734</a></span><span class="t"><span class="str">    Example:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15735" href="#t15735">15735</a></span><span class="t"><span class="str">        - Input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15736" href="#t15736">15736</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15737" href="#t15737">15737</a></span><span class="t"><span class="str">          Input shape: :math:`(N, C_{in}, H_{in}, W_{in})`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15738" href="#t15738">15738</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15739" href="#t15739">15739</a></span><span class="t"><span class="str">          Filter shape: :math:`(C_{out}, C_{in}, H_f, W_f)`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15740" href="#t15740">15740</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15741" href="#t15741">15741</a></span><span class="t"><span class="str">          Offset shape: :math:`(N, 2 * deformable\_groups * H_f * H_w, H_{in}, W_{in})`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15742" href="#t15742">15742</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15743" href="#t15743">15743</a></span><span class="t"><span class="str">          Mask shape: :math:`(N, deformable\_groups * H_f * H_w, H_{in}, W_{in})`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15744" href="#t15744">15744</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15745" href="#t15745">15745</a></span><span class="t"><span class="str">        - Output:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15746" href="#t15746">15746</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15747" href="#t15747">15747</a></span><span class="t"><span class="str">          Output shape: :math:`(N, C_{out}, H_{out}, W_{out})`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15748" href="#t15748">15748</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15749" href="#t15749">15749</a></span><span class="t"><span class="str">        Where</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15750" href="#t15750">15750</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15751" href="#t15751">15751</a></span><span class="t"><span class="str">        .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15752" href="#t15752">15752</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15753" href="#t15753">15753</a></span><span class="t"><span class="str">            H_{out}&amp;= \\frac{(H_{in} + 2 * paddings[0] - (dilations[0] * (H_f - 1) + 1))}{strides[0]} + 1 \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15754" href="#t15754">15754</a></span><span class="t"><span class="str">            W_{out}&amp;= \\frac{(W_{in} + 2 * paddings[1] - (dilations[1] * (W_f - 1) + 1))}{strides[1]} + 1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15755" href="#t15755">15755</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15756" href="#t15756">15756</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15757" href="#t15757">15757</a></span><span class="t"><span class="str">        input (Variable): The input image with [N, C, H, W] format. A Tensor with type</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15758" href="#t15758">15758</a></span><span class="t"><span class="str">            float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15759" href="#t15759">15759</a></span><span class="t"><span class="str">        offset (Variable): The input coordinate offset of deformable convolution layer.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15760" href="#t15760">15760</a></span><span class="t"><span class="str">            A Tensor with type float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15761" href="#t15761">15761</a></span><span class="t"><span class="str">        Mask (Variable, Optional): The input mask of deformable convolution layer.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15762" href="#t15762">15762</a></span><span class="t"><span class="str">            A Tensor with type float32, float64. It should be None when you use</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15763" href="#t15763">15763</a></span><span class="t"><span class="str">            deformable convolution v1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15764" href="#t15764">15764</a></span><span class="t"><span class="str">        num_filters(int): The number of filter. It is as same as the output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15765" href="#t15765">15765</a></span><span class="t"><span class="str">            image channel.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15766" href="#t15766">15766</a></span><span class="t"><span class="str">        filter_size (int|tuple): The filter size. If filter_size is a tuple,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15767" href="#t15767">15767</a></span><span class="t"><span class="str">            it must contain two integers, (filter_size_H, filter_size_W).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15768" href="#t15768">15768</a></span><span class="t"><span class="str">            Otherwise, the filter will be a square.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15769" href="#t15769">15769</a></span><span class="t"><span class="str">        stride (int|tuple): The stride size. If stride is a tuple, it must</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15770" href="#t15770">15770</a></span><span class="t"><span class="str">            contain two integers, (stride_H, stride_W). Otherwise, the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15771" href="#t15771">15771</a></span><span class="t"><span class="str">            stride_H = stride_W = stride. Default: stride = 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15772" href="#t15772">15772</a></span><span class="t"><span class="str">        padding (int|tuple): The padding size. If padding is a tuple, it must</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15773" href="#t15773">15773</a></span><span class="t"><span class="str">            contain two integers, (padding_H, padding_W). Otherwise, the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15774" href="#t15774">15774</a></span><span class="t"><span class="str">            padding_H = padding_W = padding. Default: padding = 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15775" href="#t15775">15775</a></span><span class="t"><span class="str">        dilation (int|tuple): The dilation size. If dilation is a tuple, it must</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15776" href="#t15776">15776</a></span><span class="t"><span class="str">            contain two integers, (dilation_H, dilation_W). Otherwise, the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15777" href="#t15777">15777</a></span><span class="t"><span class="str">            dilation_H = dilation_W = dilation. Default: dilation = 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15778" href="#t15778">15778</a></span><span class="t"><span class="str">        groups (int): The groups number of the deformable conv layer. According to</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15779" href="#t15779">15779</a></span><span class="t"><span class="str">            grouped convolution in Alex Krizhevsky's Deep CNN paper: when group=2,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15780" href="#t15780">15780</a></span><span class="t"><span class="str">            the first half of the filters is only connected to the first half</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15781" href="#t15781">15781</a></span><span class="t"><span class="str">            of the input channels, while the second half of the filters is only</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15782" href="#t15782">15782</a></span><span class="t"><span class="str">            connected to the second half of the input channels. Default: groups=1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15783" href="#t15783">15783</a></span><span class="t"><span class="str">        deformable_groups (int): The number of deformable group partitions.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15784" href="#t15784">15784</a></span><span class="t"><span class="str">            Default: deformable_groups = 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15785" href="#t15785">15785</a></span><span class="t"><span class="str">        im2col_step (int): Maximum number of images per im2col computation;</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15786" href="#t15786">15786</a></span><span class="t"><span class="str">            The total batch size should be devisable by this value or smaller</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15787" href="#t15787">15787</a></span><span class="t"><span class="str">            than this value; if you face out of memory problem, you can try</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15788" href="#t15788">15788</a></span><span class="t"><span class="str">            to use a smaller value here.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15789" href="#t15789">15789</a></span><span class="t"><span class="str">            Default: im2col_step = 64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15790" href="#t15790">15790</a></span><span class="t"><span class="str">        param_attr (ParamAttr, Optional): The parameter attribute for learnable parameters/weights</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15791" href="#t15791">15791</a></span><span class="t"><span class="str">            of deformable conv. If it is set to None or one attribute of ParamAttr,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15792" href="#t15792">15792</a></span><span class="t"><span class="str">            deformable conv will create ParamAttr as param_attr.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15793" href="#t15793">15793</a></span><span class="t"><span class="str">            If the Initializer of the param_attr is not set, the parameter is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15794" href="#t15794">15794</a></span><span class="t"><span class="str">            initialized with :math:`Normal(0.0, std)`, and the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15795" href="#t15795">15795</a></span><span class="t"><span class="str">            :math:`std` is :math:`(\\frac{2.0 }{filter\_elem\_num})^{0.5}`. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15796" href="#t15796">15796</a></span><span class="t"><span class="str">        bias_attr (ParamAttr|bool, Optional): The parameter attribute for the bias of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15797" href="#t15797">15797</a></span><span class="t"><span class="str">            deformable conv layer. If it is set to False, no bias will be added</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15798" href="#t15798">15798</a></span><span class="t"><span class="str">            to the output units. If it is set to None or one attribute of ParamAttr, conv2d</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15799" href="#t15799">15799</a></span><span class="t"><span class="str">            will create ParamAttr as bias_attr. If the Initializer of the bias_attr</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15800" href="#t15800">15800</a></span><span class="t"><span class="str">            is not set, the bias is initialized zero. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15801" href="#t15801">15801</a></span><span class="t"><span class="str">        modulated (bool): Make sure which version should be used between v1 and v2, where v2 is \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15802" href="#t15802">15802</a></span><span class="t"><span class="str">            used while True. Default: True.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15803" href="#t15803">15803</a></span><span class="t"><span class="str">        name(str, Optional): For details, please refer to :ref:`api_guide_Name`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15804" href="#t15804">15804</a></span><span class="t"><span class="str">                        Generally, no setting is required. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15805" href="#t15805">15805</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15806" href="#t15806">15806</a></span><span class="t"><span class="str">        Variable: The tensor variable storing the deformable convolution \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15807" href="#t15807">15807</a></span><span class="t"><span class="str">                  result. A Tensor with type float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15808" href="#t15808">15808</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15809" href="#t15809">15809</a></span><span class="t"><span class="str">        ValueError: If the shapes of input, filter_size, stride, padding and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15810" href="#t15810">15810</a></span><span class="t"><span class="str">                    groups mismatch.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15811" href="#t15811">15811</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15812" href="#t15812">15812</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15813" href="#t15813">15813</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15814" href="#t15814">15814</a></span><span class="t"><span class="str">          #deformable conv v2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15815" href="#t15815">15815</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15816" href="#t15816">15816</a></span><span class="t"><span class="str">          import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15817" href="#t15817">15817</a></span><span class="t"><span class="str">          import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15818" href="#t15818">15818</a></span><span class="t"><span class="str">          paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15819" href="#t15819">15819</a></span><span class="t"><span class="str">          </span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15820" href="#t15820">15820</a></span><span class="t"><span class="str">          C_in, H_in, W_in = 3, 32, 32</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15821" href="#t15821">15821</a></span><span class="t"><span class="str">          filter_size, deformable_groups = 3, 1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15822" href="#t15822">15822</a></span><span class="t"><span class="str">          data = fluid.data(name='data', shape=[None, C_in, H_in, W_in], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15823" href="#t15823">15823</a></span><span class="t"><span class="str">          offset = fluid.data(name='offset', shape=[None, 2*deformable_groups*filter_size**2, H_in, W_in], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15824" href="#t15824">15824</a></span><span class="t"><span class="str">          mask = fluid.data(name='mask', shape=[None, deformable_groups*filter_size**2, H_in, W_in], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15825" href="#t15825">15825</a></span><span class="t"><span class="str">          out = fluid.layers.deformable_conv(input=data, offset=offset, mask=mask,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15826" href="#t15826">15826</a></span><span class="t"><span class="str">                                             num_filters=2, filter_size=filter_size, padding=1, modulated=True)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15827" href="#t15827">15827</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15828" href="#t15828">15828</a></span><span class="t"><span class="str">          #deformable conv v1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15829" href="#t15829">15829</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15830" href="#t15830">15830</a></span><span class="t"><span class="str">          import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15831" href="#t15831">15831</a></span><span class="t"><span class="str">          C_in, H_in, W_in = 3, 32, 32</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15832" href="#t15832">15832</a></span><span class="t"><span class="str">          filter_size, deformable_groups = 3, 1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15833" href="#t15833">15833</a></span><span class="t"><span class="str">          data = fluid.data(name='data', shape=[None, C_in, H_in, W_in], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15834" href="#t15834">15834</a></span><span class="t"><span class="str">          offset = fluid.data(name='offset', shape=[None, 2*deformable_groups*filter_size**2, H_in, W_in], dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15835" href="#t15835">15835</a></span><span class="t"><span class="str">          out = fluid.layers.deformable_conv(input=data, offset=offset, mask=None,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15836" href="#t15836">15836</a></span><span class="t"><span class="str">                                             num_filters=2, filter_size=filter_size, padding=1, modulated=False)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15837" href="#t15837">15837</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15838" href="#t15838">15838</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15839" href="#t15839">15839</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15840" href="#t15840">15840</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span> <span class="str">"input"</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'deformable_conv'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15841" href="#t15841">15841</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15842" href="#t15842">15842</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15843" href="#t15843">15843</a></span><span class="t">        <span class="nam">offset</span><span class="op">,</span> <span class="str">"offset"</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'deformable_conv'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15844" href="#t15844">15844</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15845" href="#t15845">15845</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">mask</span><span class="op">,</span> <span class="str">'mask'</span><span class="op">,</span> <span class="op">(</span><span class="nam">Variable</span><span class="op">,</span> <span class="nam">type</span><span class="op">(</span><span class="key">None</span><span class="op">)</span><span class="op">)</span><span class="op">,</span> <span class="str">'deformable_conv'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15846" href="#t15846">15846</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15847" href="#t15847">15847</a></span><span class="t">    <span class="nam">num_channels</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15848" href="#t15848">15848</a></span><span class="t">    <span class="key">assert</span> <span class="nam">param_attr</span> <span class="key">is</span> <span class="key">not</span> <span class="key">False</span><span class="op">,</span> <span class="str">"param_attr should not be False here."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15849" href="#t15849">15849</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15850" href="#t15850">15850</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'deformable_conv'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15851" href="#t15851">15851</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15852" href="#t15852">15852</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15853" href="#t15853">15853</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15854" href="#t15854">15854</a></span><span class="t">        <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span><span class="str">"Input of deformable_conv must be Variable"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15855" href="#t15855">15855</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">offset</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15856" href="#t15856">15856</a></span><span class="t">        <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span><span class="str">"Input Offset of deformable_conv must be Variable"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15857" href="#t15857">15857</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15858" href="#t15858">15858</a></span><span class="t">    <span class="key">if</span> <span class="nam">groups</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15859" href="#t15859">15859</a></span><span class="t">        <span class="nam">num_filter_channels</span> <span class="op">=</span> <span class="nam">num_channels</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15860" href="#t15860">15860</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15861" href="#t15861">15861</a></span><span class="t">        <span class="key">if</span> <span class="nam">num_channels</span> <span class="op">%</span> <span class="nam">groups</span> <span class="op">!=</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15862" href="#t15862">15862</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"num_channels must be divisible by groups."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15863" href="#t15863">15863</a></span><span class="t">        <span class="nam">num_filter_channels</span> <span class="op">=</span> <span class="nam">num_channels</span> <span class="op">//</span> <span class="nam">groups</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15864" href="#t15864">15864</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15865" href="#t15865">15865</a></span><span class="t">    <span class="nam">filter_size</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">filter_size</span><span class="op">,</span> <span class="num">2</span><span class="op">,</span> <span class="str">'filter_size'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15866" href="#t15866">15866</a></span><span class="t">    <span class="nam">stride</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">stride</span><span class="op">,</span> <span class="num">2</span><span class="op">,</span> <span class="str">'stride'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15867" href="#t15867">15867</a></span><span class="t">    <span class="nam">padding</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">padding</span><span class="op">,</span> <span class="num">2</span><span class="op">,</span> <span class="str">'padding'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15868" href="#t15868">15868</a></span><span class="t">    <span class="nam">dilation</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">dilation</span><span class="op">,</span> <span class="num">2</span><span class="op">,</span> <span class="str">'dilation'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15869" href="#t15869">15869</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15870" href="#t15870">15870</a></span><span class="t">    <span class="nam">input_shape</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15871" href="#t15871">15871</a></span><span class="t">    <span class="nam">filter_shape</span> <span class="op">=</span> <span class="op">[</span><span class="nam">num_filters</span><span class="op">,</span> <span class="nam">int</span><span class="op">(</span><span class="nam">num_filter_channels</span><span class="op">)</span><span class="op">]</span> <span class="op">+</span> <span class="nam">filter_size</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15872" href="#t15872">15872</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15873" href="#t15873">15873</a></span><span class="t">    <span class="key">def</span> <span class="nam">_get_default_param_initializer</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15874" href="#t15874">15874</a></span><span class="t">        <span class="nam">filter_elem_num</span> <span class="op">=</span> <span class="nam">filter_size</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">*</span> <span class="nam">filter_size</span><span class="op">[</span><span class="num">1</span><span class="op">]</span> <span class="op">*</span> <span class="nam">num_channels</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15875" href="#t15875">15875</a></span><span class="t">        <span class="key">if</span> <span class="nam">filter_elem_num</span> <span class="op">&lt;=</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15876" href="#t15876">15876</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15877" href="#t15877">15877</a></span><span class="t">                <span class="str">"Invalid filter number, excepted number is larger than 0, but"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15878" href="#t15878">15878</a></span><span class="t">                <span class="str">" received {}, please check the input shape and "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15879" href="#t15879">15879</a></span><span class="t">                <span class="str">"filter size."</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">filter_elem_num</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15880" href="#t15880">15880</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15881" href="#t15881">15881</a></span><span class="t">        <span class="nam">std</span> <span class="op">=</span> <span class="op">(</span><span class="num">2.0</span> <span class="op">/</span> <span class="nam">filter_elem_num</span><span class="op">)</span> <span class="op">**</span> <span class="num">0.5</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15882" href="#t15882">15882</a></span><span class="t">        <span class="key">return</span> <span class="nam">Normal</span><span class="op">(</span><span class="num">0.0</span><span class="op">,</span> <span class="nam">std</span><span class="op">,</span> <span class="num">0</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15883" href="#t15883">15883</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15884" href="#t15884">15884</a></span><span class="t">    <span class="nam">filter_param</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_parameter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15885" href="#t15885">15885</a></span><span class="t">        <span class="nam">attr</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">param_attr</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15886" href="#t15886">15886</a></span><span class="t">        <span class="nam">shape</span><span class="op">=</span><span class="nam">filter_shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15887" href="#t15887">15887</a></span><span class="t">        <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15888" href="#t15888">15888</a></span><span class="t">        <span class="nam">default_initializer</span><span class="op">=</span><span class="nam">_get_default_param_initializer</span><span class="op">(</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15889" href="#t15889">15889</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15890" href="#t15890">15890</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15891" href="#t15891">15891</a></span><span class="t">    <span class="nam">pre_bias</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15892" href="#t15892">15892</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15893" href="#t15893">15893</a></span><span class="t">    <span class="key">if</span> <span class="nam">modulated</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15894" href="#t15894">15894</a></span><span class="t">        <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15895" href="#t15895">15895</a></span><span class="t">            <span class="nam">type</span><span class="op">=</span><span class="str">'deformable_conv'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15896" href="#t15896">15896</a></span><span class="t">            <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15897" href="#t15897">15897</a></span><span class="t">                <span class="str">'Input'</span><span class="op">:</span> <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15898" href="#t15898">15898</a></span><span class="t">                <span class="str">'Filter'</span><span class="op">:</span> <span class="nam">filter_param</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15899" href="#t15899">15899</a></span><span class="t">                <span class="str">'Offset'</span><span class="op">:</span> <span class="nam">offset</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15900" href="#t15900">15900</a></span><span class="t">                <span class="str">'Mask'</span><span class="op">:</span> <span class="nam">mask</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15901" href="#t15901">15901</a></span><span class="t">            <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15902" href="#t15902">15902</a></span><span class="t">            <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Output"</span><span class="op">:</span> <span class="nam">pre_bias</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15903" href="#t15903">15903</a></span><span class="t">            <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15904" href="#t15904">15904</a></span><span class="t">                <span class="str">'strides'</span><span class="op">:</span> <span class="nam">stride</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15905" href="#t15905">15905</a></span><span class="t">                <span class="str">'paddings'</span><span class="op">:</span> <span class="nam">padding</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15906" href="#t15906">15906</a></span><span class="t">                <span class="str">'dilations'</span><span class="op">:</span> <span class="nam">dilation</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15907" href="#t15907">15907</a></span><span class="t">                <span class="str">'groups'</span><span class="op">:</span> <span class="nam">groups</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15908" href="#t15908">15908</a></span><span class="t">                <span class="str">'deformable_groups'</span><span class="op">:</span> <span class="nam">deformable_groups</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15909" href="#t15909">15909</a></span><span class="t">                <span class="str">'im2col_step'</span><span class="op">:</span> <span class="nam">im2col_step</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15910" href="#t15910">15910</a></span><span class="t">            <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15911" href="#t15911">15911</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15912" href="#t15912">15912</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15913" href="#t15913">15913</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15914" href="#t15914">15914</a></span><span class="t">        <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15915" href="#t15915">15915</a></span><span class="t">            <span class="nam">type</span><span class="op">=</span><span class="str">'deformable_conv_v1'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15916" href="#t15916">15916</a></span><span class="t">            <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15917" href="#t15917">15917</a></span><span class="t">                <span class="str">'Input'</span><span class="op">:</span> <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15918" href="#t15918">15918</a></span><span class="t">                <span class="str">'Filter'</span><span class="op">:</span> <span class="nam">filter_param</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15919" href="#t15919">15919</a></span><span class="t">                <span class="str">'Offset'</span><span class="op">:</span> <span class="nam">offset</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15920" href="#t15920">15920</a></span><span class="t">            <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15921" href="#t15921">15921</a></span><span class="t">            <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Output"</span><span class="op">:</span> <span class="nam">pre_bias</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15922" href="#t15922">15922</a></span><span class="t">            <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15923" href="#t15923">15923</a></span><span class="t">                <span class="str">'strides'</span><span class="op">:</span> <span class="nam">stride</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15924" href="#t15924">15924</a></span><span class="t">                <span class="str">'paddings'</span><span class="op">:</span> <span class="nam">padding</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15925" href="#t15925">15925</a></span><span class="t">                <span class="str">'dilations'</span><span class="op">:</span> <span class="nam">dilation</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15926" href="#t15926">15926</a></span><span class="t">                <span class="str">'groups'</span><span class="op">:</span> <span class="nam">groups</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15927" href="#t15927">15927</a></span><span class="t">                <span class="str">'deformable_groups'</span><span class="op">:</span> <span class="nam">deformable_groups</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15928" href="#t15928">15928</a></span><span class="t">                <span class="str">'im2col_step'</span><span class="op">:</span> <span class="nam">im2col_step</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15929" href="#t15929">15929</a></span><span class="t">            <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15930" href="#t15930">15930</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15931" href="#t15931">15931</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15932" href="#t15932">15932</a></span><span class="t">    <span class="nam">output</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">append_bias_op</span><span class="op">(</span><span class="nam">pre_bias</span><span class="op">,</span> <span class="nam">dim_start</span><span class="op">=</span><span class="num">1</span><span class="op">,</span> <span class="nam">dim_end</span><span class="op">=</span><span class="num">2</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t15933" href="#t15933">15933</a></span><span class="t">    <span class="key">return</span> <span class="nam">output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15934" href="#t15934">15934</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15935" href="#t15935">15935</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t15936" href="#t15936">15936</a></span><span class="t"><span class="key">def</span> <span class="nam">unfold</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">kernel_sizes</span><span class="op">,</span> <span class="nam">strides</span><span class="op">=</span><span class="num">1</span><span class="op">,</span> <span class="nam">paddings</span><span class="op">=</span><span class="num">0</span><span class="op">,</span> <span class="nam">dilations</span><span class="op">=</span><span class="num">1</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15937" href="#t15937">15937</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15938" href="#t15938">15938</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15939" href="#t15939">15939</a></span><span class="t"><span class="str">    This op returns a col buffer of sliding local blocks of input x, also known</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15940" href="#t15940">15940</a></span><span class="t"><span class="str">    as im2col for batched 2D image tensors. For each block under the convolution filter,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15941" href="#t15941">15941</a></span><span class="t"><span class="str">    all element will be rearranged as a column. While the convolution filter sliding over</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15942" href="#t15942">15942</a></span><span class="t"><span class="str">    the input feature map, a series of such columns will be formed.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15943" href="#t15943">15943</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15944" href="#t15944">15944</a></span><span class="t"><span class="str">    For each input :math:`x` with shape [N, C, H, W], the output shape [N, Cout, Lout]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15945" href="#t15945">15945</a></span><span class="t"><span class="str">    can be calculated as following.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15946" href="#t15946">15946</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15947" href="#t15947">15947</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15948" href="#t15948">15948</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15949" href="#t15949">15949</a></span><span class="t"><span class="str">        dkernel[0] &amp;= dilations[0] \times (kernel\_sizes[0] - 1) + 1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15950" href="#t15950">15950</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15951" href="#t15951">15951</a></span><span class="t"><span class="str">        dkernel[1] &amp;= dilations[1] \times (kernel\_sizes[1] - 1) + 1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15952" href="#t15952">15952</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15953" href="#t15953">15953</a></span><span class="t"><span class="str">        hout &amp;= \frac{H + paddings[0] + paddings[2] - dkernel[0]}{strides[0]} + 1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15954" href="#t15954">15954</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15955" href="#t15955">15955</a></span><span class="t"><span class="str">        wout &amp;= \frac{W + paddings[1] + paddings[3] - dkernel[1]}{strides[1]} + 1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15956" href="#t15956">15956</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15957" href="#t15957">15957</a></span><span class="t"><span class="str">        Cout &amp;= C \times kernel\_sizes[0] \times kernel\_sizes[1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15958" href="#t15958">15958</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15959" href="#t15959">15959</a></span><span class="t"><span class="str">        Lout &amp;= hout \times wout</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15960" href="#t15960">15960</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15961" href="#t15961">15961</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15962" href="#t15962">15962</a></span><span class="t"><span class="str">    Parameters:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15963" href="#t15963">15963</a></span><span class="t"><span class="str">        x(Tensor):              4-D Tensor, input tensor of format [N, C, H, W],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15964" href="#t15964">15964</a></span><span class="t"><span class="str">                                  data type can be float32 or float64</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15965" href="#t15965">15965</a></span><span class="t"><span class="str">        kernel_sizes(int|list):   The size of convolution kernel, should be [k_h, k_w]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15966" href="#t15966">15966</a></span><span class="t"><span class="str">                                  or an integer k treated as [k, k].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15967" href="#t15967">15967</a></span><span class="t"><span class="str">        strides(int|list):        The strides, should be [stride_h, stride_w]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15968" href="#t15968">15968</a></span><span class="t"><span class="str">                                  or an integer stride treated as [sride, stride].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15969" href="#t15969">15969</a></span><span class="t"><span class="str">                                  For default, strides will be [1, 1].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15970" href="#t15970">15970</a></span><span class="t"><span class="str">        paddings(int|list):       The paddings of each dimension, should be</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15971" href="#t15971">15971</a></span><span class="t"><span class="str">                                  [padding_top, padding_left, padding_bottom, padding_right]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15972" href="#t15972">15972</a></span><span class="t"><span class="str">                                  or [padding_h, padding_w] or an integer padding.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15973" href="#t15973">15973</a></span><span class="t"><span class="str">                                  If [padding_h, padding_w] was given, it will expanded to</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15974" href="#t15974">15974</a></span><span class="t"><span class="str">                                  [padding_h, padding_w, padding_h, padding_w]. If an integer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15975" href="#t15975">15975</a></span><span class="t"><span class="str">                                  padding was given, [padding, padding, padding, padding] will</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15976" href="#t15976">15976</a></span><span class="t"><span class="str">                                  be used. For default, paddings will be [0, 0, 0, 0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15977" href="#t15977">15977</a></span><span class="t"><span class="str">        dilations(int|list):      the dilations of convolution kernel, should be</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15978" href="#t15978">15978</a></span><span class="t"><span class="str">                                  [dilation_h, dilation_w], or an integer dilation treated as</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15979" href="#t15979">15979</a></span><span class="t"><span class="str">                                  [dilation, dilation]. For default, it will be [1, 1].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15980" href="#t15980">15980</a></span><span class="t"><span class="str">        name(str, optional): The default value is None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15981" href="#t15981">15981</a></span><span class="t"><span class="str">                             Normally there is no need for user to set this property.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15982" href="#t15982">15982</a></span><span class="t"><span class="str">                             For more information, please refer to :ref:`api_guide_Name`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15983" href="#t15983">15983</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15984" href="#t15984">15984</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15985" href="#t15985">15985</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15986" href="#t15986">15986</a></span><span class="t"><span class="str">        The tensor corresponding to the sliding local blocks.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15987" href="#t15987">15987</a></span><span class="t"><span class="str">        The output shape is [N, Cout, Lout] as decriabled above.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15988" href="#t15988">15988</a></span><span class="t"><span class="str">        Cout is the  total number of values within each block,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15989" href="#t15989">15989</a></span><span class="t"><span class="str">        and Lout is the total number of such blocks.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15990" href="#t15990">15990</a></span><span class="t"><span class="str">        The data type of output is the same as the input :math:`x`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15991" href="#t15991">15991</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15992" href="#t15992">15992</a></span><span class="t"><span class="str">    Return Type:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15993" href="#t15993">15993</a></span><span class="t"><span class="str">        Tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15994" href="#t15994">15994</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15995" href="#t15995">15995</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15996" href="#t15996">15996</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15997" href="#t15997">15997</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15998" href="#t15998">15998</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15999" href="#t15999">15999</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16000" href="#t16000">16000</a></span><span class="t"><span class="str">            import paddle.nn.functional as F</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16001" href="#t16001">16001</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16002" href="#t16002">16002</a></span><span class="t"><span class="str">            x = paddle.randn((100,3,224,224))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16003" href="#t16003">16003</a></span><span class="t"><span class="str">            y = F.unfold(x, [3, 3], 1, 1, 1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16004" href="#t16004">16004</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16005" href="#t16005">16005</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16006" href="#t16006">16006</a></span><span class="t">    <span class="key">return</span> <span class="nam">paddle</span><span class="op">.</span><span class="nam">nn</span><span class="op">.</span><span class="nam">functional</span><span class="op">.</span><span class="nam">unfold</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16007" href="#t16007">16007</a></span><span class="t">        <span class="nam">x</span><span class="op">,</span> <span class="nam">kernel_sizes</span><span class="op">,</span> <span class="nam">strides</span><span class="op">,</span> <span class="nam">paddings</span><span class="op">,</span> <span class="nam">dilations</span><span class="op">,</span> <span class="nam">name</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16008" href="#t16008">16008</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16009" href="#t16009">16009</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16010" href="#t16010">16010</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16011" href="#t16011">16011</a></span><span class="t"><span class="key">def</span> <span class="nam">deformable_roi_pooling</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16012" href="#t16012">16012</a></span><span class="t">    <span class="nam">input</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16013" href="#t16013">16013</a></span><span class="t">    <span class="nam">rois</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16014" href="#t16014">16014</a></span><span class="t">    <span class="nam">trans</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16015" href="#t16015">16015</a></span><span class="t">    <span class="nam">no_trans</span><span class="op">=</span><span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16016" href="#t16016">16016</a></span><span class="t">    <span class="nam">spatial_scale</span><span class="op">=</span><span class="num">1.0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16017" href="#t16017">16017</a></span><span class="t">    <span class="nam">group_size</span><span class="op">=</span><span class="op">[</span><span class="num">1</span><span class="op">,</span> <span class="num">1</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16018" href="#t16018">16018</a></span><span class="t">    <span class="nam">pooled_height</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16019" href="#t16019">16019</a></span><span class="t">    <span class="nam">pooled_width</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16020" href="#t16020">16020</a></span><span class="t">    <span class="nam">part_size</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16021" href="#t16021">16021</a></span><span class="t">    <span class="nam">sample_per_part</span><span class="op">=</span><span class="num">1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16022" href="#t16022">16022</a></span><span class="t">    <span class="nam">trans_std</span><span class="op">=</span><span class="num">0.1</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16023" href="#t16023">16023</a></span><span class="t">    <span class="nam">position_sensitive</span><span class="op">=</span><span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16024" href="#t16024">16024</a></span><span class="t">    <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16025" href="#t16025">16025</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16026" href="#t16026">16026</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16027" href="#t16027">16027</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16028" href="#t16028">16028</a></span><span class="t"><span class="str">    Deformable ROI Pooling Layer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16029" href="#t16029">16029</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16030" href="#t16030">16030</a></span><span class="t"><span class="str">    Performs deformable region-of-interest pooling on inputs. As described</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16031" href="#t16031">16031</a></span><span class="t"><span class="str">    in `Deformable Convolutional Networks &lt;https://arxiv.org/abs/1703.06211>`_, it will get offset for each bin after</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16032" href="#t16032">16032</a></span><span class="t"><span class="str">    roi pooling so that pooling at correct region. Batch_size will change to the number of region bounding boxes after deformable_roi_pooling.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16033" href="#t16033">16033</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16034" href="#t16034">16034</a></span><span class="t"><span class="str">    The operation has three steps:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16035" href="#t16035">16035</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16036" href="#t16036">16036</a></span><span class="t"><span class="str">    1. Dividing each region proposal into equal-sized sections with the pooled_width and pooled_height.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16037" href="#t16037">16037</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16038" href="#t16038">16038</a></span><span class="t"><span class="str">    2. Add offset to pixel in ROI to get new location and the new value which are computed directly through</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16039" href="#t16039">16039</a></span><span class="t"><span class="str">       bilinear interpolation with four nearest pixel.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16040" href="#t16040">16040</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16041" href="#t16041">16041</a></span><span class="t"><span class="str">    3. Sample several points in each bin to get average values as output.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16042" href="#t16042">16042</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16043" href="#t16043">16043</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16044" href="#t16044">16044</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16045" href="#t16045">16045</a></span><span class="t"><span class="str">        input (Variable):The input of deformable roi pooling and it is tensor which value type is float32. The shape of input is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16046" href="#t16046">16046</a></span><span class="t"><span class="str">                         [N, C, H, W]. Where N is batch size, C is number of input channels,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16047" href="#t16047">16047</a></span><span class="t"><span class="str">                         H is height of the feature, and W is the width of the feature.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16048" href="#t16048">16048</a></span><span class="t"><span class="str">        rois (Variable): ROIs (Regions of Interest) with type float32 to pool over. It should be</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16049" href="#t16049">16049</a></span><span class="t"><span class="str">                         a 2-D LoDTensor of shape (num_rois, 4), and the lod level</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16050" href="#t16050">16050</a></span><span class="t"><span class="str">                         is 1. Given as [[x1, y1, x2, y2], ...], (x1, y1) is</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16051" href="#t16051">16051</a></span><span class="t"><span class="str">                         the top left coordinates, and (x2, y2) is the bottom</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16052" href="#t16052">16052</a></span><span class="t"><span class="str">                         right coordinates, which value type is float32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16053" href="#t16053">16053</a></span><span class="t"><span class="str">        trans (Variable): Offset of features on ROIs while pooling which value type is float32. The format is [N, C, H, W], where</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16054" href="#t16054">16054</a></span><span class="t"><span class="str">                          N is number of ROIs, C is number of channels, which indicate the offset distance</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16055" href="#t16055">16055</a></span><span class="t"><span class="str">                          in the x and y directions, H is pooled height, and W is pooled width.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16056" href="#t16056">16056</a></span><span class="t"><span class="str">        no_trans (bool): Whether to add offset to get new value or not while roi pooling, which value with type bool is True or False.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16057" href="#t16057">16057</a></span><span class="t"><span class="str">                         If value is True, no offset will be added in operation. Default: False.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16058" href="#t16058">16058</a></span><span class="t"><span class="str">        spatial_scale (float): Ratio of input feature map height (or width) to raw image height (or width), which value type is float32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16059" href="#t16059">16059</a></span><span class="t"><span class="str">                         Equals the reciprocal of total stride in convolutional layers, Default: 1.0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16060" href="#t16060">16060</a></span><span class="t"><span class="str">        group_size (list|tuple): The number of groups which input channels are divided and the input is list or tuple, which value type is int32. (eg.number of input channels</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16061" href="#t16061">16061</a></span><span class="t"><span class="str">                          is k1 * k2 * (C + 1), which k1 and k2 are group width and height and C+1 is number of output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16062" href="#t16062">16062</a></span><span class="t"><span class="str">                          channels.) eg.(4, 6), which 4 is height of group and 6 is width of group. Default: [1, 1].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16063" href="#t16063">16063</a></span><span class="t"><span class="str">        pooled_height (int): The pooled output height which value type is int32. Default: 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16064" href="#t16064">16064</a></span><span class="t"><span class="str">        pooled_width (int): The pooled output width which value type is int32. Default: 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16065" href="#t16065">16065</a></span><span class="t"><span class="str">        part_size (list|tuple): The height and width of offset which values in list or tuple is int32, eg.(4, 6), which height is 4 and width is 6, and values always equal to pooled_height \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16066" href="#t16066">16066</a></span><span class="t"><span class="str">                         and pooled_width. Default: if None, default value is [pooled_height, pooled_width].</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16067" href="#t16067">16067</a></span><span class="t"><span class="str">        sample_per_part (int): The number of samples in each bin which value type is int32. If value is bigger, it will consume more performance. Default: 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16068" href="#t16068">16068</a></span><span class="t"><span class="str">        trans_std (float): Coefficient of offset which value type is float32. It controls weight of offset. Default: 0.1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16069" href="#t16069">16069</a></span><span class="t"><span class="str">        position_sensitive (bool): Whether to choose deformable psroi pooling mode or not, and value type is bool(True or False). If value is False, input dimension equals to output dimension. \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16070" href="#t16070">16070</a></span><span class="t"><span class="str">                                   If value is True, input dimension should be output dimension * pooled_height * pooled_width. Default: False.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16071" href="#t16071">16071</a></span><span class="t"><span class="str">        name (str|None): Name of layer. Default: None.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16072" href="#t16072">16072</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16073" href="#t16073">16073</a></span><span class="t"><span class="str">        Variable: Output of deformable roi pooling is that, if position sensitive is False, input dimension equals to output dimension. If position sensitive is True,\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16074" href="#t16074">16074</a></span><span class="t"><span class="str">                  input dimension should be the result of output dimension divided by pooled height and pooled width.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16075" href="#t16075">16075</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16076" href="#t16076">16076</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16077" href="#t16077">16077</a></span><span class="t"><span class="str">      .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16078" href="#t16078">16078</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16079" href="#t16079">16079</a></span><span class="t"><span class="str">        # position_sensitive=True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16080" href="#t16080">16080</a></span><span class="t"><span class="str">        import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16081" href="#t16081">16081</a></span><span class="t"><span class="str">        input = fluid.data(name="input",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16082" href="#t16082">16082</a></span><span class="t"><span class="str">                           shape=[2, 192, 64, 64],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16083" href="#t16083">16083</a></span><span class="t"><span class="str">                           dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16084" href="#t16084">16084</a></span><span class="t"><span class="str">        rois = fluid.data(name="rois",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16085" href="#t16085">16085</a></span><span class="t"><span class="str">                          shape=[-1, 4],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16086" href="#t16086">16086</a></span><span class="t"><span class="str">                          dtype='float32',</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16087" href="#t16087">16087</a></span><span class="t"><span class="str">                          lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16088" href="#t16088">16088</a></span><span class="t"><span class="str">        trans = fluid.data(name="trans",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16089" href="#t16089">16089</a></span><span class="t"><span class="str">                           shape=[2, 384, 64, 64],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16090" href="#t16090">16090</a></span><span class="t"><span class="str">                           dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16091" href="#t16091">16091</a></span><span class="t"><span class="str">        x = fluid.layers.deformable_roi_pooling(input=input,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16092" href="#t16092">16092</a></span><span class="t"><span class="str">                                                rois=rois,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16093" href="#t16093">16093</a></span><span class="t"><span class="str">                                                trans=trans,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16094" href="#t16094">16094</a></span><span class="t"><span class="str">                                                no_trans=False,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16095" href="#t16095">16095</a></span><span class="t"><span class="str">                                                spatial_scale=1.0,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16096" href="#t16096">16096</a></span><span class="t"><span class="str">                                                group_size=(1, 1),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16097" href="#t16097">16097</a></span><span class="t"><span class="str">                                                pooled_height=8,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16098" href="#t16098">16098</a></span><span class="t"><span class="str">                                                pooled_width=8,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16099" href="#t16099">16099</a></span><span class="t"><span class="str">                                                part_size=(8, 8),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16100" href="#t16100">16100</a></span><span class="t"><span class="str">                                                sample_per_part=4,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16101" href="#t16101">16101</a></span><span class="t"><span class="str">                                                trans_std=0.1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16102" href="#t16102">16102</a></span><span class="t"><span class="str">                                                position_sensitive=True)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16103" href="#t16103">16103</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16104" href="#t16104">16104</a></span><span class="t"><span class="str">        # position_sensitive=False</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16105" href="#t16105">16105</a></span><span class="t"><span class="str">        import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16106" href="#t16106">16106</a></span><span class="t"><span class="str">        input = fluid.data(name="input",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16107" href="#t16107">16107</a></span><span class="t"><span class="str">                           shape=[2, 192, 64, 64],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16108" href="#t16108">16108</a></span><span class="t"><span class="str">                           dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16109" href="#t16109">16109</a></span><span class="t"><span class="str">        rois = fluid.data(name="rois",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16110" href="#t16110">16110</a></span><span class="t"><span class="str">                          shape=[-1, 4],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16111" href="#t16111">16111</a></span><span class="t"><span class="str">                          dtype='float32',</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16112" href="#t16112">16112</a></span><span class="t"><span class="str">                          lod_level=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16113" href="#t16113">16113</a></span><span class="t"><span class="str">        trans = fluid.data(name="trans",</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16114" href="#t16114">16114</a></span><span class="t"><span class="str">                           shape=[2, 384, 64, 64],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16115" href="#t16115">16115</a></span><span class="t"><span class="str">                           dtype='float32')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16116" href="#t16116">16116</a></span><span class="t"><span class="str">        x = fluid.layers.deformable_roi_pooling(input=input,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16117" href="#t16117">16117</a></span><span class="t"><span class="str">                                                rois=rois,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16118" href="#t16118">16118</a></span><span class="t"><span class="str">                                                trans=trans,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16119" href="#t16119">16119</a></span><span class="t"><span class="str">                                                no_trans=False,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16120" href="#t16120">16120</a></span><span class="t"><span class="str">                                                spatial_scale=1.0,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16121" href="#t16121">16121</a></span><span class="t"><span class="str">                                                group_size=(1, 1),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16122" href="#t16122">16122</a></span><span class="t"><span class="str">                                                pooled_height=8,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16123" href="#t16123">16123</a></span><span class="t"><span class="str">                                                pooled_width=8,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16124" href="#t16124">16124</a></span><span class="t"><span class="str">                                                part_size=(8, 8),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16125" href="#t16125">16125</a></span><span class="t"><span class="str">                                                sample_per_part=4,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16126" href="#t16126">16126</a></span><span class="t"><span class="str">                                                trans_std=0.1,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16127" href="#t16127">16127</a></span><span class="t"><span class="str">                                                position_sensitive=False)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16128" href="#t16128">16128</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16129" href="#t16129">16129</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16130" href="#t16130">16130</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16131" href="#t16131">16131</a></span><span class="t">        <span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'deformable_roi_pooling'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16132" href="#t16132">16132</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16133" href="#t16133">16133</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16134" href="#t16134">16134</a></span><span class="t">        <span class="nam">rois</span><span class="op">,</span> <span class="str">'rois'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'deformable_roi_pooling'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16135" href="#t16135">16135</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16136" href="#t16136">16136</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16137" href="#t16137">16137</a></span><span class="t">        <span class="nam">trans</span><span class="op">,</span> <span class="str">'trans'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'deformable_roi_pooling'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16138" href="#t16138">16138</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16139" href="#t16139">16139</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16140" href="#t16140">16140</a></span><span class="t">        <span class="nam">group_size</span><span class="op">,</span> <span class="str">'group_size'</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">,</span> <span class="str">'deformable_roi_pooling'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16141" href="#t16141">16141</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16142" href="#t16142">16142</a></span><span class="t">    <span class="key">if</span> <span class="nam">part_size</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16143" href="#t16143">16143</a></span><span class="t">        <span class="nam">check_type</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16144" href="#t16144">16144</a></span><span class="t">            <span class="nam">part_size</span><span class="op">,</span> <span class="str">'part_size'</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">,</span> <span class="str">'deformable_roi_pooling'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16145" href="#t16145">16145</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16146" href="#t16146">16146</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16147" href="#t16147">16147</a></span><span class="t">    <span class="nam">input_channels</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16148" href="#t16148">16148</a></span><span class="t">    <span class="key">if</span> <span class="nam">position_sensitive</span> <span class="op">==</span> <span class="key">False</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16149" href="#t16149">16149</a></span><span class="t">        <span class="nam">output_channels</span> <span class="op">=</span> <span class="nam">input_channels</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16150" href="#t16150">16150</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16151" href="#t16151">16151</a></span><span class="t">        <span class="nam">output_channels</span> <span class="op">=</span> <span class="nam">input_channels</span> <span class="op">/</span> <span class="nam">pooled_height</span> <span class="op">/</span> <span class="nam">pooled_width</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16152" href="#t16152">16152</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16153" href="#t16153">16153</a></span><span class="t">    <span class="key">if</span> <span class="nam">part_size</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16154" href="#t16154">16154</a></span><span class="t">        <span class="nam">part_height</span> <span class="op">=</span> <span class="nam">pooled_height</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16155" href="#t16155">16155</a></span><span class="t">        <span class="nam">part_width</span> <span class="op">=</span> <span class="nam">pooled_width</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16156" href="#t16156">16156</a></span><span class="t">        <span class="nam">part_size</span> <span class="op">=</span> <span class="op">[</span><span class="nam">part_height</span><span class="op">,</span> <span class="nam">part_width</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16157" href="#t16157">16157</a></span><span class="t">    <span class="nam">part_size</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">part_size</span><span class="op">,</span> <span class="num">2</span><span class="op">,</span> <span class="str">'part_size'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16158" href="#t16158">16158</a></span><span class="t">    <span class="nam">group_size</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_to_list</span><span class="op">(</span><span class="nam">group_size</span><span class="op">,</span> <span class="num">2</span><span class="op">,</span> <span class="str">'group_size'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16159" href="#t16159">16159</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'deformable_psroi_pooling'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16160" href="#t16160">16160</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16161" href="#t16161">16161</a></span><span class="t">    <span class="nam">output</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16162" href="#t16162">16162</a></span><span class="t">    <span class="nam">top_count</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="str">'int32'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16163" href="#t16163">16163</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16164" href="#t16164">16164</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"deformable_psroi_pooling"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16165" href="#t16165">16165</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Input"</span><span class="op">:</span> <span class="nam">input</span><span class="op">,</span> <span class="str">"ROIs"</span><span class="op">:</span> <span class="nam">rois</span><span class="op">,</span> <span class="str">"Trans"</span><span class="op">:</span> <span class="nam">trans</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16166" href="#t16166">16166</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Output"</span><span class="op">:</span> <span class="nam">output</span><span class="op">,</span> <span class="str">"TopCount"</span><span class="op">:</span> <span class="nam">top_count</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16167" href="#t16167">16167</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16168" href="#t16168">16168</a></span><span class="t">            <span class="str">"no_trans"</span><span class="op">:</span> <span class="nam">no_trans</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16169" href="#t16169">16169</a></span><span class="t">            <span class="str">"spatial_scale"</span><span class="op">:</span> <span class="nam">spatial_scale</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16170" href="#t16170">16170</a></span><span class="t">            <span class="str">"output_dim"</span><span class="op">:</span> <span class="nam">output_channels</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16171" href="#t16171">16171</a></span><span class="t">            <span class="str">"group_size"</span><span class="op">:</span> <span class="nam">group_size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16172" href="#t16172">16172</a></span><span class="t">            <span class="str">"pooled_height"</span><span class="op">:</span> <span class="nam">pooled_height</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16173" href="#t16173">16173</a></span><span class="t">            <span class="str">"pooled_width"</span><span class="op">:</span> <span class="nam">pooled_width</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16174" href="#t16174">16174</a></span><span class="t">            <span class="str">"part_size"</span><span class="op">:</span> <span class="nam">part_size</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16175" href="#t16175">16175</a></span><span class="t">            <span class="str">"sample_per_part"</span><span class="op">:</span> <span class="nam">sample_per_part</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16176" href="#t16176">16176</a></span><span class="t">            <span class="str">"trans_std"</span><span class="op">:</span> <span class="nam">trans_std</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16177" href="#t16177">16177</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16178" href="#t16178">16178</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16179" href="#t16179">16179</a></span><span class="t">    <span class="key">return</span> <span class="nam">output</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16180" href="#t16180">16180</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16181" href="#t16181">16181</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16182" href="#t16182">16182</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.shard_index"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16183" href="#t16183">16183</a></span><span class="t"><span class="key">def</span> <span class="nam">shard_index</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">index_num</span><span class="op">,</span> <span class="nam">nshards</span><span class="op">,</span> <span class="nam">shard_id</span><span class="op">,</span> <span class="nam">ignore_value</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16184" href="#t16184">16184</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16185" href="#t16185">16185</a></span><span class="t"><span class="str">    Reset the values of `input` according to the shard it beloning to.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16186" href="#t16186">16186</a></span><span class="t"><span class="str">    Every value in `input` must be a non-negative integer, and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16187" href="#t16187">16187</a></span><span class="t"><span class="str">    the parameter `index_num` represents the integer above the maximum</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16188" href="#t16188">16188</a></span><span class="t"><span class="str">    value of `input`. Thus, all values in `input` must be in the range</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16189" href="#t16189">16189</a></span><span class="t"><span class="str">    [0, index_num) and each value can be regarded as the offset to the beginning</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16190" href="#t16190">16190</a></span><span class="t"><span class="str">    of the range. The range is further split into multiple shards. Specifically,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16191" href="#t16191">16191</a></span><span class="t"><span class="str">    we first compute the `shard_size` according to the following formula,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16192" href="#t16192">16192</a></span><span class="t"><span class="str">    which represents the number of integers each shard can hold. So for the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16193" href="#t16193">16193</a></span><span class="t"><span class="str">    i'th shard, it can hold values in the range [i*shard_size, (i+1)*shard_size).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16194" href="#t16194">16194</a></span><span class="t"><span class="str">    ::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16195" href="#t16195">16195</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16196" href="#t16196">16196</a></span><span class="t"><span class="str">        shard_size = (index_num + nshards - 1) // nshards</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16197" href="#t16197">16197</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16198" href="#t16198">16198</a></span><span class="t"><span class="str">    For each value `v` in `input`, we reset it to a new value according to the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16199" href="#t16199">16199</a></span><span class="t"><span class="str">    following formula:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16200" href="#t16200">16200</a></span><span class="t"><span class="str">    ::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16201" href="#t16201">16201</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16202" href="#t16202">16202</a></span><span class="t"><span class="str">        v = v - shard_id * shard_size if shard_id * shard_size &lt;= v &lt; (shard_id+1) * shard_size else ignore_value</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16203" href="#t16203">16203</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16204" href="#t16204">16204</a></span><span class="t"><span class="str">    That is, the value `v` is set to the new offset within the range represented by the shard `shard_id`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16205" href="#t16205">16205</a></span><span class="t"><span class="str">    if it in the range. Otherwise, we reset it to be `ignore_value`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16206" href="#t16206">16206</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16207" href="#t16207">16207</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16208" href="#t16208">16208</a></span><span class="t"><span class="str">        input (Tensor): Input tensor with data type int64 or int32. It's last dimension must be 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16209" href="#t16209">16209</a></span><span class="t"><span class="str">        index_num (int): An integer represents the integer above the maximum value of `input`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16210" href="#t16210">16210</a></span><span class="t"><span class="str">        nshards (int): The number of shards.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16211" href="#t16211">16211</a></span><span class="t"><span class="str">        shard_id (int): The index of the current shard.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16212" href="#t16212">16212</a></span><span class="t"><span class="str">        ignore_value (int): An integer value out of sharded index range.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16213" href="#t16213">16213</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16214" href="#t16214">16214</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16215" href="#t16215">16215</a></span><span class="t"><span class="str">        Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16216" href="#t16216">16216</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16217" href="#t16217">16217</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16218" href="#t16218">16218</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16219" href="#t16219">16219</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16220" href="#t16220">16220</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16221" href="#t16221">16221</a></span><span class="t"><span class="str">            label = paddle.to_tensor([[16], [1]], "int64")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16222" href="#t16222">16222</a></span><span class="t"><span class="str">            shard_label = paddle.shard_index(input=label,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16223" href="#t16223">16223</a></span><span class="t"><span class="str">                                             index_num=20,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16224" href="#t16224">16224</a></span><span class="t"><span class="str">                                             nshards=2,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16225" href="#t16225">16225</a></span><span class="t"><span class="str">                                             shard_id=0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16226" href="#t16226">16226</a></span><span class="t"><span class="str">            print(shard_label)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16227" href="#t16227">16227</a></span><span class="t"><span class="str">            # [[-1], [1]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16228" href="#t16228">16228</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16229" href="#t16229">16229</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16230" href="#t16230">16230</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">shard_index</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16231" href="#t16231">16231</a></span><span class="t">            <span class="nam">input</span><span class="op">,</span> <span class="nam">index_num</span><span class="op">,</span> <span class="nam">nshards</span><span class="op">,</span> <span class="nam">shard_id</span><span class="op">,</span> <span class="nam">ignore_value</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16232" href="#t16232">16232</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16233" href="#t16233">16233</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16234" href="#t16234">16234</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">[</span><span class="str">'int64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">]</span><span class="op">,</span> <span class="str">'shard_index'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16235" href="#t16235">16235</a></span><span class="t">    <span class="nam">op_type</span> <span class="op">=</span> <span class="str">'shard_index'</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16236" href="#t16236">16236</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="nam">op_type</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16237" href="#t16237">16237</a></span><span class="t">    <span class="key">if</span> <span class="nam">shard_id</span> <span class="op">&lt;</span> <span class="num">0</span> <span class="key">or</span> <span class="nam">shard_id</span> <span class="op">>=</span> <span class="nam">nshards</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16238" href="#t16238">16238</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16239" href="#t16239">16239</a></span><span class="t">            <span class="str">'The shard_id(%d) should be in [0, %d)'</span> <span class="op">%</span> <span class="op">(</span><span class="nam">shard_id</span><span class="op">,</span> <span class="nam">nshards</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16240" href="#t16240">16240</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16241" href="#t16241">16241</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16242" href="#t16242">16242</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">input</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16243" href="#t16243">16243</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16244" href="#t16244">16244</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="nam">op_type</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16245" href="#t16245">16245</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="op">[</span><span class="nam">input</span><span class="op">]</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16246" href="#t16246">16246</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16247" href="#t16247">16247</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16248" href="#t16248">16248</a></span><span class="t">            <span class="str">'index_num'</span><span class="op">:</span> <span class="nam">index_num</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16249" href="#t16249">16249</a></span><span class="t">            <span class="str">'nshards'</span><span class="op">:</span> <span class="nam">nshards</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16250" href="#t16250">16250</a></span><span class="t">            <span class="str">'shard_id'</span><span class="op">:</span> <span class="nam">shard_id</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16251" href="#t16251">16251</a></span><span class="t">            <span class="str">'ignore_value'</span><span class="op">:</span> <span class="nam">ignore_value</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16252" href="#t16252">16252</a></span><span class="t">        <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16253" href="#t16253">16253</a></span><span class="t">        <span class="nam">stop_gradient</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16254" href="#t16254">16254</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16255" href="#t16255">16255</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16256" href="#t16256">16256</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16257" href="#t16257">16257</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16258" href="#t16258">16258</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16259" href="#t16259">16259</a></span><span class="t"><span class="key">def</span> <span class="nam">hard_swish</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">threshold</span><span class="op">=</span><span class="num">6.0</span><span class="op">,</span> <span class="nam">scale</span><span class="op">=</span><span class="num">6.0</span><span class="op">,</span> <span class="nam">offset</span><span class="op">=</span><span class="num">3.0</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16260" href="#t16260">16260</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16261" href="#t16261">16261</a></span><span class="t"><span class="str">    This operator implements the hard_swish activation function.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16262" href="#t16262">16262</a></span><span class="t"><span class="str">    Hard_swish is proposed in MobileNetV3, and performs better in computational stability and efficiency compared to swish function.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16263" href="#t16263">16263</a></span><span class="t"><span class="str">    For more details please refer to: https://arxiv.org/pdf/1905.02244.pdf</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16264" href="#t16264">16264</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16265" href="#t16265">16265</a></span><span class="t"><span class="str">    The formula is as follows:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16266" href="#t16266">16266</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16267" href="#t16267">16267</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16268" href="#t16268">16268</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16269" href="#t16269">16269</a></span><span class="t"><span class="str">        out = \\frac{x * (min(max(0, x+offset), threshold))}{scale}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16270" href="#t16270">16270</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16271" href="#t16271">16271</a></span><span class="t"><span class="str">    In the above equation:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16272" href="#t16272">16272</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16273" href="#t16273">16273</a></span><span class="t"><span class="str">    ``threshold`` and ``scale`` should be positive, ``offset`` can be positive or negative. It is recommended to use default parameters.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16274" href="#t16274">16274</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16275" href="#t16275">16275</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16276" href="#t16276">16276</a></span><span class="t"><span class="str">        x (Variable): Input feature, multi-dimensional Tensor. The data type should be float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16277" href="#t16277">16277</a></span><span class="t"><span class="str">        threshold (float, optional): The threshold in Relu function. Default: 6.0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16278" href="#t16278">16278</a></span><span class="t"><span class="str">        scale (float, optional): The scale factor. Default: 6.0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16279" href="#t16279">16279</a></span><span class="t"><span class="str">        offset (float, optional): The offset factor. Default: 3.0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16280" href="#t16280">16280</a></span><span class="t"><span class="str">        name (str, optional): The default value is None. Normally there is no need for user to set this property. For more information, please refer to :ref:`api_guide_Name`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16281" href="#t16281">16281</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16282" href="#t16282">16282</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16283" href="#t16283">16283</a></span><span class="t"><span class="str">        Variable: The output tensor with the same shape and data type as input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16284" href="#t16284">16284</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16285" href="#t16285">16285</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16286" href="#t16286">16286</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16287" href="#t16287">16287</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16288" href="#t16288">16288</a></span><span class="t"><span class="str">    .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16289" href="#t16289">16289</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16290" href="#t16290">16290</a></span><span class="t"><span class="str">        import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16291" href="#t16291">16291</a></span><span class="t"><span class="str">        import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16292" href="#t16292">16292</a></span><span class="t"><span class="str">        import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16293" href="#t16293">16293</a></span><span class="t"><span class="str">        paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16294" href="#t16294">16294</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16295" href="#t16295">16295</a></span><span class="t"><span class="str">        DATATYPE='float32'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16296" href="#t16296">16296</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16297" href="#t16297">16297</a></span><span class="t"><span class="str">        x_data = np.array([i for i in range(1,5)]).reshape([1,1,4]).astype(DATATYPE)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16298" href="#t16298">16298</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16299" href="#t16299">16299</a></span><span class="t"><span class="str">        x = fluid.data(name="x", shape=[None,1,4], dtype=DATATYPE)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16300" href="#t16300">16300</a></span><span class="t"><span class="str">        y = fluid.layers.hard_swish(x)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16301" href="#t16301">16301</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16302" href="#t16302">16302</a></span><span class="t"><span class="str">        place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16303" href="#t16303">16303</a></span><span class="t"><span class="str">        #place = fluid.CUDAPlace(0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16304" href="#t16304">16304</a></span><span class="t"><span class="str">        exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16305" href="#t16305">16305</a></span><span class="t"><span class="str">        out, = exe.run(feed={'x':x_data}, fetch_list=[y.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16306" href="#t16306">16306</a></span><span class="t"><span class="str">        print(out)  # [[0.66666667, 1.66666667,3., 4.]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16307" href="#t16307">16307</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16308" href="#t16308">16308</a></span><span class="t">    <span class="key">if</span> <span class="nam">_non_static_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16309" href="#t16309">16309</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">hard_swish</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16310" href="#t16310">16310</a></span><span class="t">            <span class="nam">x</span><span class="op">,</span> <span class="str">'threshold'</span><span class="op">,</span> <span class="nam">threshold</span><span class="op">,</span> <span class="str">'scale'</span><span class="op">,</span> <span class="nam">scale</span><span class="op">,</span> <span class="str">'offset'</span><span class="op">,</span> <span class="nam">offset</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16311" href="#t16311">16311</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16312" href="#t16312">16312</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16313" href="#t16313">16313</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16314" href="#t16314">16314</a></span><span class="t">        <span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float16'</span><span class="op">,</span> <span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'hard_swish'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16315" href="#t16315">16315</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16316" href="#t16316">16316</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16317" href="#t16317">16317</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'hard_swish'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16318" href="#t16318">16318</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16319" href="#t16319">16319</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16320" href="#t16320">16320</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'hard_swish'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16321" href="#t16321">16321</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16322" href="#t16322">16322</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16323" href="#t16323">16323</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'threshold'</span><span class="op">:</span> <span class="nam">threshold</span><span class="op">,</span> <span class="str">'scale'</span><span class="op">:</span> <span class="nam">scale</span><span class="op">,</span> <span class="str">'offset'</span><span class="op">:</span> <span class="nam">offset</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16324" href="#t16324">16324</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16325" href="#t16325">16325</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16326" href="#t16326">16326</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16327" href="#t16327">16327</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16328" href="#t16328">16328</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16329" href="#t16329">16329</a></span><span class="t"><span class="key">def</span> <span class="nam">mish</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">threshold</span><span class="op">=</span><span class="num">20</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16330" href="#t16330">16330</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16331" href="#t16331">16331</a></span><span class="t"><span class="str">    This operator implements the mish activation function.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16332" href="#t16332">16332</a></span><span class="t"><span class="str">    Refer to `Mish: A Self Regularized Non-Monotonic Neural</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16333" href="#t16333">16333</a></span><span class="t"><span class="str">    Activation Function &lt;https://arxiv.org/abs/1908.08681>`_</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16334" href="#t16334">16334</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16335" href="#t16335">16335</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16336" href="#t16336">16336</a></span><span class="t"><span class="str">    The formula is as follows if :attr:`threshold` is :code:`None` or negative:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16337" href="#t16337">16337</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16338" href="#t16338">16338</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16339" href="#t16339">16339</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16340" href="#t16340">16340</a></span><span class="t"><span class="str">        out = x * \\tanh(\\ln(1 + e^{x}))</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16341" href="#t16341">16341</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16342" href="#t16342">16342</a></span><span class="t"><span class="str">    The formula is as follows if :attr:`threshold` is set as positive value:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16343" href="#t16343">16343</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16344" href="#t16344">16344</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16345" href="#t16345">16345</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16346" href="#t16346">16346</a></span><span class="t"><span class="str">        out = \\begin{cases}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16347" href="#t16347">16347</a></span><span class="t"><span class="str">                x \\ast \\tanh(x), \\text{if } x > \\text{threshold} \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16348" href="#t16348">16348</a></span><span class="t"><span class="str">                x \\ast \\tanh(e^{x}), \\text{if } x &lt; -\\text{threshold} \\\\</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16349" href="#t16349">16349</a></span><span class="t"><span class="str">                x \\ast \\tanh(\\ln(1 + e^{x})),  \\text{otherwise}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16350" href="#t16350">16350</a></span><span class="t"><span class="str">              \\end{cases}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16351" href="#t16351">16351</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16352" href="#t16352">16352</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16353" href="#t16353">16353</a></span><span class="t"><span class="str">        x (Variable): Input feature, multi-dimensional Tensor. The data type</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16354" href="#t16354">16354</a></span><span class="t"><span class="str">                      should be float16, float32 or float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16355" href="#t16355">16355</a></span><span class="t"><span class="str">        threshold (float|None): threshold for softplus in Mish operator.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16356" href="#t16356">16356</a></span><span class="t"><span class="str">                Approximate value of softplus will be used if absolute value</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16357" href="#t16357">16357</a></span><span class="t"><span class="str">                of input is greater than :attr:threshold and :attr:threshold</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16358" href="#t16358">16358</a></span><span class="t"><span class="str">                is set as positive value. For none or negative threshold,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16359" href="#t16359">16359</a></span><span class="t"><span class="str">                approximate value is not used. Default 20.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16360" href="#t16360">16360</a></span><span class="t"><span class="str">        name (str, optional): The default value is None. Normally there is no</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16361" href="#t16361">16361</a></span><span class="t"><span class="str">                need for user to set this property. For more information, please</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16362" href="#t16362">16362</a></span><span class="t"><span class="str">                refer to :ref:`api_guide_Name`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16363" href="#t16363">16363</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16364" href="#t16364">16364</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16365" href="#t16365">16365</a></span><span class="t"><span class="str">        Variable: The output tensor with the same shape and data type as input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16366" href="#t16366">16366</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16367" href="#t16367">16367</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16368" href="#t16368">16368</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16369" href="#t16369">16369</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16370" href="#t16370">16370</a></span><span class="t"><span class="str">    .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16371" href="#t16371">16371</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16372" href="#t16372">16372</a></span><span class="t"><span class="str">        import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16373" href="#t16373">16373</a></span><span class="t"><span class="str">        import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16374" href="#t16374">16374</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16375" href="#t16375">16375</a></span><span class="t"><span class="str">        DATATYPE='float32'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16376" href="#t16376">16376</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16377" href="#t16377">16377</a></span><span class="t"><span class="str">        x_data = np.array([i for i in range(1,5)]).reshape([1,1,4]).astype(DATATYPE)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16378" href="#t16378">16378</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16379" href="#t16379">16379</a></span><span class="t"><span class="str">        x = fluid.data(name="x", shape=[None,1,4], dtype=DATATYPE)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16380" href="#t16380">16380</a></span><span class="t"><span class="str">        y = fluid.layers.mish(x)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16381" href="#t16381">16381</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16382" href="#t16382">16382</a></span><span class="t"><span class="str">        place = fluid.CPUPlace()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16383" href="#t16383">16383</a></span><span class="t"><span class="str">        # place = fluid.CUDAPlace(0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16384" href="#t16384">16384</a></span><span class="t"><span class="str">        exe = fluid.Executor(place)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16385" href="#t16385">16385</a></span><span class="t"><span class="str">        out, = exe.run(feed={'x':x_data}, fetch_list=[y.name])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16386" href="#t16386">16386</a></span><span class="t"><span class="str">        print(out)  # [[0.66666667, 1.66666667, 3., 4.]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16387" href="#t16387">16387</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16388" href="#t16388">16388</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16389" href="#t16389">16389</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">mish</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">threshold</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16390" href="#t16390">16390</a></span><span class="t">    <span class="key">if</span> <span class="nam">_in_legacy_dygraph</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16391" href="#t16391">16391</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">mish</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'threshold'</span><span class="op">,</span> <span class="nam">threshold</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16392" href="#t16392">16392</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16393" href="#t16393">16393</a></span><span class="t">    <span class="nam">check_variable_and_dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="str">'x'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'mish'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16394" href="#t16394">16394</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">threshold</span><span class="op">,</span> <span class="str">'threshold'</span><span class="op">,</span> <span class="op">(</span><span class="nam">float</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">,</span> <span class="str">'mish'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16395" href="#t16395">16395</a></span><span class="t">    <span class="key">assert</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16396" href="#t16396">16396</a></span><span class="t">        <span class="nam">threshold</span> <span class="op">></span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16397" href="#t16397">16397</a></span><span class="t">    <span class="op">)</span><span class="op">,</span> <span class="str">"threshold of mish should be greater than 0, "</span> <span class="str">"but got {}"</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16398" href="#t16398">16398</a></span><span class="t">        <span class="nam">threshold</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16399" href="#t16399">16399</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16400" href="#t16400">16400</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16401" href="#t16401">16401</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">'mish'</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16402" href="#t16402">16402</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">x</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16403" href="#t16403">16403</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16404" href="#t16404">16404</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">'mish'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16405" href="#t16405">16405</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">'X'</span><span class="op">:</span> <span class="nam">x</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16406" href="#t16406">16406</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">'Out'</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16407" href="#t16407">16407</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">'threshold'</span><span class="op">:</span> <span class="nam">threshold</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16408" href="#t16408">16408</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16409" href="#t16409">16409</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16410" href="#t16410">16410</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16411" href="#t16411">16411</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16412" href="#t16412">16412</a></span><span class="t"><span class="key">def</span> <span class="nam">gather_tree</span><span class="op">(</span><span class="nam">ids</span><span class="op">,</span> <span class="nam">parents</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16413" href="#t16413">16413</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16414" href="#t16414">16414</a></span><span class="t"><span class="str">    To be used after beam search. After beam search, we get selected ids at</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16415" href="#t16415">16415</a></span><span class="t"><span class="str">    each time step and the corresponding parents in the search tree. Both ids</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16416" href="#t16416">16416</a></span><span class="t"><span class="str">    and parents have the layout :attr:`[max_time, batch_size, beam_size]`. Then</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16417" href="#t16417">16417</a></span><span class="t"><span class="str">    :attr:`gather_tree` is used to backtrace from the last time step and</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16418" href="#t16418">16418</a></span><span class="t"><span class="str">    generate the full sequences by collecting selected ids.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16419" href="#t16419">16419</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16420" href="#t16420">16420</a></span><span class="t"><span class="str">    Here is an example:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16421" href="#t16421">16421</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16422" href="#t16422">16422</a></span><span class="t"><span class="str">    .. code-block:: text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16423" href="#t16423">16423</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16424" href="#t16424">16424</a></span><span class="t"><span class="str">            Given:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16425" href="#t16425">16425</a></span><span class="t"><span class="str">                ids = [[[2 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16426" href="#t16426">16426</a></span><span class="t"><span class="str">                        [6 1]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16427" href="#t16427">16427</a></span><span class="t"><span class="str">                       [[3 9]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16428" href="#t16428">16428</a></span><span class="t"><span class="str">                        [6 1]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16429" href="#t16429">16429</a></span><span class="t"><span class="str">                       [[0 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16430" href="#t16430">16430</a></span><span class="t"><span class="str">                        [9 0]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16431" href="#t16431">16431</a></span><span class="t"><span class="str">                parents = [[[0 0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16432" href="#t16432">16432</a></span><span class="t"><span class="str">                            [1 1]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16433" href="#t16433">16433</a></span><span class="t"><span class="str">                           [[1 0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16434" href="#t16434">16434</a></span><span class="t"><span class="str">                            [1 0]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16435" href="#t16435">16435</a></span><span class="t"><span class="str">                           [[0 0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16436" href="#t16436">16436</a></span><span class="t"><span class="str">                            [0 1]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16437" href="#t16437">16437</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16438" href="#t16438">16438</a></span><span class="t"><span class="str">            Then:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16439" href="#t16439">16439</a></span><span class="t"><span class="str">                gather_tree(ids, parents)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16440" href="#t16440">16440</a></span><span class="t"><span class="str">                         = [[[2 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16441" href="#t16441">16441</a></span><span class="t"><span class="str">                             [1 6]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16442" href="#t16442">16442</a></span><span class="t"><span class="str">                            [[3 3]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16443" href="#t16443">16443</a></span><span class="t"><span class="str">                             [6 1]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16444" href="#t16444">16444</a></span><span class="t"><span class="str">                            [[0 1]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16445" href="#t16445">16445</a></span><span class="t"><span class="str">                             [9 0]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16446" href="#t16446">16446</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16447" href="#t16447">16447</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16448" href="#t16448">16448</a></span><span class="t"><span class="str">        ids(Tensor): A Tensor with shape :attr:`[length, batch_size, beam_size]`</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16449" href="#t16449">16449</a></span><span class="t"><span class="str">            and data type :attr:`int32` or :attr:`int64`. It contains the selected</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16450" href="#t16450">16450</a></span><span class="t"><span class="str">            ids of all time steps.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16451" href="#t16451">16451</a></span><span class="t"><span class="str">        parents(Tensor): A Tensor with the same shape and data type as :attr:`ids`,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16452" href="#t16452">16452</a></span><span class="t"><span class="str">            It contains the parents corresponding to selected ids when searching</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16453" href="#t16453">16453</a></span><span class="t"><span class="str">            among beams.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16454" href="#t16454">16454</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16455" href="#t16455">16455</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16456" href="#t16456">16456</a></span><span class="t"><span class="str">            A Tensor with the same shape and data type as :attr:`ids`. \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16457" href="#t16457">16457</a></span><span class="t"><span class="str">            It contains the full sequences. The sequences are collected from \</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16458" href="#t16458">16458</a></span><span class="t"><span class="str">            :attr:`ids` by backtracing according to :attr:`parents`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16459" href="#t16459">16459</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16460" href="#t16460">16460</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16461" href="#t16461">16461</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16462" href="#t16462">16462</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16463" href="#t16463">16463</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16464" href="#t16464">16464</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16465" href="#t16465">16465</a></span><span class="t"><span class="str">            ids = paddle.to_tensor([[[2, 2], [6, 1]], [[3, 9], [6, 1]], [[0, 1], [9, 0]]])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16466" href="#t16466">16466</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16467" href="#t16467">16467</a></span><span class="t"><span class="str">            parents = paddle.to_tensor([[[0, 0], [1, 1]], [[1, 0], [1, 0]], [[0, 0], [0, 1]]])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16468" href="#t16468">16468</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16469" href="#t16469">16469</a></span><span class="t"><span class="str">            final_sequences = paddle.nn.functional.gather_tree(ids, parents)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16470" href="#t16470">16470</a></span><span class="t"><span class="str">            # [[[2, 2], [1, 6]], [[3, 3], [6, 1]], [[0, 1], [9, 0]]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16471" href="#t16471">16471</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16472" href="#t16472">16472</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16473" href="#t16473">16473</a></span><span class="t">    <span class="key">return</span> <span class="nam">paddle</span><span class="op">.</span><span class="nam">nn</span><span class="op">.</span><span class="nam">functional</span><span class="op">.</span><span class="nam">gather_tree</span><span class="op">(</span><span class="nam">ids</span><span class="op">,</span> <span class="nam">parents</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16474" href="#t16474">16474</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16475" href="#t16475">16475</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16476" href="#t16476">16476</a></span><span class="t"><span class="op">@</span><span class="nam">deprecated</span><span class="op">(</span><span class="nam">since</span><span class="op">=</span><span class="str">"2.0.0"</span><span class="op">,</span> <span class="nam">update_to</span><span class="op">=</span><span class="str">"paddle.uniform"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16477" href="#t16477">16477</a></span><span class="t"><span class="op">@</span><span class="nam">templatedoc</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16478" href="#t16478">16478</a></span><span class="t"><span class="key">def</span> <span class="nam">uniform_random</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16479" href="#t16479">16479</a></span><span class="t">    <span class="nam">shape</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="str">'float32'</span><span class="op">,</span> <span class="nam">min</span><span class="op">=</span><span class="op">-</span><span class="num">1.0</span><span class="op">,</span> <span class="nam">max</span><span class="op">=</span><span class="num">1.0</span><span class="op">,</span> <span class="nam">seed</span><span class="op">=</span><span class="num">0</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16480" href="#t16480">16480</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16481" href="#t16481">16481</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16482" href="#t16482">16482</a></span><span class="t"><span class="str">    This OP returns a Tensor filled with random values sampled from a uniform</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16483" href="#t16483">16483</a></span><span class="t"><span class="str">    distribution in the range [``min``, ``max``), with ``shape`` and ``dtype``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16484" href="#t16484">16484</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16485" href="#t16485">16485</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16486" href="#t16486">16486</a></span><span class="t"><span class="str">    ::</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16487" href="#t16487">16487</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16488" href="#t16488">16488</a></span><span class="t"><span class="str">        Input:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16489" href="#t16489">16489</a></span><span class="t"><span class="str">          shape = [1, 2]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16490" href="#t16490">16490</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16491" href="#t16491">16491</a></span><span class="t"><span class="str">        Output:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16492" href="#t16492">16492</a></span><span class="t"><span class="str">          result=[[0.8505902, 0.8397286]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16493" href="#t16493">16493</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16494" href="#t16494">16494</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16495" href="#t16495">16495</a></span><span class="t"><span class="str">        shape(list|tuple|Tensor): The shape of the output Tensor. If ``shape``</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16496" href="#t16496">16496</a></span><span class="t"><span class="str">            is a list or tuple, the elements of it should be integers or Tensors</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16497" href="#t16497">16497</a></span><span class="t"><span class="str">            (with the shape [1], and the data type int32 or int64). If ``shape``</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16498" href="#t16498">16498</a></span><span class="t"><span class="str">            is a Tensor, it should be a 1-D Tensor(with the data type int32 or</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16499" href="#t16499">16499</a></span><span class="t"><span class="str">            int64).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16500" href="#t16500">16500</a></span><span class="t"><span class="str">        dtype(str|np.dtype|core.VarDesc.VarType, optional): The data type of</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16501" href="#t16501">16501</a></span><span class="t"><span class="str">            the output Tensor. Supported data types: float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16502" href="#t16502">16502</a></span><span class="t"><span class="str">            Default is float32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16503" href="#t16503">16503</a></span><span class="t"><span class="str">        min(float|int, optional): The lower bound on the range of random values</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16504" href="#t16504">16504</a></span><span class="t"><span class="str">            to generate, ``min`` is included in the range. Default is -1.0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16505" href="#t16505">16505</a></span><span class="t"><span class="str">        max(float|int, optional): The upper bound on the range of random values</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16506" href="#t16506">16506</a></span><span class="t"><span class="str">            to generate, ``max`` is excluded in the range. Default is 1.0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16507" href="#t16507">16507</a></span><span class="t"><span class="str">        seed(int, optional): Random seed used for generating samples. 0 means</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16508" href="#t16508">16508</a></span><span class="t"><span class="str">            use a seed generated by the system. Note that if seed is not 0,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16509" href="#t16509">16509</a></span><span class="t"><span class="str">            this operator will always generate the same random numbers every</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16510" href="#t16510">16510</a></span><span class="t"><span class="str">            time. Default is 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16511" href="#t16511">16511</a></span><span class="t"><span class="str">        name(str, optional): The default value is None. Normally there is no</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16512" href="#t16512">16512</a></span><span class="t"><span class="str">            need for user to set this property. For more information, please</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16513" href="#t16513">16513</a></span><span class="t"><span class="str">            refer to :ref:`api_guide_Name`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16514" href="#t16514">16514</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16515" href="#t16515">16515</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16516" href="#t16516">16516</a></span><span class="t"><span class="str">        Tensor: A Tensor filled with random values sampled from a uniform</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16517" href="#t16517">16517</a></span><span class="t"><span class="str">        distribution in the range [``min``, ``max``), with ``shape`` and ``dtype``.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16518" href="#t16518">16518</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16519" href="#t16519">16519</a></span><span class="t"><span class="str">    Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16520" href="#t16520">16520</a></span><span class="t"><span class="str">        TypeError: If ``shape`` is not list, tuple, Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16521" href="#t16521">16521</a></span><span class="t"><span class="str">        TypeError: If ``dtype`` is not float32, float64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16522" href="#t16522">16522</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16523" href="#t16523">16523</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16524" href="#t16524">16524</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16525" href="#t16525">16525</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16526" href="#t16526">16526</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16527" href="#t16527">16527</a></span><span class="t"><span class="str">            import paddle.fluid as fluid</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16528" href="#t16528">16528</a></span><span class="t"><span class="str">            paddle.enable_static()</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16529" href="#t16529">16529</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16530" href="#t16530">16530</a></span><span class="t"><span class="str">            # example 1:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16531" href="#t16531">16531</a></span><span class="t"><span class="str">            # attr shape is a list which doesn't contain Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16532" href="#t16532">16532</a></span><span class="t"><span class="str">            result_1 = fluid.layers.uniform_random(shape=[3, 4])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16533" href="#t16533">16533</a></span><span class="t"><span class="str">            # [[ 0.84524226,  0.6921872,   0.56528175,  0.71690357],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16534" href="#t16534">16534</a></span><span class="t"><span class="str">            #  [-0.34646994, -0.45116323, -0.09902662, -0.11397249],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16535" href="#t16535">16535</a></span><span class="t"><span class="str">            #  [ 0.433519,    0.39483607, -0.8660099,   0.83664286]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16536" href="#t16536">16536</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16537" href="#t16537">16537</a></span><span class="t"><span class="str">            # example 2:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16538" href="#t16538">16538</a></span><span class="t"><span class="str">            # attr shape is a list which contains Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16539" href="#t16539">16539</a></span><span class="t"><span class="str">            dim_1 = fluid.layers.fill_constant([1], "int64", 2)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16540" href="#t16540">16540</a></span><span class="t"><span class="str">            dim_2 = fluid.layers.fill_constant([1], "int32", 3)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16541" href="#t16541">16541</a></span><span class="t"><span class="str">            result_2 = fluid.layers.uniform_random(shape=[dim_1, dim_2])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16542" href="#t16542">16542</a></span><span class="t"><span class="str">            # [[-0.9951253,   0.30757582, 0.9899647 ],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16543" href="#t16543">16543</a></span><span class="t"><span class="str">            #  [ 0.5864527,   0.6607096,  -0.8886161 ]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16544" href="#t16544">16544</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16545" href="#t16545">16545</a></span><span class="t"><span class="str">            # example 3:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16546" href="#t16546">16546</a></span><span class="t"><span class="str">            # attr shape is a Tensor, the data type must be int64 or int32.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16547" href="#t16547">16547</a></span><span class="t"><span class="str">            var_shape = fluid.data(name='var_shape', shape=[2], dtype="int64")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16548" href="#t16548">16548</a></span><span class="t"><span class="str">            result_3 = fluid.layers.uniform_random(var_shape)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16549" href="#t16549">16549</a></span><span class="t"><span class="str">            # if var_shape's value is [2, 3]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16550" href="#t16550">16550</a></span><span class="t"><span class="str">            # result_3 is:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16551" href="#t16551">16551</a></span><span class="t"><span class="str">            # [[-0.8517412,  -0.4006908,   0.2551912 ],</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16552" href="#t16552">16552</a></span><span class="t"><span class="str">            #  [ 0.3364414,   0.36278176, -0.16085452]]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16553" href="#t16553">16553</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16554" href="#t16554">16554</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t16555" href="#t16555">16555</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">core</span><span class="op">.</span><span class="nam">VarDesc</span><span class="op">.</span><span class="nam">VarType</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">16555&#x202F;&#x219B;&#x202F;16558</span><span class="annotate long">line 16555 didn't jump to line 16558, because the condition on line 16555 was never false</span></span></p>
    <p class="run"><span class="n"><a id="t16556" href="#t16556">16556</a></span><span class="t">        <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">convert_np_dtype_to_dtype_</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16557" href="#t16557">16557</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16558" href="#t16558">16558</a></span><span class="t">    <span class="key">if</span> <span class="nam">in_dygraph_mode</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16559" href="#t16559">16559</a></span><span class="t">        <span class="nam">shape</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_shape_to_list</span><span class="op">(</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16560" href="#t16560">16560</a></span><span class="t">        <span class="key">return</span> <span class="nam">_C_ops</span><span class="op">.</span><span class="nam">uniform_random</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16561" href="#t16561">16561</a></span><span class="t">            <span class="nam">shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16562" href="#t16562">16562</a></span><span class="t">            <span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16563" href="#t16563">16563</a></span><span class="t">            <span class="nam">float</span><span class="op">(</span><span class="nam">min</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16564" href="#t16564">16564</a></span><span class="t">            <span class="nam">float</span><span class="op">(</span><span class="nam">max</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16565" href="#t16565">16565</a></span><span class="t">            <span class="nam">seed</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16566" href="#t16566">16566</a></span><span class="t">            <span class="nam">_current_expected_place</span><span class="op">(</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16567" href="#t16567">16567</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t16568" href="#t16568">16568</a></span><span class="t">    <span class="key">elif</span> <span class="nam">_in_legacy_dygraph</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">16568&#x202F;&#x219B;&#x202F;16569</span><span class="annotate long">line 16568 didn't jump to line 16569, because the condition on line 16568 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16569" href="#t16569">16569</a></span><span class="t">        <span class="nam">shape</span> <span class="op">=</span> <span class="nam">utils</span><span class="op">.</span><span class="nam">convert_shape_to_list</span><span class="op">(</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16570" href="#t16570">16570</a></span><span class="t">        <span class="key">return</span> <span class="nam">_legacy_C_ops</span><span class="op">.</span><span class="nam">uniform_random</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16571" href="#t16571">16571</a></span><span class="t">            <span class="str">'shape'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16572" href="#t16572">16572</a></span><span class="t">            <span class="nam">shape</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16573" href="#t16573">16573</a></span><span class="t">            <span class="str">'min'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16574" href="#t16574">16574</a></span><span class="t">            <span class="nam">float</span><span class="op">(</span><span class="nam">min</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16575" href="#t16575">16575</a></span><span class="t">            <span class="str">'max'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16576" href="#t16576">16576</a></span><span class="t">            <span class="nam">float</span><span class="op">(</span><span class="nam">max</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16577" href="#t16577">16577</a></span><span class="t">            <span class="str">'seed'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16578" href="#t16578">16578</a></span><span class="t">            <span class="nam">seed</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16579" href="#t16579">16579</a></span><span class="t">            <span class="str">'dtype'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16580" href="#t16580">16580</a></span><span class="t">            <span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16581" href="#t16581">16581</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16582" href="#t16582">16582</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16583" href="#t16583">16583</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">shape</span><span class="op">,</span> <span class="str">'shape'</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">,</span> <span class="str">'uniform_random/rand'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16584" href="#t16584">16584</a></span><span class="t">    <span class="nam">check_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16585" href="#t16585">16585</a></span><span class="t">        <span class="nam">dtype</span><span class="op">,</span> <span class="str">'dtype'</span><span class="op">,</span> <span class="op">(</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'uint16'</span><span class="op">)</span><span class="op">,</span> <span class="str">'uniform_random/rand'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16586" href="#t16586">16586</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16587" href="#t16587">16587</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">min</span><span class="op">,</span> <span class="str">'min'</span><span class="op">,</span> <span class="op">(</span><span class="nam">float</span><span class="op">,</span> <span class="nam">int</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">,</span> <span class="str">'uniform_random/rand'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16588" href="#t16588">16588</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">max</span><span class="op">,</span> <span class="str">'max'</span><span class="op">,</span> <span class="op">(</span><span class="nam">float</span><span class="op">,</span> <span class="nam">int</span><span class="op">,</span> <span class="nam">Variable</span><span class="op">)</span><span class="op">,</span> <span class="str">'uniform_random/rand'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16589" href="#t16589">16589</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16590" href="#t16590">16590</a></span><span class="t">    <span class="nam">inputs</span> <span class="op">=</span> <span class="nam">dict</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16591" href="#t16591">16591</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="op">{</span><span class="str">'seed'</span><span class="op">:</span> <span class="nam">seed</span><span class="op">,</span> <span class="str">'min'</span><span class="op">:</span> <span class="nam">min</span><span class="op">,</span> <span class="str">'max'</span><span class="op">:</span> <span class="nam">max</span><span class="op">,</span> <span class="str">'dtype'</span><span class="op">:</span> <span class="nam">dtype</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16592" href="#t16592">16592</a></span><span class="t">    <span class="nam">utils</span><span class="op">.</span><span class="nam">get_shape_tensor_inputs</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16593" href="#t16593">16593</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span><span class="op">,</span> <span class="nam">shape</span><span class="op">=</span><span class="nam">shape</span><span class="op">,</span> <span class="nam">op_type</span><span class="op">=</span><span class="str">'uniform_random/rand'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16594" href="#t16594">16594</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16595" href="#t16595">16595</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16596" href="#t16596">16596</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"uniform_random"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16597" href="#t16597">16597</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16598" href="#t16598">16598</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16599" href="#t16599">16599</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"uniform_random"</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">=</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">attrs</span><span class="op">=</span><span class="nam">attrs</span><span class="op">,</span> <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">out</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16600" href="#t16600">16600</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16601" href="#t16601">16601</a></span><span class="t">    <span class="nam">utils</span><span class="op">.</span><span class="nam">try_set_static_shape_tensor</span><span class="op">(</span><span class="nam">out</span><span class="op">,</span> <span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16602" href="#t16602">16602</a></span><span class="t">    <span class="key">return</span> <span class="nam">out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16603" href="#t16603">16603</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16604" href="#t16604">16604</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16605" href="#t16605">16605</a></span><span class="t"><span class="key">def</span> <span class="nam">unbind</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="num">0</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16606" href="#t16606">16606</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16607" href="#t16607">16607</a></span><span class="t"><span class="str">    Removes a tensor dimension, then split the input tensor into multiple sub-Tensors.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16608" href="#t16608">16608</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16609" href="#t16609">16609</a></span><span class="t"><span class="str">        input (Variable): The input variable which is an N-D Tensor, data type being float32, float64, int32 or int64.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16610" href="#t16610">16610</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16611" href="#t16611">16611</a></span><span class="t"><span class="str">        axis (int32|int64, optional): A scalar with type ``int32|int64`` shape [1]. The dimension along which to unbind. If :math:`axis &lt; 0`, the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16612" href="#t16612">16612</a></span><span class="t"><span class="str">            dimension to unbind along is :math:`rank(input) + axis`. Default is 0.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16613" href="#t16613">16613</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16614" href="#t16614">16614</a></span><span class="t"><span class="str">        list(Variable): The list of segmented Tensor variables.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16615" href="#t16615">16615</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16616" href="#t16616">16616</a></span><span class="t"><span class="str">    Example:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16617" href="#t16617">16617</a></span><span class="t"><span class="str">        .. code-block:: python</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16618" href="#t16618">16618</a></span><span class="t"><span class="str">            import paddle</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16619" href="#t16619">16619</a></span><span class="t"><span class="str">            # input is a variable which shape is [3, 4, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16620" href="#t16620">16620</a></span><span class="t"><span class="str">            input = paddle.fluid.data(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16621" href="#t16621">16621</a></span><span class="t"><span class="str">                 name="input", shape=[3, 4, 5], dtype="float32")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16622" href="#t16622">16622</a></span><span class="t"><span class="str">            [x0, x1, x2] = paddle.tensor.unbind(input, axis=0)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16623" href="#t16623">16623</a></span><span class="t"><span class="str">            # x0.shape [4, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16624" href="#t16624">16624</a></span><span class="t"><span class="str">            # x1.shape [4, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16625" href="#t16625">16625</a></span><span class="t"><span class="str">            # x2.shape [4, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16626" href="#t16626">16626</a></span><span class="t"><span class="str">            [x0, x1, x2, x3] = paddle.tensor.unbind(input, axis=1)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16627" href="#t16627">16627</a></span><span class="t"><span class="str">            # x0.shape [3, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16628" href="#t16628">16628</a></span><span class="t"><span class="str">            # x1.shape [3, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16629" href="#t16629">16629</a></span><span class="t"><span class="str">            # x2.shape [3, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16630" href="#t16630">16630</a></span><span class="t"><span class="str">            # x3.shape [3, 5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16631" href="#t16631">16631</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16632" href="#t16632">16632</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16633" href="#t16633">16633</a></span><span class="t">    <span class="nam">helper</span> <span class="op">=</span> <span class="nam">LayerHelper</span><span class="op">(</span><span class="str">"unbind"</span><span class="op">,</span> <span class="op">**</span><span class="nam">locals</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16634" href="#t16634">16634</a></span><span class="t">    <span class="nam">check_type</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="str">'input'</span><span class="op">,</span> <span class="op">(</span><span class="nam">Variable</span><span class="op">)</span><span class="op">,</span> <span class="str">'unbind'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16635" href="#t16635">16635</a></span><span class="t">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16636" href="#t16636">16636</a></span><span class="t">    <span class="nam">check_dtype</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16637" href="#t16637">16637</a></span><span class="t">        <span class="nam">dtype</span><span class="op">,</span> <span class="str">'unbind'</span><span class="op">,</span> <span class="op">[</span><span class="str">'float32'</span><span class="op">,</span> <span class="str">'float64'</span><span class="op">,</span> <span class="str">'int32'</span><span class="op">,</span> <span class="str">'int64'</span><span class="op">]</span><span class="op">,</span> <span class="str">'unbind'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16638" href="#t16638">16638</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16639" href="#t16639">16639</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">axis</span><span class="op">,</span> <span class="op">(</span><span class="nam">int</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16640" href="#t16640">16640</a></span><span class="t">        <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16641" href="#t16641">16641</a></span><span class="t">            <span class="str">"The type of 'axis'  must be int, but received %s."</span> <span class="op">%</span> <span class="op">(</span><span class="nam">type</span><span class="op">(</span><span class="nam">axis</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16642" href="#t16642">16642</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16643" href="#t16643">16643</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">axis</span><span class="op">,</span> <span class="nam">np</span><span class="op">.</span><span class="nam">generic</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16644" href="#t16644">16644</a></span><span class="t">        <span class="nam">axis</span> <span class="op">=</span> <span class="nam">np</span><span class="op">.</span><span class="nam">asscalar</span><span class="op">(</span><span class="nam">axis</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16645" href="#t16645">16645</a></span><span class="t">    <span class="nam">input_shape</span> <span class="op">=</span> <span class="nam">input</span><span class="op">.</span><span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16646" href="#t16646">16646</a></span><span class="t">    <span class="nam">axis_</span> <span class="op">=</span> <span class="nam">axis</span> <span class="key">if</span> <span class="nam">axis</span> <span class="op">>=</span> <span class="num">0</span> <span class="key">else</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input_shape</span><span class="op">)</span> <span class="op">+</span> <span class="nam">axis</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16647" href="#t16647">16647</a></span><span class="t">    <span class="nam">num</span> <span class="op">=</span> <span class="nam">input_shape</span><span class="op">[</span><span class="nam">axis_</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16648" href="#t16648">16648</a></span><span class="t">    <span class="nam">outs</span> <span class="op">=</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16649" href="#t16649">16649</a></span><span class="t">        <span class="nam">helper</span><span class="op">.</span><span class="nam">create_variable_for_type_inference</span><span class="op">(</span><span class="nam">dtype</span><span class="op">=</span><span class="nam">helper</span><span class="op">.</span><span class="nam">input_dtype</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16650" href="#t16650">16650</a></span><span class="t">        <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">num</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16651" href="#t16651">16651</a></span><span class="t">    <span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16652" href="#t16652">16652</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16653" href="#t16653">16653</a></span><span class="t">    <span class="nam">helper</span><span class="op">.</span><span class="nam">append_op</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16654" href="#t16654">16654</a></span><span class="t">        <span class="nam">type</span><span class="op">=</span><span class="str">"unbind"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16655" href="#t16655">16655</a></span><span class="t">        <span class="nam">inputs</span><span class="op">=</span><span class="op">{</span><span class="str">"X"</span><span class="op">:</span> <span class="nam">input</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16656" href="#t16656">16656</a></span><span class="t">        <span class="nam">outputs</span><span class="op">=</span><span class="op">{</span><span class="str">"Out"</span><span class="op">:</span> <span class="nam">outs</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16657" href="#t16657">16657</a></span><span class="t">        <span class="nam">attrs</span><span class="op">=</span><span class="op">{</span><span class="str">"axis"</span><span class="op">:</span> <span class="nam">axis</span><span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t16658" href="#t16658">16658</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t16659" href="#t16659">16659</a></span><span class="t">    <span class="key">return</span> <span class="nam">outs</span>&nbsp;</span><span class="r"></span></p>
</main>
<footer>
    <div class="content">
        <p>
            <a id="prevFileLink" class="nav" href="d_a9a759b3e33e713a_metric_op_py.html">&#xab; prev</a> &nbsp; &nbsp;
            <a id="indexLink" class="nav" href="index.html">&Hat; index</a> &nbsp; &nbsp;
            <a id="nextFileLink" class="nav" href="d_a9a759b3e33e713a_ops_py.html">&#xbb; next</a>
            &nbsp; &nbsp; &nbsp;
            <a class="nav" href="https://coverage.readthedocs.io/en/7.2.4">coverage.py v7.2.4</a>,
            created at 2023-05-05 14:52 -0500
        </p>
    </div>
</footer>
</body>
</html>
